{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef0d711",
   "metadata": {},
   "source": [
    "# Create the environment with different reward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c13955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym_unbalanced_disk import UnbalancedDisk\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class AC_UnbalancedDisk(UnbalancedDisk):\n",
    "    def __init__(self, umax=3., dt=0.025, render_mode='human'):\n",
    "        super().__init__(umax=umax, dt=dt, render_mode=render_mode)\n",
    "\n",
    "        self.target = np.pi\n",
    "        low = [-np.pi, -40]\n",
    "        high = [np.pi, 40]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array(low, dtype=np.float32),\n",
    "            high=np.array(high, dtype=np.float32),\n",
    "            shape=(2,)\n",
    "        )\n",
    "\n",
    "        self.recent_omegas = []\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "\n",
    "        th = obs[0]\n",
    "        omega = obs[1]\n",
    "\n",
    "        # Normalize angle so π maps to 0\n",
    "        theta = ((th - np.pi) % (2 * np.pi)) - np.pi\n",
    "\n",
    "        # Update buffer of recent omega values\n",
    "        self.recent_omegas.append(omega)\n",
    "        if len(self.recent_omegas) > 10:\n",
    "            self.recent_omegas.pop(0)\n",
    "\n",
    "        # Base reward structure\n",
    "        if abs(theta) < np.pi / 2:\n",
    "            reward = min(-0.5, -5 + abs(omega))\n",
    "        elif abs(theta) > np.pi / 2 and abs(theta) < 3 * np.pi / 4:\n",
    "            reward = abs(theta)**2 / (1 + abs(omega))**1\n",
    "        elif abs(theta) > 3 * np.pi / 4 and abs(theta) < 11 * np.pi / 12:\n",
    "            reward = abs(theta)**4 / (1 + abs(omega))**2\n",
    "\n",
    "        \n",
    "        else:\n",
    "            reward = abs(theta)**4 / (1 + abs(omega))**2\n",
    "             \n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs, info = super().reset()\n",
    "        self.recent_omegas = []  # Reset history\n",
    "        return obs, info\n",
    "\n",
    "class AC_UnbalancedDisk1(UnbalancedDisk):\n",
    "    def __init__(self, umax=3., dt=0.025, render_mode='human', randomize_friction=True):\n",
    "        super().__init__(umax=umax, dt=dt, render_mode=render_mode)\n",
    "\n",
    "        self.target = np.pi\n",
    "        self.randomize_friction = randomize_friction  \n",
    "\n",
    "        low = [-np.pi, -40]\n",
    "        high = [np.pi, 40]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array(low, dtype=np.float32),\n",
    "            high=np.array(high, dtype=np.float32),\n",
    "            shape=(2,)\n",
    "        )\n",
    "\n",
    "        self.recent_omegas = []\n",
    "\n",
    "    def step(self, action):\n",
    "        # Sample a new random friction multiplier every step if enabled\n",
    "        friction_scale = np.random.uniform(0.6, 1.5) if self.randomize_friction else 1.0\n",
    "\n",
    "        # Temporarily patch gamma and Fc\n",
    "        original_gamma = self.gamma\n",
    "        original_Fc = self.Fc\n",
    "        self.gamma *= friction_scale\n",
    "        self.Fc *= friction_scale\n",
    "\n",
    "        # Do the physics step using modified friction\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "\n",
    "        # Restore friction coefficients\n",
    "        self.gamma = original_gamma\n",
    "        self.Fc = original_Fc\n",
    "\n",
    "        # Reward logic\n",
    "        th = obs[0]\n",
    "        omega = obs[1]\n",
    "        theta = ((th - np.pi) % (2 * np.pi)) - np.pi\n",
    "        # self.recent_omegas.append(omega)\n",
    "\n",
    "        theta_abs = np.abs(((th + np.pi) % (2 * np.pi)) - np.pi)  # shortest distance to target (π)\n",
    "        omega_abs = np.abs(omega)\n",
    "\n",
    "        # Region 1: θ < 0.5π\n",
    "        if theta_abs < 0.5 * np.pi:\n",
    "            if omega_abs < 5:\n",
    "                reward = np.maximum(-omega_abs**2, -0.5) - np.abs(2 * np.sin(0.5 * (np.pi - np.pi * (omega_abs) / 5)))\n",
    "            else:\n",
    "                reward = np.maximum(-omega_abs**2, -0.5)\n",
    "\n",
    "        # Region 2: 0.5π ≤ θ < 0.75π\n",
    "        elif 0.5 * np.pi <= theta_abs < 0.75 * np.pi:\n",
    "            reward = 2 * (-np.cos(theta_abs)) / (0.01 + omega_abs)\n",
    "\n",
    "        # Region 3: 0.75π ≤ θ ≤ π\n",
    "        elif 0.75 * np.pi <= theta_abs <= np.pi:\n",
    "            reward = (-np.cos(theta_abs - np.pi / 4))**0.5 / (0.01 + omega_abs**2)\n",
    "\n",
    "        \n",
    "        # Normalize theta around zero (distance from target)\n",
    "        # theta_abs = np.abs(((th + np.pi) % (2 * np.pi)) - np.pi)  # shortest distance to target (π)\n",
    "        # omega_abs = np.abs(omega)\n",
    "\n",
    "        # # Region 1: θ < 0.5π\n",
    "        # if theta_abs < 0.5 * np.pi:\n",
    "        #     if omega_abs < 5:\n",
    "        #         reward = np.maximum(-omega_abs**2, -0.5) - np.abs(2 * np.sin(0.5 * (np.pi - np.pi * (omega_abs) / 5)))\n",
    "        #     else:\n",
    "        #         reward = np.maximum(-omega_abs**2, -0.5)\n",
    "\n",
    "        # # Region 2: 0.5π ≤ θ < 0.75π\n",
    "        # elif 0.5 * np.pi <= theta_abs < 0.75 * np.pi:\n",
    "        #     reward = 2 * (-np.cos(theta_abs)) / (0.01 + omega_abs)\n",
    "\n",
    "        # # Region 3: 0.75π ≤ θ ≤ π\n",
    "        # elif 0.75 * np.pi <= theta_abs <= np.pi:\n",
    "        #     reward = (-np.cos(theta_abs - np.pi / 2))**0.5 / (0.0001 + omega_abs**1.5)\n",
    "        \n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs, info = super().reset()\n",
    "        self.recent_omegas = []\n",
    "        return obs, info\n",
    "\n",
    "        \n",
    "class AC_UnbalancedDisk5(UnbalancedDisk):\n",
    "    def __init__(self, umax=3., dt=0.025, render_mode='human', randomize_friction=True):\n",
    "        super().__init__(umax=umax, dt=dt, render_mode=render_mode)\n",
    "\n",
    "        self.target = np.pi\n",
    "        self.randomize_friction = randomize_friction\n",
    "\n",
    "        low = [-np.pi, -40]\n",
    "        high = [np.pi, 40]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array(low, dtype=np.float32),\n",
    "            high=np.array(high, dtype=np.float32),\n",
    "            shape=(2,)\n",
    "        )\n",
    "\n",
    "        self.recent_omegas = []\n",
    "\n",
    "    def step(self, action):\n",
    "        # Sample a new random friction multiplier every step if enabled\n",
    "        friction_scale = np.random.uniform(0.6, 1.5) if self.randomize_friction else 1.0\n",
    "\n",
    "        # Temporarily patch gamma and Fc\n",
    "        original_gamma = self.gamma\n",
    "        original_Fc = self.Fc\n",
    "        self.gamma *= friction_scale\n",
    "        self.Fc *= friction_scale\n",
    "\n",
    "        # Perform physics step\n",
    "        obs, reward, terminated, truncated, info = super().step(action)\n",
    "\n",
    "        # Restore original friction\n",
    "        self.gamma = original_gamma\n",
    "        self.Fc = original_Fc\n",
    "\n",
    "        # Extract angle and angular velocity\n",
    "        th = obs[0]\n",
    "        omega = obs[1]\n",
    "\n",
    "        # Normalize angle around π (i.e., make π → 0)\n",
    "        theta = ((th - np.pi) % (2 * np.pi)) - np.pi\n",
    "        theta_abs = abs(theta)\n",
    "        omega_abs = abs(omega)\n",
    "\n",
    "        # Apply reward based on region\n",
    "        if theta_abs <= 0.5 * np.pi:\n",
    "            reward = min(-1, -(np.pi) - 1 + abs(omega))\n",
    "        elif theta_abs <= 0.75 * np.pi:\n",
    "            reward = (-np.cos(theta_abs)) / (0.1 + omega_abs)\n",
    "        else:\n",
    "            reward = 5*(-np.cos(theta_abs))**0.5 / (0.1 + omega_abs)\n",
    "            # Add anti-stall penalty\n",
    "            # Stall detection: angular velocity near zero for several steps\n",
    "            \n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "        # if len(self.recent_omegas) > 10:\n",
    "        #     self.recent_omegas.pop(0)\n",
    "\n",
    "        # if abs(theta) < np.pi / 2:\n",
    "        #     reward = min(-1, -np.pi -1 + abs(omega))\n",
    "        # elif abs(theta) > np.pi / 2 and abs(theta) < 3 * np.pi / 4:\n",
    "        #     reward = abs(theta)**2 / (1 + abs(omega))\n",
    "        # elif abs(theta) > 3 * np.pi / 4 and abs(theta) < 11 * np.pi / 12:\n",
    "        #     reward = abs(theta)**4 / (1 + abs(omega))**2\n",
    "        #     if all(abs(w) < 0.05 for w in self.recent_omegas):\n",
    "        #         reward = 1 / (1 + abs(omega))\n",
    "        # else:\n",
    "        #     reward = abs(theta)**4 / (1 + abs(omega))**2\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        obs, info = super().reset()\n",
    "        self.recent_omegas = []\n",
    "        return obs, info\n",
    "\n",
    "\n",
    "class DQN_UnbalancedDisk(AC_UnbalancedDisk5):\n",
    "    def __init__(self, umax=3., dt=0.025, n_actions=10, randomize_friction=True, render_mode='human'):\n",
    "        super().__init__(umax=umax, dt=dt, randomize_friction=randomize_friction, render_mode=render_mode)\n",
    "\n",
    "\n",
    "        self.actions = np.linspace(-umax, umax, n_actions)\n",
    "\n",
    "        # Override action space to Discrete\n",
    "        self.action_space = spaces.Discrete(n_actions)\n",
    "\n",
    "    def step(self, action):\n",
    "        idx = int(np.argmin(np.abs(self.actions - action)))\n",
    "        obs, reward, terminated, truncated, info = super().step(self.actions[idx])\n",
    "\n",
    "        return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e224e3d1",
   "metadata": {},
   "source": [
    "# Train one DQN for the 1st Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d327bc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.05e+03 |\n",
      "|    exploration_rate | 0.962     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1149      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00525   |\n",
      "|    n_updates        | 474       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.05e+03 |\n",
      "|    exploration_rate | 0.924     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1208      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00321   |\n",
      "|    n_updates        | 974       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-440.75 +/- 1.59\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -441     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00601  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.04e+03 |\n",
      "|    exploration_rate | 0.886     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 973       |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 6000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00548   |\n",
      "|    n_updates        | 1474      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.848     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1046      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 8000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00349   |\n",
      "|    n_updates        | 1974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-458.59 +/- 2.59\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -459     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.81      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 969       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total_timesteps  | 10000     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1018     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -970     |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1055     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 14000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 3474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-416.69 +/- 0.09\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -417     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -944     |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1006     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 16000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -919     |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1031     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 18000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-429.40 +/- 0.33\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -429     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 994      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -871     |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1015     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 22000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00897  |\n",
      "|    n_updates        | 5474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1033     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00968  |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-428.84 +/- 10.60\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -429     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00675  |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -818     |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1000     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 26000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0886   |\n",
      "|    n_updates        | 6474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -790     |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1015     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 28000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 6974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=1240.74 +/- 2590.04\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | 1.24e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -768     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 977      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 30000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -744     |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 989      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 32000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 7974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -713     |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1002     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 34000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 8474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-134.79 +/- 0.49\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -135     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -684     |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -656     |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 996      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 38000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.521    |\n",
      "|    n_updates        | 9474     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-109.63 +/- 0.59\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -110     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -630     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 979      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 40000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -606     |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 989      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 42000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 10474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -585     |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 995      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 44000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.734    |\n",
      "|    n_updates        | 10974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-133.42 +/- 0.52\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -133     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.943    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -563     |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 977      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -544     |\n",
      "|    exploration_rate | 0.088    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 982      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 50000 steps because the DQN model reached max_episodes=100, by playing for 100 episodes \n",
      "Eval num_timesteps=50000, episode_reward=-100.62 +/- 1.16\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -101     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7012c53b16c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnMaxEpisodes, CallbackList\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "n_actions = 10 \n",
    "\n",
    "env = Monitor(TimeLimit(DQN_UnbalancedDisk(n_actions=n_actions,randomize_friction=True), max_episode_steps=500))\n",
    "# Evaluation env (no random friction)\n",
    "eval_env = Monitor(TimeLimit(DQN_UnbalancedDisk(n_actions=n_actions,randomize_friction=False), max_episode_steps=500))\n",
    "\n",
    "learning_rate = 1e-3\n",
    "target_update_interval = 1_000\n",
    "policy_kwargs = dict(\n",
    "        net_arch=[256,256,256],\n",
    "        activation_fn=nn.ReLU\n",
    "    )\n",
    "\n",
    "# Callbacks\n",
    "stop_cb = StopTrainingOnMaxEpisodes(max_episodes=100, verbose=1)\n",
    "eval_cb = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=f\"./best_dqn_christos/\",\n",
    "    log_path=None,\n",
    "    eval_freq=5000,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    ")\n",
    "callback = CallbackList([stop_cb, eval_cb])\n",
    "\n",
    "# Model\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=learning_rate,\n",
    "    #exploration_fraction=exploration_fraction,\n",
    "    #exploration_final_eps=exploration_final_eps,\n",
    "    target_update_interval=target_update_interval,\n",
    "    gamma=0.95,\n",
    "    batch_size=256,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=500_000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e952c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  0.0251, omega:  1.9008, action:  4.0000\n",
      "theta =  0.0926, omega:  3.5873, action:  6.0000\n",
      "theta =  0.2010, omega:  4.9410, action:  6.0000\n",
      "theta =  0.3353, omega:  5.8723, action:  6.0000\n",
      "theta =  0.4901, omega:  6.3365, action:  6.0000\n",
      "theta =  0.6491, omega:  6.3497, action:  7.0000\n",
      "theta =  0.8046, omega:  5.9633, action:  7.0000\n",
      "theta =  0.9458, omega:  5.2663, action:  7.0000\n",
      "theta =  1.0667, omega:  4.3469, action:  3.0000\n",
      "theta =  1.1618, omega:  3.2907, action:  6.0000\n",
      "theta =  1.2298, omega:  2.1642, action:  6.0000\n",
      "theta =  1.2705, omega:  1.0170, action:  6.0000\n",
      "theta =  1.2598, omega: -1.7330, action:  0.0000\n",
      "theta =  1.1846, omega: -4.2738, action:  0.0000\n",
      "theta =  1.0482, omega: -6.5997, action:  0.0000\n",
      "theta =  0.8575, omega: -8.5831, action:  0.0000\n",
      "theta =  0.6228, omega: -10.0546, action:  0.0000\n",
      "theta =  0.3627, omega: -10.8358, action:  0.0000\n",
      "theta =  0.0895, omega: -10.8008, action:  0.0000\n",
      "theta = -0.1723, omega: -9.9276, action:  0.0000\n",
      "theta = -0.4014, omega: -8.3151, action:  0.0000\n",
      "theta = -0.5827, omega: -6.1553, action:  0.0000\n",
      "theta = -0.7080, omega: -3.6615, action:  0.0000\n",
      "theta = -0.7426, omega:  0.7437, action:  3.0000\n",
      "theta = -0.6742, omega:  4.7220, action:  4.0000\n",
      "theta = -0.5112, omega:  8.2722, action:  6.0000\n",
      "theta = -0.2643, omega:  11.1355, action:  3.0000\n",
      "theta =  0.0379, omega:  13.0641, action:  3.0000\n",
      "theta =  0.3791, omega:  13.9140, action:  3.0000\n",
      "theta =  0.7260, omega:  13.7314, action:  4.0000\n",
      "theta =  1.0581, omega:  12.7501, action:  4.0000\n",
      "theta =  1.3597, omega:  11.3076, action:  4.0000\n",
      "theta =  1.6231, omega:  9.7228, action:  4.0000\n",
      "theta =  1.8468, omega:  8.2179, action:  4.0000\n",
      "theta =  2.0345, omega:  6.9345, action:  4.0000\n",
      "theta =  2.1895, omega:  5.4725, action:  2.0000\n",
      "theta =  2.3124, omega:  4.3076, action:  2.0000\n",
      "theta =  2.4079, omega:  3.4071, action:  2.0000\n",
      "theta =  2.4829, omega:  2.7372, action:  2.0000\n",
      "theta =  2.5472, omega:  2.2606, action:  2.0000\n",
      "theta =  2.5801, omega:  0.5503, action:  0.0000\n",
      "theta =  2.5920, omega:  0.3317, action:  2.0000\n",
      "theta =  2.5974, omega:  0.1416, action:  2.0000\n",
      "theta =  2.5992, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5979, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5984, omega:  0.0015, action:  2.0000\n",
      "theta =  2.5984, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5994, omega:  0.0011, action:  2.0000\n",
      "theta =  2.5987, omega: -0.0014, action:  2.0000\n",
      "theta =  2.5994, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5985, omega: -0.0024, action:  2.0000\n",
      "theta =  2.5992, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5991, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5976, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6002, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5999, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5973, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5970, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5992, omega:  0.0000, action:  2.0000\n",
      "theta =  2.5976, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5991, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5993, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5978, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6014, omega: -0.0016, action:  2.0000\n",
      "theta =  2.5973, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6001, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5994, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5998, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5968, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5992, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5979, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5991, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5978, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5996, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5975, omega:  0.0010, action:  2.0000\n",
      "theta =  2.5968, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6001, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5991, omega:  0.0025, action:  2.0000\n",
      "theta =  2.5995, omega: -0.0010, action:  2.0000\n",
      "theta =  2.6005, omega:  0.0017, action:  2.0000\n",
      "theta =  2.5977, omega: -0.0000, action:  2.0000\n",
      "theta =  2.5988, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5995, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5995, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5990, omega:  0.0012, action:  2.0000\n",
      "theta =  2.5984, omega:  0.0008, action:  2.0000\n",
      "theta =  2.5972, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5982, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5991, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5980, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6002, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5989, omega: -0.0018, action:  2.0000\n",
      "theta =  2.5990, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5995, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5979, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5991, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5988, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5990, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5994, omega:  0.0012, action:  2.0000\n",
      "theta =  2.5990, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5985, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5978, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5992, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5976, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6000, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5993, omega: -0.0014, action:  2.0000\n",
      "theta =  2.6005, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5997, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6004, omega:  0.0011, action:  2.0000\n",
      "theta =  2.5999, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5977, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5988, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5980, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6002, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6008, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5987, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5981, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5981, omega:  0.0015, action:  2.0000\n",
      "theta =  2.5993, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5981, omega:  0.0020, action:  2.0000\n",
      "theta =  2.5980, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5981, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5980, omega: -0.0022, action:  2.0000\n",
      "theta =  2.5978, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5987, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5980, omega:  0.0015, action:  2.0000\n",
      "theta =  2.5987, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6003, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5980, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5989, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5970, omega:  0.0011, action:  2.0000\n",
      "theta =  2.5994, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6000, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5988, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5995, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5975, omega:  0.0005, action:  2.0000\n",
      "theta =  2.5987, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5986, omega: -0.0017, action:  2.0000\n",
      "theta =  2.5990, omega: -0.0014, action:  2.0000\n",
      "theta =  2.5993, omega: -0.0020, action:  2.0000\n",
      "theta =  2.5992, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6000, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5990, omega: -0.0019, action:  2.0000\n",
      "theta =  2.5983, omega: -0.0029, action:  2.0000\n",
      "theta =  2.5963, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5990, omega: -0.0027, action:  2.0000\n",
      "theta =  2.5983, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5973, omega: -0.0017, action:  2.0000\n",
      "theta =  2.5986, omega: -0.0022, action:  2.0000\n",
      "theta =  2.5993, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5999, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5987, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5987, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5981, omega:  0.0014, action:  2.0000\n",
      "theta =  2.5990, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6029, omega:  0.2944, action:  6.0000\n",
      "theta =  2.6076, omega:  0.1374, action:  2.0000\n",
      "theta =  2.6092, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6090, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6092, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6075, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6101, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6101, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6088, omega: -0.0016, action:  2.0000\n",
      "theta =  2.6110, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6094, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6082, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6077, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6097, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6092, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6080, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6080, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6089, omega: -0.0022, action:  2.0000\n",
      "theta =  2.6100, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6092, omega: -0.0015, action:  2.0000\n",
      "theta =  2.6098, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6085, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6088, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6107, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6100, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6091, omega: -0.0018, action:  2.0000\n",
      "theta =  2.6076, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6087, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6093, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6114, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6086, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6090, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6096, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6088, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6067, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6099, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6099, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6089, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6072, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6083, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6099, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6091, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6098, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6115, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6105, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6069, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6092, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6084, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6096, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6088, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6104, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6094, omega: -0.0017, action:  2.0000\n",
      "theta =  2.6088, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6084, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6094, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6112, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6085, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6097, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6100, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6113, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6089, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6098, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6115, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6102, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6096, omega: -0.0022, action:  2.0000\n",
      "theta =  2.6094, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6102, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6094, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6090, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6091, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6097, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6106, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6095, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6100, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6093, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6107, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6093, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6096, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6101, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6107, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6086, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6100, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6086, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6093, omega: -0.0010, action:  2.0000\n",
      "theta =  2.6086, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6078, omega: -0.0020, action:  2.0000\n",
      "theta =  2.6106, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6084, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6099, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6094, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6093, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6101, omega:  0.0021, action:  2.0000\n",
      "theta =  2.6097, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6115, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6090, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6106, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6072, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6095, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6097, omega: -0.0015, action:  2.0000\n",
      "theta =  2.6099, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6093, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6085, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6108, omega:  0.0030, action:  2.0000\n",
      "theta =  2.6087, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6111, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6079, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6101, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6097, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6098, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6084, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6088, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6096, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6096, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6107, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6100, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6084, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6082, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6090, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6098, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6091, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6089, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6093, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6112, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6081, omega: -0.0010, action:  2.0000\n",
      "theta =  2.6089, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6090, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6100, omega: -0.0016, action:  2.0000\n",
      "theta =  2.6090, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6084, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6105, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6082, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6106, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6088, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6107, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6075, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6086, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6081, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6093, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6098, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6115, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6079, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6084, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6101, omega: -0.0014, action:  2.0000\n",
      "theta =  2.6117, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6100, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6087, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6085, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6108, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6069, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6093, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6101, omega:  0.0005, action:  2.0000\n",
      "theta =  2.5997, omega: -0.7722, action:  1.0000\n",
      "theta =  2.5879, omega: -0.1741, action:  5.0000\n",
      "theta =  2.5860, omega: -0.0708, action:  2.0000\n",
      "theta =  2.5835, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5862, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5850, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5836, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5845, omega: -0.0023, action:  2.0000\n",
      "theta =  2.5849, omega:  0.0012, action:  2.0000\n",
      "theta =  2.5843, omega: -0.0021, action:  2.0000\n",
      "theta =  2.5852, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5832, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5846, omega: -0.0024, action:  2.0000\n",
      "theta =  2.5836, omega:  0.0008, action:  2.0000\n",
      "theta =  2.5844, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5836, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5819, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5850, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5850, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5861, omega: -0.0021, action:  2.0000\n",
      "theta =  2.5849, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5836, omega: -0.0016, action:  2.0000\n",
      "theta =  2.5848, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5843, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5854, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5840, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5843, omega:  0.0012, action:  2.0000\n",
      "theta =  2.5848, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5828, omega:  0.0010, action:  2.0000\n",
      "theta =  2.5822, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5856, omega: -0.0023, action:  2.0000\n",
      "theta =  2.5850, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5839, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5833, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5821, omega: -0.0013, action:  2.0000\n",
      "theta =  2.5845, omega: -0.0000, action:  2.0000\n",
      "theta =  2.5829, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5835, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5826, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5838, omega: -0.0017, action:  2.0000\n",
      "theta =  2.5828, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5846, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5851, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5857, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5848, omega:  0.0005, action:  2.0000\n",
      "theta =  2.5844, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5857, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5831, omega: -0.0017, action:  2.0000\n",
      "theta =  2.5827, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5831, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5849, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5838, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5846, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5844, omega:  0.0000, action:  2.0000\n",
      "theta =  2.5862, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5846, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5857, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5844, omega:  0.0016, action:  2.0000\n",
      "theta =  2.5831, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5847, omega:  0.0000, action:  2.0000\n",
      "theta =  2.5841, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5831, omega: -0.0000, action:  2.0000\n",
      "theta =  2.5836, omega:  0.0005, action:  2.0000\n",
      "theta =  2.5829, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5853, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5849, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5821, omega:  0.0010, action:  2.0000\n",
      "theta =  2.5825, omega:  0.0008, action:  2.0000\n",
      "theta =  2.5843, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5815, omega: -0.0014, action:  2.0000\n",
      "theta =  2.5828, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5826, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5853, omega:  0.0020, action:  2.0000\n",
      "theta =  2.5826, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5851, omega: -0.0019, action:  2.0000\n",
      "theta =  2.5829, omega: -0.0022, action:  2.0000\n",
      "theta =  2.5828, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5820, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5844, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5838, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5841, omega:  0.0010, action:  2.0000\n",
      "theta =  2.5841, omega: -0.0014, action:  2.0000\n",
      "theta =  2.5853, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5816, omega: -0.0019, action:  2.0000\n",
      "theta =  2.5849, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5832, omega: -0.0000, action:  2.0000\n",
      "theta =  2.5822, omega: -0.0015, action:  2.0000\n",
      "theta =  2.5832, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5826, omega:  0.0008, action:  2.0000\n",
      "theta =  2.5847, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5823, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5852, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5877, omega:  0.2541, action:  3.0000\n",
      "theta =  2.5912, omega:  0.0525, action:  2.0000\n",
      "theta =  2.5900, omega:  0.0016, action:  2.0000\n",
      "theta =  2.5892, omega:  0.0000, action:  2.0000\n",
      "theta =  2.5911, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5904, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5893, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5899, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5920, omega: -0.0014, action:  2.0000\n",
      "theta =  2.5910, omega: -0.0018, action:  2.0000\n",
      "theta =  2.5913, omega:  0.0005, action:  2.0000\n",
      "theta =  2.5915, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5904, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5909, omega:  0.0014, action:  2.0000\n",
      "theta =  2.5897, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5923, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5900, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5896, omega:  0.0011, action:  2.0000\n",
      "theta =  2.5908, omega: -0.0000, action:  2.0000\n",
      "theta =  2.5922, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5898, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5920, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5908, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5902, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5887, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5902, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5906, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5899, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5900, omega:  0.0017, action:  2.0000\n",
      "theta =  2.5915, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5888, omega: -0.0010, action:  2.0000\n",
      "theta =  2.5905, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5906, omega:  0.0018, action:  2.0000\n",
      "theta =  2.5894, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5916, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5895, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5903, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5898, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5902, omega: -0.0001, action:  2.0000\n",
      "theta =  2.5882, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5908, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5911, omega:  0.0010, action:  2.0000\n",
      "theta =  2.5905, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5904, omega:  0.0019, action:  2.0000\n",
      "theta =  2.5885, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5902, omega:  0.0009, action:  2.0000\n",
      "theta =  2.5894, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5913, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5894, omega: -0.0014, action:  2.0000\n",
      "theta =  2.5914, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5893, omega: -0.0022, action:  2.0000\n",
      "theta =  2.5898, omega: -0.0016, action:  2.0000\n",
      "theta =  2.5896, omega:  0.0020, action:  2.0000\n",
      "theta =  2.5903, omega:  0.0013, action:  2.0000\n",
      "theta =  2.5910, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5893, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5904, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5890, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5894, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5891, omega: -0.0015, action:  2.0000\n",
      "theta =  2.5915, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5919, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5902, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5903, omega:  0.0013, action:  2.0000\n",
      "theta =  2.5808, omega: -0.8244, action:  1.0000\n",
      "theta =  2.5652, omega: -0.2794, action:  5.0000\n",
      "theta =  2.5583, omega: -0.2375, action:  2.0000\n",
      "theta =  2.5545, omega: -0.2103, action:  2.0000\n",
      "theta =  2.5503, omega: -0.2007, action:  2.0000\n",
      "theta =  2.5441, omega: -0.2014, action:  2.0000\n",
      "theta =  2.5381, omega: -0.2169, action:  2.0000\n",
      "theta =  2.5370, omega:  0.0681, action:  5.0000\n",
      "theta =  2.5363, omega: -0.0246, action:  2.0000\n",
      "theta =  2.5377, omega: -0.0570, action:  2.0000\n",
      "theta =  2.5393, omega:  0.1114, action:  5.0000\n",
      "theta =  2.5379, omega: -0.0198, action:  2.0000\n",
      "theta =  2.5367, omega: -0.0517, action:  2.0000\n",
      "theta =  2.5343, omega: -0.0856, action:  2.0000\n",
      "theta =  2.5333, omega: -0.1243, action:  2.0000\n",
      "theta =  2.5289, omega: -0.1683, action:  2.0000\n",
      "theta =  2.5291, omega:  0.0619, action:  5.0000\n",
      "theta =  2.5293, omega: -0.0442, action:  2.0000\n",
      "theta =  2.5281, omega: -0.1018, action:  2.0000\n",
      "theta =  2.5234, omega: -0.1627, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0563, action:  5.0000\n",
      "theta =  2.5236, omega: -0.0602, action:  2.0000\n",
      "theta =  2.5219, omega:  0.0799, action:  5.0000\n",
      "theta =  2.5213, omega: -0.0537, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0821, action:  5.0000\n",
      "theta =  2.5223, omega: -0.0539, action:  2.0000\n",
      "theta =  2.5242, omega:  0.0845, action:  5.0000\n",
      "theta =  2.5242, omega: -0.0536, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0846, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0517, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0878, action:  5.0000\n",
      "theta =  2.5257, omega: -0.0478, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0872, action:  5.0000\n",
      "theta =  2.5270, omega: -0.0477, action:  2.0000\n",
      "theta =  2.5237, omega: -0.1093, action:  2.0000\n",
      "theta =  2.5230, omega:  0.0694, action:  5.0000\n",
      "theta =  2.5238, omega: -0.0555, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0837, action:  5.0000\n",
      "theta =  2.5239, omega: -0.0521, action:  2.0000\n",
      "theta =  2.5251, omega:  0.0855, action:  5.0000\n",
      "theta =  2.5232, omega: -0.0505, action:  2.0000\n",
      "theta =  2.5248, omega:  0.0875, action:  5.0000\n",
      "theta =  2.5268, omega: -0.0491, action:  2.0000\n",
      "theta =  2.5238, omega: -0.1113, action:  2.0000\n",
      "theta =  2.5253, omega:  0.0678, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0561, action:  2.0000\n",
      "theta =  2.5212, omega:  0.0846, action:  5.0000\n",
      "theta =  2.5259, omega: -0.0517, action:  2.0000\n",
      "theta =  2.5256, omega:  0.0857, action:  5.0000\n",
      "theta =  2.5238, omega: -0.0513, action:  2.0000\n",
      "theta =  2.5264, omega:  0.0870, action:  5.0000\n",
      "theta =  2.5242, omega: -0.0493, action:  2.0000\n",
      "theta =  2.5267, omega:  0.0874, action:  5.0000\n",
      "theta =  2.5271, omega: -0.0465, action:  2.0000\n",
      "theta =  2.5237, omega: -0.1114, action:  2.0000\n",
      "theta =  2.5237, omega:  0.0706, action:  5.0000\n",
      "theta =  2.5233, omega: -0.0544, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0843, action:  5.0000\n",
      "theta =  2.5240, omega: -0.0522, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0861, action:  5.0000\n",
      "theta =  2.5240, omega: -0.0491, action:  2.0000\n",
      "theta =  2.5251, omega:  0.0875, action:  5.0000\n",
      "theta =  2.5269, omega: -0.0497, action:  2.0000\n",
      "theta =  2.5246, omega: -0.1119, action:  2.0000\n",
      "theta =  2.5225, omega:  0.0706, action:  5.0000\n",
      "theta =  2.5235, omega: -0.0535, action:  2.0000\n",
      "theta =  2.5231, omega:  0.0818, action:  5.0000\n",
      "theta =  2.5231, omega: -0.0506, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0841, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0509, action:  2.0000\n",
      "theta =  2.5264, omega:  0.0871, action:  5.0000\n",
      "theta =  2.5274, omega: -0.0486, action:  2.0000\n",
      "theta =  2.5237, omega: -0.1140, action:  2.0000\n",
      "theta =  2.5234, omega:  0.0697, action:  5.0000\n",
      "theta =  2.5230, omega: -0.0560, action:  2.0000\n",
      "theta =  2.5227, omega:  0.0808, action:  5.0000\n",
      "theta =  2.5223, omega: -0.0549, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0833, action:  5.0000\n",
      "theta =  2.5245, omega: -0.0521, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0848, action:  5.0000\n",
      "theta =  2.5247, omega: -0.0524, action:  2.0000\n",
      "theta =  2.5254, omega:  0.0858, action:  5.0000\n",
      "theta =  2.5264, omega: -0.0499, action:  2.0000\n",
      "theta =  2.5237, omega: -0.1150, action:  2.0000\n",
      "theta =  2.5244, omega:  0.0685, action:  5.0000\n",
      "theta =  2.5237, omega: -0.0562, action:  2.0000\n",
      "theta =  2.5230, omega:  0.0808, action:  5.0000\n",
      "theta =  2.5241, omega: -0.0566, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0838, action:  5.0000\n",
      "theta =  2.5249, omega: -0.0535, action:  2.0000\n",
      "theta =  2.5255, omega:  0.0827, action:  5.0000\n",
      "theta =  2.5240, omega: -0.0509, action:  2.0000\n",
      "theta =  2.5251, omega:  0.0848, action:  5.0000\n",
      "theta =  2.5263, omega: -0.0504, action:  2.0000\n",
      "theta =  2.5231, omega: -0.1164, action:  2.0000\n",
      "theta =  2.5230, omega:  0.0679, action:  5.0000\n",
      "theta =  2.5234, omega: -0.0579, action:  2.0000\n",
      "theta =  2.5233, omega:  0.0808, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0544, action:  2.0000\n",
      "theta =  2.5251, omega:  0.0801, action:  5.0000\n",
      "theta =  2.5241, omega: -0.0545, action:  2.0000\n",
      "theta =  2.5226, omega:  0.0833, action:  5.0000\n",
      "theta =  2.5234, omega: -0.0519, action:  2.0000\n",
      "theta =  2.5256, omega:  0.0828, action:  5.0000\n",
      "theta =  2.5228, omega: -0.0519, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0873, action:  5.0000\n",
      "theta =  2.5261, omega: -0.0490, action:  2.0000\n",
      "theta =  2.5269, omega:  0.0888, action:  5.0000\n",
      "theta =  2.5271, omega: -0.0486, action:  2.0000\n",
      "theta =  2.5247, omega: -0.1103, action:  2.0000\n",
      "theta =  2.5229, omega:  0.0695, action:  5.0000\n",
      "theta =  2.5244, omega: -0.0550, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0834, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0510, action:  2.0000\n",
      "theta =  2.5255, omega:  0.0843, action:  5.0000\n",
      "theta =  2.5250, omega: -0.0498, action:  2.0000\n",
      "theta =  2.5241, omega:  0.0854, action:  5.0000\n",
      "theta =  2.5261, omega: -0.0474, action:  2.0000\n",
      "theta =  2.5264, omega:  0.0889, action:  5.0000\n",
      "theta =  2.5262, omega: -0.0471, action:  2.0000\n",
      "theta =  2.5271, omega:  0.0915, action:  5.0000\n",
      "theta =  2.5268, omega: -0.0464, action:  2.0000\n",
      "theta =  2.5264, omega: -0.1031, action:  2.0000\n",
      "theta =  2.5228, omega: -0.1690, action:  2.0000\n",
      "theta =  2.5221, omega:  0.0513, action:  5.0000\n",
      "theta =  2.5214, omega: -0.0653, action:  2.0000\n",
      "theta =  2.5217, omega:  0.0759, action:  5.0000\n",
      "theta =  2.5214, omega: -0.0599, action:  2.0000\n",
      "theta =  2.5216, omega:  0.0750, action:  5.0000\n",
      "theta =  2.5208, omega: -0.0590, action:  2.0000\n",
      "theta =  2.5214, omega:  0.0751, action:  5.0000\n",
      "theta =  2.5210, omega: -0.0586, action:  2.0000\n",
      "theta =  2.5216, omega:  0.0778, action:  5.0000\n",
      "theta =  2.5216, omega: -0.0580, action:  2.0000\n",
      "theta =  2.5222, omega:  0.0785, action:  5.0000\n",
      "theta =  2.5241, omega: -0.0582, action:  2.0000\n",
      "theta =  2.5236, omega:  0.0801, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0559, action:  2.0000\n",
      "theta =  2.5232, omega:  0.0786, action:  5.0000\n",
      "theta =  2.5214, omega: -0.0544, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0836, action:  5.0000\n",
      "theta =  2.5215, omega: -0.0539, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0840, action:  5.0000\n",
      "theta =  2.5291, omega:  0.1808, action:  3.0000\n",
      "theta =  2.5271, omega: -0.0285, action:  2.0000\n",
      "theta =  2.5313, omega:  0.1027, action:  5.0000\n",
      "theta =  2.5310, omega: -0.0385, action:  2.0000\n",
      "theta =  2.5283, omega: -0.0906, action:  2.0000\n",
      "theta =  2.5251, omega: -0.1477, action:  2.0000\n",
      "theta =  2.5265, omega:  0.0621, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0549, action:  2.0000\n",
      "theta =  2.5256, omega:  0.0860, action:  5.0000\n",
      "theta =  2.5260, omega: -0.0503, action:  2.0000\n",
      "theta =  2.5281, omega:  0.0875, action:  5.0000\n",
      "theta =  2.5267, omega: -0.0478, action:  2.0000\n",
      "theta =  2.5247, omega: -0.1090, action:  2.0000\n",
      "theta =  2.5246, omega:  0.0704, action:  5.0000\n",
      "theta =  2.5238, omega: -0.0543, action:  2.0000\n",
      "theta =  2.5258, omega:  0.0830, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0526, action:  2.0000\n",
      "theta =  2.5241, omega:  0.0851, action:  5.0000\n",
      "theta =  2.5253, omega: -0.0516, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0873, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0470, action:  2.0000\n",
      "theta =  2.5280, omega:  0.0901, action:  5.0000\n",
      "theta =  2.5263, omega: -0.0465, action:  2.0000\n",
      "theta =  2.5287, omega:  0.0929, action:  5.0000\n",
      "theta =  2.5271, omega: -0.0457, action:  2.0000\n",
      "theta =  2.5253, omega: -0.1044, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0744, action:  5.0000\n",
      "theta =  2.5247, omega: -0.0520, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0892, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0459, action:  2.0000\n",
      "theta =  2.5263, omega:  0.0913, action:  5.0000\n",
      "theta =  2.5278, omega: -0.0444, action:  2.0000\n",
      "theta =  2.5246, omega: -0.1075, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0732, action:  5.0000\n",
      "theta =  2.5240, omega: -0.0516, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0874, action:  5.0000\n",
      "theta =  2.5245, omega: -0.0498, action:  2.0000\n",
      "theta =  2.5272, omega:  0.0908, action:  5.0000\n",
      "theta =  2.5254, omega: -0.0473, action:  2.0000\n",
      "theta =  2.5263, omega:  0.0917, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0463, action:  2.0000\n",
      "theta =  2.5284, omega:  0.0939, action:  5.0000\n",
      "theta =  2.5284, omega: -0.0419, action:  2.0000\n",
      "theta =  2.5263, omega: -0.0991, action:  2.0000\n",
      "theta =  2.5228, omega: -0.1635, action:  2.0000\n",
      "theta =  2.5225, omega:  0.0539, action:  5.0000\n",
      "theta =  2.5197, omega: -0.0627, action:  2.0000\n",
      "theta =  2.5244, omega:  0.0777, action:  5.0000\n",
      "theta =  2.5217, omega: -0.0565, action:  2.0000\n",
      "theta =  2.5239, omega:  0.0803, action:  5.0000\n",
      "theta =  2.5225, omega: -0.0553, action:  2.0000\n",
      "theta =  2.5221, omega:  0.0813, action:  5.0000\n",
      "theta =  2.5225, omega: -0.0542, action:  2.0000\n",
      "theta =  2.5224, omega:  0.0828, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0546, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0837, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0541, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0831, action:  5.0000\n",
      "theta =  2.5252, omega: -0.0516, action:  2.0000\n",
      "theta =  2.5262, omega:  0.0882, action:  5.0000\n",
      "theta =  2.5260, omega: -0.0487, action:  2.0000\n",
      "theta =  2.5273, omega:  0.0880, action:  5.0000\n",
      "theta =  2.5249, omega: -0.0458, action:  2.0000\n",
      "theta =  2.5280, omega:  0.0936, action:  5.0000\n",
      "theta =  2.5266, omega: -0.0456, action:  2.0000\n",
      "theta =  2.5300, omega:  0.0939, action:  5.0000\n",
      "theta =  2.5272, omega: -0.0437, action:  2.0000\n",
      "theta =  2.5260, omega: -0.1008, action:  2.0000\n",
      "theta =  2.5252, omega: -0.1644, action:  2.0000\n",
      "theta =  2.5232, omega:  0.0556, action:  5.0000\n",
      "theta =  2.5214, omega: -0.0620, action:  2.0000\n",
      "theta =  2.5232, omega:  0.0777, action:  5.0000\n",
      "theta =  2.5211, omega: -0.0572, action:  2.0000\n",
      "theta =  2.5225, omega:  0.0793, action:  5.0000\n",
      "theta =  2.5241, omega: -0.0557, action:  2.0000\n",
      "theta =  2.5239, omega:  0.0818, action:  5.0000\n",
      "theta =  2.5244, omega: -0.0535, action:  2.0000\n",
      "theta =  2.5223, omega:  0.0822, action:  5.0000\n",
      "theta =  2.5242, omega: -0.0554, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0829, action:  5.0000\n",
      "theta =  2.5243, omega: -0.0518, action:  2.0000\n",
      "theta =  2.5238, omega:  0.0856, action:  5.0000\n",
      "theta =  2.5262, omega: -0.0521, action:  2.0000\n",
      "theta =  2.5220, omega: -0.1171, action:  2.0000\n",
      "theta =  2.5217, omega:  0.0672, action:  5.0000\n",
      "theta =  2.5214, omega: -0.0591, action:  2.0000\n",
      "theta =  2.5249, omega:  0.0797, action:  5.0000\n",
      "theta =  2.5218, omega: -0.0555, action:  2.0000\n",
      "theta =  2.5239, omega:  0.0813, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0537, action:  2.0000\n",
      "theta =  2.5254, omega:  0.0825, action:  5.0000\n",
      "theta =  2.5235, omega: -0.0551, action:  2.0000\n",
      "theta =  2.5257, omega:  0.0833, action:  5.0000\n",
      "theta =  2.5242, omega: -0.0520, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0866, action:  5.0000\n",
      "theta =  2.5253, omega: -0.0502, action:  2.0000\n",
      "theta =  2.5254, omega:  0.0858, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0477, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0873, action:  5.0000\n",
      "theta =  2.5281, omega: -0.0455, action:  2.0000\n",
      "theta =  2.5251, omega: -0.1074, action:  2.0000\n",
      "theta =  2.5252, omega:  0.0724, action:  5.0000\n",
      "theta =  2.5244, omega: -0.0549, action:  2.0000\n",
      "theta =  2.5262, omega:  0.0844, action:  5.0000\n",
      "theta =  2.5259, omega: -0.0512, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0866, action:  5.0000\n",
      "theta =  2.5269, omega: -0.0482, action:  2.0000\n",
      "theta =  2.5230, omega: -0.1136, action:  2.0000\n",
      "theta =  2.5239, omega:  0.0691, action:  5.0000\n",
      "theta =  2.5232, omega: -0.0563, action:  2.0000\n",
      "theta =  2.5235, omega:  0.0821, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0527, action:  2.0000\n",
      "theta =  2.5248, omega:  0.0845, action:  5.0000\n",
      "theta =  2.5240, omega: -0.0488, action:  2.0000\n",
      "theta =  2.5266, omega:  0.0860, action:  5.0000\n",
      "theta =  2.5257, omega: -0.0510, action:  2.0000\n",
      "theta =  2.5278, omega:  0.0883, action:  5.0000\n",
      "theta =  2.5257, omega: -0.0489, action:  2.0000\n",
      "theta =  2.5273, omega:  0.0903, action:  5.0000\n",
      "theta =  2.5260, omega: -0.0466, action:  2.0000\n",
      "theta =  2.5280, omega:  0.0925, action:  5.0000\n",
      "theta =  2.5263, omega: -0.0459, action:  2.0000\n",
      "theta =  2.5283, omega:  0.0943, action:  5.0000\n",
      "theta =  2.5295, omega: -0.0431, action:  2.0000\n",
      "theta =  2.5281, omega: -0.0990, action:  2.0000\n",
      "theta =  2.5243, omega: -0.1618, action:  2.0000\n",
      "theta =  2.5240, omega:  0.0560, action:  5.0000\n",
      "theta =  2.5228, omega: -0.0638, action:  2.0000\n",
      "theta =  2.5241, omega:  0.0783, action:  5.0000\n",
      "theta =  2.5230, omega: -0.0571, action:  2.0000\n",
      "theta =  2.5249, omega:  0.0808, action:  5.0000\n",
      "theta =  2.5219, omega: -0.0563, action:  2.0000\n",
      "theta =  2.5268, omega:  0.0817, action:  5.0000\n",
      "theta =  2.5230, omega: -0.0527, action:  2.0000\n",
      "theta =  2.5246, omega:  0.0812, action:  5.0000\n",
      "theta =  2.5236, omega: -0.0522, action:  2.0000\n",
      "theta =  2.5256, omega:  0.0825, action:  5.0000\n",
      "theta =  2.5253, omega: -0.0511, action:  2.0000\n",
      "theta =  2.5262, omega:  0.0867, action:  5.0000\n",
      "theta =  2.5224, omega: -0.0496, action:  2.0000\n",
      "theta =  2.5214, omega: -0.1146, action:  2.0000\n",
      "theta =  2.5230, omega:  0.0665, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0554, action:  2.0000\n",
      "theta =  2.5246, omega:  0.0816, action:  5.0000\n",
      "theta =  2.5225, omega: -0.0534, action:  2.0000\n",
      "theta =  2.5241, omega:  0.0816, action:  5.0000\n",
      "theta =  2.5228, omega: -0.0522, action:  2.0000\n",
      "theta =  2.5266, omega:  0.0832, action:  5.0000\n",
      "theta =  2.5260, omega: -0.0528, action:  2.0000\n",
      "theta =  2.5253, omega:  0.0862, action:  5.0000\n",
      "theta =  2.5262, omega: -0.0482, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0891, action:  5.0000\n",
      "theta =  2.5246, omega: -0.0490, action:  2.0000\n",
      "theta =  2.5267, omega:  0.0900, action:  5.0000\n",
      "theta =  2.5266, omega: -0.0446, action:  2.0000\n",
      "theta =  2.5271, omega:  0.0918, action:  5.0000\n",
      "theta =  2.5278, omega: -0.0448, action:  2.0000\n",
      "theta =  2.5254, omega: -0.1009, action:  2.0000\n",
      "theta =  2.5268, omega:  0.0757, action:  5.0000\n",
      "theta =  2.5279, omega: -0.0505, action:  2.0000\n",
      "theta =  2.5261, omega: -0.1134, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0694, action:  5.0000\n",
      "theta =  2.5243, omega: -0.0536, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0843, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0515, action:  2.0000\n",
      "theta =  2.5235, omega:  0.0842, action:  5.0000\n",
      "theta =  2.5257, omega: -0.0488, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0879, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0497, action:  2.0000\n",
      "theta =  2.5266, omega:  0.0884, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0458, action:  2.0000\n",
      "theta =  2.5275, omega:  0.0925, action:  5.0000\n",
      "theta =  2.5277, omega: -0.0459, action:  2.0000\n",
      "theta =  2.5257, omega: -0.1041, action:  2.0000\n",
      "theta =  2.5265, omega:  0.0739, action:  5.0000\n",
      "theta =  2.5250, omega: -0.0512, action:  2.0000\n",
      "theta =  2.5251, omega:  0.0864, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0480, action:  2.0000\n",
      "theta =  2.5268, omega:  0.0915, action:  5.0000\n",
      "theta =  2.5270, omega: -0.0464, action:  2.0000\n",
      "theta =  2.5265, omega: -0.1067, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0726, action:  5.0000\n",
      "theta =  2.5257, omega: -0.0534, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0880, action:  5.0000\n",
      "theta =  2.5263, omega: -0.0484, action:  2.0000\n",
      "theta =  2.5280, omega:  0.0895, action:  5.0000\n",
      "theta =  2.5260, omega: -0.0472, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0890, action:  5.0000\n",
      "theta =  2.5288, omega: -0.0456, action:  2.0000\n",
      "theta =  2.5271, omega: -0.1049, action:  2.0000\n",
      "theta =  2.5226, omega: -0.1706, action:  2.0000\n",
      "theta =  2.5221, omega:  0.0524, action:  5.0000\n",
      "theta =  2.5220, omega: -0.0665, action:  2.0000\n",
      "theta =  2.5197, omega:  0.0753, action:  5.0000\n",
      "theta =  2.5215, omega: -0.0602, action:  2.0000\n",
      "theta =  2.5224, omega:  0.0751, action:  5.0000\n",
      "theta =  2.5203, omega: -0.0606, action:  2.0000\n",
      "theta =  2.5229, omega:  0.0776, action:  5.0000\n",
      "theta =  2.5188, omega: -0.0591, action:  2.0000\n",
      "theta =  2.5218, omega:  0.0768, action:  5.0000\n",
      "theta =  2.5210, omega: -0.0592, action:  2.0000\n",
      "theta =  2.5209, omega:  0.0803, action:  5.0000\n",
      "theta =  2.5224, omega: -0.0565, action:  2.0000\n",
      "theta =  2.5227, omega:  0.0766, action:  5.0000\n",
      "theta =  2.5227, omega: -0.0583, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0794, action:  5.0000\n",
      "theta =  2.5234, omega: -0.0557, action:  2.0000\n",
      "theta =  2.5253, omega:  0.0821, action:  5.0000\n",
      "theta =  2.5233, omega: -0.0545, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0826, action:  5.0000\n",
      "theta =  2.5225, omega: -0.0529, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0855, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0533, action:  2.0000\n",
      "theta =  2.5252, omega:  0.0843, action:  5.0000\n",
      "theta =  2.5262, omega: -0.0506, action:  2.0000\n",
      "theta =  2.5258, omega:  0.0865, action:  5.0000\n",
      "theta =  2.5262, omega: -0.0498, action:  2.0000\n",
      "theta =  2.5272, omega:  0.0875, action:  5.0000\n",
      "theta =  2.5243, omega: -0.0473, action:  2.0000\n",
      "theta =  2.5273, omega:  0.0920, action:  5.0000\n",
      "theta =  2.5264, omega: -0.0449, action:  2.0000\n",
      "theta =  2.5274, omega:  0.0933, action:  5.0000\n",
      "theta =  2.5283, omega: -0.0442, action:  2.0000\n",
      "theta =  2.5234, omega: -0.1007, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0774, action:  5.0000\n",
      "theta =  2.5272, omega: -0.0475, action:  2.0000\n",
      "theta =  2.5242, omega: -0.1139, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0681, action:  5.0000\n",
      "theta =  2.5254, omega: -0.0531, action:  2.0000\n",
      "theta =  2.5234, omega:  0.0833, action:  5.0000\n",
      "theta =  2.5259, omega: -0.0507, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0873, action:  5.0000\n",
      "theta =  2.5259, omega: -0.0488, action:  2.0000\n",
      "theta =  2.5266, omega:  0.0881, action:  5.0000\n",
      "theta =  2.5249, omega: -0.0475, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0925, action:  5.0000\n",
      "theta =  2.5261, omega: -0.0463, action:  2.0000\n",
      "theta =  2.5272, omega:  0.0930, action:  5.0000\n",
      "theta =  2.5288, omega: -0.0433, action:  2.0000\n",
      "theta =  2.5264, omega: -0.0992, action:  2.0000\n",
      "theta =  2.5208, omega: -0.1635, action:  2.0000\n",
      "theta =  2.5227, omega:  0.0534, action:  5.0000\n",
      "theta =  2.5219, omega: -0.0627, action:  2.0000\n",
      "theta =  2.5218, omega:  0.0766, action:  5.0000\n",
      "theta =  2.5212, omega: -0.0588, action:  2.0000\n",
      "theta =  2.5222, omega:  0.0789, action:  5.0000\n",
      "theta =  2.5231, omega: -0.0558, action:  2.0000\n",
      "theta =  2.5229, omega:  0.0806, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0562, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0802, action:  5.0000\n",
      "theta =  2.5235, omega: -0.0545, action:  2.0000\n",
      "theta =  2.5239, omega:  0.0826, action:  5.0000\n",
      "theta =  2.5250, omega: -0.0538, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0832, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0518, action:  2.0000\n",
      "theta =  2.5273, omega:  0.0851, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0503, action:  2.0000\n",
      "theta =  2.5254, omega:  0.0880, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0496, action:  2.0000\n",
      "theta =  2.5267, omega:  0.0894, action:  5.0000\n",
      "theta =  2.5269, omega: -0.0458, action:  2.0000\n",
      "theta =  2.5232, omega: -0.1091, action:  2.0000\n",
      "theta =  2.5231, omega:  0.0716, action:  5.0000\n",
      "theta =  2.5247, omega: -0.0536, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0863, action:  5.0000\n",
      "theta =  2.5263, omega: -0.0487, action:  2.0000\n",
      "theta =  2.5257, omega:  0.0865, action:  5.0000\n",
      "theta =  2.5250, omega: -0.0490, action:  2.0000\n",
      "theta =  2.5265, omega:  0.0868, action:  5.0000\n",
      "theta =  2.5257, omega: -0.0461, action:  2.0000\n",
      "theta =  2.5278, omega:  0.0917, action:  5.0000\n",
      "theta =  2.5284, omega: -0.0444, action:  2.0000\n",
      "theta =  2.5246, omega: -0.1035, action:  2.0000\n",
      "theta =  2.5255, omega:  0.0747, action:  5.0000\n",
      "theta =  2.5236, omega: -0.0519, action:  2.0000\n",
      "theta =  2.5267, omega:  0.0881, action:  5.0000\n",
      "theta =  2.5264, omega: -0.0481, action:  2.0000\n",
      "theta =  2.5230, omega: -0.1110, action:  2.0000\n",
      "theta =  2.5242, omega:  0.0708, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0543, action:  2.0000\n",
      "theta =  2.5254, omega:  0.0838, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0523, action:  2.0000\n",
      "theta =  2.5262, omega:  0.0861, action:  5.0000\n",
      "theta =  2.5261, omega: -0.0493, action:  2.0000\n",
      "theta =  2.5264, omega:  0.0877, action:  5.0000\n",
      "theta =  2.5272, omega: -0.0505, action:  2.0000\n",
      "theta =  2.5238, omega: -0.1128, action:  2.0000\n",
      "theta =  2.5248, omega:  0.0692, action:  5.0000\n",
      "theta =  2.5227, omega: -0.0554, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0830, action:  5.0000\n",
      "theta =  2.5277, omega: -0.0520, action:  2.0000\n",
      "theta =  2.5227, omega: -0.1197, action:  2.0000\n",
      "theta =  2.5224, omega:  0.0631, action:  5.0000\n",
      "theta =  2.5232, omega: -0.0602, action:  2.0000\n",
      "theta =  2.5226, omega:  0.0785, action:  5.0000\n",
      "theta =  2.5225, omega: -0.0576, action:  2.0000\n",
      "theta =  2.5224, omega:  0.0780, action:  5.0000\n",
      "theta =  2.5223, omega: -0.0560, action:  2.0000\n",
      "theta =  2.5219, omega:  0.0780, action:  5.0000\n",
      "theta =  2.5242, omega: -0.0561, action:  2.0000\n",
      "theta =  2.5237, omega:  0.0811, action:  5.0000\n",
      "theta =  2.5232, omega: -0.0557, action:  2.0000\n",
      "theta =  2.5235, omega:  0.0800, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0529, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0853, action:  5.0000\n",
      "theta =  2.5233, omega: -0.0514, action:  2.0000\n",
      "theta =  2.5240, omega:  0.0835, action:  5.0000\n",
      "theta =  2.5234, omega: -0.0502, action:  2.0000\n",
      "theta =  2.5246, omega:  0.0853, action:  5.0000\n",
      "theta =  2.5232, omega: -0.0484, action:  2.0000\n",
      "theta =  2.5266, omega:  0.0882, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0458, action:  2.0000\n",
      "theta =  2.5275, omega:  0.0924, action:  5.0000\n",
      "theta =  2.5276, omega: -0.0460, action:  2.0000\n",
      "theta =  2.5248, omega: -0.1059, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0726, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0506, action:  2.0000\n",
      "theta =  2.5254, omega:  0.0864, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0465, action:  2.0000\n",
      "theta =  2.5275, omega:  0.0899, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0472, action:  2.0000\n",
      "theta =  2.5292, omega:  0.0901, action:  5.0000\n",
      "theta =  2.5272, omega: -0.0458, action:  2.0000\n",
      "theta =  2.5254, omega: -0.1028, action:  2.0000\n",
      "theta =  2.5272, omega:  0.0739, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0492, action:  2.0000\n",
      "theta =  2.5249, omega:  0.0881, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0429, action:  2.0000\n",
      "theta =  2.5280, omega:  0.0919, action:  5.0000\n",
      "theta =  2.5281, omega: -0.0434, action:  2.0000\n",
      "theta =  2.5257, omega: -0.1058, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0721, action:  5.0000\n",
      "theta =  2.5256, omega: -0.0511, action:  2.0000\n",
      "theta =  2.5279, omega:  0.0868, action:  5.0000\n",
      "theta =  2.5240, omega: -0.0476, action:  2.0000\n",
      "theta =  2.5264, omega:  0.0885, action:  5.0000\n",
      "theta =  2.5286, omega: -0.0455, action:  2.0000\n",
      "theta =  2.5241, omega: -0.1083, action:  2.0000\n",
      "theta =  2.5236, omega:  0.0724, action:  5.0000\n",
      "theta =  2.5239, omega: -0.0528, action:  2.0000\n",
      "theta =  2.5252, omega:  0.0847, action:  5.0000\n",
      "theta =  2.5243, omega: -0.0492, action:  2.0000\n",
      "theta =  2.5259, omega:  0.0858, action:  5.0000\n",
      "theta =  2.5268, omega: -0.0468, action:  2.0000\n",
      "theta =  2.5237, omega: -0.1139, action:  2.0000\n",
      "theta =  2.5246, omega:  0.0673, action:  5.0000\n",
      "theta =  2.5233, omega: -0.0576, action:  2.0000\n",
      "theta =  2.5235, omega:  0.0811, action:  5.0000\n",
      "theta =  2.5242, omega: -0.0525, action:  2.0000\n",
      "theta =  2.5235, omega:  0.0833, action:  5.0000\n",
      "theta =  2.5244, omega: -0.0501, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0852, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0496, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0876, action:  5.0000\n",
      "theta =  2.5266, omega: -0.0490, action:  2.0000\n",
      "theta =  2.5240, omega: -0.1121, action:  2.0000\n",
      "theta =  2.5230, omega:  0.0707, action:  5.0000\n",
      "theta =  2.5228, omega: -0.0556, action:  2.0000\n",
      "theta =  2.5242, omega:  0.0803, action:  5.0000\n",
      "theta =  2.5238, omega: -0.0516, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0864, action:  5.0000\n",
      "theta =  2.5241, omega: -0.0520, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0858, action:  5.0000\n",
      "theta =  2.5260, omega: -0.0495, action:  2.0000\n",
      "theta =  2.5269, omega:  0.0895, action:  5.0000\n",
      "theta =  2.5264, omega: -0.0473, action:  2.0000\n",
      "theta =  2.5281, omega:  0.0905, action:  5.0000\n",
      "theta =  2.5265, omega: -0.0445, action:  2.0000\n",
      "theta =  2.5285, omega:  0.0943, action:  5.0000\n",
      "theta =  2.5263, omega: -0.0432, action:  2.0000\n",
      "theta =  2.5300, omega:  0.0952, action:  5.0000\n",
      "theta =  2.5283, omega: -0.0401, action:  2.0000\n",
      "theta =  2.5264, omega: -0.0967, action:  2.0000\n",
      "theta =  2.5242, omega: -0.1545, action:  2.0000\n",
      "theta =  2.5237, omega:  0.0616, action:  5.0000\n",
      "theta =  2.5214, omega: -0.0574, action:  2.0000\n",
      "theta =  2.5229, omega:  0.0789, action:  5.0000\n",
      "theta =  2.5229, omega: -0.0532, action:  2.0000\n",
      "theta =  2.5253, omega:  0.0823, action:  5.0000\n",
      "theta =  2.5244, omega: -0.0528, action:  2.0000\n",
      "theta =  2.5242, omega:  0.0836, action:  5.0000\n",
      "theta =  2.5244, omega: -0.0507, action:  2.0000\n",
      "theta =  2.5260, omega:  0.0866, action:  5.0000\n",
      "theta =  2.5262, omega: -0.0495, action:  2.0000\n",
      "theta =  2.5267, omega:  0.0871, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0470, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0899, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0464, action:  2.0000\n",
      "theta =  2.5272, omega:  0.0932, action:  5.0000\n",
      "theta =  2.5283, omega: -0.0429, action:  2.0000\n",
      "theta =  2.5258, omega: -0.1027, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0750, action:  5.0000\n",
      "theta =  2.5252, omega: -0.0505, action:  2.0000\n",
      "theta =  2.5284, omega:  0.0905, action:  5.0000\n",
      "theta =  2.5278, omega: -0.0458, action:  2.0000\n",
      "theta =  2.5241, omega: -0.1070, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0711, action:  5.0000\n",
      "theta =  2.5239, omega: -0.0536, action:  2.0000\n",
      "theta =  2.5234, omega:  0.0864, action:  5.0000\n",
      "theta =  2.5252, omega: -0.0493, action:  2.0000\n",
      "theta =  2.5248, omega:  0.0867, action:  5.0000\n",
      "theta =  2.5271, omega: -0.0483, action:  2.0000\n",
      "theta =  2.5228, omega: -0.1129, action:  2.0000\n",
      "theta =  2.5245, omega:  0.0686, action:  5.0000\n",
      "theta =  2.5235, omega: -0.0558, action:  2.0000\n",
      "theta =  2.5243, omega:  0.0817, action:  5.0000\n",
      "theta =  2.5223, omega: -0.0541, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0849, action:  5.0000\n",
      "theta =  2.5250, omega: -0.0496, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0850, action:  5.0000\n",
      "theta =  2.5255, omega: -0.0493, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0879, action:  5.0000\n",
      "theta =  2.5251, omega: -0.0476, action:  2.0000\n",
      "theta =  2.5275, omega:  0.0919, action:  5.0000\n",
      "theta =  2.5274, omega: -0.0456, action:  2.0000\n",
      "theta =  2.5233, omega: -0.1080, action:  2.0000\n",
      "theta =  2.5271, omega:  0.0736, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0532, action:  2.0000\n",
      "theta =  2.5282, omega:  0.0866, action:  5.0000\n",
      "theta =  2.5253, omega: -0.0480, action:  2.0000\n",
      "theta =  2.5270, omega:  0.0903, action:  5.0000\n",
      "theta =  2.5265, omega: -0.0460, action:  2.0000\n",
      "theta =  2.5265, omega:  0.0893, action:  5.0000\n",
      "theta =  2.5287, omega: -0.0432, action:  2.0000\n",
      "theta =  2.5250, omega: -0.1044, action:  2.0000\n",
      "theta =  2.5251, omega:  0.0736, action:  5.0000\n",
      "theta =  2.5243, omega: -0.0507, action:  2.0000\n",
      "theta =  2.5271, omega:  0.0877, action:  5.0000\n",
      "theta =  2.5261, omega: -0.0475, action:  2.0000\n",
      "theta =  2.5284, omega:  0.0920, action:  5.0000\n",
      "theta =  2.5246, omega: -0.0448, action:  2.0000\n",
      "theta =  2.5267, omega:  0.0927, action:  5.0000\n",
      "theta =  2.5274, omega: -0.0442, action:  2.0000\n",
      "theta =  2.5248, omega: -0.1024, action:  2.0000\n",
      "theta =  2.5261, omega:  0.0754, action:  5.0000\n",
      "theta =  2.5273, omega: -0.0501, action:  2.0000\n",
      "theta =  2.5227, omega: -0.1127, action:  2.0000\n",
      "theta =  2.5241, omega:  0.0700, action:  5.0000\n",
      "theta =  2.5226, omega: -0.0570, action:  2.0000\n",
      "theta =  2.5239, omega:  0.0835, action:  5.0000\n",
      "theta =  2.5258, omega: -0.0516, action:  2.0000\n",
      "theta =  2.5247, omega:  0.0847, action:  5.0000\n",
      "theta =  2.5243, omega: -0.0524, action:  2.0000\n",
      "theta =  2.5257, omega:  0.0858, action:  5.0000\n",
      "theta =  2.5264, omega: -0.0477, action:  2.0000\n",
      "theta =  2.5257, omega:  0.0877, action:  5.0000\n",
      "theta =  2.5274, omega: -0.0456, action:  2.0000\n",
      "theta =  2.5248, omega: -0.1101, action:  2.0000\n",
      "theta =  2.5227, omega:  0.0707, action:  5.0000\n",
      "theta =  2.5245, omega: -0.0550, action:  2.0000\n",
      "theta =  2.5233, omega:  0.0839, action:  5.0000\n",
      "theta =  2.5233, omega: -0.0516, action:  2.0000\n",
      "theta =  2.5250, omega:  0.0863, action:  5.0000\n",
      "theta =  2.5248, omega: -0.0493, action:  2.0000\n",
      "theta =  2.5263, omega:  0.0877, action:  5.0000\n",
      "theta =  2.5252, omega: -0.0450, action:  2.0000\n",
      "theta =  2.5249, omega:  0.0915, action:  5.0000\n",
      "theta =  2.5285, omega: -0.0467, action:  2.0000\n",
      "theta =  2.5249, omega: -0.1075, action:  2.0000\n",
      "theta =  2.5265, omega:  0.0744, action:  5.0000\n",
      "theta =  2.5236, omega: -0.0541, action:  2.0000\n",
      "theta =  2.5249, omega:  0.0866, action:  5.0000\n",
      "theta =  2.5156, omega: -0.9256, action:  1.0000\n",
      "theta =  2.4974, omega: -0.5493, action:  4.0000\n",
      "theta =  2.4879, omega: -0.2218, action:  5.0000\n",
      "theta =  2.4840, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4848, omega:  0.0030, action:  5.0000\n",
      "theta =  2.4853, omega:  0.0034, action:  5.0000\n",
      "theta =  2.4852, omega:  0.0034, action:  5.0000\n",
      "theta =  2.4852, omega: -0.0003, action:  5.0000\n",
      "theta =  2.4855, omega:  0.0023, action:  5.0000\n",
      "theta =  2.4870, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4858, omega:  0.0021, action:  5.0000\n",
      "theta =  2.4856, omega:  0.0001, action:  5.0000\n",
      "theta =  2.4843, omega:  0.0041, action:  5.0000\n",
      "theta =  2.4845, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4860, omega:  0.0034, action:  5.0000\n",
      "theta =  2.4855, omega:  0.0025, action:  5.0000\n",
      "theta =  2.4868, omega:  0.0031, action:  5.0000\n",
      "theta =  2.4857, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4869, omega:  0.0024, action:  5.0000\n",
      "theta =  2.4849, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4860, omega:  0.0026, action:  5.0000\n",
      "theta =  2.4861, omega:  0.0026, action:  5.0000\n",
      "theta =  2.4872, omega:  0.0046, action:  4.0000\n",
      "theta =  2.4851, omega:  0.0027, action:  5.0000\n",
      "theta =  2.4861, omega:  0.0037, action:  5.0000\n",
      "theta =  2.4859, omega:  0.0031, action:  5.0000\n",
      "theta =  2.4852, omega:  0.0042, action:  5.0000\n",
      "theta =  2.4866, omega:  0.0056, action:  5.0000\n",
      "theta =  2.4862, omega:  0.0051, action:  5.0000\n",
      "theta =  2.4854, omega:  0.0070, action:  5.0000\n",
      "theta =  2.4868, omega:  0.0067, action:  5.0000\n",
      "theta =  2.4869, omega:  0.0094, action:  5.0000\n",
      "theta =  2.4871, omega:  0.0094, action:  5.0000\n",
      "theta =  2.4882, omega:  0.0131, action:  5.0000\n",
      "theta =  2.4893, omega:  0.0183, action:  5.0000\n",
      "theta =  2.4894, omega:  0.0236, action:  6.0000\n",
      "theta =  2.4882, omega:  0.0292, action:  6.0000\n",
      "theta =  2.4905, omega:  0.0381, action:  6.0000\n",
      "theta =  2.4906, omega:  0.0463, action:  6.0000\n",
      "theta =  2.4926, omega:  0.0623, action:  6.0000\n",
      "theta =  2.4947, omega:  0.0780, action:  6.0000\n",
      "theta =  2.4942, omega: -0.1221, action:  2.0000\n",
      "theta =  2.4926, omega:  0.0121, action:  5.0000\n",
      "theta =  2.4934, omega:  0.0300, action:  6.0000\n",
      "theta =  2.4949, omega:  0.0465, action:  6.0000\n",
      "theta =  2.4951, omega:  0.0678, action:  6.0000\n",
      "theta =  2.4954, omega: -0.1204, action:  2.0000\n",
      "theta =  2.4918, omega:  0.0123, action:  5.0000\n",
      "theta =  2.4925, omega:  0.0354, action:  5.0000\n",
      "theta =  2.4952, omega:  0.0544, action:  6.0000\n",
      "theta =  2.4991, omega:  0.0799, action:  6.0000\n",
      "theta =  2.4958, omega: -0.1123, action:  2.0000\n",
      "theta =  2.4974, omega:  0.0176, action:  5.0000\n",
      "theta =  2.4982, omega:  0.0421, action:  6.0000\n",
      "theta =  2.4988, omega:  0.0690, action:  6.0000\n",
      "theta =  2.4978, omega: -0.1115, action:  2.0000\n",
      "theta =  2.4972, omega:  0.0181, action:  5.0000\n",
      "theta =  2.4968, omega:  0.0456, action:  6.0000\n",
      "theta =  2.5000, omega:  0.0768, action:  6.0000\n",
      "theta =  2.4977, omega: -0.1071, action:  2.0000\n",
      "theta =  2.5002, omega:  0.0210, action:  5.0000\n",
      "theta =  2.4998, omega:  0.0510, action:  6.0000\n",
      "theta =  2.5010, omega:  0.0831, action:  6.0000\n",
      "theta =  2.5006, omega: -0.1030, action:  2.0000\n",
      "theta =  2.5005, omega:  0.0259, action:  5.0000\n",
      "theta =  2.5019, omega:  0.0597, action:  6.0000\n",
      "theta =  2.5014, omega: -0.1111, action:  2.0000\n",
      "theta =  2.5007, omega:  0.0235, action:  5.0000\n",
      "theta =  2.5010, omega:  0.0553, action:  5.0000\n",
      "theta =  2.5028, omega:  0.0939, action:  6.0000\n",
      "theta =  2.5017, omega: -0.0953, action:  2.0000\n",
      "theta =  2.5022, omega:  0.0276, action:  5.0000\n",
      "theta =  2.5027, omega:  0.0655, action:  6.0000\n",
      "theta =  2.5021, omega: -0.1023, action:  2.0000\n",
      "theta =  2.5025, omega:  0.0264, action:  5.0000\n",
      "theta =  2.5032, omega:  0.0683, action:  6.0000\n",
      "theta =  2.5012, omega: -0.1026, action:  2.0000\n",
      "theta =  2.5008, omega:  0.0269, action:  5.0000\n",
      "theta =  2.5027, omega:  0.0678, action:  6.0000\n",
      "theta =  2.5017, omega: -0.1023, action:  2.0000\n",
      "theta =  2.5014, omega:  0.0276, action:  5.0000\n",
      "theta =  2.5031, omega:  0.0690, action:  6.0000\n",
      "theta =  2.5034, omega: -0.1034, action:  2.0000\n",
      "theta =  2.5018, omega:  0.0269, action:  5.0000\n",
      "theta =  2.5056, omega:  0.0688, action:  6.0000\n",
      "theta =  2.5026, omega: -0.1028, action:  2.0000\n",
      "theta =  2.5029, omega:  0.0288, action:  7.0000\n",
      "theta =  2.5046, omega:  0.0680, action:  6.0000\n",
      "theta =  2.5037, omega: -0.1014, action:  2.0000\n",
      "theta =  2.5023, omega:  0.0303, action:  5.0000\n",
      "theta =  2.5028, omega:  0.0710, action:  6.0000\n",
      "theta =  2.5021, omega: -0.1015, action:  2.0000\n",
      "theta =  2.5026, omega:  0.0296, action:  5.0000\n",
      "theta =  2.5038, omega:  0.0719, action:  6.0000\n",
      "theta =  2.5039, omega: -0.0993, action:  2.0000\n",
      "theta =  2.5037, omega:  0.0318, action:  5.0000\n",
      "theta =  2.5047, omega:  0.0724, action:  6.0000\n",
      "theta =  2.5060, omega: -0.0987, action:  2.0000\n",
      "theta =  2.5039, omega:  0.0331, action:  5.0000\n",
      "theta =  2.5050, omega:  0.0751, action:  6.0000\n",
      "theta =  2.5045, omega: -0.0974, action:  2.0000\n",
      "theta =  2.5035, omega:  0.0324, action:  5.0000\n",
      "theta =  2.5061, omega:  0.0756, action:  6.0000\n",
      "theta =  2.5059, omega: -0.0945, action:  2.0000\n",
      "theta =  2.5042, omega:  0.0329, action:  5.0000\n",
      "theta =  2.5061, omega:  0.0790, action:  6.0000\n",
      "theta =  2.5058, omega: -0.0928, action:  2.0000\n",
      "theta =  2.5042, omega:  0.0362, action:  5.0000\n",
      "theta =  2.5061, omega:  0.0823, action:  6.0000\n",
      "theta =  2.5064, omega: -0.0896, action:  2.0000\n",
      "theta =  2.5058, omega:  0.0375, action:  5.0000\n",
      "theta =  2.5074, omega:  0.0870, action:  6.0000\n",
      "theta =  2.5077, omega: -0.0879, action:  2.0000\n",
      "theta =  2.5068, omega:  0.0414, action:  5.0000\n",
      "theta =  2.5091, omega:  0.0919, action:  6.0000\n",
      "theta =  2.5084, omega: -0.0843, action:  2.0000\n",
      "theta =  2.5074, omega:  0.0423, action:  5.0000\n",
      "theta =  2.5090, omega:  0.0972, action:  6.0000\n",
      "theta =  2.5091, omega: -0.0792, action:  2.0000\n",
      "theta =  2.5099, omega:  0.0476, action:  5.0000\n",
      "theta =  2.5107, omega: -0.0938, action:  2.0000\n",
      "theta =  2.5077, omega:  0.0422, action:  5.0000\n",
      "theta =  2.5102, omega:  0.0977, action:  6.0000\n",
      "theta =  2.5101, omega: -0.0764, action:  2.0000\n",
      "theta =  2.5111, omega:  0.0481, action:  5.0000\n",
      "theta =  2.5083, omega: -0.0898, action:  2.0000\n",
      "theta =  2.5106, omega:  0.0428, action:  5.0000\n",
      "theta =  2.5099, omega: -0.0952, action:  2.0000\n",
      "theta =  2.5093, omega:  0.0417, action:  5.0000\n",
      "theta =  2.5092, omega: -0.0989, action:  2.0000\n",
      "theta =  2.5066, omega:  0.0408, action:  5.0000\n",
      "theta =  2.5086, omega:  0.0935, action:  6.0000\n",
      "theta =  2.5095, omega: -0.0827, action:  2.0000\n",
      "theta =  2.5097, omega:  0.0463, action:  5.0000\n",
      "theta =  2.5075, omega: -0.0943, action:  2.0000\n",
      "theta =  2.5067, omega:  0.0409, action:  5.0000\n",
      "theta =  2.5123, omega:  0.0950, action:  6.0000\n",
      "theta =  2.5094, omega: -0.0797, action:  2.0000\n",
      "theta =  2.5090, omega:  0.0440, action:  5.0000\n",
      "theta =  2.5078, omega: -0.0955, action:  2.0000\n",
      "theta =  2.5106, omega:  0.0431, action:  5.0000\n",
      "theta =  2.5086, omega: -0.0988, action:  2.0000\n",
      "theta =  2.5076, omega:  0.0395, action:  5.0000\n",
      "theta =  2.5101, omega:  0.0926, action:  6.0000\n",
      "theta =  2.5097, omega: -0.0822, action:  2.0000\n",
      "theta =  2.5095, omega:  0.0443, action:  5.0000\n",
      "theta =  2.5079, omega: -0.0947, action:  2.0000\n",
      "theta =  2.5070, omega:  0.0411, action:  5.0000\n",
      "theta =  2.5107, omega:  0.0957, action:  6.0000\n",
      "theta =  2.5151, omega:  0.1549, action:  3.0000\n",
      "theta =  2.5130, omega: -0.0616, action:  2.0000\n",
      "theta =  2.5139, omega:  0.0596, action:  5.0000\n",
      "theta =  2.5137, omega: -0.0817, action:  2.0000\n",
      "theta =  2.5126, omega:  0.0532, action:  5.0000\n",
      "theta =  2.5012, omega: -0.9863, action:  1.0000\n",
      "theta =  2.4820, omega: -0.6460, action:  7.0000\n",
      "theta =  2.4688, omega: -0.3572, action:  5.0000\n",
      "theta =  2.4634, omega: -0.0980, action:  5.0000\n",
      "theta =  2.4620, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4646, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4616, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4629, omega: -0.0004, action:  5.0000\n",
      "theta =  2.4618, omega:  0.0023, action:  5.0000\n",
      "theta =  2.4631, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4617, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4645, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4629, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4613, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4629, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4621, omega:  0.0024, action:  5.0000\n",
      "theta =  2.4631, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4619, omega: -0.0004, action:  5.0000\n",
      "theta =  2.4626, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4627, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4655, omega: -0.0004, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4625, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4640, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4630, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4622, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4646, omega: -0.0010, action:  5.0000\n",
      "theta =  2.4635, omega:  0.0019, action:  5.0000\n",
      "theta =  2.4641, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4620, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4620, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4623, omega:  0.0027, action:  5.0000\n",
      "theta =  2.4639, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4638, omega: -0.0003, action:  5.0000\n",
      "theta =  2.4623, omega: -0.0009, action:  6.0000\n",
      "theta =  2.4632, omega: -0.0015, action:  5.0000\n",
      "theta =  2.4628, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4616, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4619, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4639, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4649, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0039, action:  5.0000\n",
      "theta =  2.4645, omega:  0.0025, action:  5.0000\n",
      "theta =  2.4634, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4627, omega:  0.0001, action:  5.0000\n",
      "theta =  2.4642, omega:  0.0023, action:  5.0000\n",
      "theta =  2.4639, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4626, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4633, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4640, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4626, omega: -0.0010, action:  5.0000\n",
      "theta =  2.4636, omega: -0.0019, action:  5.0000\n",
      "theta =  2.4640, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4646, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4651, omega:  0.0022, action:  5.0000\n",
      "theta =  2.4630, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4627, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4639, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4641, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4646, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4629, omega: -0.0000, action:  5.0000\n",
      "theta =  2.4658, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4623, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4659, omega:  0.0020, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4640, omega:  0.0019, action:  5.0000\n",
      "theta =  2.4642, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4631, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4619, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4635, omega: -0.0011, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4641, omega: -0.0011, action:  5.0000\n",
      "theta =  2.4659, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4647, omega:  0.0020, action:  5.0000\n",
      "theta =  2.4645, omega:  0.0000, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0028, action:  5.0000\n",
      "theta =  2.4625, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4643, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4645, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4636, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4645, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4650, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4655, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4666, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4634, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4621, omega:  0.0021, action:  5.0000\n",
      "theta =  2.4641, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4630, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4636, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4635, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4635, omega:  0.0043, action:  5.0000\n",
      "theta =  2.4640, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4638, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4647, omega: -0.0002, action:  5.0000\n",
      "theta =  2.4652, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0022, action:  5.0000\n",
      "theta =  2.4657, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4647, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4624, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4630, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4650, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4639, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0000, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4642, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4640, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0020, action:  5.0000\n",
      "theta =  2.4641, omega: -0.0004, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4644, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0000, action:  5.0000\n",
      "theta =  2.4635, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4660, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4658, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0026, action:  5.0000\n",
      "theta =  2.4632, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4641, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4644, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4645, omega: -0.0005, action:  5.0000\n",
      "theta =  2.4652, omega: -0.0002, action:  5.0000\n",
      "theta =  2.4647, omega: -0.0007, action:  5.0000\n",
      "theta =  2.4644, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4643, omega:  0.0031, action:  5.0000\n",
      "theta =  2.4641, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4638, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0020, action:  5.0000\n",
      "theta =  2.4654, omega: -0.0005, action:  5.0000\n",
      "theta =  2.4660, omega:  0.0029, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4666, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4644, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4642, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4653, omega:  0.0019, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4660, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4661, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4649, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4638, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4652, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0021, action:  5.0000\n",
      "theta =  2.4650, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4646, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4658, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4642, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4678, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4633, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4653, omega: -0.0001, action:  5.0000\n",
      "theta =  2.4655, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4649, omega: -0.0003, action:  5.0000\n",
      "theta =  2.4655, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4642, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4668, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4652, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4659, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4649, omega:  0.0014, action:  5.0000\n",
      "theta =  2.4626, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4636, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4651, omega:  0.0022, action:  5.0000\n",
      "theta =  2.4663, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4638, omega:  0.0030, action:  5.0000\n",
      "theta =  2.4645, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4668, omega: -0.0014, action:  5.0000\n",
      "theta =  2.4648, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4658, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4653, omega: -0.0004, action:  5.0000\n",
      "theta =  2.4662, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4662, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4637, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0022, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0026, action:  5.0000\n",
      "theta =  2.4662, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4666, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4680, omega:  0.0021, action:  5.0000\n",
      "theta =  2.4653, omega:  0.0025, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4661, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4662, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4646, omega:  0.0027, action:  5.0000\n",
      "theta =  2.4652, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4659, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4652, omega:  0.0009, action:  5.0000\n",
      "theta =  2.4656, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4664, omega: -0.0012, action:  5.0000\n",
      "theta =  2.4653, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4652, omega: -0.0006, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0024, action:  5.0000\n",
      "theta =  2.4636, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4644, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4660, omega:  0.0019, action:  5.0000\n",
      "theta =  2.4663, omega:  0.0001, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4668, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0026, action:  5.0000\n",
      "theta =  2.4675, omega:  0.0024, action:  5.0000\n",
      "theta =  2.4664, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4654, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4668, omega: -0.0004, action:  5.0000\n",
      "theta =  2.4655, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4667, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4690, omega:  0.0020, action:  5.0000\n",
      "theta =  2.4655, omega:  0.0012, action:  5.0000\n",
      "theta =  2.4678, omega:  0.0018, action:  5.0000\n",
      "theta =  2.4669, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4651, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4684, omega:  0.0003, action:  5.0000\n",
      "theta =  2.4655, omega:  0.0000, action:  5.0000\n",
      "theta =  2.4670, omega:  0.0021, action:  5.0000\n",
      "theta =  2.4661, omega:  0.0026, action:  5.0000\n",
      "theta =  2.4667, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4670, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4669, omega:  0.0004, action:  5.0000\n",
      "theta =  2.4649, omega:  0.0007, action:  5.0000\n",
      "theta =  2.4678, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4659, omega:  0.0008, action:  5.0000\n",
      "theta =  2.4673, omega:  0.0015, action:  5.0000\n",
      "theta =  2.4669, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4675, omega:  0.0027, action:  5.0000\n",
      "theta =  2.4676, omega:  0.0010, action:  5.0000\n",
      "theta =  2.4680, omega:  0.0019, action:  5.0000\n",
      "theta =  2.4667, omega:  0.0001, action:  5.0000\n",
      "theta =  2.4681, omega:  0.0013, action:  5.0000\n",
      "theta =  2.4684, omega:  0.0006, action:  5.0000\n",
      "theta =  2.4658, omega:  0.0016, action:  5.0000\n",
      "theta =  2.4678, omega:  0.0011, action:  5.0000\n",
      "theta =  2.4667, omega:  0.0005, action:  5.0000\n",
      "theta =  2.4687, omega:  0.0023, action:  5.0000\n",
      "theta =  2.4658, omega: -0.0012, action:  5.0000\n",
      "theta =  2.4659, omega:  0.0024, action:  5.0000\n",
      "theta =  2.4658, omega:  0.0001, action:  5.0000\n",
      "theta =  2.4682, omega:  0.0017, action:  5.0000\n",
      "theta =  2.4684, omega:  0.0002, action:  5.0000\n",
      "theta =  2.4484, omega: -1.6110, action:  0.0000\n",
      "theta =  2.3884, omega: -3.2675, action:  0.0000\n",
      "theta =  2.2839, omega: -5.0556, action:  0.0000\n",
      "theta =  2.1498, omega: -5.6482, action:  2.0000\n",
      "theta =  1.9817, omega: -7.8612, action:  0.0000\n",
      "theta =  1.7553, omega: -10.2350, action:  0.0000\n",
      "theta =  1.4679, omega: -12.6661, action:  0.0000\n",
      "theta =  1.1224, omega: -14.9029, action:  0.0000\n",
      "theta =  0.7308, omega: -16.5481, action:  0.0000\n",
      "theta =  0.3057, omega: -17.1761, action:  0.0000\n",
      "theta = -0.1198, omega: -16.5146, action:  0.0000\n",
      "theta = -0.5116, omega: -14.6049, action:  0.0000\n",
      "theta = -0.8414, omega: -11.7563, action:  0.0000\n",
      "theta = -1.0930, omega: -8.3809, action:  0.0000\n",
      "theta = -1.2368, omega: -2.9639, action:  3.0000\n",
      "theta = -1.2451, omega:  2.1840, action:  3.0000\n",
      "theta = -1.1310, omega:  6.9825, action:  3.0000\n",
      "theta = -0.8993, omega:  11.3735, action:  3.0000\n",
      "theta = -0.5692, omega:  15.0474, action:  3.0000\n",
      "theta = -0.1549, omega:  17.6051, action:  3.0000\n",
      "theta =  0.2786, omega:  16.9094, action:  0.0000\n",
      "theta =  0.6785, omega:  14.9748, action:  0.0000\n",
      "theta =  1.0368, omega:  13.5633, action:  2.0000\n",
      "theta =  1.3599, omega:  12.1078, action:  4.0000\n",
      "theta =  1.6415, omega:  10.4941, action:  4.0000\n",
      "theta =  1.8773, omega:  8.5184, action:  2.0000\n",
      "theta =  2.0703, omega:  6.8062, action:  2.0000\n",
      "theta =  2.2187, omega:  5.4030, action:  2.0000\n",
      "theta =  2.3405, omega:  4.3012, action:  2.0000\n",
      "theta =  2.4403, omega:  3.4751, action:  2.0000\n",
      "theta =  2.5168, omega:  2.8831, action:  2.0000\n",
      "theta =  2.5668, omega:  1.0963, action:  0.0000\n",
      "theta =  2.5909, omega:  0.8400, action:  2.0000\n",
      "theta =  2.6118, omega:  0.6509, action:  2.0000\n",
      "theta =  2.6247, omega:  0.5111, action:  2.0000\n",
      "theta =  2.6357, omega:  0.4118, action:  2.0000\n",
      "theta =  2.6448, omega:  0.3444, action:  2.0000\n",
      "theta =  2.6530, omega:  0.3036, action:  2.0000\n",
      "theta =  2.6584, omega:  0.2832, action:  2.0000\n",
      "theta =  2.6664, omega:  0.2858, action:  2.0000\n",
      "theta =  2.6754, omega:  0.3089, action:  2.0000\n",
      "theta =  2.6821, omega:  0.3517, action:  2.0000\n",
      "theta =  2.6774, omega: -0.7395, action:  0.0000\n",
      "theta =  2.6648, omega: -0.3889, action:  2.0000\n",
      "theta =  2.6591, omega: -0.0773, action:  2.0000\n",
      "theta =  2.6590, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6594, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6575, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6571, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6557, omega:  0.0023, action:  2.0000\n",
      "theta =  2.6583, omega:  0.0032, action:  2.0000\n",
      "theta =  2.6556, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6575, omega:  0.0029, action:  2.0000\n",
      "theta =  2.6586, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6572, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6571, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6577, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6577, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6576, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6587, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6562, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6588, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6591, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6569, omega:  0.0034, action:  2.0000\n",
      "theta =  2.6581, omega:  0.0031, action:  2.0000\n",
      "theta =  2.6582, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6589, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6590, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6588, omega:  0.0027, action:  2.0000\n",
      "theta =  2.6588, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6603, omega:  0.0032, action:  2.0000\n",
      "theta =  2.6579, omega:  0.0021, action:  2.0000\n",
      "theta =  2.6591, omega:  0.0035, action:  2.0000\n",
      "theta =  2.6609, omega:  0.0031, action:  2.0000\n",
      "theta =  2.6579, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6612, omega:  0.0033, action:  2.0000\n",
      "theta =  2.6592, omega:  0.0032, action:  2.0000\n",
      "theta =  2.6605, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6592, omega:  0.0036, action:  2.0000\n",
      "theta =  2.6596, omega:  0.0030, action:  2.0000\n",
      "theta =  2.6590, omega:  0.0037, action:  2.0000\n",
      "theta =  2.6594, omega:  0.0040, action:  2.0000\n",
      "theta =  2.6603, omega:  0.0039, action:  2.0000\n",
      "theta =  2.6591, omega:  0.0037, action:  2.0000\n",
      "theta =  2.6614, omega:  0.0030, action:  2.0000\n",
      "theta =  2.6607, omega:  0.0028, action:  2.0000\n",
      "theta =  2.6598, omega:  0.0036, action:  2.0000\n",
      "theta =  2.6590, omega:  0.0041, action:  2.0000\n",
      "theta =  2.6595, omega:  0.0059, action:  2.0000\n",
      "theta =  2.6600, omega:  0.0034, action:  2.0000\n",
      "theta =  2.6608, omega:  0.0047, action:  2.0000\n",
      "theta =  2.6624, omega:  0.0083, action:  2.0000\n",
      "theta =  2.6602, omega:  0.0093, action:  2.0000\n",
      "theta =  2.6606, omega:  0.0122, action:  2.0000\n",
      "theta =  2.6632, omega:  0.0138, action:  2.0000\n",
      "theta =  2.6599, omega:  0.0179, action:  2.0000\n",
      "theta =  2.6616, omega:  0.0238, action:  2.0000\n",
      "theta =  2.6637, omega:  0.0284, action:  2.0000\n",
      "theta =  2.6637, omega:  0.0389, action:  2.0000\n",
      "theta =  2.6671, omega:  0.0489, action:  2.0000\n",
      "theta =  2.6662, omega:  0.0648, action:  2.0000\n",
      "theta =  2.6679, omega:  0.0828, action:  2.0000\n",
      "theta =  2.6706, omega:  0.1057, action:  2.0000\n",
      "theta =  2.6738, omega:  0.1352, action:  2.0000\n",
      "theta =  2.6748, omega:  0.1727, action:  2.0000\n",
      "theta =  2.6826, omega:  0.2230, action:  2.0000\n",
      "theta =  2.6884, omega:  0.2881, action:  2.0000\n",
      "theta =  2.6966, omega:  0.3697, action:  2.0000\n",
      "theta =  2.6921, omega: -0.6863, action:  0.0000\n",
      "theta =  2.6799, omega: -0.2952, action:  2.0000\n",
      "theta =  2.6758, omega:  0.0088, action:  2.0000\n",
      "theta =  2.6769, omega:  0.0585, action:  2.0000\n",
      "theta =  2.6800, omega:  0.1106, action:  2.0000\n",
      "theta =  2.6842, omega:  0.1689, action:  2.0000\n",
      "theta =  2.6875, omega:  0.2347, action:  2.0000\n",
      "theta =  2.6952, omega:  0.3159, action:  2.0000\n",
      "theta =  2.6873, omega: -0.7361, action:  0.0000\n",
      "theta =  2.6753, omega: -0.3521, action:  2.0000\n",
      "theta =  2.6720, omega: -0.0063, action:  2.0000\n",
      "theta =  2.6702, omega:  0.0330, action:  2.0000\n",
      "theta =  2.6728, omega:  0.0677, action:  2.0000\n",
      "theta =  2.6743, omega:  0.1061, action:  2.0000\n",
      "theta =  2.6793, omega:  0.1487, action:  2.0000\n",
      "theta =  2.6811, omega:  0.2029, action:  2.0000\n",
      "theta =  2.6887, omega:  0.2681, action:  2.0000\n",
      "theta =  2.6967, omega:  0.3514, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7058, action:  0.0000\n",
      "theta =  2.6790, omega: -0.3146, action:  2.0000\n",
      "theta =  2.6745, omega:  0.0068, action:  2.0000\n",
      "theta =  2.6775, omega:  0.0485, action:  2.0000\n",
      "theta =  2.6766, omega:  0.0964, action:  2.0000\n",
      "theta =  2.6806, omega:  0.1453, action:  2.0000\n",
      "theta =  2.6850, omega:  0.2052, action:  2.0000\n",
      "theta =  2.6911, omega:  0.2778, action:  2.0000\n",
      "theta =  2.6992, omega:  0.3673, action:  2.0000\n",
      "theta =  2.6949, omega: -0.6836, action:  0.0000\n",
      "theta =  2.6820, omega: -0.2854, action:  2.0000\n",
      "theta =  2.6792, omega:  0.0127, action:  2.0000\n",
      "theta =  2.6818, omega:  0.0677, action:  2.0000\n",
      "theta =  2.6823, omega:  0.1290, action:  2.0000\n",
      "theta =  2.6849, omega:  0.1941, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2743, action:  2.0000\n",
      "theta =  2.7019, omega:  0.3676, action:  2.0000\n",
      "theta =  2.6959, omega: -0.6760, action:  0.0000\n",
      "theta =  2.6837, omega: -0.2750, action:  2.0000\n",
      "theta =  2.6822, omega:  0.0171, action:  2.0000\n",
      "theta =  2.6844, omega:  0.0817, action:  2.0000\n",
      "theta =  2.6867, omega:  0.1482, action:  2.0000\n",
      "theta =  2.6921, omega:  0.2242, action:  2.0000\n",
      "theta =  2.6979, omega:  0.3128, action:  2.0000\n",
      "theta =  2.7061, omega:  0.4215, action:  2.0000\n",
      "theta =  2.7035, omega: -0.6179, action:  0.0000\n",
      "theta =  2.6931, omega: -0.1930, action:  2.0000\n",
      "theta =  2.6907, omega:  0.0473, action:  2.0000\n",
      "theta =  2.6947, omega:  0.1434, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2440, action:  2.0000\n",
      "theta =  2.7071, omega:  0.3578, action:  2.0000\n",
      "theta =  2.7027, omega: -0.6685, action:  0.0000\n",
      "theta =  2.6908, omega: -0.2494, action:  2.0000\n",
      "theta =  2.6891, omega:  0.0316, action:  2.0000\n",
      "theta =  2.6900, omega:  0.1139, action:  2.0000\n",
      "theta =  2.6947, omega:  0.2064, action:  2.0000\n",
      "theta =  2.7027, omega:  0.3061, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7265, action:  0.0000\n",
      "theta =  2.6814, omega: -0.3281, action:  2.0000\n",
      "theta =  2.6787, omega:  0.0071, action:  2.0000\n",
      "theta =  2.6780, omega:  0.0606, action:  2.0000\n",
      "theta =  2.6823, omega:  0.1179, action:  2.0000\n",
      "theta =  2.6864, omega:  0.1794, action:  2.0000\n",
      "theta =  2.6909, omega:  0.2525, action:  2.0000\n",
      "theta =  2.6967, omega:  0.3435, action:  2.0000\n",
      "theta =  2.6936, omega: -0.7057, action:  0.0000\n",
      "theta =  2.6811, omega: -0.3098, action:  2.0000\n",
      "theta =  2.6795, omega:  0.0080, action:  2.0000\n",
      "theta =  2.6777, omega:  0.0580, action:  2.0000\n",
      "theta =  2.6800, omega:  0.1107, action:  2.0000\n",
      "theta =  2.6831, omega:  0.1689, action:  2.0000\n",
      "theta =  2.6886, omega:  0.2361, action:  2.0000\n",
      "theta =  2.6949, omega:  0.3222, action:  2.0000\n",
      "theta =  2.6916, omega: -0.7342, action:  0.0000\n",
      "theta =  2.6762, omega: -0.3454, action:  2.0000\n",
      "theta =  2.6716, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6728, omega:  0.0372, action:  2.0000\n",
      "theta =  2.6750, omega:  0.0743, action:  2.0000\n",
      "theta =  2.6770, omega:  0.1152, action:  2.0000\n",
      "theta =  2.6801, omega:  0.1626, action:  2.0000\n",
      "theta =  2.6852, omega:  0.2188, action:  2.0000\n",
      "theta =  2.6888, omega:  0.2921, action:  2.0000\n",
      "theta =  2.7006, omega:  0.3832, action:  2.0000\n",
      "theta =  2.6955, omega: -0.6696, action:  0.0000\n",
      "theta =  2.6844, omega: -0.2684, action:  2.0000\n",
      "theta =  2.6807, omega:  0.0172, action:  2.0000\n",
      "theta =  2.6828, omega:  0.0790, action:  2.0000\n",
      "theta =  2.6850, omega:  0.1441, action:  2.0000\n",
      "theta =  2.6898, omega:  0.2158, action:  2.0000\n",
      "theta =  2.6971, omega:  0.3001, action:  2.0000\n",
      "theta =  2.6893, omega: -0.7459, action:  0.0000\n",
      "theta =  2.6771, omega: -0.3591, action:  2.0000\n",
      "theta =  2.6708, omega: -0.0124, action:  2.0000\n",
      "theta =  2.6735, omega:  0.0319, action:  2.0000\n",
      "theta =  2.6713, omega:  0.0693, action:  2.0000\n",
      "theta =  2.6751, omega:  0.1086, action:  2.0000\n",
      "theta =  2.6780, omega:  0.1523, action:  2.0000\n",
      "theta =  2.6831, omega:  0.2061, action:  2.0000\n",
      "theta =  2.6880, omega:  0.2750, action:  2.0000\n",
      "theta =  2.7034, omega:  0.8274, action:  6.0000\n",
      "theta =  2.7096, omega: -0.2898, action:  0.0000\n",
      "theta =  2.7073, omega:  0.0459, action:  2.0000\n",
      "theta =  2.7075, omega:  0.1790, action:  2.0000\n",
      "theta =  2.7165, omega:  0.3232, action:  2.0000\n",
      "theta =  2.7107, omega: -0.6746, action:  0.0000\n",
      "theta =  2.6990, omega: -0.2297, action:  2.0000\n",
      "theta =  2.6997, omega:  0.4047, action:  6.0000\n",
      "theta =  2.6989, omega: -0.6456, action:  0.0000\n",
      "theta =  2.6842, omega: -0.2357, action:  2.0000\n",
      "theta =  2.6846, omega:  0.0300, action:  2.0000\n",
      "theta =  2.6866, omega:  0.1021, action:  2.0000\n",
      "theta =  2.6915, omega:  0.1797, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2703, action:  2.0000\n",
      "theta =  2.6889, omega: -0.7694, action:  0.0000\n",
      "theta =  2.6750, omega: -0.3863, action:  2.0000\n",
      "theta =  2.6700, omega: -0.0402, action:  2.0000\n",
      "theta =  2.6702, omega:  0.0270, action:  2.0000\n",
      "theta =  2.6701, omega:  0.0545, action:  2.0000\n",
      "theta =  2.6717, omega:  0.0879, action:  2.0000\n",
      "theta =  2.6731, omega:  0.1239, action:  2.0000\n",
      "theta =  2.6781, omega:  0.1710, action:  2.0000\n",
      "theta =  2.6851, omega:  0.2289, action:  2.0000\n",
      "theta =  2.6918, omega:  0.2980, action:  2.0000\n",
      "theta =  2.6852, omega: -0.7629, action:  0.0000\n",
      "theta =  2.6716, omega: -0.3948, action:  2.0000\n",
      "theta =  2.6649, omega: -0.0649, action:  2.0000\n",
      "theta =  2.6655, omega:  0.0120, action:  2.0000\n",
      "theta =  2.6654, omega:  0.0240, action:  2.0000\n",
      "theta =  2.6669, omega:  0.0366, action:  2.0000\n",
      "theta =  2.6651, omega:  0.0564, action:  2.0000\n",
      "theta =  2.6671, omega:  0.0757, action:  2.0000\n",
      "theta =  2.6697, omega:  0.1016, action:  2.0000\n",
      "theta =  2.6722, omega:  0.1292, action:  2.0000\n",
      "theta =  2.6786, omega:  0.1695, action:  2.0000\n",
      "theta =  2.6818, omega:  0.2191, action:  2.0000\n",
      "theta =  2.6897, omega:  0.2837, action:  2.0000\n",
      "theta =  2.6971, omega:  0.3658, action:  2.0000\n",
      "theta =  2.6925, omega: -0.6921, action:  0.0000\n",
      "theta =  2.6802, omega: -0.3017, action:  2.0000\n",
      "theta =  2.6764, omega:  0.0114, action:  2.0000\n",
      "theta =  2.6777, omega:  0.0570, action:  2.0000\n",
      "theta =  2.6791, omega:  0.1035, action:  2.0000\n",
      "theta =  2.6812, omega:  0.1594, action:  2.0000\n",
      "theta =  2.6859, omega:  0.2227, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2994, action:  2.0000\n",
      "theta =  2.6871, omega: -0.7546, action:  0.0000\n",
      "theta =  2.6712, omega: -0.3784, action:  2.0000\n",
      "theta =  2.6695, omega: -0.0401, action:  2.0000\n",
      "theta =  2.6696, omega:  0.0205, action:  2.0000\n",
      "theta =  2.6677, omega:  0.0431, action:  2.0000\n",
      "theta =  2.6702, omega:  0.0686, action:  2.0000\n",
      "theta =  2.6744, omega:  0.0996, action:  2.0000\n",
      "theta =  2.6761, omega:  0.1358, action:  2.0000\n",
      "theta =  2.6788, omega:  0.1800, action:  2.0000\n",
      "theta =  2.6851, omega:  0.2337, action:  2.0000\n",
      "theta =  2.6897, omega:  0.3074, action:  2.0000\n",
      "theta =  2.6836, omega: -0.7553, action:  0.0000\n",
      "theta =  2.6703, omega: -0.3837, action:  2.0000\n",
      "theta =  2.6639, omega: -0.0517, action:  2.0000\n",
      "theta =  2.6638, omega:  0.0140, action:  2.0000\n",
      "theta =  2.6657, omega:  0.0294, action:  2.0000\n",
      "theta =  2.6669, omega:  0.0476, action:  2.0000\n",
      "theta =  2.6687, omega:  0.0684, action:  2.0000\n",
      "theta =  2.6711, omega:  0.0890, action:  2.0000\n",
      "theta =  2.6730, omega:  0.1206, action:  2.0000\n",
      "theta =  2.6773, omega:  0.1576, action:  2.0000\n",
      "theta =  2.6816, omega:  0.2067, action:  2.0000\n",
      "theta =  2.6861, omega:  0.2676, action:  2.0000\n",
      "theta =  2.6955, omega:  0.3442, action:  2.0000\n",
      "theta =  2.6887, omega: -0.7156, action:  0.0000\n",
      "theta =  2.6753, omega: -0.3306, action:  2.0000\n",
      "theta =  2.6716, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6722, omega:  0.0382, action:  2.0000\n",
      "theta =  2.6740, omega:  0.0755, action:  2.0000\n",
      "theta =  2.6765, omega:  0.1159, action:  2.0000\n",
      "theta =  2.6794, omega:  0.1639, action:  2.0000\n",
      "theta =  2.6844, omega:  0.2228, action:  2.0000\n",
      "theta =  2.6924, omega:  0.2939, action:  2.0000\n",
      "theta =  2.6837, omega: -0.7671, action:  0.0000\n",
      "theta =  2.6710, omega: -0.3948, action:  2.0000\n",
      "theta =  2.6638, omega: -0.0663, action:  2.0000\n",
      "theta =  2.6637, omega:  0.0116, action:  2.0000\n",
      "theta =  2.6653, omega:  0.0265, action:  2.0000\n",
      "theta =  2.6664, omega:  0.0388, action:  2.0000\n",
      "theta =  2.6650, omega:  0.0571, action:  2.0000\n",
      "theta =  2.6661, omega:  0.0774, action:  2.0000\n",
      "theta =  2.6700, omega:  0.1031, action:  2.0000\n",
      "theta =  2.6729, omega:  0.1344, action:  2.0000\n",
      "theta =  2.6777, omega:  0.1750, action:  2.0000\n",
      "theta =  2.6826, omega:  0.2243, action:  2.0000\n",
      "theta =  2.6901, omega:  0.2894, action:  2.0000\n",
      "theta =  2.6974, omega:  0.3740, action:  2.0000\n",
      "theta =  2.6917, omega: -0.6798, action:  0.0000\n",
      "theta =  2.6807, omega: -0.2858, action:  2.0000\n",
      "theta =  2.6805, omega:  0.0117, action:  2.0000\n",
      "theta =  2.6804, omega:  0.0647, action:  2.0000\n",
      "theta =  2.6810, omega:  0.1183, action:  2.0000\n",
      "theta =  2.6846, omega:  0.1782, action:  2.0000\n",
      "theta =  2.6902, omega:  0.2520, action:  2.0000\n",
      "theta =  2.6974, omega:  0.3378, action:  2.0000\n",
      "theta =  2.6939, omega: -0.7120, action:  0.0000\n",
      "theta =  2.6814, omega: -0.3196, action:  2.0000\n",
      "theta =  2.6752, omega:  0.0063, action:  2.0000\n",
      "theta =  2.6776, omega:  0.0521, action:  2.0000\n",
      "theta =  2.6776, omega:  0.1009, action:  2.0000\n",
      "theta =  2.6820, omega:  0.1526, action:  2.0000\n",
      "theta =  2.6883, omega:  0.2161, action:  2.0000\n",
      "theta =  2.6937, omega:  0.2922, action:  2.0000\n",
      "theta =  2.6855, omega: -0.7645, action:  0.0000\n",
      "theta =  2.6767, omega:  0.0185, action:  3.0000\n",
      "theta =  2.6793, omega:  0.0693, action:  2.0000\n",
      "theta =  2.6803, omega:  0.1221, action:  2.0000\n",
      "theta =  2.6847, omega:  0.1835, action:  2.0000\n",
      "theta =  2.6898, omega:  0.2557, action:  2.0000\n",
      "theta =  2.6969, omega:  0.3406, action:  2.0000\n",
      "theta =  2.6909, omega: -0.7077, action:  0.0000\n",
      "theta =  2.6797, omega: -0.3150, action:  2.0000\n",
      "theta =  2.6778, omega:  0.0041, action:  2.0000\n",
      "theta =  2.6777, omega:  0.0538, action:  2.0000\n",
      "theta =  2.6768, omega:  0.1021, action:  2.0000\n",
      "theta =  2.6819, omega:  0.1575, action:  2.0000\n",
      "theta =  2.6877, omega:  0.2218, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2992, action:  2.0000\n",
      "theta =  2.6883, omega: -0.7549, action:  0.0000\n",
      "theta =  2.6738, omega: -0.3773, action:  2.0000\n",
      "theta =  2.6689, omega: -0.0410, action:  2.0000\n",
      "theta =  2.6677, omega:  0.0227, action:  2.0000\n",
      "theta =  2.6676, omega:  0.0440, action:  2.0000\n",
      "theta =  2.6704, omega:  0.0692, action:  2.0000\n",
      "theta =  2.6740, omega:  0.0993, action:  2.0000\n",
      "theta =  2.6743, omega:  0.1347, action:  2.0000\n",
      "theta =  2.6785, omega:  0.1786, action:  2.0000\n",
      "theta =  2.6836, omega:  0.2356, action:  2.0000\n",
      "theta =  2.6918, omega:  0.3060, action:  2.0000\n",
      "theta =  2.6858, omega: -0.7550, action:  0.0000\n",
      "theta =  2.6706, omega: -0.3838, action:  2.0000\n",
      "theta =  2.6648, omega: -0.0536, action:  2.0000\n",
      "theta =  2.6653, omega:  0.0121, action:  2.0000\n",
      "theta =  2.6656, omega:  0.0321, action:  2.0000\n",
      "theta =  2.6717, omega:  0.5157, action:  6.0000\n",
      "theta =  2.6702, omega: -0.6327, action:  0.0000\n",
      "theta =  2.6586, omega: -0.3017, action:  2.0000\n",
      "theta =  2.6536, omega: -0.0041, action:  2.0000\n",
      "theta =  2.6561, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6567, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6556, omega:  0.0026, action:  2.0000\n",
      "theta =  2.6556, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6560, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6550, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6548, omega:  0.0021, action:  2.0000\n",
      "theta =  2.6556, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6552, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6548, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6556, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6547, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6550, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6560, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6539, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6557, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6562, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6552, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6579, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6605, omega:  0.4557, action:  6.0000\n",
      "theta =  2.6565, omega: -0.7120, action:  0.0000\n",
      "theta =  2.6426, omega: -0.4155, action:  2.0000\n",
      "theta =  2.6361, omega: -0.1639, action:  2.0000\n",
      "theta =  2.6349, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6347, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6360, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6357, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6353, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6354, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6338, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6360, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6362, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6343, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6352, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6346, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6358, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6331, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6353, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6348, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6357, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6343, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6343, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6359, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6335, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6361, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6345, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6349, omega: -0.0020, action:  2.0000\n",
      "theta =  2.6359, omega: -0.0024, action:  2.0000\n",
      "theta =  2.6353, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6363, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6343, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6370, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6353, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6346, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6359, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6354, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6354, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6371, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6349, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6356, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6366, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6345, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6349, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6348, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6349, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6347, omega:  0.0021, action:  2.0000\n",
      "theta =  2.6352, omega: -0.0010, action:  2.0000\n",
      "theta =  2.6356, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6351, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6370, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6373, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6346, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6369, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6363, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6359, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6359, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6371, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6365, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6362, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6356, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6351, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6342, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6357, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6357, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6340, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6359, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6350, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6362, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6377, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6358, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6349, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6365, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6354, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6367, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6361, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6348, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6363, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6354, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6351, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6356, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6360, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6357, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6350, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6386, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6410, omega:  0.4005, action:  3.0000\n",
      "theta =  2.6486, omega:  0.3490, action:  2.0000\n",
      "theta =  2.6594, omega:  0.3228, action:  2.0000\n",
      "theta =  2.6662, omega:  0.3222, action:  2.0000\n",
      "theta =  2.6762, omega:  0.3425, action:  2.0000\n",
      "theta =  2.6848, omega:  0.3850, action:  2.0000\n",
      "theta =  2.6771, omega: -0.7116, action:  0.0000\n",
      "theta =  2.6666, omega: -0.3535, action:  2.0000\n",
      "theta =  2.6610, omega: -0.0362, action:  2.0000\n",
      "theta =  2.6634, omega:  0.0048, action:  2.0000\n",
      "theta =  2.6613, omega:  0.0085, action:  2.0000\n",
      "theta =  2.6616, omega:  0.0148, action:  2.0000\n",
      "theta =  2.6605, omega:  0.0201, action:  2.0000\n",
      "theta =  2.6626, omega:  0.0255, action:  2.0000\n",
      "theta =  2.6637, omega:  0.0350, action:  2.0000\n",
      "theta =  2.6640, omega:  0.0460, action:  2.0000\n",
      "theta =  2.6664, omega:  0.0588, action:  2.0000\n",
      "theta =  2.6698, omega:  0.0753, action:  2.0000\n",
      "theta =  2.6691, omega:  0.0990, action:  2.0000\n",
      "theta =  2.6726, omega:  0.1282, action:  2.0000\n",
      "theta =  2.6761, omega:  0.1634, action:  2.0000\n",
      "theta =  2.6791, omega:  0.2099, action:  2.0000\n",
      "theta =  2.6924, omega:  0.7390, action:  7.0000\n",
      "theta =  2.6930, omega: -0.3931, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0027, action:  2.0000\n",
      "theta =  2.6905, omega:  0.0930, action:  2.0000\n",
      "theta =  2.6949, omega:  0.1848, action:  2.0000\n",
      "theta =  2.7003, omega:  0.2874, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7420, action:  0.0000\n",
      "theta =  2.6816, omega: -0.3407, action:  2.0000\n",
      "theta =  2.6782, omega:  0.0039, action:  2.0000\n",
      "theta =  2.6788, omega:  0.0556, action:  2.0000\n",
      "theta =  2.6825, omega:  0.1098, action:  2.0000\n",
      "theta =  2.6834, omega:  0.1699, action:  2.0000\n",
      "theta =  2.6895, omega:  0.2384, action:  2.0000\n",
      "theta =  2.6967, omega:  0.3235, action:  2.0000\n",
      "theta =  2.6885, omega: -0.7255, action:  0.0000\n",
      "theta =  2.6761, omega: -0.3409, action:  2.0000\n",
      "theta =  2.6722, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6745, omega:  0.0412, action:  2.0000\n",
      "theta =  2.6749, omega:  0.0819, action:  2.0000\n",
      "theta =  2.6761, omega:  0.1251, action:  2.0000\n",
      "theta =  2.6811, omega:  0.1765, action:  2.0000\n",
      "theta =  2.6869, omega:  0.2404, action:  2.0000\n",
      "theta =  2.6930, omega:  0.3176, action:  2.0000\n",
      "theta =  2.6877, omega: -0.7389, action:  0.0000\n",
      "theta =  2.6735, omega: -0.3597, action:  2.0000\n",
      "theta =  2.6693, omega: -0.0159, action:  2.0000\n",
      "theta =  2.6688, omega:  0.0270, action:  2.0000\n",
      "theta =  2.6694, omega:  0.0578, action:  2.0000\n",
      "theta =  2.6736, omega:  0.0874, action:  2.0000\n",
      "theta =  2.6776, omega:  0.1240, action:  2.0000\n",
      "theta =  2.6798, omega:  0.1701, action:  2.0000\n",
      "theta =  2.6835, omega:  0.2281, action:  2.0000\n",
      "theta =  2.6893, omega:  0.2962, action:  2.0000\n",
      "theta =  2.6857, omega: -0.7661, action:  0.0000\n",
      "theta =  2.6692, omega: -0.3954, action:  2.0000\n",
      "theta =  2.6646, omega: -0.0661, action:  2.0000\n",
      "theta =  2.6623, omega:  0.0096, action:  2.0000\n",
      "theta =  2.6655, omega:  0.0213, action:  2.0000\n",
      "theta =  2.6646, omega:  0.0342, action:  2.0000\n",
      "theta =  2.6664, omega:  0.0476, action:  2.0000\n",
      "theta =  2.6668, omega:  0.0686, action:  2.0000\n",
      "theta =  2.6682, omega:  0.0892, action:  2.0000\n",
      "theta =  2.6716, omega:  0.1193, action:  2.0000\n",
      "theta =  2.6758, omega:  0.1538, action:  2.0000\n",
      "theta =  2.6804, omega:  0.1991, action:  2.0000\n",
      "theta =  2.6848, omega:  0.2561, action:  2.0000\n",
      "theta =  2.6927, omega:  0.3302, action:  2.0000\n",
      "theta =  2.6883, omega: -0.7320, action:  0.0000\n",
      "theta =  2.6746, omega: -0.3530, action:  2.0000\n",
      "theta =  2.6695, omega: -0.0120, action:  2.0000\n",
      "theta =  2.6685, omega:  0.0258, action:  2.0000\n",
      "theta =  2.6701, omega:  0.0557, action:  2.0000\n",
      "theta =  2.6722, omega:  0.0843, action:  2.0000\n",
      "theta =  2.6743, omega:  0.1207, action:  2.0000\n",
      "theta =  2.6793, omega:  0.1659, action:  2.0000\n",
      "theta =  2.6825, omega:  0.2191, action:  2.0000\n",
      "theta =  2.6886, omega:  0.2853, action:  2.0000\n",
      "theta =  2.6986, omega:  0.3706, action:  2.0000\n",
      "theta =  2.6947, omega: -0.6843, action:  0.0000\n",
      "theta =  2.6822, omega: -0.2900, action:  2.0000\n",
      "theta =  2.6796, omega:  0.0129, action:  2.0000\n",
      "theta =  2.6800, omega:  0.0634, action:  2.0000\n",
      "theta =  2.6810, omega:  0.1195, action:  2.0000\n",
      "theta =  2.6834, omega:  0.1818, action:  2.0000\n",
      "theta =  2.6923, omega:  0.2523, action:  2.0000\n",
      "theta =  2.6973, omega:  0.3401, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7060, action:  0.0000\n",
      "theta =  2.6803, omega: -0.3141, action:  2.0000\n",
      "theta =  2.6763, omega:  0.0065, action:  2.0000\n",
      "theta =  2.6792, omega:  0.0572, action:  2.0000\n",
      "theta =  2.6780, omega:  0.1037, action:  2.0000\n",
      "theta =  2.6847, omega:  0.1621, action:  2.0000\n",
      "theta =  2.6884, omega:  0.2266, action:  2.0000\n",
      "theta =  2.6948, omega:  0.3049, action:  2.0000\n",
      "theta =  2.6866, omega: -0.7493, action:  0.0000\n",
      "theta =  2.6737, omega: -0.3692, action:  2.0000\n",
      "theta =  2.6697, omega: -0.0293, action:  2.0000\n",
      "theta =  2.6684, omega:  0.0243, action:  2.0000\n",
      "theta =  2.6703, omega:  0.0526, action:  2.0000\n",
      "theta =  2.6734, omega:  0.0828, action:  2.0000\n",
      "theta =  2.6743, omega:  0.1189, action:  2.0000\n",
      "theta =  2.6791, omega:  0.1635, action:  2.0000\n",
      "theta =  2.6831, omega:  0.2106, action:  2.0000\n",
      "theta =  2.6873, omega:  0.2778, action:  2.0000\n",
      "theta =  2.6969, omega:  0.3600, action:  2.0000\n",
      "theta =  2.6906, omega: -0.6950, action:  0.0000\n",
      "theta =  2.6774, omega: -0.3044, action:  2.0000\n",
      "theta =  2.6769, omega:  0.0072, action:  2.0000\n",
      "theta =  2.6768, omega:  0.0542, action:  2.0000\n",
      "theta =  2.6786, omega:  0.1023, action:  2.0000\n",
      "theta =  2.6809, omega:  0.1579, action:  2.0000\n",
      "theta =  2.6874, omega:  0.2197, action:  2.0000\n",
      "theta =  2.6922, omega:  0.2981, action:  2.0000\n",
      "theta =  2.6850, omega: -0.7571, action:  0.0000\n",
      "theta =  2.6742, omega: -0.3777, action:  2.0000\n",
      "theta =  2.6676, omega: -0.0405, action:  2.0000\n",
      "theta =  2.6659, omega:  0.0201, action:  2.0000\n",
      "theta =  2.6699, omega:  0.0433, action:  2.0000\n",
      "theta =  2.6710, omega:  0.0689, action:  2.0000\n",
      "theta =  2.6726, omega:  0.0972, action:  2.0000\n",
      "theta =  2.6745, omega:  0.1319, action:  2.0000\n",
      "theta =  2.6791, omega:  0.1776, action:  2.0000\n",
      "theta =  2.6845, omega:  0.2313, action:  2.0000\n",
      "theta =  2.6902, omega:  0.2995, action:  2.0000\n",
      "theta =  2.6835, omega: -0.7616, action:  0.0000\n",
      "theta =  2.6704, omega: -0.3927, action:  2.0000\n",
      "theta =  2.6619, omega: -0.0628, action:  2.0000\n",
      "theta =  2.6642, omega:  0.0097, action:  2.0000\n",
      "theta =  2.6638, omega:  0.0230, action:  2.0000\n",
      "theta =  2.6646, omega:  0.0372, action:  2.0000\n",
      "theta =  2.6665, omega:  0.0537, action:  2.0000\n",
      "theta =  2.6676, omega:  0.0723, action:  2.0000\n",
      "theta =  2.6708, omega:  0.0969, action:  2.0000\n",
      "theta =  2.6731, omega:  0.1248, action:  2.0000\n",
      "theta =  2.6769, omega:  0.1625, action:  2.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m obs, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# policy\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m      9\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/envs/gpy-env/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py:255\u001b[0m, in \u001b[0;36mDQN.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    253\u001b[0m         action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     action, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m action, state\n",
      "File \u001b[0;32m~/anaconda3/envs/gpy-env/lib/python3.10/site-packages/stable_baselines3/common/policies.py:370\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[43mactions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc, assignment]\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msquash_output:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;66;03m# Rescale to proper domain when using squashing\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = DQN_UnbalancedDisk(randomize_friction=False)\n",
    "# best trial 11\n",
    "# Trial 11 finished with value: 1425.5780135999998 and parameters: {'learning_rate': 0.002910910188933282, 'gamma': 0.9629183426032542, 'batch_size': 256, 'n_actions': 10, 'net_arch_style': 'medium', 'activation_fn': 'relu'}\n",
    "#model = DQN.load('optuna_dqn_trials/optuna_best_model_trial_21/best_model.zip')\n",
    "obs, _ = env.reset()\n",
    "for i in range(5000):\n",
    "    action, _states = model.predict(obs)  # policy\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    t = (obs[0] + np.pi)%(2*np.pi) - np.pi\n",
    "    print( f'theta = {t: .4f}, omega: {obs[1]: .4f}, action: {action: .4f}')\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f31fc",
   "metadata": {},
   "source": [
    "# Optuna hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d719c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:02:16,386] A new study created in memory with name: no-name-8ed675e3-11c5-4fd4-bda7-c2f4684cff05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.8e+03 |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1366     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.207    |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.78e+03 |\n",
      "|    exploration_rate | 0.898     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1341      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.193     |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-881.68 +/- 1.47\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -882     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.75e+03 |\n",
      "|    exploration_rate | 0.847     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1063      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0962    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.66e+03 |\n",
      "|    exploration_rate | 0.796     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1136      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.107     |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-799.17 +/- 0.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -799     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.58e+03 |\n",
      "|    exploration_rate | 0.745     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 1042      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0689    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.52e+03 |\n",
      "|    exploration_rate | 0.694     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1077      |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0533    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-778.41 +/- 0.18\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -778     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.0555   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.48e+03 |\n",
      "|    exploration_rate | 0.643     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 1013      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0411    |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.592     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 1038      |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0537    |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-746.38 +/- 0.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -746     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.053    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration_rate | 0.541     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 993       |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0449    |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.32e+03 |\n",
      "|    exploration_rate | 0.49      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 1017      |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0316    |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-747.40 +/- 0.35\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -747     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.28e+03 |\n",
      "|    exploration_rate | 0.439     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 983       |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total_timesteps  | 26400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0181    |\n",
      "|    n_updates        | 6574      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.24e+03 |\n",
      "|    exploration_rate | 0.388     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 1003      |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total_timesteps  | 28800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0242    |\n",
      "|    n_updates        | 7174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-725.82 +/- 0.08\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -726     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.21e+03 |\n",
      "|    exploration_rate | 0.337     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 979       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total_timesteps  | 31200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0186    |\n",
      "|    n_updates        | 7774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.18e+03 |\n",
      "|    exploration_rate | 0.286     |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 991       |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 33600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0192    |\n",
      "|    n_updates        | 8374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-518.37 +/- 11.88\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -518     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.256    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.14e+03 |\n",
      "|    exploration_rate | 0.234     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 966       |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total_timesteps  | 36000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0184    |\n",
      "|    n_updates        | 8974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.11e+03 |\n",
      "|    exploration_rate | 0.183     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 977       |\n",
      "|    time_elapsed     | 39        |\n",
      "|    total_timesteps  | 38400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0336    |\n",
      "|    n_updates        | 9574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-439.96 +/- 10.88\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -440     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration_rate | 0.132     |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 957       |\n",
      "|    time_elapsed     | 42        |\n",
      "|    total_timesteps  | 40800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.0443    |\n",
      "|    n_updates        | 10174     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.01e+03 |\n",
      "|    exploration_rate | 0.0814    |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 971       |\n",
      "|    time_elapsed     | 44        |\n",
      "|    total_timesteps  | 43200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.504     |\n",
      "|    n_updates        | 10774     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-1833.00 +/- 2.86\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.83e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0431    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 45000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 0.918     |\n",
      "|    n_updates        | 11224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -949     |\n",
      "|    exploration_rate | 0.0304   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.795    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -906     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 913      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.872    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-273.91 +/- 2.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -274     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -827     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.614    |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -791     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 907      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.906    |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-210.04 +/- 14.18\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -210     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -275     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=9311.88 +/- 1764.58\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 9.31e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 0.968    |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -213     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -153     |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 1.83     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-234.87 +/- 4.44\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -235     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 142      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 860      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.68     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 314      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.12     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-290.86 +/- 1.25\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -291     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.88     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 387      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.29     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 662      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 854      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 3.32     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-1267.01 +/- 17.25\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.27e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00531   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 75000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000853  |\n",
      "|    loss             | 3.17      |\n",
      "|    n_updates        | 18724     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 701      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 3.05     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 732      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 4.22     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-285.97 +/- 2.62\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -286     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.9      |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 757      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 2.83     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 878      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 836      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 3.87     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-279.71 +/- 5.16\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -280     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 4.05     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 900      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 832      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 3.74     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 922      |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 9.01     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-261.13 +/- 3.45\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -261     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00531  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000853 |\n",
      "|    loss             | 5.85     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:04:04,553] Trial 0 finished with value: 9311.878546 and parameters: {'learning_rate': 0.0008531201903112037, 'exploration_fraction': 0.46778418743876093, 'exploration_final_eps': 0.005306016110069708, 'gamma': 0.9606172326893972, 'target_update_interval': 500, 'batch_size': 256, 'n_actions': 8, 'net_arch_style': 'medium'}. Best is trial 0 with value: 9311.878546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.81e+03 |\n",
      "|    exploration_rate | 0.849     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1208      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000757  |\n",
      "|    loss             | 0.00141   |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.56e+03 |\n",
      "|    exploration_rate | 0.699     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1229      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000757  |\n",
      "|    loss             | 0.00143   |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-775.26 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -775     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.35e+03 |\n",
      "|    exploration_rate | 0.548     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 984       |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000757  |\n",
      "|    loss             | 0.00832   |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.18e+03 |\n",
      "|    exploration_rate | 0.397     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1024      |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000757  |\n",
      "|    loss             | 0.0757    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-601.25 +/- 8.21\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -601     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0382   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -998     |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 929      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0645   |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -905     |\n",
      "|    exploration_rate | 0.0959   |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0629   |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-753.47 +/- 0.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -753     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0583   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0714   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -822     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0763   |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 923      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0541   |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-287.47 +/- 0.78\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -287     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0646   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -716     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -335     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0973   |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-404.07 +/- 4.82\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -404     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -113     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0779   |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -133     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0734   |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-309.46 +/- 0.04\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -309     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -159     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 836      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0889   |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -187     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.069    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-419.16 +/- 6.81\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -419     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -205     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -24.1    |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=3297.84 +/- 7213.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 3.3e+03  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.088    |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -57.4    |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 815      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -92      |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-701.77 +/- 4.53\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -702     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.437    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -124     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 818      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0626   |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -152     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0696   |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-757.85 +/- 0.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -758     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -128     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 820      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-749.67 +/- 1.74\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -750     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0573   |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -182     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -205     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0734   |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-666.26 +/- 0.63\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -666     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0748   |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -227     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -185     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0801   |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 844      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-755.92 +/- 0.54\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -756     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -155     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 836      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -159     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0551   |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-756.17 +/- 0.69\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -756     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -178     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -187     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.695    |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-487.51 +/- 9.41\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -488     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0799   |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -202     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0776   |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -215     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0561   |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-587.76 +/- 10.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -588     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.36     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -224     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.0781   |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -357     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.39     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-305.34 +/- 2.38\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -305     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -460     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.328    |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -467     |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-254.23 +/- 11.66\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -254     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0404   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000757 |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:05:52,816] Trial 1 finished with value: 3297.8401393999993 and parameters: {'learning_rate': 0.0007572839834961514, 'exploration_fraction': 0.1528418630427323, 'exploration_final_eps': 0.04043118557565367, 'gamma': 0.979833080372951, 'target_update_interval': 10000, 'batch_size': 256, 'n_actions': 22, 'net_arch_style': 'huge'}. Best is trial 0 with value: 9311.878546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.77e+03 |\n",
      "|    exploration_rate | 0.931     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1463      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.0148    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.7e+03 |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1377     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00373  |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-794.70 +/- 0.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -795     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00557  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.6e+03 |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1115     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.52e+03 |\n",
      "|    exploration_rate | 0.722     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1178      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00213   |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-771.80 +/- 0.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -772     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.45e+03 |\n",
      "|    exploration_rate | 0.653     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 1072      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.0127    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration_rate | 0.583     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1103      |\n",
      "|    time_elapsed     | 13        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00731   |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-775.18 +/- 1.38\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -775     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00717  |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.32e+03 |\n",
      "|    exploration_rate | 0.514     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 1041      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00608   |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.26e+03 |\n",
      "|    exploration_rate | 0.444     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 1070      |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00459   |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-778.46 +/- 0.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -778     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00527  |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.22e+03 |\n",
      "|    exploration_rate | 0.375     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 1022      |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.0136    |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.18e+03 |\n",
      "|    exploration_rate | 0.306     |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 1039      |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00597   |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-763.73 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -764     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.15e+03 |\n",
      "|    exploration_rate | 0.236     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 1008      |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total_timesteps  | 26400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00612   |\n",
      "|    n_updates        | 6574      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.11e+03 |\n",
      "|    exploration_rate | 0.167     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 1023      |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total_timesteps  | 28800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.00677   |\n",
      "|    n_updates        | 7174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-466.87 +/- 3.17\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -467     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.08e+03 |\n",
      "|    exploration_rate | 0.0972    |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 997       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total_timesteps  | 31200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.02      |\n",
      "|    n_updates        | 7774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 0.0475    |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 1005      |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 33600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.0186    |\n",
      "|    n_updates        | 8374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-726.90 +/- 5.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -727     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.0475    |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 979       |\n",
      "|    time_elapsed     | 36        |\n",
      "|    total_timesteps  | 36000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000321  |\n",
      "|    loss             | 0.0151    |\n",
      "|    n_updates        | 8974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 993      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-799.94 +/- 1.78\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -800     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -964     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 977      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.206    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-776.21 +/- 1.65\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -776     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -925     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -916     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 978      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-772.02 +/- 1.06\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -772     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0985   |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -906     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 965      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0992   |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 975      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-776.17 +/- 8.26\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -776     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -897     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0815   |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-805.94 +/- 3.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -806     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0902   |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -888     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -849     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 963      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -815     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-776.02 +/- 0.17\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -776     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -792     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 960      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -772     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 967      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0577   |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-773.83 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -774     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -755     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -747     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 964      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0915   |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-765.13 +/- 0.97\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -765     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -740     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 955      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0978   |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -736     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 959      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0948   |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-775.04 +/- 0.37\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -775     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0694   |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -733     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0985   |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -727     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 958      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0488   |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-778.24 +/- 0.17\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -778     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -726     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 952      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.083    |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -729     |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.0428   |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-772.03 +/- 1.65\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -772     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0475   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000321 |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:07:27,814] Trial 2 finished with value: -466.873164 and parameters: {'learning_rate': 0.00032108808035123595, 'exploration_fraction': 0.3292000266958512, 'exploration_final_eps': 0.04748099669485608, 'gamma': 0.9704859371227581, 'target_update_interval': 10000, 'batch_size': 512, 'n_actions': 8, 'net_arch_style': 'medium'}. Best is trial 0 with value: 9311.878546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.84e+03 |\n",
      "|    exploration_rate | 0.888     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1272      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.19      |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.71e+03 |\n",
      "|    exploration_rate | 0.776     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1319      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.0734    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-2484.35 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.766     |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 5000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.0678    |\n",
      "|    n_updates        | 1224      |\n",
      "-----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.54e+03 |\n",
      "|    exploration_rate | 0.663     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 703       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.323     |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.551     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 803       |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.533     |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-766.73 +/- 1.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -767     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.414    |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.34e+03 |\n",
      "|    exploration_rate | 0.439     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 802       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.32      |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.27e+03 |\n",
      "|    exploration_rate | 0.327     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 852       |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.148     |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-796.49 +/- 4.12\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -796     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.21e+03 |\n",
      "|    exploration_rate | 0.215     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 836       |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.117     |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.16e+03 |\n",
      "|    exploration_rate | 0.103     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 868       |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.12      |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-747.02 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -747     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0653   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.12e+03 |\n",
      "|    exploration_rate | 0.00638   |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 854       |\n",
      "|    time_elapsed     | 25        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.112     |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.08e+03 |\n",
      "|    exploration_rate | 0.00638   |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 877       |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.0761    |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-745.95 +/- 1.80\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -746     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0827   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.05e+03 |\n",
      "|    exploration_rate | 0.00638   |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 860       |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total_timesteps  | 26400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.056     |\n",
      "|    n_updates        | 6574      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.00638   |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 880       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total_timesteps  | 28800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000243  |\n",
      "|    loss             | 0.0752    |\n",
      "|    n_updates        | 7174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-729.92 +/- 0.04\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -730     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 866      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -983     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-729.22 +/- 0.13\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -729     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -967     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0279   |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -952     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 890      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-728.07 +/- 0.21\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -728     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -927     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-724.67 +/- 0.51\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -725     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -917     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -907     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 892      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00989  |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-727.11 +/- 1.20\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -727     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -899     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -891     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-724.00 +/- 1.25\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -724     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -883     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00953  |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -877     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-716.55 +/- 3.49\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -717     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00855  |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -870     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -825     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00575  |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -790     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 902      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-693.12 +/- 5.16\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -693     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -770     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -755     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 901      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00618  |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-640.06 +/- 7.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -640     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -742     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 894      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -731     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-703.05 +/- 1.82\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -703     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -725     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.00586  |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -717     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-542.93 +/- 3.63\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -543     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -709     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -697     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=1451.86 +/- 3421.28\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.45e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -679     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.454    |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -656     |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.296    |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-289.90 +/- 6.55\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -290     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00638  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000243 |\n",
      "|    loss             | 0.815    |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:09:10,291] Trial 3 finished with value: 1451.8645513999998 and parameters: {'learning_rate': 0.00024275674391600188, 'exploration_fraction': 0.21259207073712108, 'exploration_final_eps': 0.006375113812586001, 'gamma': 0.9579069196138921, 'target_update_interval': 500, 'batch_size': 512, 'n_actions': 20, 'net_arch_style': 'medium'}. Best is trial 0 with value: 9311.878546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.71e+03 |\n",
      "|    exploration_rate | 0.91      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1265      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.00235   |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.56e+03 |\n",
      "|    exploration_rate | 0.82      |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1231      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.00172   |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-763.10 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -763     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.00141  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.46e+03 |\n",
      "|    exploration_rate | 0.73      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1004      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.00438   |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.33e+03 |\n",
      "|    exploration_rate | 0.64      |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1069      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.00586   |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-742.23 +/- 7.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -742     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.00328  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.26e+03 |\n",
      "|    exploration_rate | 0.55      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 974       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.00622   |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.2e+03 |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1010     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-762.49 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -762     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.14e+03 |\n",
      "|    exploration_rate | 0.369     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 958       |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.00528   |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.1e+03 |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 979      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-546.44 +/- 18.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -546     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 0.189     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 931       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.0125    |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.0991    |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 949       |\n",
      "|    time_elapsed     | 25        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.000854  |\n",
      "|    loss             | 0.0174    |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-621.35 +/- 2.33\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -621     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0616   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.00962  |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -991     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 916      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -956     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 929      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.212    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-441.18 +/- 4.67\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -441     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -932     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 905      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -915     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 913      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-639.60 +/- 10.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -640     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -901     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -890     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.073    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-736.55 +/- 1.28\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -737     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0527   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -880     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0876   |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -871     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0393   |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-734.33 +/- 0.52\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -734     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -857     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -850     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 887      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.048    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-723.50 +/- 0.45\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -724     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0747   |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -844     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 874      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.0903   |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -828     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-320.05 +/- 5.63\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -320     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -812     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -793     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-281.94 +/- 7.94\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -282     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.306    |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -775     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -717     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -614     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.5      |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-1801.92 +/- 0.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -1.8e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.384    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -585     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 848      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.364    |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -487     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 851      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.911    |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-207.24 +/- 3.12\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -207     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.906    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -460     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 845      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.561    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -436     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 851      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.989    |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-440.46 +/- 1.40\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -440     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.571    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -407     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 843      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.719    |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -389     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 847      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.52     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-281.31 +/- 1.87\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -281     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -153     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.812    |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -137     |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.923    |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-290.17 +/- 1.36\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -290     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -31.2    |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 824      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.791    |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -21.5    |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 0.799    |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-525.03 +/- 6.00\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -525     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0152   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.000854 |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:10:59,891] Trial 4 finished with value: -207.23530879999998 and parameters: {'learning_rate': 0.0008535044676979867, 'exploration_fraction': 0.2623474295624548, 'exploration_final_eps': 0.015239257752978016, 'gamma': 0.9629114703312606, 'target_update_interval': 5000, 'batch_size': 512, 'n_actions': 14, 'net_arch_style': 'large'}. Best is trial 0 with value: 9311.878546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.81e+03 |\n",
      "|    exploration_rate | 0.937     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1411      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0109    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.75e+03 |\n",
      "|    exploration_rate | 0.874     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1415      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.01      |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-795.64 +/- 0.31\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -796     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.64e+03 |\n",
      "|    exploration_rate | 0.811     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1129      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0177    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.58e+03 |\n",
      "|    exploration_rate | 0.748     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1193      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0104    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-744.87 +/- 0.21\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -745     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.51e+03 |\n",
      "|    exploration_rate | 0.685     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 1084      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.00861   |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.622     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1108      |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0141    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-754.74 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -755     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.607    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration_rate | 0.559     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 1038      |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0153    |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.31e+03 |\n",
      "|    exploration_rate | 0.496     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 1069      |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0257    |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-725.73 +/- 2.55\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -726     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.27e+03 |\n",
      "|    exploration_rate | 0.433     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 1022      |\n",
      "|    time_elapsed     | 21        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0152    |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.22e+03 |\n",
      "|    exploration_rate | 0.37      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 1043      |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0136    |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-616.99 +/- 16.47\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -617     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.18e+03 |\n",
      "|    exploration_rate | 0.308     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 1010      |\n",
      "|    time_elapsed     | 26        |\n",
      "|    total_timesteps  | 26400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0186    |\n",
      "|    n_updates        | 6574      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.13e+03 |\n",
      "|    exploration_rate | 0.245     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 1026      |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total_timesteps  | 28800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0144    |\n",
      "|    n_updates        | 7174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-279.68 +/- 13.31\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -280     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.09e+03 |\n",
      "|    exploration_rate | 0.182     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 997       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total_timesteps  | 31200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0363    |\n",
      "|    n_updates        | 7774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.04e+03 |\n",
      "|    exploration_rate | 0.119     |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 1009      |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 33600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.0633    |\n",
      "|    n_updates        | 8374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-370.19 +/- 6.35\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -370     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.082    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -931     |\n",
      "|    exploration_rate | 0.0557   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 979      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -904     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 989      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.0649   |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=11403.58 +/- 6346.40\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.14e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.349    |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -771     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 927      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -745     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 939      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.818    |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-24.06 +/- 4.48\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -24.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.417    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -723     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.347    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -768     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-536.57 +/- 10.84\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -537     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -832     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -893     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.02     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-2211.06 +/- 0.62\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.21e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00898   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 55000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 0.974     |\n",
      "|    n_updates        | 13724     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -948     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 701      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 678      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-2216.29 +/- 1.79\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.22e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00898   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 60000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 1.25      |\n",
      "|    n_updates        | 14974     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.00898   |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 626       |\n",
      "|    time_elapsed     | 95        |\n",
      "|    total_timesteps  | 60000     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.00898   |\n",
      "| time/               |           |\n",
      "|    episodes         | 104       |\n",
      "|    fps              | 623       |\n",
      "|    time_elapsed     | 100       |\n",
      "|    total_timesteps  | 62400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 2.41      |\n",
      "|    n_updates        | 15574     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.00898   |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 621       |\n",
      "|    time_elapsed     | 104       |\n",
      "|    total_timesteps  | 64800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00685   |\n",
      "|    loss             | 2.5       |\n",
      "|    n_updates        | 16174     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-291.74 +/- 0.95\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -292     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.54     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -974     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 624      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.79     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -942     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 631      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-292.49 +/- 1.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -292     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 3.43     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -905     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 634      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 643      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-264.53 +/- 0.91\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -265     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.24     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -847     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 647      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.38     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -820     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 655      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.68     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=19683.43 +/- 2991.17\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.97e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.32     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -796     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 650      |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -810     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 653      |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2        |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-298.04 +/- 1.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -298     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 1.76     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -790     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 655      |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -777     |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 663      |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.08     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-270.80 +/- 1.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -271     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00898  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00685  |\n",
      "|    loss             | 2.89     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:13:15,975] Trial 5 finished with value: 19683.4258638 and parameters: {'learning_rate': 0.006854834012003672, 'exploration_fraction': 0.37781539370692047, 'exploration_final_eps': 0.00898464888128019, 'gamma': 0.9869285458492697, 'target_update_interval': 1000, 'batch_size': 512, 'n_actions': 13, 'net_arch_style': 'medium'}. Best is trial 5 with value: 19683.4258638.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.52e+03 |\n",
      "|    exploration_rate | 0.831     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1404      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00543   |\n",
      "|    loss             | 0.0129    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.39e+03 |\n",
      "|    exploration_rate | 0.661     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1362      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00543   |\n",
      "|    loss             | 0.0149    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-768.56 +/- 1.69\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -769     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.26e+03 |\n",
      "|    exploration_rate | 0.492     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1085      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00543   |\n",
      "|    loss             | 0.0149    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.15e+03 |\n",
      "|    exploration_rate | 0.322     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1137      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00543   |\n",
      "|    loss             | 0.172     |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-553.69 +/- 4.11\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -554     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 0.153     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 1031      |\n",
      "|    time_elapsed     | 11        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00543   |\n",
      "|    loss             | 0.022     |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -954     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1055     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-346.27 +/- 8.67\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -346     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -680     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 944      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -686     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 940      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.514    |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-292.51 +/- 1.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -293     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.488    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -671     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.457    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -632     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 914      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.794    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-284.08 +/- 0.41\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -284     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -159     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.605    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -211     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 876      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-296.36 +/- 0.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -296     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 2.7      |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -217     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 862      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -221     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.555    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-287.20 +/- 2.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -287     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 0.817    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -225     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 866      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 2.16     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -226     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-293.29 +/- 0.38\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -293     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -214     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 868      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -150     |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-310.76 +/- 0.14\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -311     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 5.34     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 244      |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 846      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 655      |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 3.03     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-2484.48 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0208    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 50000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00543   |\n",
      "|    loss             | 5.71      |\n",
      "|    n_updates        | 12474     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 953      |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 735      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 3.84     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.3e+03  |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 725      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 3.58     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=22819.88 +/- 12.15\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.28e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 8.78     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.64e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 675      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 6.34     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.16e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 662      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 11.5     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=23861.21 +/- 13.99\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.39e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 7.87     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.56e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 613      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.38e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 607      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 7.03     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.29e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 600      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 9.9      |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=25282.76 +/- 12.80\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.53e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 9.83     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.24e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 576      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 15       |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.06e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 576      |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 10.3     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=13515.19 +/- 6.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.35e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 11.1     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.98e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 558      |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 7.6      |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.83e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 554      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 7.79     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=13467.85 +/- 16.89\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.35e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 10.9     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 8.5e+03  |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 545      |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 10.3     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 9.27e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 549      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 8.75     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=20871.29 +/- 3682.46\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.09e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 7.56     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 9.97e+03 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 537      |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.08e+04 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 537      |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 11.8     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=18192.59 +/- 35.87\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.82e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 9.9      |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.14e+04 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 530      |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 7.54     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.23e+04 |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 532      |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 9.79     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=24546.33 +/- 68.15\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.45e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0208   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00543  |\n",
      "|    loss             | 9.85     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:16:07,025] Trial 6 finished with value: 25282.755853 and parameters: {'learning_rate': 0.005429531577496494, 'exploration_fraction': 0.13874049817687506, 'exploration_final_eps': 0.020846582329240512, 'gamma': 0.967470364234846, 'target_update_interval': 500, 'batch_size': 256, 'n_actions': 9, 'net_arch_style': 'large'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.94e+03 |\n",
      "|    exploration_rate | 0.932     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1212      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.00961   |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.9e+03 |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1221     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-949.01 +/- 12.74\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -949     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.75e+03 |\n",
      "|    exploration_rate | 0.796     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1032      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.0319    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.64e+03 |\n",
      "|    exploration_rate | 0.727     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1089      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.134     |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-493.29 +/- 0.09\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -493     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.0486   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.59e+03 |\n",
      "|    exploration_rate | 0.659     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 983       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.0449    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.59e+03 |\n",
      "|    exploration_rate | 0.591     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1020      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.0926    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-769.63 +/- 1.50\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -770     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.5e+03 |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 977      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.0345   |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.43e+03 |\n",
      "|    exploration_rate | 0.455     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 997       |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.048     |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-619.89 +/- 1.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -620     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.35e+03 |\n",
      "|    exploration_rate | 0.387     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 958       |\n",
      "|    time_elapsed     | 22        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.465     |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.3e+03 |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 983      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.0911   |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-825.83 +/- 4.31\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -826     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.25e+03 |\n",
      "|    exploration_rate | 0.251     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 956       |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total_timesteps  | 26400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.0768    |\n",
      "|    n_updates        | 6574      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.2e+03 |\n",
      "|    exploration_rate | 0.182    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.465    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-473.49 +/- 8.85\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -473     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.148    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.279    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.16e+03 |\n",
      "|    exploration_rate | 0.114     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 945       |\n",
      "|    time_elapsed     | 33        |\n",
      "|    total_timesteps  | 31200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.85      |\n",
      "|    n_updates        | 7774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.13e+03 |\n",
      "|    exploration_rate | 0.0462    |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 958       |\n",
      "|    time_elapsed     | 35        |\n",
      "|    total_timesteps  | 33600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.206     |\n",
      "|    n_updates        | 8374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-200.64 +/- 59.78\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -201     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00647  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.674    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.00226   |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 928       |\n",
      "|    time_elapsed     | 38        |\n",
      "|    total_timesteps  | 36000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.384     |\n",
      "|    n_updates        | 8974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -977     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 937      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-284.74 +/- 1.65\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -285     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.747    |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -939     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 917      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.894    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 926      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-294.11 +/- 0.49\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -294     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -870     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 907      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.995    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 914      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 0.857    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-1970.17 +/- 0.69\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.97e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00226   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 50000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 0.654     |\n",
      "|    n_updates        | 12474     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -833     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -807     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 897      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-1856.24 +/- 9.76\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.86e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00226   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 55000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 1.92      |\n",
      "|    n_updates        | 13724     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -835     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 815      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.73     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -847     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 809      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 3.64     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-782.85 +/- 3.60\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -783     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 3.25     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -845     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 797      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -798     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -768     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 796      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.97     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-1249.67 +/- 6.54\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.25e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00226   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 65000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 3.31      |\n",
      "|    n_updates        | 16224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -743     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 3.25     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -714     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-438.17 +/- 7.43\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -438     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 3.2      |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -701     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 784      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.11     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -687     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 777      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.56     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-644.29 +/- 25.51\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -644     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 4.29     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -677     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 773      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.16     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -671     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 1.85     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-805.20 +/- 0.38\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -805     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.99     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -677     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 3.81     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -658     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-306.65 +/- 14.27\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -307     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 6.5      |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -646     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 2.58     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -610     |\n",
      "|    exploration_rate | 0.00226  |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 761      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0079   |\n",
      "|    loss             | 6.05     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-2484.40 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.00226   |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 90000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0079    |\n",
      "|    loss             | 4.44      |\n",
      "|    n_updates        | 22474     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:18:23,441] Trial 7 finished with value: -200.63647659999998 and parameters: {'learning_rate': 0.007896176318298666, 'exploration_fraction': 0.3514758903876649, 'exploration_final_eps': 0.0022551637177505917, 'gamma': 0.9859398067065549, 'target_update_interval': 500, 'batch_size': 256, 'n_actions': 24, 'net_arch_style': 'large'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.71e+03 |\n",
      "|    exploration_rate | 0.875     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 514       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.0366    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.59e+03 |\n",
      "|    exploration_rate | 0.749     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 504       |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.0264    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-776.90 +/- 0.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -777     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.624     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 386       |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.0345    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.3e+03 |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.0516   |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-801.74 +/- 0.57\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -802     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.22e+03 |\n",
      "|    exploration_rate | 0.373     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 390       |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.0131    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.15e+03 |\n",
      "|    exploration_rate | 0.248     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 397       |\n",
      "|    time_elapsed     | 36        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.0143    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-579.69 +/- 8.30\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -580     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.08e+03 |\n",
      "|    exploration_rate | 0.122     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 369       |\n",
      "|    time_elapsed     | 45        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.021     |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.0129    |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 366       |\n",
      "|    time_elapsed     | 52        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 0.0683    |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-407.48 +/- 0.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -407     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -973     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.938    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -531     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 358      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.785    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=3865.52 +/- 6788.55\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 3.87e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 0.856    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -509     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 2.36     |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -507     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 369      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 3.83     |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=3931.15 +/- 5660.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 3.93e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.47     |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -506     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 3.32     |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -40.8    |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 366      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.25     |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=1648.81 +/- 1216.51\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.65e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 6.1      |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -25.7    |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.53     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -44.1    |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 5.51     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-268.32 +/- 2.29\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -268     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.44     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 40       |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.35     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 5.2      |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-293.43 +/- 0.91\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -293     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 3.24     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.76     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.7      |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 5.79     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-1331.60 +/- 3.47\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.33e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0129    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 50000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 4.58      |\n",
      "|    n_updates        | 12474     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 80.3     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 338      |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.83     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 342      |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.08     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-2162.46 +/- 3.32\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.16e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0129    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 55000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 6.95      |\n",
      "|    n_updates        | 13724     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 194      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 325      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 5.63     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 101      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 6.63     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-118.74 +/- 125.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -119     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.99     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 48.7     |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 317      |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 321      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 5.53     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 243      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 322      |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 7.72     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-152.45 +/- 0.94\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -152     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 7.31     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 275      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 323      |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 6.84     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 305      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 326      |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 8.05     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-210.24 +/- 0.50\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -210     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 8.24     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 469      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 323      |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 7.16     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 431      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 321      |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 5.02     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-1985.80 +/- 5.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.99e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0129    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 75000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 7.83      |\n",
      "|    n_updates        | 18724     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 387      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 317      |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 4.6      |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 344      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 3.88     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-2026.61 +/- 0.89\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.03e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0129    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 80000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 5.63      |\n",
      "|    n_updates        | 19974     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 293      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 6.9      |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 135      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 318      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 8.76     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-91.78 +/- 19.69\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -91.8    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 9.22     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 140      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 9.02     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 129      |\n",
      "|    exploration_rate | 0.0129   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 320      |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00376  |\n",
      "|    loss             | 7.87     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-1331.77 +/- 713.68\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.33e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0129    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 90000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00376   |\n",
      "|    loss             | 8.49      |\n",
      "|    n_updates        | 22474     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:23:10,773] Trial 8 finished with value: 3931.1481324 and parameters: {'learning_rate': 0.0037573556403088905, 'exploration_fraction': 0.188985029537983, 'exploration_final_eps': 0.012889221148000077, 'gamma': 0.9611058881129871, 'target_update_interval': 500, 'batch_size': 512, 'n_actions': 12, 'net_arch_style': 'medium'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.79e+03 |\n",
      "|    exploration_rate | 0.922     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 439       |\n",
      "|    time_elapsed     | 5         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0308    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.74e+03 |\n",
      "|    exploration_rate | 0.844     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 466       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0308    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-831.02 +/- 0.93\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -831     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.64e+03 |\n",
      "|    exploration_rate | 0.766     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 441       |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0319    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.56e+03 |\n",
      "|    exploration_rate | 0.688     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 460       |\n",
      "|    time_elapsed     | 20        |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.024     |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-793.35 +/- 1.65\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -793     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.47e+03 |\n",
      "|    exploration_rate | 0.61      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 422       |\n",
      "|    time_elapsed     | 28        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0414    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.38e+03 |\n",
      "|    exploration_rate | 0.532     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 446       |\n",
      "|    time_elapsed     | 32        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0342    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-787.79 +/- 0.91\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -788     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.32e+03 |\n",
      "|    exploration_rate | 0.454     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 443       |\n",
      "|    time_elapsed     | 37        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0219    |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.27e+03 |\n",
      "|    exploration_rate | 0.376     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 446       |\n",
      "|    time_elapsed     | 43        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0449    |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-747.62 +/- 0.21\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -748     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.21e+03 |\n",
      "|    exploration_rate | 0.298     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 437       |\n",
      "|    time_elapsed     | 49        |\n",
      "|    total_timesteps  | 21600     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.0311    |\n",
      "|    n_updates        | 5374      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.14e+03 |\n",
      "|    exploration_rate | 0.22      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 455       |\n",
      "|    time_elapsed     | 52        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.114     |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-405.43 +/- 25.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -405     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 0.142     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 442       |\n",
      "|    time_elapsed     | 59        |\n",
      "|    total_timesteps  | 26400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00231   |\n",
      "|    loss             | 0.275     |\n",
      "|    n_updates        | 6574      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1e+03   |\n",
      "|    exploration_rate | 0.0639   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.487    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-226.49 +/- 2.57\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -226     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -889     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.961    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -839     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 426      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 0.827    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-284.63 +/- 0.66\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -285     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -802     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -754     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 427      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-227.60 +/- 3.56\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -228     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -701     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -678     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 2.15     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-284.64 +/- 0.44\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -285     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 3.87     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -653     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 414      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 2.28     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -633     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 2.5      |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-288.77 +/- 0.82\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -289     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 2.89     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -617     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 2.96     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -601     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 417      |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 3.76     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-282.63 +/- 0.44\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -283     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 3.39     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -587     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.03     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -575     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 421      |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4        |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-286.72 +/- 1.10\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -287     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.05     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -563     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -500     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 415      |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.24     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -445     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 413      |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.04     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-283.59 +/- 0.46\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -284     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.73     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -362     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.77     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -320     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.15     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-281.34 +/- 1.32\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -281     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.95     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -287     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 6.12     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -261     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.49     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-245.31 +/- 2.48\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -245     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 6.69     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -232     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.83     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -208     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 7        |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-288.55 +/- 0.57\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -289     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.81     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -189     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 403      |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.1      |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.73     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-293.71 +/- 1.63\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -294     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 4.96     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.49     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -178     |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 5.18     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-285.07 +/- 1.27\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -285     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0521   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00231  |\n",
      "|    loss             | 6.52     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:26:56,316] Trial 9 finished with value: -226.48711599999996 and parameters: {'learning_rate': 0.002305931970239223, 'exploration_fraction': 0.2916275097319186, 'exploration_final_eps': 0.05208479810922657, 'gamma': 0.9873156890266516, 'target_update_interval': 1000, 'batch_size': 512, 'n_actions': 8, 'net_arch_style': 'medium'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.47e+03 |\n",
      "|    exploration_rate | 0.783     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 698       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00237   |\n",
      "|    loss             | 0.00182   |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.19e+03 |\n",
      "|    exploration_rate | 0.566     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 588       |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00237   |\n",
      "|    loss             | 0.013     |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-280.89 +/- 9.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -281     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.349     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 465       |\n",
      "|    time_elapsed     | 15        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00237   |\n",
      "|    loss             | 0.0134    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -861     |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 507      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-270.08 +/- 13.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -270     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0964   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -656     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 472      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.572    |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -620     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 483      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-286.60 +/- 0.80\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -287     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.206    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -404     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.49     |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -423     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 460      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-643.10 +/- 14.89\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -643     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -450     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 420      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -473     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-534.96 +/- 5.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -535     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -490     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 384      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.355    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -504     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-737.94 +/- 6.56\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -738     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -518     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 380      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -529     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 392      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-617.09 +/- 17.39\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -617     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -539     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -546     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-561.40 +/- 16.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -561     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.0922   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -550     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.165    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -545     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 383      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=7949.22 +/- 6801.92\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 7.95e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -543     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -534     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-235.99 +/- 7.66\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -236     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.313    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -512     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -332     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.392    |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-525.13 +/- 7.61\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -525     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.704    |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -293     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -120     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.427    |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-254.25 +/- 1.54\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -254     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.592    |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 30.8     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 77.3     |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 351      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 495      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.394    |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-256.01 +/- 1.87\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -256     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 514      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.472    |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 515      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.731    |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-240.62 +/- 2.98\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -241     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.581    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 498      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.561    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 498      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.553    |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-435.00 +/- 5.26\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -435     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.385    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 452      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.761    |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 466      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 350      |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.877    |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-380.65 +/- 6.00\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -381     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.479    |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 784      |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.03e+03 |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 344      |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-32.01 +/- 33.32\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -32      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 2.8      |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.43e+03 |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.93e+03 |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 335      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=4407.79 +/- 7200.16\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 4.41e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00136  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00237  |\n",
      "|    loss             | 0.584    |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:31:27,467] Trial 10 finished with value: 7949.219603 and parameters: {'learning_rate': 0.002365370045814019, 'exploration_fraction': 0.11050356516065298, 'exploration_final_eps': 0.001359060904245945, 'gamma': 0.9508628348834633, 'target_update_interval': 5000, 'batch_size': 256, 'n_actions': 18, 'net_arch_style': 'large'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.51e+03 |\n",
      "|    exploration_rate | 0.768     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 502       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00985   |\n",
      "|    loss             | 0.0115    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.33e+03 |\n",
      "|    exploration_rate | 0.536     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 450       |\n",
      "|    time_elapsed     | 10        |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00985   |\n",
      "|    loss             | 0.0178    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-774.69 +/- 0.09\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -775     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.22e+03 |\n",
      "|    exploration_rate | 0.304     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 418       |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00985   |\n",
      "|    loss             | 0.0404    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.12e+03 |\n",
      "|    exploration_rate | 0.0725    |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 407       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00985   |\n",
      "|    loss             | 0.0139    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-751.58 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -752     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0339   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.05e+03 |\n",
      "|    exploration_rate | 0.0213    |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 382       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00985   |\n",
      "|    loss             | 0.01      |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -982     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 381      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-493.22 +/- 2.97\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -493     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -565     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -557     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-290.67 +/- 3.70\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -291     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.503    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -530     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 373      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.571    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -525     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 376      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.813    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-463.34 +/- 14.15\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -463     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.88     |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -533     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 2.48     |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -540     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 2.1      |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-371.92 +/- 41.17\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -372     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 6.7      |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -532     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 368      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 11.4     |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -530     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 0.893    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-345.94 +/- 21.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -346     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.76     |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -523     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 16.5     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -400     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.11     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-307.30 +/- 1.54\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -307     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.22     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -392     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 25.1     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -386     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 13.7     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=3733.14 +/- 7901.88\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 3.73e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.41     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -98.5    |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 353      |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -110     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 12.3     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-284.44 +/- 7.94\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -284     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 2.84     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -116     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.48     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -122     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-296.36 +/- 1.65\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -296     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 11.8     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -127     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 15.7     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -96.1    |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 6.18     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-427.01 +/- 0.65\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -427     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 6.32     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -107     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 354      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -63.8    |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 72.4     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 356      |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 27.5     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-449.91 +/- 12.31\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -450     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 29.7     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 92.9     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 357      |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 105      |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-697.85 +/- 14.39\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -698     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 2.94     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.04     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 157      |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 365      |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 16.9     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-328.22 +/- 16.97\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -328     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 6.85     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 361      |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 91.5     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 9.81     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-238.90 +/- 8.27\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -239     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 14       |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 81.7     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 84.2     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 6.41     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-266.43 +/- 1.16\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -266     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 18.1     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 90.6     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 360      |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 4.96     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 96.6     |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 364      |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 3.5      |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=20820.58 +/- 21.62\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.08e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0213   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00985  |\n",
      "|    loss             | 8.75     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:35:42,729] Trial 11 finished with value: 20820.575138599997 and parameters: {'learning_rate': 0.009854361140511659, 'exploration_fraction': 0.10130018151633134, 'exploration_final_eps': 0.021272417165644746, 'gamma': 0.9733341620058231, 'target_update_interval': 1000, 'batch_size': 256, 'n_actions': 12, 'net_arch_style': 'huge'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.49e+03 |\n",
      "|    exploration_rate | 0.77      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 589       |\n",
      "|    time_elapsed     | 4         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 0.0101    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.31e+03 |\n",
      "|    exploration_rate | 0.541     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 607       |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 0.0137    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-746.27 +/- 0.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -746     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.19e+03 |\n",
      "|    exploration_rate | 0.311     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 499       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 0.0246    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.1e+03 |\n",
      "|    exploration_rate | 0.0814   |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 522      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-759.34 +/- 0.28\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -759     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0432   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.00693  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.03e+03 |\n",
      "|    exploration_rate | 0.0243    |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 444       |\n",
      "|    time_elapsed     | 27        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 0.0128    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -976     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 432      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-497.88 +/- 2.50\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -498     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -902     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.534    |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -826     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 404      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.0481   |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-286.46 +/- 1.97\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -286     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -763     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.057    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -752     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 409      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-848.82 +/- 1.72\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -849     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -626     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 405      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -618     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.438    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-465.29 +/- 5.28\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -465     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.703    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -285     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 407      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.852    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -284     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.915    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=20537.57 +/- 16.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.05e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.785    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -305     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.908    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-288.53 +/- 1.94\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -289     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -302     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 370      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 0.753    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -302     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 374      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-1925.15 +/- 17.25\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.93e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0243    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 45000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 1.85      |\n",
      "|    n_updates        | 11224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -314     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 349      |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 3.7      |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -313     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 355      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 6.49     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-295.99 +/- 10.36\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -296     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 3.81     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -314     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 348      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -281     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 352      |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 3.37     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-854.88 +/- 2.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -855     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 3.56     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -309     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 5.6      |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -395     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 3.89     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-850.00 +/- 0.04\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -850     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 4.73     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -430     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 340      |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -396     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 339      |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 2.55     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -260     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 3.82     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-1709.47 +/- 23.66\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.71e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0243    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 65000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 3.81      |\n",
      "|    n_updates        | 16224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -285     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 326      |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 2.65     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -294     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 329      |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 5.03     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-2484.48 +/- 0.00\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0243    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 70000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 3.76      |\n",
      "|    n_updates        | 17474     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -334     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 306      |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 4.17     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -362     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 309      |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 4.61     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=3548.64 +/- 7601.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 3.55e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 7.07     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 306      |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 5.16     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 314      |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 307      |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 7.35     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=16786.24 +/- 5457.51\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.68e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 6.04     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 520      |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 304      |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 9.65     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 603      |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 303      |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 8.49     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-2484.47 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0243    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 85000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 6.45      |\n",
      "|    n_updates        | 21224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 654      |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 288      |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 12.6     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 581      |\n",
      "|    exploration_rate | 0.0243   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 287      |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00978  |\n",
      "|    loss             | 10.9     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-2484.48 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0243    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 90000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00978   |\n",
      "|    loss             | 10.1      |\n",
      "|    n_updates        | 22474     |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:41:10,754] Trial 12 finished with value: 20537.574299599997 and parameters: {'learning_rate': 0.009775793250269145, 'exploration_fraction': 0.10196235002044642, 'exploration_final_eps': 0.02429503092394037, 'gamma': 0.9741488951223726, 'target_update_interval': 1000, 'batch_size': 256, 'n_actions': 11, 'net_arch_style': 'huge'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.63e+03 |\n",
      "|    exploration_rate | 0.844     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 622       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0123    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.44e+03 |\n",
      "|    exploration_rate | 0.689     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 603       |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0111    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-755.42 +/- 1.58\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -755     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.31e+03 |\n",
      "|    exploration_rate | 0.533     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 448       |\n",
      "|    time_elapsed     | 16        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0256    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.22e+03 |\n",
      "|    exploration_rate | 0.378     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 492       |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0109    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-731.14 +/- 0.89\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -731     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.14e+03 |\n",
      "|    exploration_rate | 0.222     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 463       |\n",
      "|    time_elapsed     | 25        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0136    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration_rate | 0.0856    |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 451       |\n",
      "|    time_elapsed     | 31        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0112    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-738.47 +/- 1.32\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -738     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.0856    |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 434       |\n",
      "|    time_elapsed     | 38        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 0.0223    |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -793     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-761.09 +/- 0.82\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -761     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -753     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 418      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -738     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.0764   |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-748.20 +/- 1.53\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -748     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -588     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -540     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.619    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=19903.72 +/- 3624.77\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.99e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.554    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -542     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 408      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.333    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -522     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 402      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-262.27 +/- 0.76\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -262     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 2.4      |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -504     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 395      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.421    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -488     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 398      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 0.617    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-1.46 +/- 20.13\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -1.46    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -488     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 394      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -401     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 399      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=6246.70 +/- 9472.45\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 6.25e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -241     |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 391      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 389      |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 2.97     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=24649.68 +/- 164.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.46e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 4.23     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 323      |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 377      |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 3.37     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 891      |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 372      |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 5.9      |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=16016.35 +/- 4522.26\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.6e+04  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 6.63     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.24e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 363      |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 5.75     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.74e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 362      |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 12.4     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=17495.04 +/- 4735.46\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.75e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 6.94     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.05e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 345      |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.67e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 346      |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 13.5     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.34e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 343      |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 16.7     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=22858.76 +/- 802.91\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.29e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 16       |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.84e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 325      |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 16.5     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.21e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 328      |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 29       |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-2484.24 +/- 0.04\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.48e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0856    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 70000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.004     |\n",
      "|    loss             | 14        |\n",
      "|    n_updates        | 17474     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.82e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 13.4     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.32e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 313      |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 16.5     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=23843.38 +/- 24.64\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.38e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 16.4     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.71e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 300      |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 20.6     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.24e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 299      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 14.2     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=24245.52 +/- 287.97\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.42e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 13.7     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.89e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 289      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 11.6     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.51e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 288      |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 13.2     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=24257.09 +/- 14.17\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.43e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 13.1     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 8.08e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 12.4     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 8.65e+03 |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 275      |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 10.2     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=24259.50 +/- 11.73\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.43e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0856   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.004    |\n",
      "|    loss             | 13.9     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:46:51,161] Trial 13 finished with value: 24649.675007 and parameters: {'learning_rate': 0.004004079402118777, 'exploration_fraction': 0.1410198900120414, 'exploration_final_eps': 0.08562996975539182, 'gamma': 0.9764055084975232, 'target_update_interval': 1000, 'batch_size': 256, 'n_actions': 16, 'net_arch_style': 'huge'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.66e+03 |\n",
      "|    exploration_rate | 0.849     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 673       |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00364   |\n",
      "|    loss             | 0.0115    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.5e+03 |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 661      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-888.04 +/- 0.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -888     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.33e+03 |\n",
      "|    exploration_rate | 0.548     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 483       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00364   |\n",
      "|    loss             | 0.0334    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.18e+03 |\n",
      "|    exploration_rate | 0.397     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 515       |\n",
      "|    time_elapsed     | 18        |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00364   |\n",
      "|    loss             | 0.0999    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-724.76 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -725     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.08e+03 |\n",
      "|    exploration_rate | 0.247     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 481       |\n",
      "|    time_elapsed     | 24        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00364   |\n",
      "|    loss             | 0.0491    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.0961    |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 485       |\n",
      "|    time_elapsed     | 29        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00364   |\n",
      "|    loss             | 0.0807    |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-581.69 +/- 11.55\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -582     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -863     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -490     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-296.02 +/- 0.40\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -296     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.495    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -457     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 0.738    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -432     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 464      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-254.91 +/- 4.32\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -255     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -414     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 455      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -410     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 464      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 3.08     |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=21276.21 +/- 1702.50\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.13e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 2.46     |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -392     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 423      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 3.05     |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -303     |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 433      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 4.03     |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=20317.44 +/- 1299.05\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.03e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 4.15     |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 534      |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 401      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 5.37     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.24e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 396      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 4.52     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=24046.60 +/- 56.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.4e+04  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 8.82     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.72e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 347      |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 8.43     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.49e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 341      |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 9.83     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=23567.68 +/- 28.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.36e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 6.9      |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.23e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 16.3     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.75e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 321      |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 13.3     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=23841.11 +/- 143.53\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.38e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 7.83     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.16e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 314      |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 14.6     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.53e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 321      |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 9.03     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=24245.16 +/- 30.29\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.42e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 15.6     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.05e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 314      |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 17.5     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.41e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 320      |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 10.1     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=23902.70 +/- 52.73\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.39e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 14.9     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.75e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 313      |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.36e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 317      |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 10.6     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.01e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 322      |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 11.5     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=23994.92 +/- 105.10\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.4e+04  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.6e+03  |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 317      |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 8.96     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 8.16e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 322      |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 13.8     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=23974.34 +/- 24.63\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.4e+04  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 15.5     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 8.8e+03  |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 11.8     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 9.35e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 320      |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 8.44     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=23784.62 +/- 29.16\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.38e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 14.1     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 9.97e+03 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 315      |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 17.1     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.05e+04 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 319      |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 10.1     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=24138.66 +/- 32.99\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.41e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 10.4     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.12e+04 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 312      |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 9.24     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.17e+04 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 316      |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 9.46     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=24118.21 +/- 11.24\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.41e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 17       |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.23e+04 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 311      |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 7.05     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.29e+04 |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 314      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=22375.48 +/- 1340.36\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.24e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0961   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00364  |\n",
      "|    loss             | 11.4     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:51:38,930] Trial 14 finished with value: 24245.1628296 and parameters: {'learning_rate': 0.0036425595833122475, 'exploration_fraction': 0.14399982252715515, 'exploration_final_eps': 0.09612154766675504, 'gamma': 0.9782548759043739, 'target_update_interval': 500, 'batch_size': 256, 'n_actions': 16, 'net_arch_style': 'huge'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.62e+03 |\n",
      "|    exploration_rate | 0.846     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1320      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.0174    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.44e+03 |\n",
      "|    exploration_rate | 0.691     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1360      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.00634   |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-786.68 +/- 0.69\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -787     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.00851  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.31e+03 |\n",
      "|    exploration_rate | 0.537     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1093      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.0203    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.21e+03 |\n",
      "|    exploration_rate | 0.383     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1103      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.0122    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-739.71 +/- 0.20\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -740     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.13e+03 |\n",
      "|    exploration_rate | 0.228     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 980       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.017     |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration_rate | 0.09      |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1002      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.00965   |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-628.19 +/- 5.57\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -628     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -994     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 941      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.0499   |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -943     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.0854   |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-538.92 +/- 8.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -539     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.0862   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -911     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 925      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.053    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -876     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 938      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.0797   |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-272.83 +/- 1.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -273     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -830     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 902      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.194    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -794     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 913      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-561.52 +/- 3.29\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -562     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.428    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -676     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.402    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -651     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-1259.00 +/- 0.33\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.26e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.09      |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 35000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.381     |\n",
      "|    n_updates        | 8724      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -627     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 826      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -604     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 841      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.333    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-287.01 +/- 0.74\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -287     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.533    |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -525     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 827      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.729    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -511     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-1120.88 +/- 0.52\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.12e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.09      |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 45000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 0.784     |\n",
      "|    n_updates        | 11224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -496     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.699    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -485     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 809      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.726    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-288.33 +/- 0.83\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -288     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.824    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -488     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 800      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -424     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 807      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-845.25 +/- 46.99\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -845     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.733    |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -435     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -429     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-223.02 +/- 3.88\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -223     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.84     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -422     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -369     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 807      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.81     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -300     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 811      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-1277.18 +/- 6.38\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.28e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.09      |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 65000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00176   |\n",
      "|    loss             | 1.05      |\n",
      "|    n_updates        | 16224     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -267     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 789      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -246     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 795      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-255.99 +/- 12.59\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -256     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -199     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 797      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-82.00 +/- 4.75\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -82      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 792      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -170     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-201.37 +/- 8.24\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -201     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -113     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 791      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 2.3      |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -110     |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 794      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=12.18 +/- 58.69\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 12.2     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 0.844    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -62.5    |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 785      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 3.69     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -13.5    |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 788      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.06     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-777.85 +/- 0.87\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -778     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.09     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00176  |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:53:34,407] Trial 15 finished with value: 12.1786286 and parameters: {'learning_rate': 0.0017600377482063336, 'exploration_fraction': 0.14147710530038426, 'exploration_final_eps': 0.09002059853708337, 'gamma': 0.9651312107073359, 'target_update_interval': 1000, 'batch_size': 256, 'n_actions': 16, 'net_arch_style': 'large'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.76e+03 |\n",
      "|    exploration_rate | 0.866     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1236      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00011   |\n",
      "|    loss             | 0.00856   |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.52e+03 |\n",
      "|    exploration_rate | 0.732     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1279      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00011   |\n",
      "|    loss             | 0.00415   |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-753.53 +/- 0.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -754     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.36e+03 |\n",
      "|    exploration_rate | 0.598     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1035      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00011   |\n",
      "|    loss             | 0.00211   |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.23e+03 |\n",
      "|    exploration_rate | 0.464     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1073      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00011   |\n",
      "|    loss             | 0.00149   |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-296.61 +/- 1.18\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -297     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.0179   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.14e+03 |\n",
      "|    exploration_rate | 0.33      |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 986       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00011   |\n",
      "|    loss             | 0.0217    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.05e+03 |\n",
      "|    exploration_rate | 0.196     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 1008      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 14400     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00011   |\n",
      "|    loss             | 0.127     |\n",
      "|    n_updates        | 3574      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-469.85 +/- 3.39\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -470     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -904     |\n",
      "|    exploration_rate | 0.0616   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 934      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.363    |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -605     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 936      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-770.06 +/- 0.13\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -770     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -602     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 897      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.415    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -607     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 914      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-235.85 +/- 10.91\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -236     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -594     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -597     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 890      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-458.03 +/- 3.36\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -458     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.439    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -599     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.538    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -599     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-748.80 +/- 0.14\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -749     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.482    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -603     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 870      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.0586   |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -608     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-755.51 +/- 1.13\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -756     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.0772   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -605     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 868      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.395    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -419     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 868      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-604.52 +/- 4.39\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -605     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -370     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -379     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-516.06 +/- 14.56\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -516     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.053    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -391     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -405     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 860      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.307    |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-752.19 +/- 0.57\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -752     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -404     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -414     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-436.64 +/- 4.21\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -437     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.797    |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -400     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -358     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 857      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -334     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-765.53 +/- 1.20\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -766     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -309     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.305    |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -302     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-701.49 +/- 8.14\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -701     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -297     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.78     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -296     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.577    |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-585.37 +/- 5.51\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -585     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -320     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.307    |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -404     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 861      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.885    |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-529.68 +/- 3.78\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -530     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.129    |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -400     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -389     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.695    |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-557.94 +/- 29.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -558     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -389     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -346     |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 854      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.469    |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-261.73 +/- 26.05\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -262     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0316   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00011  |\n",
      "|    loss             | 0.477    |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:55:21,068] Trial 16 finished with value: -235.84519559999998 and parameters: {'learning_rate': 0.00011001099382987985, 'exploration_fraction': 0.17338671031082187, 'exploration_final_eps': 0.03155663062042575, 'gamma': 0.9672522373809624, 'target_update_interval': 10000, 'batch_size': 256, 'n_actions': 19, 'net_arch_style': 'huge'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.52e+03 |\n",
      "|    exploration_rate | 0.799     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1137      |\n",
      "|    time_elapsed     | 2         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00475   |\n",
      "|    loss             | 0.00161   |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.33e+03 |\n",
      "|    exploration_rate | 0.598     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1235      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00475   |\n",
      "|    loss             | 0.00151   |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-189.46 +/- 0.42\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -189     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.17e+03 |\n",
      "|    exploration_rate | 0.397     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1008      |\n",
      "|    time_elapsed     | 7         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00475   |\n",
      "|    loss             | 0.0121    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration_rate | 0.196     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1049      |\n",
      "|    time_elapsed     | 9         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00475   |\n",
      "|    loss             | 0.0121    |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-729.95 +/- 0.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -730     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.00772  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -979     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0912   |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -937     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 986      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-750.05 +/- 1.48\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -750     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0658   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -778     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 916      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -769     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 936      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-442.89 +/- 3.54\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -443     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -753     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 921      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0567   |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-755.05 +/- 0.44\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -755     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0887   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -751     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -751     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 909      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0727   |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-760.18 +/- 1.22\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -760     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -753     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0766   |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -755     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0709   |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-764.68 +/- 0.23\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -765     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -757     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 875      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0412   |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -759     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-805.75 +/- 1.56\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -806     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0392   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -761     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 875      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -762     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-808.34 +/- 1.27\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -808     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -760     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.076    |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -744     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 880      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=7934.30 +/- 7090.09\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 7.93e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -732     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0836   |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -718     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 864      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-354.40 +/- 2.95\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -354     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0552   |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -708     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -695     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-285.22 +/- 3.97\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -285     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.0827   |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -682     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -639     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 864      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -608     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 870      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.728    |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-584.68 +/- 10.21\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -585     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.934    |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -381     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -369     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 857      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.512    |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-454.82 +/- 5.80\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -455     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.637    |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -289     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 849      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.843    |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -280     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 857      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-554.63 +/- 3.15\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -555     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -305     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 849      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.411    |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -289     |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 854      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-523.36 +/- 2.57\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -523     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -41.9    |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 569      |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 814      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.887    |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=7362.49 +/- 9006.96\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 7.36e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 762      |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 788      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.807    |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.16e+03 |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 780      |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.537    |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=-183.51 +/- 2.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -184     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.00349  |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00475  |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 03:57:17,600] Trial 17 finished with value: 7934.3034812 and parameters: {'learning_rate': 0.0047498840765754806, 'exploration_fraction': 0.11900463713171845, 'exploration_final_eps': 0.003488196930060216, 'gamma': 0.9805130596671003, 'target_update_interval': 5000, 'batch_size': 256, 'n_actions': 10, 'net_arch_style': 'large'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.53e+03 |\n",
      "|    exploration_rate | 0.82      |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1459      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 0.0114    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.37e+03 |\n",
      "|    exploration_rate | 0.639     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 1433      |\n",
      "|    time_elapsed     | 3         |\n",
      "|    total_timesteps  | 4800      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 0.0093    |\n",
      "|    n_updates        | 1174      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-797.33 +/- 4.61\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -797     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.00867  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.22e+03 |\n",
      "|    exploration_rate | 0.459     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1081      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 0.026     |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.01e+03 |\n",
      "|    exploration_rate | 0.278     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 1093      |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 9600      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 0.247     |\n",
      "|    n_updates        | 2374      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-676.20 +/- 6.85\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -676     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.248    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -872     |\n",
      "|    exploration_rate | 0.098    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 966      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -687     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-761.33 +/- 1.89\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -761     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.418    |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -722     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 870      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 16800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 4174     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -764     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 852      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 19200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.668    |\n",
      "|    n_updates        | 4774     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-1887.81 +/- 8.76\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.89e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0563    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 20000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 0.437     |\n",
      "|    n_updates        | 4974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -764     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 767      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -714     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 790      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.877    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-286.42 +/- 0.51\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -286     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -675     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 783      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 0.936    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -641     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 798      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.82     |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-1048.98 +/- 12.05\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.05e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0563    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 30000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 0.877     |\n",
      "|    n_updates        | 7474      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -569     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 775      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -528     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 793      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-1233.49 +/- 910.32\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -1.23e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0563    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 35000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00156   |\n",
      "|    loss             | 2.33      |\n",
      "|    n_updates        | 8724      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -505     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 745      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -470     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 759      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-386.91 +/- 3.27\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -387     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 3.25     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -258     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 743      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 4        |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -220     |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 754      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=13421.36 +/- 10540.73\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.34e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 2.19     |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -16.6    |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 707      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 3.56     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 251      |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 709      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 3.7      |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=11483.76 +/- 6216.09\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.15e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 5.23     |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 716      |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 672      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 4.11     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 671      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 6.05     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=23341.35 +/- 11.84\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.33e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 7.73     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.61e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 607      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 4.9      |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.08e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 607      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 5.04     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=22351.71 +/- 133.71\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.24e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 4.92     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.59e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.16e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 6.49     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.88e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 557      |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 11       |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=24309.10 +/- 23.87\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.43e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 7.03     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.58e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 528      |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 6.96     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.27e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 526      |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 8.39     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=23985.13 +/- 30.60\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.4e+04  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 5.68     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6e+03    |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 496      |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 19.2     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.7e+03  |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 494      |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 11.1     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=23909.20 +/- 340.03\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.39e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 8.09     |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.3e+03  |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 474      |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 6.14     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.93e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 476      |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 9.19     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=24145.22 +/- 29.46\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.41e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 17.2     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 8.54e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 457      |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 11.7     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 9.22e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 459      |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 8.75     |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=24468.56 +/- 10.00\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.45e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 15.3     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 9.93e+03 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 450      |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 8.39     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.03e+04 |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 455      |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 6.05     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=24292.46 +/- 10.34\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.43e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0563   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00156  |\n",
      "|    loss             | 7.16     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 04:00:41,877] Trial 18 finished with value: 24468.560498400002 and parameters: {'learning_rate': 0.0015594255051943494, 'exploration_fraction': 0.12555631975036113, 'exploration_final_eps': 0.05626555575554941, 'gamma': 0.9548530525313613, 'target_update_interval': 500, 'batch_size': 256, 'n_actions': 14, 'net_arch_style': 'huge'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.77e+03 |\n",
      "|    exploration_rate | 0.897     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 1233      |\n",
      "|    time_elapsed     | 1         |\n",
      "|    total_timesteps  | 2400      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00511   |\n",
      "|    loss             | 0.0129    |\n",
      "|    n_updates        | 574       |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.6e+03 |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1269     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.00598  |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-759.33 +/- 0.02\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -759     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.00979  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.51e+03 |\n",
      "|    exploration_rate | 0.69      |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 1029      |\n",
      "|    time_elapsed     | 6         |\n",
      "|    total_timesteps  | 7200      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00511   |\n",
      "|    loss             | 0.0294    |\n",
      "|    n_updates        | 1774      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.4e+03 |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1075     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.008    |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-728.33 +/- 0.01\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -728     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.57     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.31e+03 |\n",
      "|    exploration_rate | 0.484     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 982       |\n",
      "|    time_elapsed     | 12        |\n",
      "|    total_timesteps  | 12000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00511   |\n",
      "|    loss             | 0.0154    |\n",
      "|    n_updates        | 2974      |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -1.2e+03 |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1017     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 14400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.0752   |\n",
      "|    n_updates        | 3574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-169.01 +/- 1.66\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -169     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.0457   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.07e+03 |\n",
      "|    exploration_rate | 0.277     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 965       |\n",
      "|    time_elapsed     | 17        |\n",
      "|    total_timesteps  | 16800     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00511   |\n",
      "|    loss             | 0.196     |\n",
      "|    n_updates        | 4174      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 600       |\n",
      "|    ep_rew_mean      | -1.04e+03 |\n",
      "|    exploration_rate | 0.174     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 987       |\n",
      "|    time_elapsed     | 19        |\n",
      "|    total_timesteps  | 19200     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00511   |\n",
      "|    loss             | 0.102     |\n",
      "|    n_updates        | 4774      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-438.20 +/- 27.72\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -438     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.139    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.0691   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -988     |\n",
      "|    exploration_rate | 0.0705   |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 950      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 5374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -926     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 970      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 24000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 5974     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-460.67 +/- 2.75\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -461     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.0879   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -586     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 921      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 26400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.417    |\n",
      "|    n_updates        | 6574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -568     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 936      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 28800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.483    |\n",
      "|    n_updates        | 7174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-296.32 +/- 0.64\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -296     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -546     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 912      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 31200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.594    |\n",
      "|    n_updates        | 7774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -526     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 924      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 33600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.567    |\n",
      "|    n_updates        | 8374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-150.17 +/- 0.61\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -150     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.453    |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -509     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 906      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 36000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.363    |\n",
      "|    n_updates        | 8974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -512     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 909      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 38400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.729    |\n",
      "|    n_updates        | 9574     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-242.33 +/- 1.68\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -242     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -497     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 40800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 10174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -27.3    |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 43200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.685    |\n",
      "|    n_updates        | 10774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-257.77 +/- 2.34\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | -258     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.679    |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -53.2    |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 854      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 45600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 11374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -66.5    |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 857      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 48000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.892    |\n",
      "|    n_updates        | 11974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=1754.46 +/- 2592.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.75e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 0.923    |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 825      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 50400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 12574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 245      |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 811      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 52800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 2.86     |\n",
      "|    n_updates        | 13174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=4738.52 +/- 9745.95\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 4.74e+03 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 321      |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 787      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 3.18     |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 308      |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 794      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 57600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 4.26     |\n",
      "|    n_updates        | 14374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=11308.51 +/- 4372.41\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.13e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 2.87     |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 424      |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 757      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 60000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 501      |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 764      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 62400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 2.65     |\n",
      "|    n_updates        | 15574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 977      |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 754      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 4.68     |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=21827.34 +/- 62.73\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.18e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 7.53     |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 1.48e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 704      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 67200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 7.19     |\n",
      "|    n_updates        | 16774    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.05e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 695      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 69600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 6.11     |\n",
      "|    n_updates        | 17374    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=22983.35 +/- 16.59\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.3e+04  |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 7.08     |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 2.66e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 640      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 6.64     |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.53e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 627      |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 74400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 6.01     |\n",
      "|    n_updates        | 18574    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-2454.85 +/- 0.04\n",
      "Episode length: 600.00 +/- 0.00\n",
      "-----------------------------------\n",
      "| eval/               |           |\n",
      "|    mean_ep_length   | 600       |\n",
      "|    mean_reward      | -2.45e+03 |\n",
      "| rollout/            |           |\n",
      "|    exploration_rate | 0.0163    |\n",
      "| time/               |           |\n",
      "|    total_timesteps  | 75000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.00511   |\n",
      "|    loss             | 6.85      |\n",
      "|    n_updates        | 18724     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 3.98e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 594      |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 76800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 11.3     |\n",
      "|    n_updates        | 19174    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 4.76e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 79200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 11.4     |\n",
      "|    n_updates        | 19774    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=15270.83 +/- 2634.06\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 1.53e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 10.1     |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 5.4e+03  |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 578      |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 81600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 14.2     |\n",
      "|    n_updates        | 20374    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.14e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 574      |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 17       |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=24281.05 +/- 23.07\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.43e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 12.6     |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 6.73e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 546      |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 86400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 17.4     |\n",
      "|    n_updates        | 21574    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | 7.52e+03 |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 544      |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 88800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 14.8     |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 90000 steps because the DQN model reached max_episodes=150, by playing for 150 episodes \n",
      "Eval num_timesteps=90000, episode_reward=23472.70 +/- 518.09\n",
      "Episode length: 600.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 600      |\n",
      "|    mean_reward      | 2.35e+04 |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0163   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.00511  |\n",
      "|    loss             | 10.8     |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 04:03:33,046] Trial 19 finished with value: 24281.047806199997 and parameters: {'learning_rate': 0.005105125464393112, 'exploration_fraction': 0.22859800313973272, 'exploration_final_eps': 0.016319978931880516, 'gamma': 0.9746110545342782, 'target_update_interval': 1000, 'batch_size': 256, 'n_actions': 17, 'net_arch_style': 'large'}. Best is trial 6 with value: 25282.755853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial value: 25282.755853\n",
      "Best hyperparameters: {'learning_rate': 0.005429531577496494, 'exploration_fraction': 0.13874049817687506, 'exploration_final_eps': 0.020846582329240512, 'gamma': 0.967470364234846, 'target_update_interval': 500, 'batch_size': 256, 'n_actions': 9, 'net_arch_style': 'large'}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnMaxEpisodes, CallbackList\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "\n",
    "\n",
    "# def set_seed(seed):\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "\n",
    "def objective(trial):\n",
    "    # set_seed(42)  # Fixed seed for reproducibility\n",
    "\n",
    "    # Sample hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    # ent_coef = trial.suggest_float(\"ent_coef\", 1e-5, 0.1, log=True)\n",
    "    exploration_fraction = trial.suggest_float(\"exploration_fraction\", 0.1, 0.5, log=True)\n",
    "    exploration_final_eps = trial.suggest_float(\"exploration_final_eps\", 1e-3, 0.1, log=True)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.95, 0.99)\n",
    "    target_update_interval = trial.suggest_categorical(\"target_update_interval\", [500, 1000, 5000, 10_000])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512])\n",
    "    n_actions = trial.suggest_int(\"n_actions\", 8, 24)\n",
    "    net_arch = trial.suggest_categorical(\"net_arch_style\", [\"medium\", \"large\", \"huge\"])\n",
    "    if net_arch == \"medium\":\n",
    "        net_arch_cfg = [128, 128]\n",
    "    elif net_arch == \"large\":\n",
    "        net_arch_cfg = [128, 128, 128]\n",
    "    elif net_arch == \"huge\":\n",
    "        net_arch_cfg = [256, 256, 256]\n",
    "\n",
    "\n",
    "    policy_kwargs = dict(\n",
    "        net_arch=net_arch_cfg,\n",
    "        activation_fn=nn.ReLU\n",
    "    )\n",
    "    #buffer_size = trial.suggest_categorical(\"buffer_size\", [10_000, 100_000, 500_000])\n",
    "\n",
    "    # Training env\n",
    "    env = Monitor(TimeLimit(DQN_UnbalancedDisk(n_actions=n_actions,randomize_friction=True), max_episode_steps=600))\n",
    "\n",
    "    # Evaluation env (no random friction)\n",
    "    eval_env = Monitor(TimeLimit(DQN_UnbalancedDisk(n_actions=n_actions,randomize_friction=False), max_episode_steps=600))\n",
    "\n",
    "    # Callbacks\n",
    "    stop_cb = StopTrainingOnMaxEpisodes(max_episodes=150, verbose=1)\n",
    "    eval_cb = EvalCallback(\n",
    "        eval_env,\n",
    "        best_model_save_path=f\"./optuna_dqn2_trials/optuna_best_model_trial_{trial.number}\",\n",
    "        log_path=None,\n",
    "        eval_freq=5000,\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "    )\n",
    "    callback = CallbackList([stop_cb, eval_cb])\n",
    "\n",
    "    # Model\n",
    "    model = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=learning_rate,\n",
    "        exploration_fraction=exploration_fraction,\n",
    "        exploration_final_eps=exploration_final_eps,\n",
    "        target_update_interval=target_update_interval,\n",
    "        gamma=gamma,\n",
    "        batch_size=batch_size,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        verbose=1,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=1_00_000, callback=callback)\n",
    "\n",
    "    return eval_cb.best_mean_reward\n",
    "\n",
    "# Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(), pruner=MedianPruner())\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Show best result\n",
    "print(\"Best trial value:\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1db8e471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  0.0248, omega:  1.9001, action:  7.0000\n",
      "theta =  0.0932, omega:  3.5875, action:  7.0000\n",
      "theta =  0.2005, omega:  4.9387, action:  7.0000\n",
      "theta =  0.3354, omega:  5.8683, action:  7.0000\n",
      "theta =  0.4902, omega:  6.3334, action:  5.0000\n",
      "theta =  0.6515, omega:  6.3463, action:  5.0000\n",
      "theta =  0.8072, omega:  5.9622, action:  6.0000\n",
      "theta =  0.9444, omega:  5.2645, action:  6.0000\n",
      "theta =  1.0654, omega:  4.3463, action:  6.0000\n",
      "theta =  1.1611, omega:  3.2914, action:  6.0000\n",
      "theta =  1.2294, omega:  2.1637, action:  6.0000\n",
      "theta =  1.2481, omega: -0.6836, action:  0.0000\n",
      "theta =  1.2005, omega: -3.2563, action:  0.0000\n",
      "theta =  1.0866, omega: -5.6508, action:  0.0000\n",
      "theta =  0.9166, omega: -7.7547, action:  0.0000\n",
      "theta =  0.7014, omega: -9.4096, action:  0.0000\n",
      "theta =  0.4511, omega: -10.4468, action:  0.0000\n",
      "theta =  0.1853, omega: -10.7127, action:  0.0000\n",
      "theta = -0.0759, omega: -10.1482, action:  0.0000\n",
      "theta = -0.3158, omega: -8.8129, action:  0.0000\n",
      "theta = -0.5135, omega: -6.8613, action:  0.0000\n",
      "theta = -0.6558, omega: -4.5048, action:  0.0000\n",
      "theta = -0.7346, omega: -1.9381, action:  0.0000\n",
      "theta = -0.7517, omega:  0.5186, action:  0.0000\n",
      "theta = -0.7042, omega:  3.1636, action:  1.0000\n",
      "theta = -0.5816, omega:  6.8983, action:  7.0000\n",
      "theta = -0.3670, omega:  10.0513, action:  8.0000\n",
      "theta = -0.0837, omega:  12.3617, action:  8.0000\n",
      "theta =  0.2430, omega:  13.6368, action:  8.0000\n",
      "theta =  0.5886, omega:  13.8405, action:  8.0000\n",
      "theta =  0.9288, omega:  13.1444, action:  8.0000\n",
      "theta =  1.2410, omega:  11.8497, action:  8.0000\n",
      "theta =  1.5199, omega:  10.2904, action:  8.0000\n",
      "theta =  1.7554, omega:  8.7325, action:  8.0000\n",
      "theta =  1.9579, omega:  7.3471, action:  8.0000\n",
      "theta =  2.1257, omega:  6.2216, action:  8.0000\n",
      "theta =  2.2640, omega:  4.9250, action:  2.0000\n",
      "theta =  2.3742, omega:  3.9192, action:  2.0000\n",
      "theta =  2.4615, omega:  3.1694, action:  2.0000\n",
      "theta =  2.5326, omega:  2.6369, action:  2.0000\n",
      "theta =  2.5785, omega:  0.8953, action:  0.0000\n",
      "theta =  2.5976, omega:  0.6712, action:  2.0000\n",
      "theta =  2.6127, omega:  0.4990, action:  2.0000\n",
      "theta =  2.6242, omega:  0.3678, action:  2.0000\n",
      "theta =  2.6301, omega:  0.2660, action:  2.0000\n",
      "theta =  2.6371, omega:  0.1862, action:  2.0000\n",
      "theta =  2.6398, omega:  0.1197, action:  2.0000\n",
      "theta =  2.6426, omega:  0.0635, action:  2.0000\n",
      "theta =  2.6435, omega:  0.0151, action:  2.0000\n",
      "theta =  2.6425, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6442, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6429, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6433, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6439, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6434, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6440, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6450, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6440, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6440, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6494, omega:  0.4217, action:  6.0000\n",
      "theta =  2.6652, omega:  0.8586, action:  5.0000\n",
      "theta =  2.6690, omega: -0.3607, action:  0.0000\n",
      "theta =  2.6692, omega:  0.2680, action:  7.0000\n",
      "theta =  2.6780, omega:  0.2992, action:  2.0000\n",
      "theta =  2.6842, omega:  0.3489, action:  2.0000\n",
      "theta =  2.6938, omega:  0.4212, action:  2.0000\n",
      "theta =  2.6919, omega: -0.6499, action:  0.0000\n",
      "theta =  2.6849, omega:  0.0694, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1398, action:  2.0000\n",
      "theta =  2.6909, omega:  0.2199, action:  2.0000\n",
      "theta =  2.6984, omega:  0.3128, action:  2.0000\n",
      "theta =  2.6919, omega: -0.7316, action:  0.0000\n",
      "theta =  2.6843, omega:  0.0813, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1552, action:  2.0000\n",
      "theta =  2.6933, omega:  0.2356, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3311, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7080, action:  0.0000\n",
      "theta =  2.6864, omega:  0.0789, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1602, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2527, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3537, action:  2.0000\n",
      "theta =  2.6982, omega: -0.6826, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0546, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1452, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2462, action:  2.0000\n",
      "theta =  2.7062, omega:  0.3608, action:  2.0000\n",
      "theta =  2.7037, omega: -0.6681, action:  0.0000\n",
      "theta =  2.6952, omega:  0.0815, action:  7.0000\n",
      "theta =  2.7016, omega:  0.1868, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2988, action:  2.0000\n",
      "theta =  2.6989, omega: -0.7243, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0812, action:  7.0000\n",
      "theta =  2.6950, omega:  0.1729, action:  2.0000\n",
      "theta =  2.7027, omega:  0.2758, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7522, action:  0.0000\n",
      "theta =  2.6848, omega:  0.0438, action:  7.0000\n",
      "theta =  2.6881, omega:  0.1220, action:  2.0000\n",
      "theta =  2.6891, omega:  0.2010, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2944, action:  2.0000\n",
      "theta =  2.6919, omega: -0.7436, action:  0.0000\n",
      "theta =  2.6845, omega:  0.0504, action:  7.0000\n",
      "theta =  2.6855, omega:  0.1190, action:  2.0000\n",
      "theta =  2.6902, omega:  0.1952, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2839, action:  2.0000\n",
      "theta =  2.6892, omega: -0.7579, action:  0.0000\n",
      "theta =  2.6814, omega:  0.0503, action:  7.0000\n",
      "theta =  2.6830, omega:  0.1120, action:  2.0000\n",
      "theta =  2.6866, omega:  0.1807, action:  2.0000\n",
      "theta =  2.6936, omega:  0.2600, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3538, action:  2.0000\n",
      "theta =  2.6959, omega: -0.6922, action:  0.0000\n",
      "theta =  2.6882, omega:  0.0383, action:  7.0000\n",
      "theta =  2.6896, omega:  0.1208, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2081, action:  2.0000\n",
      "theta =  2.7003, omega:  0.3066, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7289, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0833, action:  7.0000\n",
      "theta =  2.6966, omega:  0.6282, action:  3.0000\n",
      "theta =  2.6991, omega: -0.4729, action:  0.0000\n",
      "theta =  2.6938, omega:  0.2085, action:  7.0000\n",
      "theta =  2.7021, omega:  0.3114, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7244, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0709, action:  7.0000\n",
      "theta =  2.6901, omega:  0.1501, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2413, action:  2.0000\n",
      "theta =  2.7033, omega:  0.3432, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6906, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0446, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1370, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2335, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3420, action:  2.0000\n",
      "theta =  2.7004, omega: -0.6882, action:  0.0000\n",
      "theta =  2.6938, omega:  0.0562, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1517, action:  2.0000\n",
      "theta =  2.7010, omega:  0.2570, action:  2.0000\n",
      "theta =  2.6941, omega: -0.7705, action:  0.0000\n",
      "theta =  2.6879, omega:  0.0526, action:  7.0000\n",
      "theta =  2.6900, omega:  0.1254, action:  2.0000\n",
      "theta =  2.6919, omega:  0.2078, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2989, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7430, action:  0.0000\n",
      "theta =  2.6847, omega:  0.0519, action:  7.0000\n",
      "theta =  2.6870, omega:  0.1212, action:  2.0000\n",
      "theta =  2.6891, omega:  0.1985, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2845, action:  2.0000\n",
      "theta =  2.6882, omega: -0.7573, action:  0.0000\n",
      "theta =  2.6819, omega:  0.0512, action:  7.0000\n",
      "theta =  2.6821, omega:  0.1127, action:  2.0000\n",
      "theta =  2.6876, omega:  0.1821, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2610, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3547, action:  2.0000\n",
      "theta =  2.6958, omega: -0.6876, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0442, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1248, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2162, action:  2.0000\n",
      "theta =  2.7037, omega:  0.3180, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7183, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0767, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1581, action:  2.0000\n",
      "theta =  2.7037, omega:  0.7153, action:  3.0000\n",
      "theta =  2.7066, omega: -0.3834, action:  0.0000\n",
      "theta =  2.7073, omega:  0.3111, action:  7.0000\n",
      "theta =  2.7011, omega: -0.7107, action:  0.0000\n",
      "theta =  2.6911, omega:  0.0327, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1276, action:  2.0000\n",
      "theta =  2.6979, omega:  0.2284, action:  2.0000\n",
      "theta =  2.7052, omega:  0.3417, action:  2.0000\n",
      "theta =  2.7012, omega: -0.6837, action:  0.0000\n",
      "theta =  2.6942, omega:  0.0618, action:  7.0000\n",
      "theta =  2.6969, omega:  0.1614, action:  2.0000\n",
      "theta =  2.7014, omega:  0.2704, action:  2.0000\n",
      "theta =  2.6982, omega: -0.7525, action:  0.0000\n",
      "theta =  2.6888, omega:  0.0520, action:  7.0000\n",
      "theta =  2.6904, omega:  0.1320, action:  2.0000\n",
      "theta =  2.6942, omega:  0.2211, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3195, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7156, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0800, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1637, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2566, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3646, action:  2.0000\n",
      "theta =  2.6999, omega: -0.6698, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0769, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1763, action:  2.0000\n",
      "theta =  2.7054, omega:  0.2840, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7418, action:  0.0000\n",
      "theta =  2.6905, omega:  0.0811, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1671, action:  2.0000\n",
      "theta =  2.6971, omega:  0.2591, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3678, action:  2.0000\n",
      "theta =  2.6984, omega: -0.6639, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0805, action:  7.0000\n",
      "theta =  2.6983, omega:  0.1821, action:  2.0000\n",
      "theta =  2.7044, omega:  0.2909, action:  2.0000\n",
      "theta =  2.6999, omega: -0.7302, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0687, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1531, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2509, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3629, action:  2.0000\n",
      "theta =  2.7007, omega: -0.6680, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0800, action:  7.0000\n",
      "theta =  2.6989, omega:  0.1820, action:  2.0000\n",
      "theta =  2.7025, omega:  0.2906, action:  2.0000\n",
      "theta =  2.6985, omega: -0.7318, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0709, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1575, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2547, action:  2.0000\n",
      "theta =  2.7067, omega:  0.3692, action:  2.0000\n",
      "theta =  2.7017, omega: -0.6619, action:  0.0000\n",
      "theta =  2.6939, omega:  0.0852, action:  7.0000\n",
      "theta =  2.7004, omega:  0.1891, action:  2.0000\n",
      "theta =  2.7058, omega:  0.3036, action:  2.0000\n",
      "theta =  2.7006, omega: -0.7175, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0869, action:  7.0000\n",
      "theta =  2.6965, omega:  0.1813, action:  2.0000\n",
      "theta =  2.7019, omega:  0.2844, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7451, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0556, action:  7.0000\n",
      "theta =  2.6896, omega:  0.1365, action:  2.0000\n",
      "theta =  2.6942, omega:  0.2214, action:  2.0000\n",
      "theta =  2.7008, omega:  0.3217, action:  2.0000\n",
      "theta =  2.6965, omega: -0.7130, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0779, action:  7.0000\n",
      "theta =  2.6897, omega:  0.1615, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2539, action:  2.0000\n",
      "theta =  2.7043, omega:  0.3582, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6765, action:  0.0000\n",
      "theta =  2.6949, omega:  0.0662, action:  7.0000\n",
      "theta =  2.6960, omega:  0.1601, action:  2.0000\n",
      "theta =  2.7001, omega:  0.2634, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7627, action:  0.0000\n",
      "theta =  2.6859, omega:  0.0630, action:  7.0000\n",
      "theta =  2.6894, omega:  0.1363, action:  2.0000\n",
      "theta =  2.6918, omega:  0.2200, action:  2.0000\n",
      "theta =  2.6982, omega:  0.3169, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7229, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0676, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1459, action:  2.0000\n",
      "theta =  2.6988, omega:  0.6969, action:  7.0000\n",
      "theta =  2.7021, omega: -0.4090, action:  0.0000\n",
      "theta =  2.7018, omega:  0.2839, action:  7.0000\n",
      "theta =  2.6954, omega: -0.7447, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0560, action:  7.0000\n",
      "theta =  2.6899, omega:  0.1349, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2195, action:  2.0000\n",
      "theta =  2.7024, omega:  0.3198, action:  2.0000\n",
      "theta =  2.6959, omega: -0.7149, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0765, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1595, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2519, action:  2.0000\n",
      "theta =  2.7034, omega:  0.3559, action:  2.0000\n",
      "theta =  2.6989, omega: -0.6774, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0635, action:  7.0000\n",
      "theta =  2.6963, omega:  0.1589, action:  2.0000\n",
      "theta =  2.7025, omega:  0.2605, action:  2.0000\n",
      "theta =  2.6946, omega: -0.7658, action:  0.0000\n",
      "theta =  2.6608, omega: -1.7664, action:  0.0000\n",
      "theta =  2.6277, omega: -0.9948, action:  5.0000\n",
      "theta =  2.6132, omega: -0.3198, action:  7.0000\n",
      "theta =  2.6097, omega:  0.1659, action:  7.0000\n",
      "theta =  2.6116, omega:  0.0273, action:  2.0000\n",
      "theta =  2.6129, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6144, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6130, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6156, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6136, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6121, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6136, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6154, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6137, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6124, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6116, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6131, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6128, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6148, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6125, omega:  0.0028, action:  2.0000\n",
      "theta =  2.6136, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6129, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6118, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6134, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6119, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6141, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6117, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6134, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6146, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6140, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6130, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6139, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6143, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6124, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6146, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6144, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6121, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6137, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6133, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6150, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6144, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6136, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6148, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6158, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6119, omega: -0.0016, action:  2.0000\n",
      "theta =  2.6131, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6125, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6135, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6125, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6145, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6159, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6137, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6120, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6130, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6131, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6150, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6139, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6138, omega: -0.0014, action:  2.0000\n",
      "theta =  2.6128, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6130, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6141, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6134, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6145, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6131, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6101, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6131, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6120, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6142, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6140, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6147, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6130, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6135, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6130, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6137, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6187, omega:  0.3363, action:  6.0000\n",
      "theta =  2.6234, omega:  0.2216, action:  2.0000\n",
      "theta =  2.6306, omega:  0.1232, action:  2.0000\n",
      "theta =  2.6313, omega:  0.0385, action:  2.0000\n",
      "theta =  2.6325, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6308, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6309, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6325, omega: -0.0010, action:  2.0000\n",
      "theta =  2.6317, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6329, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6296, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6299, omega: -0.0017, action:  2.0000\n",
      "theta =  2.6320, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6316, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6312, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6333, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6323, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6302, omega:  0.0020, action:  2.0000\n",
      "theta =  2.6320, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6318, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6319, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6317, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6305, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6308, omega:  0.0023, action:  2.0000\n",
      "theta =  2.6308, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6324, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6313, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6311, omega: -0.0019, action:  2.0000\n",
      "theta =  2.6326, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6306, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6340, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6314, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6308, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6306, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6326, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6331, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6335, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6326, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6318, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6338, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6314, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6311, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6307, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6317, omega:  0.0027, action:  2.0000\n",
      "theta =  2.6309, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6318, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6313, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6316, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6328, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6306, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6303, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6330, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6303, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6334, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6323, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6314, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6323, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6325, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6297, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6316, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6328, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6315, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6305, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6321, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6318, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6336, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6329, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6325, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6318, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6320, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6320, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6322, omega: -0.0015, action:  2.0000\n",
      "theta =  2.6323, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6332, omega: -0.0024, action:  2.0000\n",
      "theta =  2.6313, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6333, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6325, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6320, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6322, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6324, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6325, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6329, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6315, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6322, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6327, omega:  0.0020, action:  2.0000\n",
      "theta =  2.6321, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6334, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6321, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6325, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6224, omega: -0.7099, action:  1.0000\n",
      "theta =  2.6133, omega: -0.0415, action:  7.0000\n",
      "theta =  2.6135, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6143, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6134, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6142, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6127, omega: -0.0015, action:  2.0000\n",
      "theta =  2.6164, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6147, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6139, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6134, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6133, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6143, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6157, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6132, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6132, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6135, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6155, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6143, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6154, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6135, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6153, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6129, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6150, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6135, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6164, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6148, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6154, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6136, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6145, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6134, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6152, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6148, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6131, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6143, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6136, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6146, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6131, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6159, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6143, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6148, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6133, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6135, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6137, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6155, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6135, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6144, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6132, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6124, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6164, omega: -0.0010, action:  2.0000\n",
      "theta =  2.6143, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6139, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6144, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6149, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6141, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6133, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6154, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6168, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6143, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6139, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6144, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6125, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6134, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6149, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6141, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6138, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6137, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6144, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6148, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6149, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6130, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6156, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6138, omega: -0.0024, action:  2.0000\n",
      "theta =  2.5999, omega: -1.2259, action:  0.0000\n",
      "theta =  2.5746, omega: -0.6273, action:  7.0000\n",
      "theta =  2.5662, omega: -0.0916, action:  4.0000\n",
      "theta =  2.5699, omega:  0.1729, action:  6.0000\n",
      "theta =  2.5690, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5728, omega:  0.2206, action:  6.0000\n",
      "theta =  2.5745, omega: -0.0029, action:  2.0000\n",
      "theta =  2.5777, omega:  0.2340, action:  6.0000\n",
      "theta =  2.5797, omega:  0.0071, action:  2.0000\n",
      "theta =  2.5834, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5816, omega:  0.0003, action:  2.0000\n",
      "theta =  2.5813, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5813, omega:  0.0012, action:  2.0000\n",
      "theta =  2.5809, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5804, omega:  0.0008, action:  2.0000\n",
      "theta =  2.5824, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5808, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5824, omega:  0.0002, action:  2.0000\n",
      "theta =  2.5818, omega:  0.0008, action:  2.0000\n",
      "theta =  2.5808, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5818, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5805, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5826, omega:  0.0013, action:  2.0000\n",
      "theta =  2.5817, omega:  0.0006, action:  2.0000\n",
      "theta =  2.5817, omega: -0.0007, action:  2.0000\n",
      "theta =  2.5801, omega: -0.0024, action:  2.0000\n",
      "theta =  2.5817, omega: -0.0003, action:  2.0000\n",
      "theta =  2.5809, omega: -0.0008, action:  2.0000\n",
      "theta =  2.5797, omega:  0.0004, action:  2.0000\n",
      "theta =  2.5809, omega: -0.0002, action:  2.0000\n",
      "theta =  2.5823, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5817, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5813, omega: -0.0005, action:  2.0000\n",
      "theta =  2.5814, omega: -0.0011, action:  2.0000\n",
      "theta =  2.5810, omega: -0.0020, action:  2.0000\n",
      "theta =  2.5813, omega:  0.0012, action:  2.0000\n",
      "theta =  2.5791, omega: -0.0004, action:  2.0000\n",
      "theta =  2.5848, omega:  0.2484, action:  6.0000\n",
      "theta =  2.5870, omega:  0.0386, action:  2.0000\n",
      "theta =  2.5875, omega: -0.0012, action:  2.0000\n",
      "theta =  2.5879, omega: -0.0017, action:  2.0000\n",
      "theta =  2.5865, omega:  0.0001, action:  2.0000\n",
      "theta =  2.5879, omega:  0.0011, action:  2.0000\n",
      "theta =  2.5902, omega:  0.2669, action:  8.0000\n",
      "theta =  2.5938, omega:  0.0741, action:  2.0000\n",
      "theta =  2.5963, omega: -0.0006, action:  2.0000\n",
      "theta =  2.5948, omega: -0.0023, action:  2.0000\n",
      "theta =  2.5958, omega:  0.0007, action:  2.0000\n",
      "theta =  2.5973, omega: -0.0009, action:  2.0000\n",
      "theta =  2.5977, omega:  0.2892, action:  6.0000\n",
      "theta =  2.6044, omega:  0.1186, action:  2.0000\n",
      "theta =  2.6048, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6073, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6064, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6054, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6052, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6063, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6042, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6045, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6069, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6056, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6066, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6065, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6073, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6040, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6055, omega: -0.0018, action:  2.0000\n",
      "theta =  2.6064, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6059, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6043, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6054, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6063, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6044, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6057, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6053, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6057, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6063, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6049, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6030, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6056, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6038, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6043, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6059, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6046, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6047, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6064, omega:  0.0027, action:  2.0000\n",
      "theta =  2.6058, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6058, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6043, omega: -0.0029, action:  2.0000\n",
      "theta =  2.6049, omega:  0.0020, action:  2.0000\n",
      "theta =  2.6060, omega:  0.0021, action:  2.0000\n",
      "theta =  2.6068, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6047, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6065, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6057, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6050, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6063, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6044, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6050, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6036, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6073, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6061, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6059, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6062, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6050, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6057, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6074, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6056, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6053, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6065, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6052, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6054, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6060, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6046, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6055, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6051, omega: -0.0020, action:  2.0000\n",
      "theta =  2.6033, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6049, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6062, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6048, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6070, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6039, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6058, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6058, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6049, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6050, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6062, omega: -0.0014, action:  2.0000\n",
      "theta =  2.6034, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6059, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6061, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6058, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6044, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6065, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6056, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6048, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6052, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6059, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6063, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6057, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6035, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6043, omega: -0.0011, action:  2.0000\n",
      "theta =  2.6058, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6053, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6055, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6054, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6057, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6063, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6060, omega:  0.0027, action:  2.0000\n",
      "theta =  2.6047, omega: -0.0018, action:  2.0000\n",
      "theta =  2.6063, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6070, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6044, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6051, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6058, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6054, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6053, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6048, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6052, omega: -0.0021, action:  2.0000\n",
      "theta =  2.6039, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6052, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6090, omega:  0.3141, action:  6.0000\n",
      "theta =  2.6159, omega:  0.1769, action:  2.0000\n",
      "theta =  2.6180, omega:  0.0508, action:  2.0000\n",
      "theta =  2.6175, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6195, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6180, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6166, omega: -0.0013, action:  2.0000\n",
      "theta =  2.6192, omega:  0.0018, action:  2.0000\n",
      "theta =  2.6180, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6186, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6182, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6176, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6183, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6190, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6174, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6187, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6179, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6186, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6185, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6212, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6187, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6194, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6179, omega:  0.0020, action:  2.0000\n",
      "theta =  2.6176, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6199, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6167, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6199, omega: -0.0014, action:  2.0000\n",
      "theta =  2.6176, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6175, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6176, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6199, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6184, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6196, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6205, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6181, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6185, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6185, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6168, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6193, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6171, omega: -0.0012, action:  2.0000\n",
      "theta =  2.6175, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6202, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6169, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6174, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6167, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6185, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6162, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6190, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6175, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6187, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6190, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6184, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6193, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6186, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6199, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6173, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6181, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6215, omega: -0.0000, action:  2.0000\n",
      "theta =  2.6187, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6192, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6186, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6199, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6194, omega: -0.0027, action:  2.0000\n",
      "theta =  2.6207, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6180, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6199, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6198, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6193, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6196, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6194, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6188, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6172, omega: -0.0014, action:  2.0000\n",
      "theta =  2.6180, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6189, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6189, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6187, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6173, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6197, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6197, omega:  0.0000, action:  2.0000\n",
      "theta =  2.6173, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6189, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6180, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6159, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6183, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6197, omega: -0.0007, action:  2.0000\n",
      "theta =  2.6192, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6193, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6171, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6184, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6183, omega:  0.0003, action:  2.0000\n",
      "theta =  2.6186, omega:  0.0004, action:  2.0000\n",
      "theta =  2.6181, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6176, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6200, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6198, omega:  0.0001, action:  2.0000\n",
      "theta =  2.6189, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6204, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6239, omega:  0.3518, action:  6.0000\n",
      "theta =  2.6310, omega:  0.2513, action:  2.0000\n",
      "theta =  2.6363, omega:  0.1700, action:  2.0000\n",
      "theta =  2.6394, omega:  0.1036, action:  2.0000\n",
      "theta =  2.6386, omega:  0.0471, action:  2.0000\n",
      "theta =  2.6414, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6432, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6426, omega: -0.0003, action:  2.0000\n",
      "theta =  2.6417, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6405, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6433, omega:  0.0016, action:  2.0000\n",
      "theta =  2.6409, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6423, omega:  0.0007, action:  2.0000\n",
      "theta =  2.6416, omega:  0.0006, action:  2.0000\n",
      "theta =  2.6404, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6419, omega: -0.0002, action:  2.0000\n",
      "theta =  2.6429, omega: -0.0016, action:  2.0000\n",
      "theta =  2.6422, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6442, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6429, omega:  0.0015, action:  2.0000\n",
      "theta =  2.6420, omega:  0.0010, action:  2.0000\n",
      "theta =  2.6424, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6433, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6425, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6400, omega: -0.0001, action:  2.0000\n",
      "theta =  2.6422, omega: -0.0008, action:  2.0000\n",
      "theta =  2.6417, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6424, omega:  0.0011, action:  2.0000\n",
      "theta =  2.6422, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6420, omega:  0.0005, action:  2.0000\n",
      "theta =  2.6428, omega:  0.0022, action:  2.0000\n",
      "theta =  2.6430, omega:  0.0020, action:  2.0000\n",
      "theta =  2.6413, omega:  0.0017, action:  2.0000\n",
      "theta =  2.6423, omega:  0.0013, action:  2.0000\n",
      "theta =  2.6429, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6417, omega:  0.0029, action:  2.0000\n",
      "theta =  2.6426, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6446, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6435, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6404, omega:  0.0024, action:  2.0000\n",
      "theta =  2.6424, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6422, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6427, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6447, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6429, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6432, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6427, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6435, omega: -0.0005, action:  2.0000\n",
      "theta =  2.6430, omega: -0.0004, action:  2.0000\n",
      "theta =  2.6425, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6487, omega:  0.4195, action:  7.0000\n",
      "theta =  2.6569, omega:  0.3882, action:  2.0000\n",
      "theta =  2.6682, omega:  0.3845, action:  2.0000\n",
      "theta =  2.6771, omega:  0.4073, action:  2.0000\n",
      "theta =  2.6875, omega:  0.4593, action:  2.0000\n",
      "theta =  2.6860, omega: -0.6363, action:  0.0000\n",
      "theta =  2.6783, omega:  0.1064, action:  7.0000\n",
      "theta =  2.6811, omega:  0.1658, action:  2.0000\n",
      "theta =  2.6883, omega:  0.2298, action:  2.0000\n",
      "theta =  2.6935, omega:  0.3132, action:  2.0000\n",
      "theta =  2.6872, omega: -0.7404, action:  0.0000\n",
      "theta =  2.6803, omega:  0.0417, action:  7.0000\n",
      "theta =  2.6810, omega:  0.1029, action:  2.0000\n",
      "theta =  2.6875, omega:  0.1662, action:  2.0000\n",
      "theta =  2.6917, omega:  0.2406, action:  2.0000\n",
      "theta =  2.6978, omega:  0.3315, action:  2.0000\n",
      "theta =  2.6922, omega: -0.7197, action:  0.0000\n",
      "theta =  2.6840, omega:  0.0679, action:  7.0000\n",
      "theta =  2.6875, omega:  0.1410, action:  2.0000\n",
      "theta =  2.6898, omega:  0.2213, action:  2.0000\n",
      "theta =  2.6985, omega:  0.3159, action:  2.0000\n",
      "theta =  2.6939, omega: -0.7252, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0865, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1602, action:  2.0000\n",
      "theta =  2.6947, omega:  0.2415, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3415, action:  2.0000\n",
      "theta =  2.6974, omega: -0.6965, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0341, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1190, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2075, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3074, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7254, action:  0.0000\n",
      "theta =  2.6887, omega:  0.0678, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1483, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2401, action:  2.0000\n",
      "theta =  2.7050, omega:  0.3462, action:  2.0000\n",
      "theta =  2.6991, omega: -0.6911, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0458, action:  7.0000\n",
      "theta =  2.6929, omega:  0.1354, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2299, action:  2.0000\n",
      "theta =  2.7060, omega:  0.3415, action:  2.0000\n",
      "theta =  2.6999, omega: -0.6882, action:  0.0000\n",
      "theta =  2.6936, omega:  0.0536, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1495, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2531, action:  2.0000\n",
      "theta =  2.6945, omega: -0.7728, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0485, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1204, action:  2.0000\n",
      "theta =  2.6902, omega:  0.1993, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2892, action:  2.0000\n",
      "theta =  2.6913, omega: -0.7509, action:  0.0000\n",
      "theta =  2.6836, omega:  0.0561, action:  7.0000\n",
      "theta =  2.6852, omega:  0.1229, action:  2.0000\n",
      "theta =  2.6881, omega:  0.1949, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2797, action:  2.0000\n",
      "theta =  2.6879, omega: -0.7676, action:  0.0000\n",
      "theta =  2.6794, omega:  0.0231, action:  7.0000\n",
      "theta =  2.6813, omega:  0.0811, action:  2.0000\n",
      "theta =  2.6827, omega:  0.1423, action:  2.0000\n",
      "theta =  2.6879, omega:  0.2113, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2914, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3928, action:  2.0000\n",
      "theta =  2.7007, omega: -0.6507, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0898, action:  7.0000\n",
      "theta =  2.6959, omega:  0.1862, action:  2.0000\n",
      "theta =  2.7018, omega:  0.2923, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7337, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0888, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1746, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2661, action:  2.0000\n",
      "theta =  2.6895, omega: -0.7680, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0547, action:  7.0000\n",
      "theta =  2.6846, omega:  0.1201, action:  2.0000\n",
      "theta =  2.6898, omega:  0.1928, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2746, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3750, action:  2.0000\n",
      "theta =  2.6978, omega: -0.6664, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0711, action:  7.0000\n",
      "theta =  2.6951, omega:  0.1635, action:  2.0000\n",
      "theta =  2.6997, omega:  0.2625, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7654, action:  0.0000\n",
      "theta =  2.6838, omega:  0.0607, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1329, action:  2.0000\n",
      "theta =  2.6968, omega:  0.6778, action:  4.0000\n",
      "theta =  2.7013, omega: -0.4291, action:  0.0000\n",
      "theta =  2.6977, omega:  0.2504, action:  7.0000\n",
      "theta =  2.7063, omega:  0.3618, action:  2.0000\n",
      "theta =  2.7015, omega: -0.6682, action:  0.0000\n",
      "theta =  2.6965, omega:  0.0789, action:  7.0000\n",
      "theta =  2.6976, omega:  0.1797, action:  2.0000\n",
      "theta =  2.7043, omega:  0.2913, action:  2.0000\n",
      "theta =  2.6973, omega: -0.7336, action:  0.0000\n",
      "theta =  2.6917, omega:  0.0690, action:  7.0000\n",
      "theta =  2.6921, omega:  0.1573, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2512, action:  2.0000\n",
      "theta =  2.7056, omega:  0.3658, action:  2.0000\n",
      "theta =  2.7010, omega: -0.6653, action:  0.0000\n",
      "theta =  2.6951, omega:  0.0844, action:  7.0000\n",
      "theta =  2.6982, omega:  0.1852, action:  2.0000\n",
      "theta =  2.7057, omega:  0.2987, action:  2.0000\n",
      "theta =  2.6983, omega: -0.7233, action:  0.0000\n",
      "theta =  2.6907, omega:  0.0776, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1708, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2718, action:  2.0000\n",
      "theta =  2.6926, omega: -0.7601, action:  0.0000\n",
      "theta =  2.6853, omega:  0.0408, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1152, action:  2.0000\n",
      "theta =  2.6922, omega:  0.1951, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2870, action:  2.0000\n",
      "theta =  2.6913, omega: -0.7566, action:  0.0000\n",
      "theta =  2.6817, omega:  0.0621, action:  7.0000\n",
      "theta =  2.6860, omega:  0.1278, action:  2.0000\n",
      "theta =  2.6888, omega:  0.1998, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2834, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3863, action:  2.0000\n",
      "theta =  2.6980, omega: -0.6563, action:  0.0000\n",
      "theta =  2.6934, omega:  0.0860, action:  7.0000\n",
      "theta =  2.6951, omega:  0.1799, action:  2.0000\n",
      "theta =  2.7036, omega:  0.2889, action:  2.0000\n",
      "theta =  2.6936, omega: -0.7392, action:  0.0000\n",
      "theta =  2.6892, omega:  0.0853, action:  7.0000\n",
      "theta =  2.6909, omega:  0.1661, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2570, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3651, action:  2.0000\n",
      "theta =  2.6976, omega: -0.6685, action:  0.0000\n",
      "theta =  2.6798, omega: -1.1875, action:  1.0000\n",
      "theta =  2.6568, omega: -0.3703, action:  7.0000\n",
      "theta =  2.6575, omega:  0.2366, action:  7.0000\n",
      "theta =  2.6633, omega:  0.2284, action:  2.0000\n",
      "theta =  2.6699, omega:  0.2371, action:  2.0000\n",
      "theta =  2.6753, omega:  0.2635, action:  2.0000\n",
      "theta =  2.6813, omega:  0.3077, action:  2.0000\n",
      "theta =  2.6903, omega:  0.3732, action:  2.0000\n",
      "theta =  2.6851, omega: -0.7019, action:  0.0000\n",
      "theta =  2.6784, omega:  0.0828, action:  7.0000\n",
      "theta =  2.6795, omega:  0.1361, action:  2.0000\n",
      "theta =  2.6842, omega:  0.1958, action:  2.0000\n",
      "theta =  2.6907, omega:  0.2691, action:  2.0000\n",
      "theta =  2.7005, omega:  0.3632, action:  2.0000\n",
      "theta =  2.7161, omega:  0.9419, action:  4.0000\n",
      "theta =  2.7244, omega: -0.1542, action:  0.0000\n",
      "theta =  2.7251, omega:  0.1277, action:  2.0000\n",
      "theta =  2.7165, omega: -0.8087, action:  0.0000\n",
      "theta =  2.7075, omega:  0.0519, action:  7.0000\n",
      "theta =  2.7094, omega:  0.1892, action:  2.0000\n",
      "theta =  2.7024, omega: -0.7990, action:  0.0000\n",
      "theta =  2.6937, omega:  0.0310, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1261, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2253, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3403, action:  2.0000\n",
      "theta =  2.7008, omega: -0.6849, action:  0.0000\n",
      "theta =  2.6949, omega:  0.0644, action:  7.0000\n",
      "theta =  2.6980, omega:  0.1638, action:  2.0000\n",
      "theta =  2.7037, omega:  0.2746, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7501, action:  0.0000\n",
      "theta =  2.6890, omega:  0.0560, action:  7.0000\n",
      "theta =  2.6904, omega:  0.1379, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2275, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3332, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7007, action:  0.0000\n",
      "theta =  2.6894, omega:  0.0362, action:  7.0000\n",
      "theta =  2.6926, omega:  0.1206, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2167, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3220, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7091, action:  0.0000\n",
      "theta =  2.6916, omega:  0.1067, action:  7.0000\n",
      "theta =  2.6945, omega:  0.1947, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2952, action:  2.0000\n",
      "theta =  2.6927, omega: -0.7374, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0762, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1546, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2397, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3386, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7002, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0353, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1206, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2098, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3148, action:  2.0000\n",
      "theta =  2.6963, omega: -0.7207, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0762, action:  7.0000\n",
      "theta =  2.6924, omega:  0.1579, action:  2.0000\n",
      "theta =  2.6977, omega:  0.2506, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3597, action:  2.0000\n",
      "theta =  2.7016, omega: -0.6733, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0724, action:  7.0000\n",
      "theta =  2.6968, omega:  0.1653, action:  2.0000\n",
      "theta =  2.7022, omega:  0.2731, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7534, action:  0.0000\n",
      "theta =  2.6866, omega:  0.0478, action:  7.0000\n",
      "theta =  2.6885, omega:  0.1277, action:  2.0000\n",
      "theta =  2.6937, omega:  0.2129, action:  2.0000\n",
      "theta =  2.7013, omega:  0.3102, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7260, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0918, action:  7.0000\n",
      "theta =  2.6909, omega:  0.1710, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2583, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3623, action:  2.0000\n",
      "theta =  2.6985, omega: -0.6743, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0659, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1591, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2619, action:  2.0000\n",
      "theta =  2.6933, omega: -0.7652, action:  0.0000\n",
      "theta =  2.6851, omega:  0.0611, action:  7.0000\n",
      "theta =  2.6879, omega:  0.1335, action:  2.0000\n",
      "theta =  2.6936, omega:  0.2155, action:  2.0000\n",
      "theta =  2.6990, omega:  0.3114, action:  2.0000\n",
      "theta =  2.6915, omega: -0.7314, action:  0.0000\n",
      "theta =  2.6853, omega:  0.0745, action:  7.0000\n",
      "theta =  2.6869, omega:  0.1462, action:  2.0000\n",
      "theta =  2.6947, omega:  0.2307, action:  2.0000\n",
      "theta =  2.6993, omega:  0.3259, action:  2.0000\n",
      "theta =  2.6939, omega: -0.7151, action:  0.0000\n",
      "theta =  2.6887, omega:  0.0721, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1500, action:  2.0000\n",
      "theta =  2.6943, omega:  0.2373, action:  2.0000\n",
      "theta =  2.7033, omega:  0.3362, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7024, action:  0.0000\n",
      "theta =  2.6915, omega:  0.0317, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1170, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2049, action:  2.0000\n",
      "theta =  2.7006, omega:  0.3069, action:  2.0000\n",
      "theta =  2.6951, omega: -0.7248, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0682, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1488, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2380, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3431, action:  2.0000\n",
      "theta =  2.6973, omega: -0.6932, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0439, action:  7.0000\n",
      "theta =  2.6994, omega:  0.6014, action:  4.0000\n",
      "theta =  2.6989, omega: -0.4887, action:  0.0000\n",
      "theta =  2.6964, omega:  0.2150, action:  7.0000\n",
      "theta =  2.7028, omega:  0.3221, action:  2.0000\n",
      "theta =  2.6983, omega: -0.7059, action:  0.0000\n",
      "theta =  2.6904, omega:  0.0323, action:  7.0000\n",
      "theta =  2.6949, omega:  0.1199, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2178, action:  2.0000\n",
      "theta =  2.7033, omega:  0.3230, action:  2.0000\n",
      "theta =  2.6992, omega: -0.7052, action:  0.0000\n",
      "theta =  2.6905, omega:  0.0333, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1249, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2186, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3276, action:  2.0000\n",
      "theta =  2.6980, omega: -0.7025, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0392, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1288, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2287, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3374, action:  2.0000\n",
      "theta =  2.7212, omega:  0.9371, action:  3.0000\n",
      "theta =  2.7291, omega: -0.1477, action:  0.0000\n",
      "theta =  2.7306, omega:  0.1430, action:  2.0000\n",
      "theta =  2.7229, omega: -0.7804, action:  0.0000\n",
      "theta =  2.7154, omega:  0.0925, action:  7.0000\n",
      "theta =  2.7191, omega:  0.2512, action:  2.0000\n",
      "theta =  2.7132, omega: -0.7228, action:  0.0000\n",
      "theta =  2.7040, omega:  0.0532, action:  7.0000\n",
      "theta =  2.7064, omega:  0.1843, action:  2.0000\n",
      "theta =  2.7139, omega:  0.3227, action:  2.0000\n",
      "theta =  2.7097, omega: -0.6776, action:  0.0000\n",
      "theta =  2.7031, omega:  0.0942, action:  7.0000\n",
      "theta =  2.7069, omega:  0.2168, action:  2.0000\n",
      "theta =  2.7004, omega: -0.7828, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0564, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1446, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2401, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3498, action:  2.0000\n",
      "theta =  2.7012, omega: -0.6784, action:  0.0000\n",
      "theta =  2.6943, omega:  0.0660, action:  7.0000\n",
      "theta =  2.6959, omega:  0.1690, action:  2.0000\n",
      "theta =  2.7029, omega:  0.2738, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7500, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0549, action:  7.0000\n",
      "theta =  2.6891, omega:  0.1349, action:  2.0000\n",
      "theta =  2.6869, omega: -0.4449, action:  1.0000\n",
      "theta =  2.6839, omega:  0.2534, action:  7.0000\n",
      "theta =  2.6923, omega:  0.3231, action:  2.0000\n",
      "theta =  2.6864, omega: -0.7382, action:  0.0000\n",
      "theta =  2.6766, omega:  0.0420, action:  7.0000\n",
      "theta =  2.6782, omega:  0.0937, action:  2.0000\n",
      "theta =  2.6833, omega:  0.1524, action:  2.0000\n",
      "theta =  2.6883, omega:  0.2185, action:  2.0000\n",
      "theta =  2.6924, omega:  0.3015, action:  2.0000\n",
      "theta =  2.7029, omega:  0.4013, action:  2.0000\n",
      "theta =  2.7003, omega: -0.6457, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0929, action:  7.0000\n",
      "theta =  2.6964, omega:  0.1909, action:  2.0000\n",
      "theta =  2.7027, omega:  0.3004, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7282, action:  0.0000\n",
      "theta =  2.6899, omega:  0.0699, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1547, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2484, action:  2.0000\n",
      "theta =  2.7069, omega:  0.3588, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6739, action:  0.0000\n",
      "theta =  2.6943, omega:  0.0715, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1672, action:  2.0000\n",
      "theta =  2.7030, omega:  0.2770, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7488, action:  0.0000\n",
      "theta =  2.6872, omega:  0.0529, action:  7.0000\n",
      "theta =  2.6901, omega:  0.1364, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2245, action:  2.0000\n",
      "theta =  2.7019, omega:  0.3262, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7074, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0855, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1708, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2668, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7694, action:  0.0000\n",
      "theta =  2.6823, omega:  0.0501, action:  7.0000\n",
      "theta =  2.6847, omega:  0.1149, action:  2.0000\n",
      "theta =  2.6900, omega:  0.1872, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2702, action:  2.0000\n",
      "theta =  2.7024, omega:  0.3716, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6729, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0667, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1560, action:  2.0000\n",
      "theta =  2.6993, omega:  0.2570, action:  2.0000\n",
      "theta =  2.6925, omega: -0.7740, action:  0.0000\n",
      "theta =  2.6831, omega:  0.0277, action:  7.0000\n",
      "theta =  2.6858, omega:  0.0949, action:  2.0000\n",
      "theta =  2.6891, omega:  0.1676, action:  2.0000\n",
      "theta =  2.6936, omega:  0.2522, action:  2.0000\n",
      "theta =  2.7018, omega:  0.3513, action:  2.0000\n",
      "theta =  2.6957, omega: -0.6901, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0450, action:  8.0000\n",
      "theta =  2.6914, omega:  0.1282, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2211, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3244, action:  2.0000\n",
      "theta =  2.6975, omega: -0.7080, action:  0.0000\n",
      "theta =  2.6899, omega:  0.1024, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1913, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2892, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7450, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0515, action:  7.0000\n",
      "theta =  2.6887, omega:  0.1270, action:  2.0000\n",
      "theta =  2.6930, omega:  0.2076, action:  2.0000\n",
      "theta =  2.6986, omega:  0.3011, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7387, action:  0.0000\n",
      "theta =  2.6820, omega:  0.0540, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1240, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2052, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2955, action:  2.0000\n",
      "theta =  2.6901, omega: -0.7483, action:  0.0000\n",
      "theta =  2.6848, omega:  0.0417, action:  7.0000\n",
      "theta =  2.6839, omega:  0.1105, action:  2.0000\n",
      "theta =  2.6885, omega:  0.1831, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2654, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3667, action:  2.0000\n",
      "theta =  2.6966, omega: -0.6759, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0598, action:  7.0000\n",
      "theta =  2.6946, omega:  0.1525, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2464, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3586, action:  2.0000\n",
      "theta =  2.7029, omega: -0.6685, action:  0.0000\n",
      "theta =  2.6957, omega:  0.0799, action:  7.0000\n",
      "theta =  2.7002, omega:  0.1822, action:  2.0000\n",
      "theta =  2.7095, omega:  0.7601, action:  5.0000\n",
      "theta =  2.7154, omega: -0.3270, action:  0.0000\n",
      "theta =  2.7130, omega:  0.0446, action:  2.0000\n",
      "theta =  2.7160, omega:  0.1964, action:  2.0000\n",
      "theta =  2.7081, omega: -0.7787, action:  0.0000\n",
      "theta =  2.7000, omega:  0.0551, action:  7.0000\n",
      "theta =  2.7008, omega:  0.1693, action:  2.0000\n",
      "theta =  2.7067, omega:  0.2903, action:  2.0000\n",
      "theta =  2.7018, omega: -0.7246, action:  0.0000\n",
      "theta =  2.6941, omega:  0.0833, action:  7.0000\n",
      "theta =  2.6973, omega:  0.1827, action:  2.0000\n",
      "theta =  2.7094, omega:  0.7605, action:  3.0000\n",
      "theta =  2.7128, omega: -0.3271, action:  0.0000\n",
      "theta =  2.7105, omega:  0.0412, action:  2.0000\n",
      "theta =  2.7141, omega:  0.1905, action:  2.0000\n",
      "theta =  2.7053, omega: -0.7879, action:  0.0000\n",
      "theta =  2.6959, omega:  0.0464, action:  7.0000\n",
      "theta =  2.6990, omega:  0.1533, action:  2.0000\n",
      "theta =  2.7055, omega:  0.2675, action:  2.0000\n",
      "theta =  2.6989, omega: -0.7464, action:  0.0000\n",
      "theta =  2.6915, omega:  0.0836, action:  7.0000\n",
      "theta =  2.6950, omega:  0.1722, action:  2.0000\n",
      "theta =  2.6996, omega:  0.2726, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7604, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0649, action:  7.0000\n",
      "theta =  2.6868, omega:  0.1379, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2182, action:  2.0000\n",
      "theta =  2.6973, omega:  0.3096, action:  2.0000\n",
      "theta =  2.7147, omega:  0.8894, action:  7.0000\n",
      "theta =  2.7214, omega: -0.2096, action:  0.0000\n",
      "theta =  2.7182, omega:  0.0974, action:  2.0000\n",
      "theta =  2.7235, omega:  0.2707, action:  2.0000\n",
      "theta =  2.7185, omega: -0.6905, action:  0.0000\n",
      "theta =  2.7129, omega:  0.1087, action:  7.0000\n",
      "theta =  2.7189, omega:  0.2620, action:  2.0000\n",
      "theta =  2.7105, omega: -0.7202, action:  0.0000\n",
      "theta =  2.7030, omega:  0.0584, action:  7.0000\n",
      "theta =  2.7063, omega:  0.1852, action:  2.0000\n",
      "theta =  2.7146, omega:  0.3226, action:  2.0000\n",
      "theta =  2.7084, omega: -0.6798, action:  0.0000\n",
      "theta =  2.7009, omega:  0.0870, action:  7.0000\n",
      "theta =  2.7053, omega:  0.2063, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7956, action:  0.0000\n",
      "theta =  2.6915, omega:  0.0230, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1062, action:  2.0000\n",
      "theta =  2.6950, omega:  0.1942, action:  2.0000\n",
      "theta =  2.7005, omega:  0.2945, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7399, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0743, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1529, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2378, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3353, action:  2.0000\n",
      "theta =  2.6951, omega: -0.7017, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0312, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1149, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2027, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3039, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7300, action:  0.0000\n",
      "theta =  2.6865, omega:  0.0802, action:  7.0000\n",
      "theta =  2.6904, omega:  0.1626, action:  2.0000\n",
      "theta =  2.6951, omega:  0.2523, action:  2.0000\n",
      "theta =  2.7035, omega:  0.3546, action:  2.0000\n",
      "theta =  2.6984, omega: -0.6834, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0582, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1475, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2485, action:  2.0000\n",
      "theta =  2.7090, omega:  0.3629, action:  2.0000\n",
      "theta =  2.7005, omega: -0.6651, action:  0.0000\n",
      "theta =  2.6954, omega:  0.0841, action:  7.0000\n",
      "theta =  2.6994, omega:  0.1894, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3032, action:  2.0000\n",
      "theta =  2.6992, omega: -0.7173, action:  0.0000\n",
      "theta =  2.6934, omega:  0.0880, action:  7.0000\n",
      "theta =  2.6962, omega:  0.1806, action:  2.0000\n",
      "theta =  2.7025, omega:  0.2869, action:  2.0000\n",
      "theta =  2.6963, omega: -0.7425, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0725, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1566, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2453, action:  2.0000\n",
      "theta =  2.7021, omega:  0.3516, action:  2.0000\n",
      "theta =  2.6994, omega: -0.6851, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0522, action:  7.0000\n",
      "theta =  2.6946, omega:  0.1456, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2436, action:  2.0000\n",
      "theta =  2.7070, omega:  0.3585, action:  2.0000\n",
      "theta =  2.7004, omega: -0.6688, action:  0.0000\n",
      "theta =  2.6979, omega:  0.0792, action:  7.0000\n",
      "theta =  2.7000, omega:  0.1831, action:  2.0000\n",
      "theta =  2.7049, omega:  0.2931, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7278, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0731, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1641, action:  2.0000\n",
      "theta =  2.6996, omega:  0.2636, action:  2.0000\n",
      "theta =  2.6905, omega: -0.7667, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0510, action:  7.0000\n",
      "theta =  2.6869, omega:  0.1223, action:  2.0000\n",
      "theta =  2.6909, omega:  0.2014, action:  2.0000\n",
      "theta =  2.6990, omega:  0.2901, action:  2.0000\n",
      "theta =  2.6900, omega: -0.7536, action:  0.0000\n",
      "theta =  2.6807, omega:  0.0623, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1247, action:  2.0000\n",
      "theta =  2.6877, omega:  0.2001, action:  2.0000\n",
      "theta =  2.6944, omega:  0.2817, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3831, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6611, action:  0.0000\n",
      "theta =  2.6933, omega:  0.0814, action:  7.0000\n",
      "theta =  2.6967, omega:  0.1747, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2773, action:  2.0000\n",
      "theta =  2.6951, omega: -0.7495, action:  0.0000\n",
      "theta =  2.6856, omega:  0.0485, action:  7.0000\n",
      "theta =  2.6898, omega:  0.1279, action:  2.0000\n",
      "theta =  2.6930, omega:  0.2148, action:  2.0000\n",
      "theta =  2.7005, omega:  0.3110, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7275, action:  0.0000\n",
      "theta =  2.6882, omega:  0.0854, action:  7.0000\n",
      "theta =  2.6902, omega:  0.1653, action:  2.0000\n",
      "theta =  2.6943, omega:  0.2539, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3534, action:  2.0000\n",
      "theta =  2.6962, omega: -0.6843, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0545, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1460, action:  2.0000\n",
      "theta =  2.6997, omega:  0.2413, action:  2.0000\n",
      "theta =  2.7068, omega:  0.3526, action:  2.0000\n",
      "theta =  2.7019, omega: -0.6745, action:  0.0000\n",
      "theta =  2.6937, omega:  0.0715, action:  7.0000\n",
      "theta =  2.6997, omega:  0.1705, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2815, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7420, action:  0.0000\n",
      "theta =  2.6894, omega:  0.0820, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1707, action:  2.0000\n",
      "theta =  2.6990, omega:  0.2633, action:  2.0000\n",
      "theta =  2.6921, omega: -0.7717, action:  0.0000\n",
      "theta =  2.6823, omega:  0.0267, action:  7.0000\n",
      "theta =  2.6841, omega:  0.0912, action:  2.0000\n",
      "theta =  2.6863, omega:  0.1592, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2365, action:  2.0000\n",
      "theta =  2.7011, omega:  0.3301, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7124, action:  0.0000\n",
      "theta =  2.6878, omega:  0.0736, action:  7.0000\n",
      "theta =  2.6966, omega:  0.6188, action:  4.0000\n",
      "theta =  2.6982, omega: -0.4871, action:  0.0000\n",
      "theta =  2.6938, omega:  0.2000, action:  7.0000\n",
      "theta =  2.6985, omega:  0.2973, action:  2.0000\n",
      "theta =  2.6931, omega: -0.7401, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0538, action:  7.0000\n",
      "theta =  2.6886, omega:  0.1282, action:  2.0000\n",
      "theta =  2.6906, omega:  0.2074, action:  2.0000\n",
      "theta =  2.6988, omega:  0.3006, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7398, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0510, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1217, action:  2.0000\n",
      "theta =  2.6905, omega:  0.1959, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2846, action:  2.0000\n",
      "theta =  2.6895, omega: -0.7593, action:  0.0000\n",
      "theta =  2.6823, omega:  0.0511, action:  7.0000\n",
      "theta =  2.6851, omega:  0.1138, action:  2.0000\n",
      "theta =  2.6871, omega:  0.1836, action:  2.0000\n",
      "theta =  2.6915, omega:  0.2617, action:  2.0000\n",
      "theta =  2.6998, omega:  0.3587, action:  2.0000\n",
      "theta =  2.6970, omega: -0.6859, action:  0.0000\n",
      "theta =  2.6899, omega:  0.0459, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1308, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2213, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3244, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7098, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0868, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1739, action:  2.0000\n",
      "theta =  2.6997, omega:  0.2694, action:  2.0000\n",
      "theta =  2.6931, omega: -0.7634, action:  0.0000\n",
      "theta =  2.6843, omega:  0.0515, action:  7.0000\n",
      "theta =  2.6860, omega:  0.1204, action:  2.0000\n",
      "theta =  2.6895, omega:  0.1965, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2832, action:  2.0000\n",
      "theta =  2.6893, omega: -0.7608, action:  0.0000\n",
      "theta =  2.6821, omega:  0.0491, action:  7.0000\n",
      "theta =  2.6822, omega:  0.1097, action:  2.0000\n",
      "theta =  2.6876, omega:  0.1765, action:  2.0000\n",
      "theta =  2.6920, omega:  0.2524, action:  2.0000\n",
      "theta =  2.7000, omega:  0.3435, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7022, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0827, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1609, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2488, action:  2.0000\n",
      "theta =  2.7013, omega:  0.3495, action:  2.0000\n",
      "theta =  2.6988, omega: -0.6869, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0500, action:  7.0000\n",
      "theta =  2.6931, omega:  0.1391, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2372, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3460, action:  2.0000\n",
      "theta =  2.6993, omega: -0.6824, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0590, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1550, action:  2.0000\n",
      "theta =  2.7023, omega:  0.2615, action:  2.0000\n",
      "theta =  2.6933, omega: -0.7641, action:  0.0000\n",
      "theta =  2.6857, omega:  0.0654, action:  3.0000\n",
      "theta =  2.6892, omega:  0.1410, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2251, action:  2.0000\n",
      "theta =  2.6992, omega:  0.3212, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7158, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0733, action:  7.0000\n",
      "theta =  2.6898, omega:  0.1516, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2418, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3444, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6935, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0460, action:  7.0000\n",
      "theta =  2.6973, omega:  0.5995, action:  4.0000\n",
      "theta =  2.7002, omega: -0.4912, action:  0.0000\n",
      "theta =  2.6911, omega: -0.0784, action:  2.0000\n",
      "theta =  2.6909, omega:  0.0754, action:  2.0000\n",
      "theta =  2.6967, omega:  0.1690, action:  2.0000\n",
      "theta =  2.6992, omega:  0.2727, action:  2.0000\n",
      "theta =  2.6936, omega: -0.7561, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0434, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1209, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2046, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2980, action:  2.0000\n",
      "theta =  2.6927, omega: -0.7413, action:  0.0000\n",
      "theta =  2.6843, omega:  0.0508, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1220, action:  2.0000\n",
      "theta =  2.6916, omega:  0.2010, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2901, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7488, action:  0.0000\n",
      "theta =  2.6820, omega:  0.0395, action:  7.0000\n",
      "theta =  2.6842, omega:  0.1052, action:  2.0000\n",
      "theta =  2.6878, omega:  0.1765, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2581, action:  2.0000\n",
      "theta =  2.7008, omega:  0.3559, action:  2.0000\n",
      "theta =  2.6977, omega: -0.6873, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0465, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1320, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2222, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3287, action:  2.0000\n",
      "theta =  2.6988, omega: -0.7048, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0310, action:  7.0000\n",
      "theta =  2.6931, omega:  0.1172, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2129, action:  2.0000\n",
      "theta =  2.7027, omega:  0.3151, action:  2.0000\n",
      "theta =  2.6969, omega: -0.7137, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0815, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1673, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2642, action:  2.0000\n",
      "theta =  2.6908, omega: -0.7688, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0498, action:  7.0000\n",
      "theta =  2.6870, omega:  0.1180, action:  2.0000\n",
      "theta =  2.6881, omega:  0.1876, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2736, action:  2.0000\n",
      "theta =  2.7040, omega:  0.3755, action:  2.0000\n",
      "theta =  2.6985, omega: -0.6672, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0742, action:  7.0000\n",
      "theta =  2.6957, omega:  0.1674, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2699, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7580, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0380, action:  7.0000\n",
      "theta =  2.6891, omega:  0.1143, action:  2.0000\n",
      "theta =  2.6932, omega:  0.1964, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2889, action:  2.0000\n",
      "theta =  2.6931, omega: -0.7532, action:  0.0000\n",
      "theta =  2.6825, omega:  0.0425, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1077, action:  2.0000\n",
      "theta =  2.6881, omega:  0.1802, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2643, action:  2.0000\n",
      "theta =  2.7012, omega:  0.3614, action:  2.0000\n",
      "theta =  2.6994, omega: -0.6771, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0585, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1482, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2438, action:  2.0000\n",
      "theta =  2.7067, omega:  0.3564, action:  2.0000\n",
      "theta =  2.6993, omega: -0.6732, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0717, action:  7.0000\n",
      "theta =  2.6961, omega:  0.1742, action:  2.0000\n",
      "theta =  2.7030, omega:  0.2829, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7415, action:  0.0000\n",
      "theta =  2.6892, omega:  0.0822, action:  7.0000\n",
      "theta =  2.6930, omega:  0.1705, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2626, action:  2.0000\n",
      "theta =  2.7066, omega:  0.3717, action:  2.0000\n",
      "theta =  2.7009, omega: -0.6569, action:  0.0000\n",
      "theta =  2.6960, omega:  0.0895, action:  7.0000\n",
      "theta =  2.6986, omega:  0.1927, action:  2.0000\n",
      "theta =  2.7079, omega:  0.3070, action:  2.0000\n",
      "theta =  2.6992, omega: -0.7174, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0868, action:  7.0000\n",
      "theta =  2.6965, omega:  0.1798, action:  2.0000\n",
      "theta =  2.7015, omega:  0.2873, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7459, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0571, action:  7.0000\n",
      "theta =  2.6919, omega:  0.1355, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2213, action:  2.0000\n",
      "theta =  2.6992, omega:  0.3230, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7141, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0789, action:  7.0000\n",
      "theta =  2.6940, omega:  0.1616, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2521, action:  2.0000\n",
      "theta =  2.7037, omega:  0.3588, action:  2.0000\n",
      "theta =  2.6988, omega: -0.6746, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0676, action:  7.0000\n",
      "theta =  2.6957, omega:  0.1637, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2703, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7581, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0418, action:  7.0000\n",
      "theta =  2.6903, omega:  0.1200, action:  2.0000\n",
      "theta =  2.6920, omega:  0.2044, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2981, action:  2.0000\n",
      "theta =  2.6937, omega: -0.7414, action:  0.0000\n",
      "theta =  2.6833, omega:  0.0519, action:  7.0000\n",
      "theta =  2.6873, omega:  0.1247, action:  2.0000\n",
      "theta =  2.6911, omega:  0.2025, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2919, action:  2.0000\n",
      "theta =  2.6900, omega: -0.7494, action:  0.0000\n",
      "theta =  2.6824, omega:  0.0407, action:  7.0000\n",
      "theta =  2.6855, omega:  0.1058, action:  2.0000\n",
      "theta =  2.6879, omega:  0.1763, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2592, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3561, action:  2.0000\n",
      "theta =  2.6950, omega: -0.6856, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0475, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1330, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2272, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3310, action:  2.0000\n",
      "theta =  2.6982, omega: -0.7018, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0362, action:  7.0000\n",
      "theta =  2.6931, omega:  0.1261, action:  2.0000\n",
      "theta =  2.6971, omega:  0.2210, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3294, action:  2.0000\n",
      "theta =  2.6994, omega: -0.7017, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0378, action:  7.0000\n",
      "theta =  2.6950, omega:  0.1304, action:  2.0000\n",
      "theta =  2.6993, omega:  0.2264, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3376, action:  2.0000\n",
      "theta =  2.6994, omega: -0.6920, action:  0.0000\n",
      "theta =  2.6948, omega:  0.0509, action:  7.0000\n",
      "theta =  2.6949, omega:  0.1489, action:  2.0000\n",
      "theta =  2.7004, omega:  0.2495, action:  2.0000\n",
      "theta =  2.6925, omega: -0.7760, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0301, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1031, action:  2.0000\n",
      "theta =  2.6894, omega:  0.1809, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2667, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3706, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6674, action:  0.0000\n",
      "theta =  2.6933, omega:  0.0734, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1675, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2722, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7555, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0438, action:  7.0000\n",
      "theta =  2.6889, omega:  0.1221, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2044, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2987, action:  2.0000\n",
      "theta =  2.6926, omega: -0.7400, action:  0.0000\n",
      "theta =  2.6850, omega:  0.0548, action:  7.0000\n",
      "theta =  2.6869, omega:  0.1248, action:  2.0000\n",
      "theta =  2.6901, omega:  0.2048, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2956, action:  2.0000\n",
      "theta =  2.6905, omega: -0.7448, action:  0.0000\n",
      "theta =  2.6830, omega:  0.0440, action:  7.0000\n",
      "theta =  2.6841, omega:  0.1133, action:  2.0000\n",
      "theta =  2.6895, omega:  0.1851, action:  2.0000\n",
      "theta =  2.6930, omega:  0.2718, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3684, action:  2.0000\n",
      "theta =  2.6982, omega: -0.6703, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0662, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1574, action:  2.0000\n",
      "theta =  2.6999, omega:  0.2585, action:  2.0000\n",
      "theta =  2.6927, omega: -0.7715, action:  0.0000\n",
      "theta =  2.6836, omega:  0.0478, action:  7.0000\n",
      "theta =  2.6864, omega:  0.1199, action:  2.0000\n",
      "theta =  2.6905, omega:  0.1967, action:  2.0000\n",
      "theta =  2.6816, omega: -0.8502, action:  0.0000\n",
      "theta =  2.6715, omega: -0.0210, action:  7.0000\n",
      "theta =  2.6704, omega:  0.0312, action:  2.0000\n",
      "theta =  2.6727, omega:  0.0663, action:  2.0000\n",
      "theta =  2.6751, omega:  0.1007, action:  2.0000\n",
      "theta =  2.6782, omega:  0.1454, action:  2.0000\n",
      "theta =  2.6835, omega:  0.1968, action:  2.0000\n",
      "theta =  2.6863, omega:  0.2607, action:  2.0000\n",
      "theta =  2.6953, omega:  0.3444, action:  2.0000\n",
      "theta =  2.6883, omega: -0.7123, action:  0.0000\n",
      "theta =  2.6822, omega:  0.0861, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1553, action:  2.0000\n",
      "theta =  2.6907, omega:  0.2287, action:  2.0000\n",
      "theta =  2.6977, omega:  0.3161, action:  2.0000\n",
      "theta =  2.6933, omega: -0.7282, action:  0.0000\n",
      "theta =  2.6841, omega:  0.0741, action:  7.0000\n",
      "theta =  2.6865, omega:  0.1453, action:  2.0000\n",
      "theta =  2.6922, omega:  0.2224, action:  2.0000\n",
      "theta =  2.6963, omega:  0.3134, action:  2.0000\n",
      "theta =  2.6912, omega: -0.7286, action:  0.0000\n",
      "theta =  2.6833, omega:  0.0748, action:  7.0000\n",
      "theta =  2.6856, omega:  0.1477, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2256, action:  2.0000\n",
      "theta =  2.7003, omega:  0.3224, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7214, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0681, action:  7.0000\n",
      "theta =  2.6886, omega:  0.1442, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2247, action:  2.0000\n",
      "theta =  2.6998, omega:  0.3223, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7178, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0717, action:  7.0000\n",
      "theta =  2.6896, omega:  0.1529, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2387, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3418, action:  2.0000\n",
      "theta =  2.6987, omega: -0.6964, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0396, action:  7.0000\n",
      "theta =  2.6964, omega:  0.5928, action:  4.0000\n",
      "theta =  2.6976, omega: -0.4967, action:  0.0000\n",
      "theta =  2.6951, omega:  0.1922, action:  7.0000\n",
      "theta =  2.7023, omega:  0.2958, action:  2.0000\n",
      "theta =  2.6960, omega: -0.7325, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0849, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1673, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2568, action:  2.0000\n",
      "theta =  2.7022, omega:  0.3625, action:  2.0000\n",
      "theta =  2.6976, omega: -0.6727, action:  0.0000\n",
      "theta =  2.6921, omega:  0.0693, action:  7.0000\n",
      "theta =  2.6965, omega:  0.1660, action:  2.0000\n",
      "theta =  2.7022, omega:  0.2704, action:  2.0000\n",
      "theta =  2.6952, omega: -0.7576, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0441, action:  7.0000\n",
      "theta =  2.6883, omega:  0.1203, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2027, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2987, action:  2.0000\n",
      "theta =  2.6925, omega: -0.7394, action:  0.0000\n",
      "theta =  2.6828, omega:  0.0554, action:  7.0000\n",
      "theta =  2.6883, omega:  0.1264, action:  2.0000\n",
      "theta =  2.6908, omega:  0.2054, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2959, action:  2.0000\n",
      "theta =  2.6917, omega: -0.7446, action:  0.0000\n",
      "theta =  2.6830, omega:  0.0449, action:  7.0000\n",
      "theta =  2.6864, omega:  0.1112, action:  2.0000\n",
      "theta =  2.6896, omega:  0.1862, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2721, action:  2.0000\n",
      "theta =  2.7043, omega:  0.3739, action:  2.0000\n",
      "theta =  2.6984, omega: -0.6671, action:  0.0000\n",
      "theta =  2.6933, omega:  0.0706, action:  7.0000\n",
      "theta =  2.6945, omega:  0.1639, action:  2.0000\n",
      "theta =  2.7012, omega:  0.2656, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7651, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0624, action:  7.0000\n",
      "theta =  2.6893, omega:  0.1346, action:  2.0000\n",
      "theta =  2.6913, omega:  0.2175, action:  2.0000\n",
      "theta =  2.6992, omega:  0.3094, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7304, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0798, action:  7.0000\n",
      "theta =  2.6895, omega:  0.1563, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2379, action:  2.0000\n",
      "theta =  2.7008, omega:  0.3334, action:  2.0000\n",
      "theta =  2.6958, omega: -0.7050, action:  0.0000\n",
      "theta =  2.6881, omega:  0.0853, action:  7.0000\n",
      "theta =  2.6905, omega:  0.1659, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2571, action:  2.0000\n",
      "theta =  2.7055, omega:  0.3634, action:  2.0000\n",
      "theta =  2.7209, omega:  0.9583, action:  7.0000\n",
      "theta =  2.7290, omega: -0.1253, action:  0.0000\n",
      "theta =  2.7319, omega:  0.1541, action:  2.0000\n",
      "theta =  2.7240, omega: -0.7678, action:  0.0000\n",
      "theta =  2.7148, omega:  0.1084, action:  7.0000\n",
      "theta =  2.7212, omega:  0.2703, action:  2.0000\n",
      "theta =  2.7133, omega: -0.7035, action:  0.0000\n",
      "theta =  2.7081, omega:  0.0822, action:  7.0000\n",
      "theta =  2.7122, omega:  0.2198, action:  2.0000\n",
      "theta =  2.7036, omega: -0.7702, action:  0.0000\n",
      "theta =  2.6961, omega:  0.0556, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1596, action:  2.0000\n",
      "theta =  2.7034, omega:  0.2704, action:  2.0000\n",
      "theta =  2.6979, omega: -0.7495, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0581, action:  7.0000\n",
      "theta =  2.6929, omega:  0.1444, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2337, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3408, action:  2.0000\n",
      "theta =  2.6993, omega: -0.6904, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0501, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1428, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2430, action:  2.0000\n",
      "theta =  2.7061, omega:  0.3555, action:  2.0000\n",
      "theta =  2.7019, omega: -0.6725, action:  0.0000\n",
      "theta =  2.6946, omega:  0.0781, action:  7.0000\n",
      "theta =  2.6985, omega:  0.1817, action:  2.0000\n",
      "theta =  2.7068, omega:  0.2938, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7273, action:  0.0000\n",
      "theta =  2.6924, omega:  0.0739, action:  7.0000\n",
      "theta =  2.6949, omega:  0.1639, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2653, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7663, action:  0.0000\n",
      "theta =  2.6862, omega:  0.0513, action:  7.0000\n",
      "theta =  2.6850, omega:  0.1231, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2012, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2907, action:  2.0000\n",
      "theta =  2.6909, omega: -0.7513, action:  0.0000\n",
      "theta =  2.6834, omega:  0.0597, action:  7.0000\n",
      "theta =  2.6863, omega:  0.1244, action:  2.0000\n",
      "theta =  2.6884, omega:  0.1985, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2801, action:  2.0000\n",
      "theta =  2.6891, omega: -0.7659, action:  0.0000\n",
      "theta =  2.6790, omega:  0.0226, action:  7.0000\n",
      "theta =  2.6825, omega:  0.0804, action:  2.0000\n",
      "theta =  2.6833, omega:  0.1403, action:  2.0000\n",
      "theta =  2.6890, omega:  0.2095, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2910, action:  2.0000\n",
      "theta =  2.7017, omega:  0.3934, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6526, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0867, action:  7.0000\n",
      "theta =  2.6975, omega:  0.1828, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2889, action:  2.0000\n",
      "theta =  2.6973, omega: -0.7414, action:  0.0000\n",
      "theta =  2.6889, omega:  0.0745, action:  7.0000\n",
      "theta =  2.6926, omega:  0.1583, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2501, action:  2.0000\n",
      "theta =  2.7055, omega:  0.3526, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6811, action:  0.0000\n",
      "theta =  2.6916, omega:  0.0589, action:  7.0000\n",
      "theta =  2.6951, omega:  0.1509, action:  2.0000\n",
      "theta =  2.6998, omega:  0.2553, action:  2.0000\n",
      "theta =  2.6931, omega: -0.7739, action:  0.0000\n",
      "theta =  2.6843, omega:  0.0292, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1015, action:  2.0000\n",
      "theta =  2.6902, omega:  0.1747, action:  2.0000\n",
      "theta =  2.6943, omega:  0.2600, action:  2.0000\n",
      "theta =  2.7024, omega:  0.3634, action:  2.0000\n",
      "theta =  2.6985, omega: -0.6763, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0604, action:  7.0000\n",
      "theta =  2.6921, omega:  0.1485, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2496, action:  2.0000\n",
      "theta =  2.6906, omega: -0.7799, action:  0.0000\n",
      "theta =  2.6835, omega:  0.0205, action:  7.0000\n",
      "theta =  2.6846, omega:  0.0882, action:  2.0000\n",
      "theta =  2.6865, omega:  0.1587, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2377, action:  2.0000\n",
      "theta =  2.6990, omega:  0.3336, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7099, action:  0.0000\n",
      "theta =  2.6878, omega:  0.0753, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1549, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2445, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3468, action:  2.0000\n",
      "theta =  2.6963, omega: -0.6923, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0437, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1316, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2265, action:  2.0000\n",
      "theta =  2.6882, omega: -0.8056, action:  0.0000\n",
      "theta =  2.6811, omega:  0.0290, action:  7.0000\n",
      "theta =  2.6820, omega:  0.0860, action:  2.0000\n",
      "theta =  2.6846, omega:  0.1484, action:  2.0000\n",
      "theta =  2.6904, omega:  0.2192, action:  2.0000\n",
      "theta =  2.6962, omega:  0.3041, action:  2.0000\n",
      "theta =  2.6894, omega: -0.7432, action:  0.0000\n",
      "theta =  2.6808, omega:  0.0399, action:  7.0000\n",
      "theta =  2.6827, omega:  0.1020, action:  2.0000\n",
      "theta =  2.6889, omega:  0.1695, action:  2.0000\n",
      "theta =  2.6917, omega:  0.2450, action:  2.0000\n",
      "theta =  2.7000, omega:  0.3378, action:  2.0000\n",
      "theta =  2.7125, omega:  0.9194, action:  7.0000\n",
      "theta =  2.7228, omega: -0.1846, action:  0.0000\n",
      "theta =  2.7225, omega:  0.1126, action:  2.0000\n",
      "theta =  2.7123, omega: -0.8270, action:  0.0000\n",
      "theta =  2.7031, omega:  0.0351, action:  7.0000\n",
      "theta =  2.7059, omega:  0.1623, action:  2.0000\n",
      "theta =  2.7131, omega:  0.2966, action:  2.0000\n",
      "theta =  2.7067, omega: -0.7035, action:  0.0000\n",
      "theta =  2.6992, omega:  0.0589, action:  7.0000\n",
      "theta =  2.7017, omega:  0.1732, action:  2.0000\n",
      "theta =  2.7090, omega:  0.2961, action:  2.0000\n",
      "theta =  2.7021, omega: -0.7152, action:  0.0000\n",
      "theta =  2.6964, omega:  0.0347, action:  7.0000\n",
      "theta =  2.6961, omega:  0.1375, action:  2.0000\n",
      "theta =  2.7024, omega:  0.2460, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7758, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0501, action:  7.0000\n",
      "theta =  2.6893, omega:  0.1263, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2090, action:  2.0000\n",
      "theta =  2.6982, omega:  0.3013, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7332, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0743, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1502, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2308, action:  2.0000\n",
      "theta =  2.6993, omega:  0.3269, action:  2.0000\n",
      "theta =  2.6952, omega: -0.7149, action:  0.0000\n",
      "theta =  2.6868, omega:  0.0741, action:  7.0000\n",
      "theta =  2.6891, omega:  0.1550, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2436, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3462, action:  2.0000\n",
      "theta =  2.6964, omega: -0.6896, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0467, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1372, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2317, action:  2.0000\n",
      "theta =  2.7056, omega:  0.3411, action:  2.0000\n",
      "theta =  2.7008, omega: -0.6895, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0545, action:  7.0000\n",
      "theta =  2.6962, omega:  0.1503, action:  2.0000\n",
      "theta =  2.6998, omega:  0.2522, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7741, action:  0.0000\n",
      "theta =  2.6849, omega:  0.0474, action:  7.0000\n",
      "theta =  2.6883, omega:  0.1212, action:  2.0000\n",
      "theta =  2.6904, omega:  0.1990, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2900, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7526, action:  0.0000\n",
      "theta =  2.6840, omega:  0.0648, action:  7.0000\n",
      "theta =  2.6845, omega:  0.1287, action:  2.0000\n",
      "theta =  2.6888, omega:  0.2003, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2853, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3886, action:  2.0000\n",
      "theta =  2.6992, omega: -0.6523, action:  0.0000\n",
      "theta =  2.6969, omega:  0.0913, action:  7.0000\n",
      "theta =  2.6968, omega:  0.1870, action:  2.0000\n",
      "theta =  2.7019, omega:  0.2957, action:  2.0000\n",
      "theta =  2.6978, omega: -0.7303, action:  0.0000\n",
      "theta =  2.6907, omega:  0.0689, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1537, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2468, action:  2.0000\n",
      "theta =  2.7052, omega:  0.3555, action:  2.0000\n",
      "theta =  2.7005, omega: -0.6754, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0663, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1655, action:  2.0000\n",
      "theta =  2.7034, omega:  0.2710, action:  2.0000\n",
      "theta =  2.6952, omega: -0.7545, action:  0.0000\n",
      "theta =  2.6879, omega:  0.0476, action:  7.0000\n",
      "theta =  2.6892, omega:  0.1263, action:  2.0000\n",
      "theta =  2.6931, omega:  0.2137, action:  2.0000\n",
      "theta =  2.7000, omega:  0.3131, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7241, action:  0.0000\n",
      "theta =  2.6884, omega:  0.0682, action:  7.0000\n",
      "theta =  2.6909, omega:  0.1478, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2345, action:  2.0000\n",
      "theta =  2.7007, omega:  0.3353, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7019, action:  0.0000\n",
      "theta =  2.6888, omega:  0.0302, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1135, action:  2.0000\n",
      "theta =  2.6961, omega:  0.2062, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3087, action:  2.0000\n",
      "theta =  2.6954, omega: -0.7262, action:  0.0000\n",
      "theta =  2.6889, omega:  0.0676, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1507, action:  2.0000\n",
      "theta =  2.6951, omega:  0.2378, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3426, action:  2.0000\n",
      "theta =  2.6988, omega: -0.6910, action:  0.0000\n",
      "theta =  2.6922, omega:  0.0458, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1358, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2316, action:  2.0000\n",
      "theta =  2.7044, omega:  0.3414, action:  2.0000\n",
      "theta =  2.7011, omega: -0.6884, action:  0.0000\n",
      "theta =  2.6948, omega:  0.0556, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1507, action:  2.0000\n",
      "theta =  2.7023, omega:  0.2554, action:  2.0000\n",
      "theta =  2.6960, omega: -0.7701, action:  0.0000\n",
      "theta =  2.6858, omega:  0.0513, action:  7.0000\n",
      "theta =  2.6896, omega:  0.1261, action:  2.0000\n",
      "theta =  2.6920, omega:  0.2078, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2975, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7426, action:  0.0000\n",
      "theta =  2.6843, omega:  0.0492, action:  7.0000\n",
      "theta =  2.6869, omega:  0.1160, action:  2.0000\n",
      "theta =  2.6898, omega:  0.1909, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2777, action:  2.0000\n",
      "theta =  2.6888, omega: -0.7639, action:  0.0000\n",
      "theta =  2.6823, omega:  0.0531, action:  7.0000\n",
      "theta =  2.6880, omega:  0.5790, action:  5.0000\n",
      "theta =  2.6861, omega: -0.5333, action:  0.0000\n",
      "theta =  2.6845, omega:  0.1992, action:  7.0000\n",
      "theta =  2.6906, omega:  0.2699, action:  2.0000\n",
      "theta =  2.6969, omega:  0.3620, action:  2.0000\n",
      "theta =  2.6952, omega: -0.6892, action:  0.0000\n",
      "theta =  2.6874, omega:  0.0361, action:  7.0000\n",
      "theta =  2.6894, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6928, omega:  0.1976, action:  2.0000\n",
      "theta =  2.7008, omega:  0.2904, action:  2.0000\n",
      "theta =  2.6915, omega: -0.7462, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0441, action:  7.0000\n",
      "theta =  2.6863, omega:  0.1134, action:  2.0000\n",
      "theta =  2.6913, omega:  0.1912, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2791, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3822, action:  2.0000\n",
      "theta =  2.7011, omega: -0.6559, action:  0.0000\n",
      "theta =  2.6938, omega:  0.0868, action:  7.0000\n",
      "theta =  2.6977, omega:  0.1870, action:  2.0000\n",
      "theta =  2.7035, omega:  0.2958, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7315, action:  0.0000\n",
      "theta =  2.6907, omega:  0.0673, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1559, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2511, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3613, action:  2.0000\n",
      "theta =  2.7020, omega: -0.6678, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0760, action:  7.0000\n",
      "theta =  2.6960, omega:  0.1755, action:  2.0000\n",
      "theta =  2.7041, omega:  0.2845, action:  2.0000\n",
      "theta =  2.6973, omega: -0.7382, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0886, action:  7.0000\n",
      "theta =  2.6924, omega:  0.1747, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2718, action:  2.0000\n",
      "theta =  2.6922, omega: -0.7639, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0525, action:  7.0000\n",
      "theta =  2.6847, omega:  0.1200, action:  2.0000\n",
      "theta =  2.6920, omega:  0.1942, action:  2.0000\n",
      "theta =  2.6865, omega: -0.4052, action:  1.0000\n",
      "theta =  2.6847, omega:  0.2730, action:  7.0000\n",
      "theta =  2.6921, omega:  0.3511, action:  2.0000\n",
      "theta =  2.6881, omega: -0.7129, action:  0.0000\n",
      "theta =  2.6820, omega:  0.0844, action:  7.0000\n",
      "theta =  2.6841, omega:  0.1458, action:  2.0000\n",
      "theta =  2.6947, omega:  0.6835, action:  6.0000\n",
      "theta =  2.6963, omega: -0.4326, action:  0.0000\n",
      "theta =  2.6955, omega:  0.2403, action:  7.0000\n",
      "theta =  2.7029, omega:  0.3412, action:  2.0000\n",
      "theta =  2.6966, omega: -0.6957, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0413, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1274, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2195, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3260, action:  2.0000\n",
      "theta =  2.6980, omega: -0.7061, action:  0.0000\n",
      "theta =  2.6909, omega:  0.0361, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1213, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2167, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3251, action:  2.0000\n",
      "theta =  2.6975, omega: -0.7074, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0323, action:  7.0000\n",
      "theta =  2.6934, omega:  0.1230, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2142, action:  2.0000\n",
      "theta =  2.7098, omega:  0.7900, action:  6.0000\n",
      "theta =  2.7138, omega: -0.3057, action:  0.0000\n",
      "theta =  2.7119, omega:  0.0519, action:  2.0000\n",
      "theta =  2.7147, omega:  0.2004, action:  2.0000\n",
      "theta =  2.7085, omega: -0.7733, action:  0.0000\n",
      "theta =  2.6990, omega:  0.0632, action:  7.0000\n",
      "theta =  2.7020, omega:  0.1806, action:  2.0000\n",
      "theta =  2.7092, omega:  0.3037, action:  2.0000\n",
      "theta =  2.7056, omega: -0.7073, action:  0.0000\n",
      "theta =  2.6962, omega:  0.0457, action:  7.0000\n",
      "theta =  2.6986, omega:  0.1472, action:  2.0000\n",
      "theta =  2.7043, omega:  0.2591, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7601, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0433, action:  7.0000\n",
      "theta =  2.6905, omega:  0.1272, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2172, action:  2.0000\n",
      "theta =  2.7023, omega:  0.3196, action:  2.0000\n",
      "theta =  2.6954, omega: -0.7142, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0796, action:  7.0000\n",
      "theta =  2.6926, omega:  0.1610, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2529, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3629, action:  2.0000\n",
      "theta =  2.6996, omega: -0.6737, action:  0.0000\n",
      "theta =  2.6941, omega:  0.0723, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1687, action:  2.0000\n",
      "theta =  2.7008, omega:  0.2753, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7503, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0517, action:  7.0000\n",
      "theta =  2.6905, omega:  0.1335, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2210, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3203, action:  2.0000\n",
      "theta =  2.6962, omega: -0.7140, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0800, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1598, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2505, action:  2.0000\n",
      "theta =  2.7050, omega:  0.3573, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6753, action:  0.0000\n",
      "theta =  2.6943, omega:  0.0661, action:  7.0000\n",
      "theta =  2.6976, omega:  0.1628, action:  2.0000\n",
      "theta =  2.7010, omega:  0.2648, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7589, action:  0.0000\n",
      "theta =  2.6872, omega:  0.0390, action:  7.0000\n",
      "theta =  2.6882, omega:  0.1174, action:  2.0000\n",
      "theta =  2.6908, omega:  0.1980, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2933, action:  2.0000\n",
      "theta =  2.6919, omega: -0.7477, action:  0.0000\n",
      "theta =  2.6826, omega:  0.0443, action:  7.0000\n",
      "theta =  2.6851, omega:  0.1137, action:  2.0000\n",
      "theta =  2.6910, omega:  0.1899, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2756, action:  2.0000\n",
      "theta =  2.7033, omega:  0.3797, action:  2.0000\n",
      "theta =  2.7220, omega:  0.9743, action:  3.0000\n",
      "theta =  2.7296, omega: -0.1092, action:  0.0000\n",
      "theta =  2.7326, omega:  0.1589, action:  2.0000\n",
      "theta =  2.7234, omega: -0.7612, action:  0.0000\n",
      "theta =  2.7164, omega:  0.0509, action:  7.0000\n",
      "theta =  2.7176, omega:  0.2114, action:  2.0000\n",
      "theta =  2.7123, omega: -0.7546, action:  0.0000\n",
      "theta =  2.7042, omega:  0.0844, action:  7.0000\n",
      "theta =  2.7094, omega:  0.2143, action:  2.0000\n",
      "theta =  2.7009, omega: -0.7817, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0620, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1564, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2577, action:  2.0000\n",
      "theta =  2.6930, omega: -0.7719, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0505, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1201, action:  2.0000\n",
      "theta =  2.6908, omega:  0.2005, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2893, action:  2.0000\n",
      "theta =  2.6910, omega: -0.7539, action:  0.0000\n",
      "theta =  2.6831, omega:  0.0614, action:  7.0000\n",
      "theta =  2.6855, omega:  0.1258, action:  2.0000\n",
      "theta =  2.6897, omega:  0.1987, action:  2.0000\n",
      "theta =  2.6944, omega:  0.2813, action:  2.0000\n",
      "theta =  2.7018, omega:  0.3813, action:  2.0000\n",
      "theta =  2.7001, omega: -0.6599, action:  0.0000\n",
      "theta =  2.6931, omega:  0.0826, action:  7.0000\n",
      "theta =  2.6962, omega:  0.1759, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2808, action:  2.0000\n",
      "theta =  2.6954, omega: -0.7460, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0551, action:  7.0000\n",
      "theta =  2.6885, omega:  0.1330, action:  2.0000\n",
      "theta =  2.6935, omega:  0.2205, action:  2.0000\n",
      "theta =  2.7003, omega:  0.3178, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7190, action:  0.0000\n",
      "theta =  2.6850, omega:  0.0743, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1554, action:  2.0000\n",
      "theta =  2.6945, omega:  0.2438, action:  2.0000\n",
      "theta =  2.7034, omega:  0.3480, action:  2.0000\n",
      "theta =  2.6988, omega: -0.6866, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0515, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1416, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2405, action:  2.0000\n",
      "theta =  2.7068, omega:  0.3529, action:  2.0000\n",
      "theta =  2.7017, omega: -0.6767, action:  0.0000\n",
      "theta =  2.6949, omega:  0.0716, action:  7.0000\n",
      "theta =  2.6990, omega:  0.1744, action:  2.0000\n",
      "theta =  2.7036, omega:  0.2823, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7390, action:  0.0000\n",
      "theta =  2.6899, omega:  0.0871, action:  7.0000\n",
      "theta =  2.6934, omega:  0.1721, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2670, action:  2.0000\n",
      "theta =  2.6914, omega: -0.7673, action:  0.0000\n",
      "theta =  2.6808, omega:  0.0478, action:  7.0000\n",
      "theta =  2.6710, omega: -0.9895, action:  0.0000\n",
      "theta =  2.6581, omega: -0.1902, action:  7.0000\n",
      "theta =  2.6530, omega:  0.0023, action:  2.0000\n",
      "theta =  2.6540, omega:  0.0025, action:  2.0000\n",
      "theta =  2.6550, omega:  0.0026, action:  2.0000\n",
      "theta =  2.6541, omega:  0.0014, action:  2.0000\n",
      "theta =  2.6554, omega:  0.0009, action:  2.0000\n",
      "theta =  2.6571, omega:  0.0012, action:  2.0000\n",
      "theta =  2.6557, omega:  0.0002, action:  2.0000\n",
      "theta =  2.6559, omega:  0.0019, action:  2.0000\n",
      "theta =  2.6546, omega: -0.0009, action:  2.0000\n",
      "theta =  2.6549, omega:  0.0008, action:  2.0000\n",
      "theta =  2.6559, omega:  0.0023, action:  2.0000\n",
      "theta =  2.6555, omega:  0.0023, action:  2.0000\n",
      "theta =  2.6563, omega:  0.0023, action:  2.0000\n",
      "theta =  2.6565, omega: -0.0006, action:  2.0000\n",
      "theta =  2.6609, omega:  0.4566, action:  8.0000\n",
      "theta =  2.6724, omega:  0.4644, action:  2.0000\n",
      "theta =  2.6862, omega:  0.5025, action:  2.0000\n",
      "theta =  2.6826, omega: -0.6094, action:  0.0000\n",
      "theta =  2.6792, omega:  0.1400, action:  7.0000\n",
      "theta =  2.6824, omega:  0.1929, action:  2.0000\n",
      "theta =  2.6865, omega:  0.2551, action:  2.0000\n",
      "theta =  2.6955, omega:  0.3338, action:  2.0000\n",
      "theta =  2.6906, omega: -0.7211, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0732, action:  7.0000\n",
      "theta =  2.6842, omega:  0.1404, action:  2.0000\n",
      "theta =  2.6905, omega:  0.2098, action:  2.0000\n",
      "theta =  2.7011, omega:  0.7601, action:  4.0000\n",
      "theta =  2.7060, omega: -0.3502, action:  0.0000\n",
      "theta =  2.7007, omega:  0.0242, action:  2.0000\n",
      "theta =  2.7042, omega:  0.1443, action:  2.0000\n",
      "theta =  2.7091, omega:  0.2721, action:  2.0000\n",
      "theta =  2.7022, omega: -0.7341, action:  0.0000\n",
      "theta =  2.6953, omega:  0.0783, action:  7.0000\n",
      "theta =  2.6981, omega:  0.1796, action:  2.0000\n",
      "theta =  2.7038, omega:  0.2925, action:  2.0000\n",
      "theta =  2.6987, omega: -0.7313, action:  0.0000\n",
      "theta =  2.6926, omega:  0.0714, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1618, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2598, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7727, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0249, action:  7.0000\n",
      "theta =  2.6835, omega:  0.0951, action:  2.0000\n",
      "theta =  2.6880, omega:  0.1676, action:  2.0000\n",
      "theta =  2.6932, omega:  0.2491, action:  2.0000\n",
      "theta =  2.7017, omega:  0.3453, action:  2.0000\n",
      "theta =  2.6959, omega: -0.6969, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0345, action:  7.0000\n",
      "theta =  2.6897, omega:  0.1167, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2046, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3041, action:  2.0000\n",
      "theta =  2.6966, omega: -0.7302, action:  0.0000\n",
      "theta =  2.6889, omega:  0.0894, action:  7.0000\n",
      "theta =  2.6899, omega:  0.1685, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2572, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3595, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6755, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0655, action:  7.0000\n",
      "theta =  2.6968, omega:  0.1582, action:  2.0000\n",
      "theta =  2.7018, omega:  0.2604, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7688, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0518, action:  7.0000\n",
      "theta =  2.6869, omega:  0.1245, action:  2.0000\n",
      "theta =  2.6914, omega:  0.2017, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2936, action:  2.0000\n",
      "theta =  2.6896, omega: -0.7465, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0434, action:  7.0000\n",
      "theta =  2.6838, omega:  0.1084, action:  2.0000\n",
      "theta =  2.6876, omega:  0.1811, action:  2.0000\n",
      "theta =  2.6933, omega:  0.2638, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3627, action:  2.0000\n",
      "theta =  2.6987, omega: -0.6784, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0571, action:  7.0000\n",
      "theta =  2.6937, omega:  0.1456, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2432, action:  2.0000\n",
      "theta =  2.7052, omega:  0.3530, action:  2.0000\n",
      "theta =  2.7007, omega: -0.6762, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0690, action:  7.0000\n",
      "theta =  2.6997, omega:  0.1683, action:  2.0000\n",
      "theta =  2.7022, omega:  0.2790, action:  2.0000\n",
      "theta =  2.6947, omega: -0.7466, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0572, action:  7.0000\n",
      "theta =  2.6915, omega:  0.1398, action:  2.0000\n",
      "theta =  2.6961, omega:  0.2292, action:  2.0000\n",
      "theta =  2.7021, omega:  0.3330, action:  2.0000\n",
      "theta =  2.6970, omega: -0.6997, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0333, action:  7.0000\n",
      "theta =  2.6975, omega:  0.5870, action:  8.0000\n",
      "theta =  2.6967, omega: -0.5038, action:  0.0000\n",
      "theta =  2.6950, omega:  0.1899, action:  7.0000\n",
      "theta =  2.7008, omega:  0.2925, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7382, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0752, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1540, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2417, action:  2.0000\n",
      "theta =  2.7023, omega:  0.3418, action:  2.0000\n",
      "theta =  2.6950, omega: -0.6944, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0401, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1277, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2225, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3282, action:  2.0000\n",
      "theta =  2.6984, omega: -0.7030, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0383, action:  7.0000\n",
      "theta =  2.6937, omega:  0.1241, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2207, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3293, action:  2.0000\n",
      "theta =  2.6997, omega: -0.7022, action:  0.0000\n",
      "theta =  2.6916, omega:  0.0395, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1279, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2256, action:  2.0000\n",
      "theta =  2.7052, omega:  0.3394, action:  2.0000\n",
      "theta =  2.7034, omega: -0.6894, action:  0.0000\n",
      "theta =  2.6939, omega:  0.0556, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1516, action:  2.0000\n",
      "theta =  2.7010, omega:  0.2534, action:  2.0000\n",
      "theta =  2.6953, omega: -0.7680, action:  0.0000\n",
      "theta =  2.6848, omega:  0.0531, action:  7.0000\n",
      "theta =  2.6856, omega:  0.1279, action:  2.0000\n",
      "theta =  2.6921, omega:  0.2074, action:  2.0000\n",
      "theta =  2.6986, omega:  0.3019, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7390, action:  0.0000\n",
      "theta =  2.6841, omega:  0.0514, action:  7.0000\n",
      "theta =  2.6851, omega:  0.1247, action:  2.0000\n",
      "theta =  2.6899, omega:  0.2030, action:  2.0000\n",
      "theta =  2.6978, omega:  0.2937, action:  2.0000\n",
      "theta =  2.6896, omega: -0.7513, action:  0.0000\n",
      "theta =  2.6812, omega:  0.0447, action:  7.0000\n",
      "theta =  2.6853, omega:  0.1077, action:  2.0000\n",
      "theta =  2.6863, omega:  0.1797, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2603, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3599, action:  2.0000\n",
      "theta =  2.6943, omega: -0.6847, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0478, action:  7.0000\n",
      "theta =  2.6917, omega:  0.1330, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2276, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3329, action:  2.0000\n",
      "theta =  2.6969, omega: -0.6977, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0397, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1281, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2237, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3339, action:  2.0000\n",
      "theta =  2.6972, omega: -0.6952, action:  0.0000\n",
      "theta =  2.6911, omega:  0.0453, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1415, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2406, action:  2.0000\n",
      "theta =  2.7070, omega:  0.3569, action:  2.0000\n",
      "theta =  2.7045, omega: -0.6706, action:  0.0000\n",
      "theta =  2.6959, omega:  0.0805, action:  6.0000\n",
      "theta =  2.6992, omega:  0.1826, action:  2.0000\n",
      "theta =  2.7070, omega:  0.2967, action:  2.0000\n",
      "theta =  2.6995, omega: -0.7227, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0792, action:  7.0000\n",
      "theta =  2.6965, omega:  0.1733, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2745, action:  2.0000\n",
      "theta =  2.6946, omega: -0.7546, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0439, action:  7.0000\n",
      "theta =  2.6887, omega:  0.1199, action:  2.0000\n",
      "theta =  2.6915, omega:  0.2021, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2964, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7418, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0517, action:  7.0000\n",
      "theta =  2.6854, omega:  0.1217, action:  2.0000\n",
      "theta =  2.6904, omega:  0.1979, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2882, action:  2.0000\n",
      "theta =  2.6893, omega: -0.7571, action:  0.0000\n",
      "theta =  2.6823, omega:  0.0607, action:  7.0000\n",
      "theta =  2.6852, omega:  0.1243, action:  2.0000\n",
      "theta =  2.6884, omega:  0.1963, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2777, action:  2.0000\n",
      "theta =  2.6877, omega: -0.7710, action:  0.0000\n",
      "theta =  2.6797, omega:  0.0490, action:  7.0000\n",
      "theta =  2.6813, omega:  0.1029, action:  2.0000\n",
      "theta =  2.6842, omega:  0.1639, action:  2.0000\n",
      "theta =  2.6897, omega:  0.2341, action:  2.0000\n",
      "theta =  2.7023, omega:  0.7853, action:  7.0000\n",
      "theta =  2.7069, omega: -0.3267, action:  0.0000\n",
      "theta =  2.7038, omega:  0.0313, action:  2.0000\n",
      "theta =  2.7077, omega:  0.1579, action:  2.0000\n",
      "theta =  2.7122, omega:  0.2927, action:  2.0000\n",
      "theta =  2.7049, omega: -0.7097, action:  0.0000\n",
      "theta =  2.6985, omega:  0.0506, action:  7.0000\n",
      "theta =  2.7019, omega:  0.1606, action:  2.0000\n",
      "theta =  2.7062, omega:  0.2805, action:  2.0000\n",
      "theta =  2.7005, omega: -0.7313, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0750, action:  7.0000\n",
      "theta =  2.6963, omega:  0.1722, action:  2.0000\n",
      "theta =  2.7008, omega:  0.2773, action:  2.0000\n",
      "theta =  2.6977, omega: -0.7493, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0515, action:  7.0000\n",
      "theta =  2.6923, omega:  0.1309, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2172, action:  2.0000\n",
      "theta =  2.6989, omega:  0.3160, action:  2.0000\n",
      "theta =  2.6945, omega: -0.7205, action:  0.0000\n",
      "theta =  2.6865, omega:  0.0713, action:  7.0000\n",
      "theta =  2.6900, omega:  0.1519, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2412, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3456, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6927, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0445, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1343, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2280, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3385, action:  2.0000\n",
      "theta =  2.7010, omega: -0.6919, action:  0.0000\n",
      "theta =  2.6926, omega:  0.0500, action:  7.0000\n",
      "theta =  2.6940, omega:  0.1431, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2453, action:  2.0000\n",
      "theta =  2.7069, omega:  0.3600, action:  2.0000\n",
      "theta =  2.7029, omega: -0.6664, action:  0.0000\n",
      "theta =  2.6955, omega:  0.0856, action:  7.0000\n",
      "theta =  2.6987, omega:  0.1912, action:  2.0000\n",
      "theta =  2.7062, omega:  0.3052, action:  2.0000\n",
      "theta =  2.7017, omega: -0.7142, action:  0.0000\n",
      "theta =  2.6922, omega:  0.0950, action:  7.0000\n",
      "theta =  2.6973, omega:  0.1923, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3000, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7282, action:  0.0000\n",
      "theta =  2.6915, omega:  0.0729, action:  7.0000\n",
      "theta =  2.6929, omega:  0.1558, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2500, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3610, action:  2.0000\n",
      "theta =  2.7005, omega: -0.6729, action:  0.0000\n",
      "theta =  2.6950, omega:  0.0738, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1744, action:  2.0000\n",
      "theta =  2.7030, omega:  0.2816, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7405, action:  0.0000\n",
      "theta =  2.6892, omega:  0.0831, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1668, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2630, action:  2.0000\n",
      "theta =  2.6900, omega: -0.7743, action:  0.0000\n",
      "theta =  2.6840, omega:  0.0222, action:  7.0000\n",
      "theta =  2.6823, omega:  0.0849, action:  2.0000\n",
      "theta =  2.6876, omega:  0.1535, action:  2.0000\n",
      "theta =  2.6885, omega:  0.2319, action:  2.0000\n",
      "theta =  2.6981, omega:  0.3222, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7211, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0853, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1583, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2411, action:  2.0000\n",
      "theta =  2.6989, omega:  0.3365, action:  2.0000\n",
      "theta =  2.6953, omega: -0.7036, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0836, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1667, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2558, action:  2.0000\n",
      "theta =  2.7040, omega:  0.3627, action:  2.0000\n",
      "theta =  2.7021, omega: -0.6720, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0714, action:  7.0000\n",
      "theta =  2.6957, omega:  0.1682, action:  2.0000\n",
      "theta =  2.7024, omega:  0.2750, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7523, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0476, action:  6.0000\n",
      "theta =  2.6896, omega:  0.1259, action:  2.0000\n",
      "theta =  2.6924, omega:  0.2129, action:  2.0000\n",
      "theta =  2.6989, omega:  0.3125, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7266, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0748, action:  7.0000\n",
      "theta =  2.6888, omega:  0.1539, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2373, action:  2.0000\n",
      "theta =  2.7016, omega:  0.3389, action:  2.0000\n",
      "theta =  2.6959, omega: -0.6973, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0387, action:  7.0000\n",
      "theta =  2.6923, omega:  0.1241, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2150, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3190, action:  2.0000\n",
      "theta =  2.6975, omega: -0.7125, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0836, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1708, action:  2.0000\n",
      "theta =  2.6903, omega: -0.4252, action:  1.0000\n",
      "theta =  2.6885, omega:  0.2805, action:  7.0000\n",
      "theta =  2.6959, omega:  0.3656, action:  2.0000\n",
      "theta =  2.6914, omega: -0.6906, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0306, action:  7.0000\n",
      "theta =  2.6859, omega:  0.1006, action:  2.0000\n",
      "theta =  2.6882, omega:  0.1786, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2629, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3661, action:  2.0000\n",
      "theta =  2.7002, omega: -0.6706, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0678, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1628, action:  2.0000\n",
      "theta =  2.7003, omega:  0.2641, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7637, action:  0.0000\n",
      "theta =  2.6879, omega:  0.0606, action:  7.0000\n",
      "theta =  2.6889, omega:  0.1348, action:  2.0000\n",
      "theta =  2.6913, omega:  0.2162, action:  2.0000\n",
      "theta =  2.6976, omega:  0.3095, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7306, action:  0.0000\n",
      "theta =  2.6848, omega:  0.0754, action:  7.0000\n",
      "theta =  2.6879, omega:  0.1479, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2326, action:  2.0000\n",
      "theta =  2.7003, omega:  0.3277, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7154, action:  0.0000\n",
      "theta =  2.6864, omega:  0.0735, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1540, action:  2.0000\n",
      "theta =  2.6951, omega:  0.2407, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3421, action:  2.0000\n",
      "theta =  2.6992, omega: -0.6967, action:  0.0000\n",
      "theta =  2.6911, omega:  0.0396, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1276, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2180, action:  2.0000\n",
      "theta =  2.7016, omega:  0.3228, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7077, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0972, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1845, action:  2.0000\n",
      "theta =  2.6998, omega:  0.2834, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7492, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0485, action:  7.0000\n",
      "theta =  2.6876, omega:  0.1206, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2017, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2924, action:  2.0000\n",
      "theta =  2.6937, omega: -0.7468, action:  0.0000\n",
      "theta =  2.6815, omega:  0.0423, action:  7.0000\n",
      "theta =  2.6838, omega:  0.1125, action:  2.0000\n",
      "theta =  2.6901, omega:  0.1856, action:  2.0000\n",
      "theta =  2.6955, omega:  0.2676, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3678, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6709, action:  0.0000\n",
      "theta =  2.6930, omega:  0.0692, action:  7.0000\n",
      "theta =  2.6968, omega:  0.1586, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2605, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7701, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0505, action:  7.0000\n",
      "theta =  2.6856, omega:  0.1222, action:  2.0000\n",
      "theta =  2.6917, omega:  0.2001, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2904, action:  2.0000\n",
      "theta =  2.6896, omega: -0.7532, action:  0.0000\n",
      "theta =  2.6805, omega:  0.0620, action:  7.0000\n",
      "theta =  2.6851, omega:  0.1256, action:  2.0000\n",
      "theta =  2.6895, omega:  0.1972, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2816, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3814, action:  2.0000\n",
      "theta =  2.6970, omega: -0.6597, action:  0.0000\n",
      "theta =  2.6936, omega:  0.0810, action:  7.0000\n",
      "theta =  2.6963, omega:  0.1736, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2758, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7503, action:  0.0000\n",
      "theta =  2.6855, omega:  0.0470, action:  7.0000\n",
      "theta =  2.6885, omega:  0.1237, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2103, action:  2.0000\n",
      "theta =  2.6984, omega:  0.3067, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7297, action:  0.0000\n",
      "theta =  2.6850, omega:  0.0843, action:  7.0000\n",
      "theta =  2.6889, omega:  0.1589, action:  2.0000\n",
      "theta =  2.6921, omega:  0.2448, action:  2.0000\n",
      "theta =  2.7001, omega:  0.3432, action:  2.0000\n",
      "theta =  2.6952, omega: -0.6958, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0371, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1228, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2144, action:  2.0000\n",
      "theta =  2.7016, omega:  0.3189, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7121, action:  0.0000\n",
      "theta =  2.6881, omega:  0.0828, action:  7.0000\n",
      "theta =  2.6936, omega:  0.1688, action:  2.0000\n",
      "theta =  2.6991, omega:  0.2620, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7713, action:  0.0000\n",
      "theta =  2.6827, omega:  0.0265, action:  7.0000\n",
      "theta =  2.6836, omega:  0.0944, action:  2.0000\n",
      "theta =  2.6887, omega:  0.1656, action:  2.0000\n",
      "theta =  2.6933, omega:  0.2445, action:  2.0000\n",
      "theta =  2.7000, omega:  0.3401, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7016, action:  0.0000\n",
      "theta =  2.6892, omega:  0.1019, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1837, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2767, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3851, action:  2.0000\n",
      "theta =  2.7017, omega: -0.6520, action:  0.0000\n",
      "theta =  2.6958, omega:  0.0981, action:  7.0000\n",
      "theta =  2.6990, omega:  0.1995, action:  2.0000\n",
      "theta =  2.7067, omega:  0.3119, action:  2.0000\n",
      "theta =  2.6999, omega: -0.7088, action:  0.0000\n",
      "theta =  2.6934, omega:  0.0350, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1304, action:  2.0000\n",
      "theta =  2.6992, omega:  0.2311, action:  2.0000\n",
      "theta =  2.7060, omega:  0.3463, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6806, action:  0.0000\n",
      "theta =  2.6955, omega:  0.0655, action:  7.0000\n",
      "theta =  2.6967, omega:  0.1715, action:  2.0000\n",
      "theta =  2.7042, omega:  0.2811, action:  2.0000\n",
      "theta =  2.6964, omega: -0.7415, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0828, action:  7.0000\n",
      "theta =  2.6929, omega:  0.1706, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2673, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7677, action:  0.0000\n",
      "theta =  2.6831, omega:  0.0496, action:  7.0000\n",
      "theta =  2.6823, omega:  0.1141, action:  2.0000\n",
      "theta =  2.6893, omega:  0.1896, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2725, action:  2.0000\n",
      "theta =  2.7050, omega:  0.3731, action:  2.0000\n",
      "theta =  2.6971, omega: -0.6672, action:  0.0000\n",
      "theta =  2.6924, omega:  0.0695, action:  7.0000\n",
      "theta =  2.6954, omega:  0.1635, action:  2.0000\n",
      "theta =  2.7001, omega:  0.2638, action:  2.0000\n",
      "theta =  2.6933, omega: -0.7621, action:  0.0000\n",
      "theta =  2.6845, omega:  0.0619, action:  7.0000\n",
      "theta =  2.6858, omega:  0.1335, action:  2.0000\n",
      "theta =  2.6903, omega:  0.2165, action:  2.0000\n",
      "theta =  2.6991, omega:  0.3070, action:  2.0000\n",
      "theta =  2.6915, omega: -0.7327, action:  0.0000\n",
      "theta =  2.6847, omega:  0.0752, action:  7.0000\n",
      "theta =  2.6871, omega:  0.1474, action:  2.0000\n",
      "theta =  2.6935, omega:  0.2288, action:  2.0000\n",
      "theta =  2.6982, omega:  0.3249, action:  2.0000\n",
      "theta =  2.6939, omega: -0.7181, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0712, action:  7.0000\n",
      "theta =  2.6893, omega:  0.1440, action:  2.0000\n",
      "theta =  2.6943, omega:  0.2302, action:  2.0000\n",
      "theta =  2.6998, omega:  0.3285, action:  2.0000\n",
      "theta =  2.6959, omega: -0.7084, action:  0.0000\n",
      "theta =  2.6887, omega:  0.0799, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1625, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2540, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3608, action:  2.0000\n",
      "theta =  2.6982, omega: -0.6744, action:  0.0000\n",
      "theta =  2.6923, omega:  0.0705, action:  7.0000\n",
      "theta =  2.6968, omega:  0.1666, action:  2.0000\n",
      "theta =  2.7019, omega:  0.2692, action:  2.0000\n",
      "theta =  2.6953, omega: -0.7574, action:  0.0000\n",
      "theta =  2.6856, omega:  0.0448, action:  7.0000\n",
      "theta =  2.6891, omega:  0.1205, action:  2.0000\n",
      "theta =  2.6937, omega:  0.2034, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2978, action:  2.0000\n",
      "theta =  2.6924, omega: -0.7397, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0546, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1271, action:  2.0000\n",
      "theta =  2.6919, omega:  0.2074, action:  2.0000\n",
      "theta =  2.6990, omega:  0.3003, action:  2.0000\n",
      "theta =  2.6904, omega: -0.7417, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0490, action:  7.0000\n",
      "theta =  2.6849, omega:  0.1184, action:  2.0000\n",
      "theta =  2.6883, omega:  0.1931, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2809, action:  2.0000\n",
      "theta =  2.6899, omega: -0.7644, action:  0.0000\n",
      "theta =  2.6798, omega:  0.0550, action:  7.0000\n",
      "theta =  2.6842, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6856, omega:  0.1808, action:  2.0000\n",
      "theta =  2.6918, omega:  0.2585, action:  2.0000\n",
      "theta =  2.7005, omega:  0.3529, action:  2.0000\n",
      "theta =  2.6963, omega: -0.6935, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0340, action:  7.0000\n",
      "theta =  2.6906, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6945, omega:  0.2003, action:  2.0000\n",
      "theta =  2.7000, omega:  0.2941, action:  2.0000\n",
      "theta =  2.6921, omega: -0.7414, action:  0.0000\n",
      "theta =  2.6847, omega:  0.0567, action:  7.0000\n",
      "theta =  2.6875, omega:  0.1293, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2107, action:  2.0000\n",
      "theta =  2.6989, omega:  0.3043, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7379, action:  0.0000\n",
      "theta =  2.6847, omega:  0.0561, action:  7.0000\n",
      "theta =  2.6856, omega:  0.1254, action:  2.0000\n",
      "theta =  2.6919, omega:  0.2050, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2965, action:  2.0000\n",
      "theta =  2.6912, omega: -0.7464, action:  0.0000\n",
      "theta =  2.6830, omega:  0.0431, action:  7.0000\n",
      "theta =  2.6862, omega:  0.1098, action:  2.0000\n",
      "theta =  2.6909, omega:  0.1829, action:  2.0000\n",
      "theta =  2.6944, omega:  0.2662, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3677, action:  2.0000\n",
      "theta =  2.6980, omega: -0.6773, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0608, action:  7.0000\n",
      "theta =  2.6936, omega:  0.1501, action:  2.0000\n",
      "theta =  2.6977, omega:  0.2498, action:  2.0000\n",
      "theta =  2.7062, omega:  0.3625, action:  2.0000\n",
      "theta =  2.7030, omega: -0.6677, action:  0.0000\n",
      "theta =  2.6941, omega:  0.0816, action:  3.0000\n",
      "theta =  2.6999, omega:  0.1826, action:  2.0000\n",
      "theta =  2.7033, omega:  0.2957, action:  2.0000\n",
      "theta =  2.6987, omega: -0.7241, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0770, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1671, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2666, action:  2.0000\n",
      "theta =  2.6925, omega: -0.7611, action:  0.0000\n",
      "theta =  2.6838, omega:  0.0621, action:  7.0000\n",
      "theta =  2.6868, omega:  0.1332, action:  2.0000\n",
      "theta =  2.6916, omega:  0.2150, action:  2.0000\n",
      "theta =  2.6966, omega:  0.3067, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7334, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0743, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1450, action:  2.0000\n",
      "theta =  2.6922, omega:  0.2260, action:  2.0000\n",
      "theta =  2.6995, omega:  0.3223, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7225, action:  0.0000\n",
      "theta =  2.6845, omega:  0.0687, action:  7.0000\n",
      "theta =  2.6882, omega:  0.1430, action:  2.0000\n",
      "theta =  2.6922, omega:  0.2279, action:  2.0000\n",
      "theta =  2.7086, omega:  0.7913, action:  4.0000\n",
      "theta =  2.7102, omega: -0.3104, action:  0.0000\n",
      "theta =  2.7074, omega:  0.0423, action:  2.0000\n",
      "theta =  2.7130, omega:  0.1830, action:  2.0000\n",
      "theta =  2.7033, omega: -0.8011, action:  0.0000\n",
      "theta =  2.6953, omega:  0.0302, action:  7.0000\n",
      "theta =  2.6982, omega:  0.1306, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2352, action:  2.0000\n",
      "theta =  2.7077, omega:  0.3524, action:  2.0000\n",
      "theta =  2.7029, omega: -0.6675, action:  0.0000\n",
      "theta =  2.6960, omega:  0.0835, action:  7.0000\n",
      "theta =  2.6999, omega:  0.1931, action:  2.0000\n",
      "theta =  2.7072, omega:  0.3103, action:  2.0000\n",
      "theta =  2.7032, omega: -0.7064, action:  0.0000\n",
      "theta =  2.6936, omega:  0.0394, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1382, action:  2.0000\n",
      "theta =  2.7000, omega:  0.2440, action:  2.0000\n",
      "theta =  2.7083, omega:  0.3636, action:  2.0000\n",
      "theta =  2.7043, omega: -0.6613, action:  0.0000\n",
      "theta =  2.6987, omega:  0.0980, action:  4.0000\n",
      "theta =  2.7026, omega:  0.2064, action:  2.0000\n",
      "theta =  2.7086, omega:  0.3280, action:  2.0000\n",
      "theta =  2.7028, omega: -0.6885, action:  0.0000\n",
      "theta =  2.6976, omega:  0.0661, action:  7.0000\n",
      "theta =  2.6993, omega:  0.1743, action:  2.0000\n",
      "theta =  2.7054, omega:  0.2898, action:  2.0000\n",
      "theta =  2.6986, omega: -0.7265, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0758, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1682, action:  2.0000\n",
      "theta =  2.6999, omega:  0.2711, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7583, action:  0.0000\n",
      "theta =  2.6859, omega:  0.0392, action:  7.0000\n",
      "theta =  2.6889, omega:  0.1166, action:  2.0000\n",
      "theta =  2.6917, omega:  0.1968, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2907, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7485, action:  0.0000\n",
      "theta =  2.6817, omega:  0.0411, action:  7.0000\n",
      "theta =  2.6864, omega:  0.1069, action:  2.0000\n",
      "theta =  2.6876, omega:  0.1810, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2651, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3662, action:  2.0000\n",
      "theta =  2.6980, omega: -0.6752, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0622, action:  7.0000\n",
      "theta =  2.6803, omega: -0.9566, action:  0.0000\n",
      "theta =  2.6660, omega: -0.1330, action:  7.0000\n",
      "theta =  2.6655, omega:  0.0115, action:  2.0000\n",
      "theta =  2.6654, omega:  0.0291, action:  2.0000\n",
      "theta =  2.6676, omega:  0.0476, action:  2.0000\n",
      "theta =  2.6703, omega:  0.0702, action:  2.0000\n",
      "theta =  2.6703, omega:  0.0981, action:  2.0000\n",
      "theta =  2.6725, omega:  0.1298, action:  2.0000\n",
      "theta =  2.6779, omega:  0.1679, action:  2.0000\n",
      "theta =  2.6879, omega:  0.6857, action:  4.0000\n",
      "theta =  2.6905, omega: -0.4484, action:  0.0000\n",
      "theta =  2.6888, omega:  0.2620, action:  7.0000\n",
      "theta =  2.6975, omega:  0.3467, action:  2.0000\n",
      "theta =  2.6905, omega: -0.7086, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0707, action:  7.0000\n",
      "theta =  2.6874, omega:  0.1383, action:  2.0000\n",
      "theta =  2.6909, omega:  0.2177, action:  2.0000\n",
      "theta =  2.6983, omega:  0.3081, action:  2.0000\n",
      "theta =  2.6931, omega: -0.7352, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0528, action:  7.0000\n",
      "theta =  2.6865, omega:  0.1220, action:  2.0000\n",
      "theta =  2.6900, omega:  0.1962, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2853, action:  2.0000\n",
      "theta =  2.6889, omega: -0.7603, action:  0.0000\n",
      "theta =  2.6808, omega:  0.0491, action:  7.0000\n",
      "theta =  2.6820, omega:  0.1102, action:  2.0000\n",
      "theta =  2.6866, omega:  0.1770, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2531, action:  2.0000\n",
      "theta =  2.6988, omega:  0.3474, action:  2.0000\n",
      "theta =  2.6929, omega: -0.6993, action:  0.0000\n",
      "theta =  2.6882, omega:  0.0293, action:  7.0000\n",
      "theta =  2.6897, omega:  0.1077, action:  2.0000\n",
      "theta =  2.6910, omega:  0.1923, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2863, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7525, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0413, action:  7.0000\n",
      "theta =  2.6832, omega:  0.1117, action:  2.0000\n",
      "theta =  2.6831, omega: -0.4743, action:  1.0000\n",
      "theta =  2.6794, omega:  0.2218, action:  7.0000\n",
      "theta =  2.6853, omega:  0.2744, action:  2.0000\n",
      "theta =  2.6927, omega:  0.3477, action:  2.0000\n",
      "theta =  2.6888, omega: -0.7165, action:  0.0000\n",
      "theta =  2.6815, omega:  0.0744, action:  7.0000\n",
      "theta =  2.6837, omega:  0.1359, action:  2.0000\n",
      "theta =  2.6919, omega:  0.6684, action:  6.0000\n",
      "theta =  2.6949, omega: -0.4495, action:  0.0000\n",
      "theta =  2.6921, omega:  0.2224, action:  7.0000\n",
      "theta =  2.6995, omega:  0.3163, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7225, action:  0.0000\n",
      "theta =  2.6849, omega:  0.0727, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1503, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2303, action:  2.0000\n",
      "theta =  2.6995, omega:  0.3306, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7095, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0793, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1622, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2553, action:  2.0000\n",
      "theta =  2.7034, omega:  0.3609, action:  2.0000\n",
      "theta =  2.6993, omega: -0.6762, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0657, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1633, action:  2.0000\n",
      "theta =  2.7013, omega:  0.2673, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7597, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0418, action:  7.0000\n",
      "theta =  2.6868, omega:  0.1166, action:  2.0000\n",
      "theta =  2.6927, omega:  0.1996, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2932, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7453, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0445, action:  7.0000\n",
      "theta =  2.6875, omega:  0.1149, action:  2.0000\n",
      "theta =  2.6898, omega:  0.1906, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2776, action:  2.0000\n",
      "theta =  2.6893, omega: -0.7655, action:  0.0000\n",
      "theta =  2.6820, omega:  0.0530, action:  7.0000\n",
      "theta =  2.6842, omega:  0.1115, action:  2.0000\n",
      "theta =  2.6878, omega:  0.1789, action:  2.0000\n",
      "theta =  2.6913, omega:  0.2566, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3492, action:  2.0000\n",
      "theta =  2.6971, omega: -0.6939, action:  0.0000\n",
      "theta =  2.6872, omega:  0.0301, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1108, action:  2.0000\n",
      "theta =  2.6935, omega:  0.1956, action:  2.0000\n",
      "theta =  2.7007, omega:  0.2923, action:  2.0000\n",
      "theta =  2.6937, omega: -0.7464, action:  0.0000\n",
      "theta =  2.6858, omega:  0.0471, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1209, action:  2.0000\n",
      "theta =  2.6896, omega:  0.1996, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2882, action:  2.0000\n",
      "theta =  2.6888, omega: -0.7557, action:  0.0000\n",
      "theta =  2.6836, omega:  0.0593, action:  7.0000\n",
      "theta =  2.6837, omega:  0.1264, action:  2.0000\n",
      "theta =  2.6888, omega:  0.1981, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2829, action:  2.0000\n",
      "theta =  2.6884, omega: -0.7648, action:  0.0000\n",
      "theta =  2.6800, omega:  0.0229, action:  7.0000\n",
      "theta =  2.6807, omega:  0.0800, action:  2.0000\n",
      "theta =  2.6827, omega:  0.1393, action:  2.0000\n",
      "theta =  2.6871, omega:  0.2081, action:  2.0000\n",
      "theta =  2.6945, omega:  0.2913, action:  2.0000\n",
      "theta =  2.7066, omega:  0.8546, action:  6.0000\n",
      "theta =  2.7161, omega: -0.2518, action:  0.0000\n",
      "theta =  2.7143, omega:  0.0725, action:  2.0000\n",
      "theta =  2.7194, omega:  0.2244, action:  2.0000\n",
      "theta =  2.7122, omega: -0.7490, action:  0.0000\n",
      "theta =  2.7036, omega:  0.0868, action:  7.0000\n",
      "theta =  2.7063, omega:  0.2095, action:  2.0000\n",
      "theta =  2.6992, omega: -0.7941, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0265, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1133, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2049, action:  2.0000\n",
      "theta =  2.7019, omega:  0.3100, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7228, action:  0.0000\n",
      "theta =  2.6888, omega:  0.0709, action:  7.0000\n",
      "theta =  2.6937, omega:  0.1543, action:  2.0000\n",
      "theta =  2.6978, omega:  0.2471, action:  2.0000\n",
      "theta =  2.7050, omega:  0.3524, action:  2.0000\n",
      "theta =  2.6980, omega: -0.6815, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0596, action:  7.0000\n",
      "theta =  2.6964, omega:  0.1535, action:  2.0000\n",
      "theta =  2.6998, omega:  0.2561, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7717, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0516, action:  7.0000\n",
      "theta =  2.6872, omega:  0.1225, action:  2.0000\n",
      "theta =  2.6908, omega:  0.2006, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2922, action:  2.0000\n",
      "theta =  2.6902, omega: -0.7487, action:  0.0000\n",
      "theta =  2.6826, omega:  0.0393, action:  7.0000\n",
      "theta =  2.6854, omega:  0.1055, action:  2.0000\n",
      "theta =  2.6890, omega:  0.1787, action:  2.0000\n",
      "theta =  2.6924, omega:  0.2588, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3594, action:  2.0000\n",
      "theta =  2.6969, omega: -0.6846, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0481, action:  7.0000\n",
      "theta =  2.6921, omega:  0.1356, action:  2.0000\n",
      "theta =  2.6961, omega:  0.2265, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3321, action:  2.0000\n",
      "theta =  2.6996, omega: -0.6999, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0395, action:  7.0000\n",
      "theta =  2.6947, omega:  0.1280, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2252, action:  2.0000\n",
      "theta =  2.7034, omega:  0.3344, action:  2.0000\n",
      "theta =  2.6988, omega: -0.6938, action:  0.0000\n",
      "theta =  2.6931, omega:  0.0482, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1407, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2408, action:  2.0000\n",
      "theta =  2.7067, omega:  0.3551, action:  2.0000\n",
      "theta =  2.7037, omega: -0.6692, action:  0.0000\n",
      "theta =  2.6968, omega:  0.0816, action:  7.0000\n",
      "theta =  2.7004, omega:  0.1855, action:  2.0000\n",
      "theta =  2.7053, omega:  0.3008, action:  2.0000\n",
      "theta =  2.7000, omega: -0.7180, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0836, action:  7.0000\n",
      "theta =  2.6992, omega:  0.1789, action:  2.0000\n",
      "theta =  2.7021, omega:  0.2838, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7469, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0551, action:  7.0000\n",
      "theta =  2.6963, omega:  0.5987, action:  8.0000\n",
      "theta =  2.6970, omega: -0.4987, action:  0.0000\n",
      "theta =  2.6928, omega:  0.1892, action:  7.0000\n",
      "theta =  2.6998, omega:  0.2859, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7527, action:  0.0000\n",
      "theta =  2.6835, omega:  0.0445, action:  7.0000\n",
      "theta =  2.6857, omega:  0.1139, action:  2.0000\n",
      "theta =  2.6906, omega:  0.1897, action:  2.0000\n",
      "theta =  2.6950, omega:  0.2794, action:  2.0000\n",
      "theta =  2.7040, omega:  0.3848, action:  2.0000\n",
      "theta =  2.7006, omega: -0.6545, action:  0.0000\n",
      "theta =  2.6962, omega:  0.0935, action:  7.0000\n",
      "theta =  2.7002, omega:  0.1915, action:  2.0000\n",
      "theta =  2.7049, omega:  0.2997, action:  2.0000\n",
      "theta =  2.6986, omega: -0.7242, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0763, action:  7.0000\n",
      "theta =  2.6949, omega:  0.1635, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2611, action:  2.0000\n",
      "theta =  2.6914, omega: -0.7682, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0476, action:  7.0000\n",
      "theta =  2.6863, omega:  0.1171, action:  2.0000\n",
      "theta =  2.6907, omega:  0.1920, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2775, action:  2.0000\n",
      "theta =  2.7096, omega:  0.8507, action:  6.0000\n",
      "theta =  2.7160, omega: -0.2547, action:  0.0000\n",
      "theta =  2.7166, omega:  0.0708, action:  2.0000\n",
      "theta =  2.7180, omega:  0.2298, action:  2.0000\n",
      "theta =  2.7111, omega: -0.7436, action:  0.0000\n",
      "theta =  2.7042, omega:  0.0935, action:  7.0000\n",
      "theta =  2.7071, omega:  0.2230, action:  2.0000\n",
      "theta =  2.7004, omega: -0.7795, action:  0.0000\n",
      "theta =  2.6941, omega:  0.0415, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1355, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2340, action:  2.0000\n",
      "theta =  2.7066, omega:  0.3472, action:  2.0000\n",
      "theta =  2.7019, omega: -0.6787, action:  0.0000\n",
      "theta =  2.6950, omega:  0.0683, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1718, action:  2.0000\n",
      "theta =  2.7044, omega:  0.2816, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7416, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0852, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1689, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2670, action:  2.0000\n",
      "theta =  2.7061, omega:  0.3762, action:  2.0000\n",
      "theta =  2.7023, omega: -0.6538, action:  0.0000\n",
      "theta =  2.6973, omega:  0.0982, action:  7.0000\n",
      "theta =  2.7022, omega:  0.2024, action:  2.0000\n",
      "theta =  2.7071, omega:  0.3209, action:  2.0000\n",
      "theta =  2.7025, omega: -0.7033, action:  0.0000\n",
      "theta =  2.6956, omega:  0.0452, action:  7.0000\n",
      "theta =  2.6965, omega:  0.1434, action:  2.0000\n",
      "theta =  2.7025, omega:  0.2507, action:  2.0000\n",
      "theta =  2.6937, omega: -0.7743, action:  0.0000\n",
      "theta =  2.6856, omega:  0.0490, action:  7.0000\n",
      "theta =  2.6882, omega:  0.1266, action:  2.0000\n",
      "theta =  2.6916, omega:  0.2080, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2977, action:  2.0000\n",
      "theta =  2.6919, omega: -0.7413, action:  0.0000\n",
      "theta =  2.6841, omega:  0.0525, action:  3.0000\n",
      "theta =  2.6880, omega:  0.1239, action:  2.0000\n",
      "theta =  2.6894, omega:  0.2009, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2912, action:  2.0000\n",
      "theta =  2.6911, omega: -0.7515, action:  0.0000\n",
      "theta =  2.6817, omega:  0.0645, action:  7.0000\n",
      "theta =  2.6848, omega:  0.1284, action:  2.0000\n",
      "theta =  2.6875, omega:  0.2003, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2853, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3870, action:  2.0000\n",
      "theta =  2.6994, omega: -0.6542, action:  0.0000\n",
      "theta =  2.6937, omega:  0.0842, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1836, action:  2.0000\n",
      "theta =  2.7030, omega:  0.2929, action:  2.0000\n",
      "theta =  2.6960, omega: -0.7363, action:  0.0000\n",
      "theta =  2.6884, omega:  0.0818, action:  7.0000\n",
      "theta =  2.6929, omega:  0.1669, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2608, action:  2.0000\n",
      "theta =  2.6898, omega: -0.7765, action:  0.0000\n",
      "theta =  2.6830, omega:  0.0195, action:  7.0000\n",
      "theta =  2.6839, omega:  0.0825, action:  2.0000\n",
      "theta =  2.6880, omega:  0.1502, action:  2.0000\n",
      "theta =  2.6905, omega:  0.2251, action:  2.0000\n",
      "theta =  2.6955, omega:  0.3156, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7287, action:  0.0000\n",
      "theta =  2.6832, omega:  0.0731, action:  7.0000\n",
      "theta =  2.6849, omega:  0.1429, action:  2.0000\n",
      "theta =  2.6930, omega:  0.2199, action:  2.0000\n",
      "theta =  2.6984, omega:  0.3149, action:  2.0000\n",
      "theta =  2.6916, omega: -0.7296, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0765, action:  7.0000\n",
      "theta =  2.6875, omega:  0.1469, action:  2.0000\n",
      "theta =  2.6909, omega:  0.2269, action:  2.0000\n",
      "theta =  2.6982, omega:  0.3193, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7223, action:  0.0000\n",
      "theta =  2.6866, omega:  0.0864, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1621, action:  2.0000\n",
      "theta =  2.6938, omega:  0.2474, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3479, action:  2.0000\n",
      "theta =  2.6972, omega: -0.6919, action:  0.0000\n",
      "theta =  2.6884, omega:  0.0410, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1264, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2174, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3208, action:  2.0000\n",
      "theta =  2.6962, omega: -0.7125, action:  0.0000\n",
      "theta =  2.6904, omega:  0.0825, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1693, action:  2.0000\n",
      "theta =  2.6979, omega:  0.2679, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7677, action:  0.0000\n",
      "theta =  2.6836, omega:  0.0489, action:  7.0000\n",
      "theta =  2.6840, omega:  0.1179, action:  2.0000\n",
      "theta =  2.6897, omega:  0.1905, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2755, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3773, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6632, action:  0.0000\n",
      "theta =  2.6954, omega:  0.0775, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1732, action:  2.0000\n",
      "theta =  2.7007, omega:  0.2757, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7509, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0480, action:  7.0000\n",
      "theta =  2.6879, omega:  0.1240, action:  2.0000\n",
      "theta =  2.6939, omega:  0.2068, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3049, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7363, action:  0.0000\n",
      "theta =  2.6866, omega:  0.0755, action:  7.0000\n",
      "theta =  2.6900, omega:  0.1488, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2317, action:  2.0000\n",
      "theta =  2.7012, omega:  0.3279, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7130, action:  0.0000\n",
      "theta =  2.6888, omega:  0.0763, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1571, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2487, action:  2.0000\n",
      "theta =  2.7041, omega:  0.3497, action:  2.0000\n",
      "theta =  2.6983, omega: -0.6874, action:  0.0000\n",
      "theta =  2.6916, omega:  0.0512, action:  7.0000\n",
      "theta =  2.6924, omega:  0.1415, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2386, action:  2.0000\n",
      "theta =  2.7050, omega:  0.3504, action:  2.0000\n",
      "theta =  2.7025, omega: -0.6784, action:  0.0000\n",
      "theta =  2.6962, omega:  0.0669, action:  7.0000\n",
      "theta =  2.6983, omega:  0.1690, action:  2.0000\n",
      "theta =  2.7025, omega:  0.2764, action:  2.0000\n",
      "theta =  2.6977, omega: -0.7452, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0592, action:  7.0000\n",
      "theta =  2.6903, omega:  0.1409, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2327, action:  2.0000\n",
      "theta =  2.7021, omega:  0.3385, action:  2.0000\n",
      "theta =  2.6976, omega: -0.6979, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0390, action:  7.0000\n",
      "theta =  2.6945, omega:  0.1298, action:  2.0000\n",
      "theta =  2.6971, omega:  0.2225, action:  2.0000\n",
      "theta =  2.7035, omega:  0.3310, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6983, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0405, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1314, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2316, action:  2.0000\n",
      "theta =  2.7050, omega:  0.3426, action:  2.0000\n",
      "theta =  2.7016, omega: -0.6839, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0592, action:  7.0000\n",
      "theta =  2.6997, omega:  0.1580, action:  2.0000\n",
      "theta =  2.7038, omega:  0.2658, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7586, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0416, action:  7.0000\n",
      "theta =  2.6905, omega:  0.1206, action:  2.0000\n",
      "theta =  2.6918, omega:  0.2064, action:  2.0000\n",
      "theta =  2.7001, omega:  0.3012, action:  2.0000\n",
      "theta =  2.6916, omega: -0.7354, action:  0.0000\n",
      "theta =  2.6840, omega:  0.0733, action:  7.0000\n",
      "theta =  2.6885, omega:  0.1489, action:  2.0000\n",
      "theta =  2.6921, omega:  0.2312, action:  2.0000\n",
      "theta =  2.6994, omega:  0.3281, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7114, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0790, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1594, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2460, action:  2.0000\n",
      "theta =  2.7089, omega:  0.8185, action:  8.0000\n",
      "theta =  2.7151, omega: -0.2810, action:  0.0000\n",
      "theta =  2.7117, omega:  0.0610, action:  2.0000\n",
      "theta =  2.7169, omega:  0.2110, action:  2.0000\n",
      "theta =  2.7093, omega: -0.7636, action:  0.0000\n",
      "theta =  2.6999, omega:  0.0720, action:  7.0000\n",
      "theta =  2.7101, omega:  0.6586, action:  3.0000\n",
      "theta =  2.7130, omega: -0.4153, action:  0.0000\n",
      "theta =  2.7134, omega:  0.3054, action:  7.0000\n",
      "theta =  2.7053, omega: -0.6992, action:  0.0000\n",
      "theta =  2.6981, omega:  0.0638, action:  7.0000\n",
      "theta =  2.7039, omega:  0.1786, action:  2.0000\n",
      "theta =  2.7095, omega:  0.3007, action:  2.0000\n",
      "theta =  2.7033, omega: -0.7106, action:  0.0000\n",
      "theta =  2.6952, omega:  0.0380, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1420, action:  2.0000\n",
      "theta =  2.7026, omega:  0.2530, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7685, action:  0.0000\n",
      "theta =  2.6865, omega:  0.0627, action:  7.0000\n",
      "theta =  2.6894, omega:  0.1397, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2283, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3277, action:  2.0000\n",
      "theta =  2.6960, omega: -0.7098, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0809, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1636, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2570, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3676, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6678, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0772, action:  7.0000\n",
      "theta =  2.6973, omega:  0.1767, action:  2.0000\n",
      "theta =  2.7047, omega:  0.2844, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7425, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0819, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1669, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2609, action:  2.0000\n",
      "theta =  2.7061, omega:  0.3698, action:  2.0000\n",
      "theta =  2.7007, omega: -0.6630, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0812, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1841, action:  2.0000\n",
      "theta =  2.7044, omega:  0.2929, action:  2.0000\n",
      "theta =  2.7001, omega: -0.7295, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0694, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1569, action:  2.0000\n",
      "theta =  2.6998, omega:  0.2517, action:  2.0000\n",
      "theta =  2.6899, omega: -0.7777, action:  0.0000\n",
      "theta =  2.6847, omega:  0.0195, action:  7.0000\n",
      "theta =  2.6837, omega:  0.0881, action:  2.0000\n",
      "theta =  2.6886, omega:  0.1544, action:  2.0000\n",
      "theta =  2.6917, omega:  0.2339, action:  2.0000\n",
      "theta =  2.6986, omega:  0.3270, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7163, action:  0.0000\n",
      "theta =  2.6862, omega:  0.0674, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1431, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2269, action:  2.0000\n",
      "theta =  2.7003, omega:  0.3240, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7156, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0744, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1518, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2426, action:  2.0000\n",
      "theta =  2.7044, omega:  0.3444, action:  2.0000\n",
      "theta =  2.6969, omega: -0.6933, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0432, action:  7.0000\n",
      "theta =  2.6931, omega:  0.1331, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2260, action:  2.0000\n",
      "theta =  2.7027, omega:  0.3346, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6970, action:  0.0000\n",
      "theta =  2.6924, omega:  0.0437, action:  7.0000\n",
      "theta =  2.6949, omega:  0.1363, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2381, action:  2.0000\n",
      "theta =  2.7064, omega:  0.3476, action:  2.0000\n",
      "theta =  2.7018, omega: -0.6791, action:  0.0000\n",
      "theta =  2.6948, omega:  0.0671, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1662, action:  2.0000\n",
      "theta =  2.7036, omega:  0.2772, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7450, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0598, action:  7.0000\n",
      "theta =  2.6898, omega:  0.1413, action:  2.0000\n",
      "theta =  2.6961, omega:  0.2328, action:  2.0000\n",
      "theta =  2.7023, omega:  0.3391, action:  2.0000\n",
      "theta =  2.6981, omega: -0.6927, action:  0.0000\n",
      "theta =  2.6909, omega:  0.0443, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1336, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2291, action:  2.0000\n",
      "theta =  2.7053, omega:  0.3398, action:  2.0000\n",
      "theta =  2.7003, omega: -0.6873, action:  0.0000\n",
      "theta =  2.6939, omega:  0.0531, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1502, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2517, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7727, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0493, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1214, action:  2.0000\n",
      "theta =  2.6896, omega:  0.2001, action:  2.0000\n",
      "theta =  2.6977, omega:  0.2911, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7491, action:  0.0000\n",
      "theta =  2.6839, omega:  0.0398, action:  7.0000\n",
      "theta =  2.6876, omega:  0.1062, action:  2.0000\n",
      "theta =  2.6878, omega:  0.1787, action:  2.0000\n",
      "theta =  2.6932, omega:  0.2611, action:  2.0000\n",
      "theta =  2.7013, omega:  0.3612, action:  2.0000\n",
      "theta =  2.6954, omega: -0.6804, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0532, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1402, action:  2.0000\n",
      "theta =  2.6979, omega:  0.2354, action:  2.0000\n",
      "theta =  2.7035, omega:  0.3439, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6879, action:  0.0000\n",
      "theta =  2.6948, omega:  0.0545, action:  7.0000\n",
      "theta =  2.6975, omega:  0.1485, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2504, action:  2.0000\n",
      "theta =  2.7075, omega:  0.3666, action:  2.0000\n",
      "theta =  2.7031, omega: -0.6595, action:  0.0000\n",
      "theta =  2.6965, omega:  0.0951, action:  7.0000\n",
      "theta =  2.7006, omega:  0.2041, action:  2.0000\n",
      "theta =  2.7074, omega:  0.3233, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6949, action:  0.0000\n",
      "theta =  2.6941, omega:  0.0565, action:  7.0000\n",
      "theta =  2.6979, omega:  0.1595, action:  2.0000\n",
      "theta =  2.7033, omega:  0.2718, action:  2.0000\n",
      "theta =  2.6958, omega: -0.7517, action:  0.0000\n",
      "theta =  2.6872, omega:  0.0543, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1396, action:  2.0000\n",
      "theta =  2.6972, omega:  0.2297, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3377, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6961, action:  0.0000\n",
      "theta =  2.6909, omega:  0.0403, action:  7.0000\n",
      "theta =  2.6965, omega:  0.1304, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2236, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3358, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6948, action:  0.0000\n",
      "theta =  2.6918, omega:  0.0479, action:  7.0000\n",
      "theta =  2.6947, omega:  0.1389, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2387, action:  2.0000\n",
      "theta =  2.7070, omega:  0.3546, action:  2.0000\n",
      "theta =  2.7016, omega: -0.6731, action:  0.0000\n",
      "theta =  2.6959, omega:  0.0754, action:  7.0000\n",
      "theta =  2.6981, omega:  0.1811, action:  2.0000\n",
      "theta =  2.7033, omega:  0.2905, action:  2.0000\n",
      "theta =  2.6978, omega: -0.7276, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0742, action:  7.0000\n",
      "theta =  2.6943, omega:  0.1666, action:  2.0000\n",
      "theta =  2.7014, omega:  0.2643, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7661, action:  0.0000\n",
      "theta =  2.6826, omega:  0.0506, action:  7.0000\n",
      "theta =  2.6860, omega:  0.1232, action:  2.0000\n",
      "theta =  2.6909, omega:  0.1998, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2894, action:  2.0000\n",
      "theta =  2.6895, omega: -0.7533, action:  0.0000\n",
      "theta =  2.6833, omega:  0.0631, action:  7.0000\n",
      "theta =  2.6853, omega:  0.1269, action:  2.0000\n",
      "theta =  2.6880, omega:  0.1982, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2803, action:  2.0000\n",
      "theta =  2.6883, omega: -0.7636, action:  0.0000\n",
      "theta =  2.6792, omega:  0.0241, action:  7.0000\n",
      "theta =  2.6808, omega:  0.0797, action:  2.0000\n",
      "theta =  2.6845, omega:  0.1409, action:  2.0000\n",
      "theta =  2.6882, omega:  0.2098, action:  2.0000\n",
      "theta =  2.6938, omega:  0.2911, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3895, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6542, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0852, action:  7.0000\n",
      "theta =  2.6960, omega:  0.1792, action:  2.0000\n",
      "theta =  2.7023, omega:  0.2844, action:  2.0000\n",
      "theta =  2.6959, omega: -0.7458, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0558, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1340, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2206, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3184, action:  2.0000\n",
      "theta =  2.6959, omega: -0.7168, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0746, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1530, action:  2.0000\n",
      "theta =  2.6955, omega:  0.2441, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3497, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6853, action:  0.0000\n",
      "theta =  2.6918, omega:  0.0516, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1453, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2433, action:  2.0000\n",
      "theta =  2.7073, omega:  0.3573, action:  2.0000\n",
      "theta =  2.7028, omega: -0.6713, action:  0.0000\n",
      "theta =  2.6960, omega:  0.0772, action:  7.0000\n",
      "theta =  2.6990, omega:  0.1807, action:  2.0000\n",
      "theta =  2.7045, omega:  0.2923, action:  2.0000\n",
      "theta =  2.7006, omega: -0.7319, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0699, action:  7.0000\n",
      "theta =  2.6934, omega:  0.1612, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2587, action:  2.0000\n",
      "theta =  2.7074, omega:  0.3740, action:  2.0000\n",
      "theta =  2.7026, omega: -0.6579, action:  0.0000\n",
      "theta =  2.6978, omega:  0.0944, action:  7.0000\n",
      "theta =  2.7002, omega:  0.2002, action:  2.0000\n",
      "theta =  2.7065, omega:  0.3205, action:  2.0000\n",
      "theta =  2.7020, omega: -0.7002, action:  0.0000\n",
      "theta =  2.6947, omega:  0.0487, action:  7.0000\n",
      "theta =  2.6960, omega:  0.1478, action:  2.0000\n",
      "theta =  2.7024, omega:  0.2550, action:  2.0000\n",
      "theta =  2.6973, omega: -0.7660, action:  0.0000\n",
      "theta =  2.6853, omega:  0.0648, action:  7.0000\n",
      "theta =  2.6904, omega:  0.1412, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2280, action:  2.0000\n",
      "theta =  2.6995, omega:  0.3259, action:  2.0000\n",
      "theta =  2.6962, omega: -0.7115, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0817, action:  7.0000\n",
      "theta =  2.6905, omega:  0.1633, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2556, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3622, action:  2.0000\n",
      "theta =  2.6975, omega: -0.6700, action:  0.0000\n",
      "theta =  2.6934, omega:  0.0720, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1713, action:  2.0000\n",
      "theta =  2.7026, omega:  0.2744, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7490, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0509, action:  7.0000\n",
      "theta =  2.6907, omega:  0.1310, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2196, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3207, action:  2.0000\n",
      "theta =  2.6941, omega: -0.7183, action:  0.0000\n",
      "theta =  2.6890, omega:  0.0745, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1559, action:  2.0000\n",
      "theta =  2.6971, omega:  0.2463, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3513, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6856, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0531, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1453, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2448, action:  2.0000\n",
      "theta =  2.7065, omega:  0.3585, action:  2.0000\n",
      "theta =  2.7026, omega: -0.6674, action:  0.0000\n",
      "theta =  2.6955, omega:  0.0811, action:  7.0000\n",
      "theta =  2.6999, omega:  0.1862, action:  2.0000\n",
      "theta =  2.7043, omega:  0.2987, action:  2.0000\n",
      "theta =  2.6986, omega: -0.7232, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0790, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1736, action:  2.0000\n",
      "theta =  2.7005, omega:  0.2736, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7549, action:  0.0000\n",
      "theta =  2.6864, omega:  0.0437, action:  7.0000\n",
      "theta =  2.6880, omega:  0.1195, action:  2.0000\n",
      "theta =  2.6914, omega:  0.1992, action:  2.0000\n",
      "theta =  2.6991, omega:  0.2928, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7478, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0443, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1133, action:  2.0000\n",
      "theta =  2.6900, omega:  0.1889, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2732, action:  2.0000\n",
      "theta =  2.7012, omega:  0.3766, action:  2.0000\n",
      "theta =  2.7004, omega: -0.6618, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0777, action:  7.0000\n",
      "theta =  2.6951, omega:  0.1723, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2762, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7486, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0487, action:  7.0000\n",
      "theta =  2.6906, omega:  0.1255, action:  2.0000\n",
      "theta =  2.6931, omega:  0.2111, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3094, action:  2.0000\n",
      "theta =  2.6927, omega: -0.7269, action:  0.0000\n",
      "theta =  2.6879, omega:  0.0858, action:  7.0000\n",
      "theta =  2.6901, omega:  0.1632, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2496, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3528, action:  2.0000\n",
      "theta =  2.6981, omega: -0.6874, action:  0.0000\n",
      "theta =  2.6918, omega:  0.0495, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1374, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2332, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3426, action:  2.0000\n",
      "theta =  2.6988, omega: -0.6885, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0557, action:  7.0000\n",
      "theta =  2.6962, omega:  0.1504, action:  2.0000\n",
      "theta =  2.7004, omega:  0.2553, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7717, action:  0.0000\n",
      "theta =  2.6835, omega:  0.0526, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1215, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2007, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2919, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7485, action:  0.0000\n",
      "theta =  2.6856, omega:  0.0395, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1082, action:  2.0000\n",
      "theta =  2.6877, omega:  0.1799, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2651, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3643, action:  2.0000\n",
      "theta =  2.6980, omega: -0.6784, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0559, action:  7.0000\n",
      "theta =  2.6936, omega:  0.1452, action:  2.0000\n",
      "theta =  2.6990, omega:  0.2428, action:  2.0000\n",
      "theta =  2.7057, omega:  0.3509, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6767, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0688, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1686, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2758, action:  2.0000\n",
      "theta =  2.6979, omega: -0.7491, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0553, action:  7.0000\n",
      "theta =  2.6926, omega:  0.1374, action:  2.0000\n",
      "theta =  2.6944, omega:  0.2272, action:  2.0000\n",
      "theta =  2.7021, omega:  0.3277, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7075, action:  0.0000\n",
      "theta =  2.6907, omega:  0.1098, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1973, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2949, action:  2.0000\n",
      "theta =  2.6939, omega: -0.7427, action:  0.0000\n",
      "theta =  2.6864, omega:  0.0548, action:  7.0000\n",
      "theta =  2.6883, omega:  0.1300, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2114, action:  2.0000\n",
      "theta =  2.6980, omega:  0.3050, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7318, action:  0.0000\n",
      "theta =  2.6838, omega:  0.0770, action:  7.0000\n",
      "theta =  2.6882, omega:  0.1483, action:  2.0000\n",
      "theta =  2.6942, omega:  0.2295, action:  2.0000\n",
      "theta =  2.7006, omega:  0.3259, action:  2.0000\n",
      "theta =  2.6958, omega: -0.7152, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0757, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1544, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2397, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3418, action:  2.0000\n",
      "theta =  2.6964, omega: -0.6948, action:  0.0000\n",
      "theta =  2.6909, omega:  0.0401, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1261, action:  2.0000\n",
      "theta =  2.6955, omega:  0.2180, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3250, action:  2.0000\n",
      "theta =  2.6981, omega: -0.7060, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0316, action:  7.0000\n",
      "theta =  2.6978, omega:  0.5890, action:  8.0000\n",
      "theta =  2.6984, omega: -0.5034, action:  0.0000\n",
      "theta =  2.6966, omega:  0.1896, action:  7.0000\n",
      "theta =  2.7026, omega:  0.2936, action:  2.0000\n",
      "theta =  2.6962, omega: -0.7390, action:  0.0000\n",
      "theta =  2.6880, omega:  0.0741, action:  7.0000\n",
      "theta =  2.6904, omega:  0.1543, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2448, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3471, action:  2.0000\n",
      "theta =  2.6982, omega: -0.6894, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0484, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1362, action:  2.0000\n",
      "theta =  2.6991, omega:  0.2346, action:  2.0000\n",
      "theta =  2.7055, omega:  0.3414, action:  2.0000\n",
      "theta =  2.7008, omega: -0.6874, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0564, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1509, action:  2.0000\n",
      "theta =  2.7003, omega:  0.2569, action:  2.0000\n",
      "theta =  2.6930, omega: -0.7699, action:  0.0000\n",
      "theta =  2.6853, omega:  0.0525, action:  7.0000\n",
      "theta =  2.6874, omega:  0.1248, action:  2.0000\n",
      "theta =  2.6903, omega:  0.2049, action:  2.0000\n",
      "theta =  2.6997, omega:  0.2991, action:  2.0000\n",
      "theta =  2.6906, omega: -0.7428, action:  0.0000\n",
      "theta =  2.6857, omega:  0.0499, action:  7.0000\n",
      "theta =  2.6867, omega:  0.1196, action:  2.0000\n",
      "theta =  2.6936, omega:  0.1981, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2848, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3909, action:  2.0000\n",
      "theta =  2.7014, omega: -0.6484, action:  0.0000\n",
      "theta =  2.6938, omega:  0.0967, action:  7.0000\n",
      "theta =  2.7006, omega:  0.1999, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3126, action:  2.0000\n",
      "theta =  2.6995, omega: -0.7121, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0462, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1422, action:  2.0000\n",
      "theta =  2.6996, omega:  0.2408, action:  2.0000\n",
      "theta =  2.7066, omega:  0.3543, action:  2.0000\n",
      "theta =  2.7022, omega: -0.6737, action:  0.0000\n",
      "theta =  2.6953, omega:  0.0755, action:  7.0000\n",
      "theta =  2.7001, omega:  0.1796, action:  2.0000\n",
      "theta =  2.7039, omega:  0.2909, action:  2.0000\n",
      "theta =  2.6979, omega: -0.7317, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0729, action:  7.0000\n",
      "theta =  2.6942, omega:  0.1621, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2619, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7709, action:  0.0000\n",
      "theta =  2.6838, omega:  0.0491, action:  7.0000\n",
      "theta =  2.6831, omega:  0.1193, action:  2.0000\n",
      "theta =  2.6891, omega:  0.1966, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2822, action:  2.0000\n",
      "theta =  2.6893, omega: -0.7619, action:  0.0000\n",
      "theta =  2.6803, omega:  0.0487, action:  7.0000\n",
      "theta =  2.6821, omega:  0.1086, action:  2.0000\n",
      "theta =  2.6850, omega:  0.1743, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2526, action:  2.0000\n",
      "theta =  2.6991, omega:  0.3453, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7016, action:  0.0000\n",
      "theta =  2.6877, omega:  0.1040, action:  7.0000\n",
      "theta =  2.6907, omega:  0.1848, action:  2.0000\n",
      "theta =  2.6955, omega:  0.2728, action:  2.0000\n",
      "theta =  2.7052, omega:  0.3802, action:  2.0000\n",
      "theta =  2.7015, omega: -0.6568, action:  0.0000\n",
      "theta =  2.6947, omega:  0.0901, action:  7.0000\n",
      "theta =  2.6967, omega:  0.1895, action:  2.0000\n",
      "theta =  2.7059, omega:  0.3000, action:  2.0000\n",
      "theta =  2.6973, omega: -0.7227, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0770, action:  7.0000\n",
      "theta =  2.7005, omega:  0.6328, action:  3.0000\n",
      "theta =  2.7006, omega: -0.4584, action:  0.0000\n",
      "theta =  2.6984, omega:  0.2434, action:  7.0000\n",
      "theta =  2.7068, omega:  0.3557, action:  2.0000\n",
      "theta =  2.7036, omega: -0.6700, action:  0.0000\n",
      "theta =  2.6965, omega:  0.0791, action:  7.0000\n",
      "theta =  2.6985, omega:  0.1844, action:  2.0000\n",
      "theta =  2.7038, omega:  0.2981, action:  2.0000\n",
      "theta =  2.7009, omega: -0.7225, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0825, action:  7.0000\n",
      "theta =  2.6969, omega:  0.1752, action:  2.0000\n",
      "theta =  2.7015, omega:  0.2774, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7508, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0487, action:  7.0000\n",
      "theta =  2.6870, omega:  0.1290, action:  2.0000\n",
      "theta =  2.6933, omega:  0.2094, action:  2.0000\n",
      "theta =  2.6980, omega:  0.3052, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7334, action:  0.0000\n",
      "theta =  2.6857, omega:  0.0759, action:  7.0000\n",
      "theta =  2.6892, omega:  0.1498, action:  2.0000\n",
      "theta =  2.6938, omega:  0.2342, action:  2.0000\n",
      "theta =  2.6989, omega:  0.3309, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7077, action:  0.0000\n",
      "theta =  2.6868, omega:  0.0831, action:  7.0000\n",
      "theta =  2.6903, omega:  0.1642, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2548, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3613, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6733, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0674, action:  7.0000\n",
      "theta =  2.6949, omega:  0.1608, action:  2.0000\n",
      "theta =  2.7020, omega:  0.2664, action:  2.0000\n",
      "theta =  2.6959, omega: -0.7607, action:  0.0000\n",
      "theta =  2.6857, omega:  0.0400, action:  7.0000\n",
      "theta =  2.6889, omega:  0.1154, action:  2.0000\n",
      "theta =  2.6927, omega:  0.1954, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2893, action:  2.0000\n",
      "theta =  2.6930, omega: -0.7485, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0435, action:  7.0000\n",
      "theta =  2.6862, omega:  0.1101, action:  2.0000\n",
      "theta =  2.6910, omega:  0.1858, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2718, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3722, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6673, action:  0.0000\n",
      "theta =  2.6923, omega:  0.0734, action:  7.0000\n",
      "theta =  2.6957, omega:  0.1627, action:  2.0000\n",
      "theta =  2.7013, omega:  0.2678, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7601, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0575, action:  7.0000\n",
      "theta =  2.6880, omega:  0.1301, action:  2.0000\n",
      "theta =  2.6909, omega:  0.2109, action:  2.0000\n",
      "theta =  2.7001, omega:  0.3050, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7351, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0739, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1454, action:  2.0000\n",
      "theta =  2.6930, omega:  0.2257, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3218, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7205, action:  0.0000\n",
      "theta =  2.6878, omega:  0.0687, action:  7.0000\n",
      "theta =  2.6888, omega:  0.1458, action:  2.0000\n",
      "theta =  2.6924, omega:  0.2269, action:  2.0000\n",
      "theta =  2.7007, omega:  0.3271, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7144, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0782, action:  7.0000\n",
      "theta =  2.6899, omega:  0.1574, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2470, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3514, action:  2.0000\n",
      "theta =  2.6987, omega: -0.6852, action:  0.0000\n",
      "theta =  2.6917, omega:  0.0566, action:  7.0000\n",
      "theta =  2.6950, omega:  0.1466, action:  2.0000\n",
      "theta =  2.6998, omega:  0.2463, action:  2.0000\n",
      "theta =  2.7082, omega:  0.3581, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6686, action:  0.0000\n",
      "theta =  2.6957, omega:  0.0827, action:  7.0000\n",
      "theta =  2.6988, omega:  0.1850, action:  2.0000\n",
      "theta =  2.7051, omega:  0.2990, action:  2.0000\n",
      "theta =  2.7005, omega: -0.7239, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0811, action:  7.0000\n",
      "theta =  2.6940, omega:  0.1732, action:  2.0000\n",
      "theta =  2.7017, omega:  0.2773, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7522, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0455, action:  7.0000\n",
      "theta =  2.6895, omega:  0.1209, action:  2.0000\n",
      "theta =  2.6921, omega:  0.2045, action:  2.0000\n",
      "theta =  2.6972, omega:  0.2996, action:  2.0000\n",
      "theta =  2.6921, omega: -0.7394, action:  0.0000\n",
      "theta =  2.6862, omega:  0.0522, action:  7.0000\n",
      "theta =  2.6887, omega:  0.1261, action:  2.0000\n",
      "theta =  2.6905, omega:  0.2034, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2955, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7474, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0432, action:  7.0000\n",
      "theta =  2.6845, omega:  0.1120, action:  2.0000\n",
      "theta =  2.6882, omega:  0.1832, action:  2.0000\n",
      "theta =  2.6937, omega:  0.2661, action:  2.0000\n",
      "theta =  2.7024, omega:  0.3685, action:  2.0000\n",
      "theta =  2.6960, omega: -0.6721, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0639, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1547, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2514, action:  2.0000\n",
      "theta =  2.7083, omega:  0.3675, action:  2.0000\n",
      "theta =  2.7014, omega: -0.6636, action:  0.0000\n",
      "theta =  2.6960, omega:  0.0883, action:  7.0000\n",
      "theta =  2.7058, omega:  0.6588, action:  4.0000\n",
      "theta =  2.7068, omega: -0.4220, action:  0.0000\n",
      "theta =  2.7083, omega:  0.2861, action:  7.0000\n",
      "theta =  2.7008, omega: -0.7275, action:  0.0000\n",
      "theta =  2.6937, omega:  0.0781, action:  7.0000\n",
      "theta =  2.6986, omega:  0.1747, action:  2.0000\n",
      "theta =  2.7021, omega:  0.2814, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7456, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0586, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1398, action:  2.0000\n",
      "theta =  2.6935, omega:  0.2293, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3294, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7059, action:  0.0000\n",
      "theta =  2.6895, omega:  0.1055, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1926, action:  2.0000\n",
      "theta =  2.6993, omega:  0.2905, action:  2.0000\n",
      "theta =  2.6962, omega: -0.7437, action:  0.0000\n",
      "theta =  2.6848, omega:  0.0518, action:  7.0000\n",
      "theta =  2.6870, omega:  0.1266, action:  2.0000\n",
      "theta =  2.6913, omega:  0.2059, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2968, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7433, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0465, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1166, action:  2.0000\n",
      "theta =  2.6894, omega:  0.1932, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2787, action:  2.0000\n",
      "theta =  2.6896, omega: -0.7635, action:  0.0000\n",
      "theta =  2.6786, omega:  0.0546, action:  7.0000\n",
      "theta =  2.6831, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6919, omega:  0.6473, action:  7.0000\n",
      "theta =  2.6936, omega: -0.4690, action:  0.0000\n",
      "theta =  2.6913, omega:  0.2139, action:  7.0000\n",
      "theta =  2.6989, omega:  0.3050, action:  2.0000\n",
      "theta =  2.6914, omega: -0.7371, action:  0.0000\n",
      "theta =  2.6839, omega:  0.0525, action:  7.0000\n",
      "theta =  2.6855, omega:  0.1208, action:  2.0000\n",
      "theta =  2.6906, omega:  0.1941, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2831, action:  2.0000\n",
      "theta =  2.7022, omega:  0.3873, action:  2.0000\n",
      "theta =  2.6996, omega: -0.6516, action:  0.0000\n",
      "theta =  2.6961, omega:  0.0914, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1929, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3017, action:  2.0000\n",
      "theta =  2.6988, omega: -0.7243, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0758, action:  7.0000\n",
      "theta =  2.6946, omega:  0.1647, action:  2.0000\n",
      "theta =  2.6900, omega: -0.4266, action:  1.0000\n",
      "theta =  2.6895, omega:  0.2581, action:  7.0000\n",
      "theta =  2.6959, omega:  0.3391, action:  2.0000\n",
      "theta =  2.6906, omega: -0.7116, action:  0.0000\n",
      "theta =  2.6829, omega:  0.0670, action:  7.0000\n",
      "theta =  2.6868, omega:  0.1352, action:  2.0000\n",
      "theta =  2.6901, omega:  0.2127, action:  2.0000\n",
      "theta =  2.6987, omega:  0.3007, action:  2.0000\n",
      "theta =  2.6917, omega: -0.7437, action:  0.0000\n",
      "theta =  2.6831, omega:  0.0435, action:  7.0000\n",
      "theta =  2.6843, omega:  0.1101, action:  2.0000\n",
      "theta =  2.6864, omega:  0.1829, action:  2.0000\n",
      "theta =  2.6936, omega:  0.2625, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3606, action:  2.0000\n",
      "theta =  2.6959, omega: -0.6805, action:  0.0000\n",
      "theta =  2.6910, omega:  0.0534, action:  7.0000\n",
      "theta =  2.6919, omega:  0.1403, action:  2.0000\n",
      "theta =  2.7022, omega:  0.7020, action:  4.0000\n",
      "theta =  2.7043, omega: -0.3940, action:  0.0000\n",
      "theta =  2.7053, omega:  0.3037, action:  7.0000\n",
      "theta =  2.7010, omega: -0.7191, action:  0.0000\n",
      "theta =  2.6936, omega:  0.0854, action:  7.0000\n",
      "theta =  2.6961, omega:  0.1817, action:  2.0000\n",
      "theta =  2.7024, omega:  0.2856, action:  2.0000\n",
      "theta =  2.6965, omega: -0.7427, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0574, action:  7.0000\n",
      "theta =  2.6900, omega:  0.1396, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2253, action:  2.0000\n",
      "theta =  2.7018, omega:  0.3289, action:  2.0000\n",
      "theta =  2.6969, omega: -0.7058, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0981, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1873, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2820, action:  2.0000\n",
      "theta =  2.6911, omega: -0.7536, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0391, action:  7.0000\n",
      "theta =  2.6858, omega:  0.1101, action:  2.0000\n",
      "theta =  2.6894, omega:  0.1850, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2731, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3758, action:  2.0000\n",
      "theta =  2.6996, omega: -0.6643, action:  0.0000\n",
      "theta =  2.6935, omega:  0.0796, action:  7.0000\n",
      "theta =  2.6962, omega:  0.1747, action:  2.0000\n",
      "theta =  2.7015, omega:  0.2771, action:  2.0000\n",
      "theta =  2.6965, omega: -0.7482, action:  0.0000\n",
      "theta =  2.6872, omega:  0.0531, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1339, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2179, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3210, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7181, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0743, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1558, action:  2.0000\n",
      "theta =  2.6945, omega:  0.2444, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3504, action:  2.0000\n",
      "theta =  2.6977, omega: -0.6848, action:  0.0000\n",
      "theta =  2.6917, omega:  0.0531, action:  7.0000\n",
      "theta =  2.6950, omega:  0.1441, action:  2.0000\n",
      "theta =  2.6990, omega:  0.2427, action:  2.0000\n",
      "theta =  2.7072, omega:  0.3575, action:  2.0000\n",
      "theta =  2.7041, omega: -0.6723, action:  0.0000\n",
      "theta =  2.6961, omega:  0.0772, action:  7.0000\n",
      "theta =  2.7011, omega:  0.1793, action:  2.0000\n",
      "theta =  2.7041, omega:  0.2919, action:  2.0000\n",
      "theta =  2.6998, omega: -0.7302, action:  0.0000\n",
      "theta =  2.6917, omega:  0.0722, action:  7.0000\n",
      "theta =  2.6940, omega:  0.1608, action:  2.0000\n",
      "theta =  2.6990, omega:  0.2603, action:  2.0000\n",
      "theta =  2.6914, omega: -0.7702, action:  0.0000\n",
      "theta =  2.6824, omega:  0.0491, action:  7.0000\n",
      "theta =  2.6777, omega: -0.5283, action:  1.0000\n",
      "theta =  2.6760, omega:  0.1797, action:  7.0000\n",
      "theta =  2.6788, omega:  0.2222, action:  2.0000\n",
      "theta =  2.6862, omega:  0.2809, action:  2.0000\n",
      "theta =  2.6923, omega:  0.3539, action:  2.0000\n",
      "theta =  2.6899, omega: -0.7066, action:  0.0000\n",
      "theta =  2.6811, omega:  0.0751, action:  7.0000\n",
      "theta =  2.6846, omega:  0.1343, action:  2.0000\n",
      "theta =  2.6875, omega:  0.2040, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2874, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3841, action:  2.0000\n",
      "theta =  2.6987, omega: -0.6573, action:  0.0000\n",
      "theta =  2.6938, omega:  0.0808, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1735, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2780, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7501, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0467, action:  7.0000\n",
      "theta =  2.6881, omega:  0.1273, action:  2.0000\n",
      "theta =  2.6924, omega:  0.2091, action:  2.0000\n",
      "theta =  2.6994, omega:  0.3033, action:  2.0000\n",
      "theta =  2.6914, omega: -0.7339, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0760, action:  7.0000\n",
      "theta =  2.6886, omega:  0.1490, action:  2.0000\n",
      "theta =  2.6938, omega:  0.2338, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3306, action:  2.0000\n",
      "theta =  2.6963, omega: -0.7084, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0811, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1603, action:  2.0000\n",
      "theta =  2.6978, omega:  0.2519, action:  2.0000\n",
      "theta =  2.7033, omega:  0.3590, action:  2.0000\n",
      "theta =  2.7005, omega: -0.6791, action:  0.0000\n",
      "theta =  2.6929, omega:  0.0639, action:  7.0000\n",
      "theta =  2.6969, omega:  0.1571, action:  2.0000\n",
      "theta =  2.6996, omega:  0.2618, action:  2.0000\n",
      "theta =  2.6921, omega: -0.7678, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0546, action:  7.0000\n",
      "theta =  2.6876, omega:  0.1268, action:  2.0000\n",
      "theta =  2.6918, omega:  0.2073, action:  2.0000\n",
      "theta =  2.6981, omega:  0.3002, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7427, action:  0.0000\n",
      "theta =  2.6824, omega:  0.0498, action:  7.0000\n",
      "theta =  2.6859, omega:  0.1188, action:  2.0000\n",
      "theta =  2.6909, omega:  0.1956, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2802, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3843, action:  2.0000\n",
      "theta =  2.7007, omega: -0.6534, action:  0.0000\n",
      "theta =  2.6930, omega:  0.0909, action:  7.0000\n",
      "theta =  2.6975, omega:  0.1898, action:  2.0000\n",
      "theta =  2.7043, omega:  0.2977, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7266, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0731, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1625, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2603, action:  2.0000\n",
      "theta =  2.7070, omega:  0.3700, action:  2.0000\n",
      "theta =  2.7028, omega: -0.6608, action:  0.0000\n",
      "theta =  2.6954, omega:  0.0887, action:  7.0000\n",
      "theta =  2.7003, omega:  0.1939, action:  2.0000\n",
      "theta =  2.7059, omega:  0.3083, action:  2.0000\n",
      "theta =  2.7015, omega: -0.7130, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0332, action:  7.0000\n",
      "theta =  2.6937, omega:  0.1271, action:  2.0000\n",
      "theta =  2.6993, omega:  0.2287, action:  2.0000\n",
      "theta =  2.7071, omega:  0.3433, action:  2.0000\n",
      "theta =  2.7018, omega: -0.6821, action:  0.0000\n",
      "theta =  2.6948, omega:  0.0669, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1678, action:  2.0000\n",
      "theta =  2.7042, omega:  0.2768, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7446, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0761, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1613, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2539, action:  2.0000\n",
      "theta =  2.7037, omega:  0.3631, action:  2.0000\n",
      "theta =  2.7005, omega: -0.6685, action:  0.0000\n",
      "theta =  2.6946, omega:  0.0756, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1760, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2837, action:  2.0000\n",
      "theta =  2.6969, omega: -0.7380, action:  0.0000\n",
      "theta =  2.6904, omega:  0.0852, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1722, action:  2.0000\n",
      "theta =  2.6961, omega:  0.2664, action:  2.0000\n",
      "theta =  2.7069, omega:  0.3769, action:  2.0000\n",
      "theta =  2.7019, omega: -0.6547, action:  0.0000\n",
      "theta =  2.6961, omega:  0.0940, action:  7.0000\n",
      "theta =  2.6987, omega:  0.1997, action:  2.0000\n",
      "theta =  2.7056, omega:  0.3147, action:  2.0000\n",
      "theta =  2.7004, omega: -0.7091, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0368, action:  7.0000\n",
      "theta =  2.6945, omega:  0.1327, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2350, action:  2.0000\n",
      "theta =  2.7084, omega:  0.3534, action:  2.0000\n",
      "theta =  2.7039, omega: -0.6736, action:  0.0000\n",
      "theta =  2.6959, omega:  0.0774, action:  7.0000\n",
      "theta =  2.6993, omega:  0.1843, action:  2.0000\n",
      "theta =  2.7049, omega:  0.2993, action:  2.0000\n",
      "theta =  2.7004, omega: -0.7208, action:  0.0000\n",
      "theta =  2.6918, omega:  0.0822, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1771, action:  2.0000\n",
      "theta =  2.7021, omega:  0.2796, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7468, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0511, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1284, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2149, action:  2.0000\n",
      "theta =  2.7009, omega:  0.3154, action:  2.0000\n",
      "theta =  2.6948, omega: -0.7231, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0671, action:  6.0000\n",
      "theta =  2.6899, omega:  0.1463, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2344, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3341, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7027, action:  0.0000\n",
      "theta =  2.6889, omega:  0.0306, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1167, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2052, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3085, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7249, action:  0.0000\n",
      "theta =  2.6896, omega:  0.0678, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1491, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2391, action:  2.0000\n",
      "theta =  2.7019, omega:  0.3420, action:  2.0000\n",
      "theta =  2.6978, omega: -0.6934, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0447, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1334, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2287, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3364, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6926, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0505, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1446, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2442, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3584, action:  2.0000\n",
      "theta =  2.7049, omega: -0.6683, action:  0.0000\n",
      "theta =  2.6956, omega:  0.0828, action:  7.0000\n",
      "theta =  2.6993, omega:  0.1894, action:  2.0000\n",
      "theta =  2.7065, omega:  0.3038, action:  2.0000\n",
      "theta =  2.6997, omega: -0.7162, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0906, action:  7.0000\n",
      "theta =  2.6967, omega:  0.1888, action:  2.0000\n",
      "theta =  2.7029, omega:  0.2929, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7344, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0846, action:  7.0000\n",
      "theta =  2.6935, omega:  0.1704, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2617, action:  2.0000\n",
      "theta =  2.7064, omega:  0.3722, action:  2.0000\n",
      "theta =  2.7002, omega: -0.6602, action:  0.0000\n",
      "theta =  2.6936, omega:  0.0872, action:  7.0000\n",
      "theta =  2.7003, omega:  0.1900, action:  2.0000\n",
      "theta =  2.7066, omega:  0.3033, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7211, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0829, action:  7.0000\n",
      "theta =  2.6946, omega:  0.1742, action:  2.0000\n",
      "theta =  2.7000, omega:  0.2769, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7530, action:  0.0000\n",
      "theta =  2.6855, omega:  0.0455, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1195, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2000, action:  2.0000\n",
      "theta =  2.6999, omega:  0.2947, action:  2.0000\n",
      "theta =  2.6927, omega: -0.7447, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0454, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6908, omega:  0.1918, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2778, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3810, action:  2.0000\n",
      "theta =  2.7003, omega: -0.6587, action:  0.0000\n",
      "theta =  2.6939, omega:  0.0847, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1817, action:  2.0000\n",
      "theta =  2.7034, omega:  0.2899, action:  2.0000\n",
      "theta =  2.6970, omega: -0.7352, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0856, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1705, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2639, action:  2.0000\n",
      "theta =  2.6919, omega: -0.7693, action:  0.0000\n",
      "theta =  2.6811, omega:  0.0263, action:  7.0000\n",
      "theta =  2.6836, omega:  0.0911, action:  2.0000\n",
      "theta =  2.6867, omega:  0.1594, action:  2.0000\n",
      "theta =  2.6919, omega:  0.2388, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3325, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7115, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0736, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1521, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2369, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3353, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7034, action:  0.0000\n",
      "theta =  2.6877, omega:  0.0302, action:  7.0000\n",
      "theta =  2.6906, omega:  0.1154, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2009, action:  2.0000\n",
      "theta =  2.6988, omega:  0.3022, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7317, action:  0.0000\n",
      "theta =  2.6881, omega:  0.0859, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1653, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2544, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3590, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6786, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0624, action:  7.0000\n",
      "theta =  2.6954, omega:  0.1519, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2558, action:  2.0000\n",
      "theta =  2.7070, omega:  0.3715, action:  2.0000\n",
      "theta =  2.7031, omega: -0.6563, action:  0.0000\n",
      "theta =  2.6987, omega:  0.0971, action:  7.0000\n",
      "theta =  2.7003, omega:  0.2070, action:  2.0000\n",
      "theta =  2.7084, omega:  0.3288, action:  2.0000\n",
      "theta =  2.7028, omega: -0.6917, action:  0.0000\n",
      "theta =  2.6963, omega:  0.0605, action:  7.0000\n",
      "theta =  2.7001, omega:  0.1658, action:  2.0000\n",
      "theta =  2.7035, omega:  0.2785, action:  2.0000\n",
      "theta =  2.6977, omega: -0.7382, action:  0.0000\n",
      "theta =  2.6910, omega:  0.0831, action:  7.0000\n",
      "theta =  2.6945, omega:  0.1694, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2696, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7614, action:  0.0000\n",
      "theta =  2.6838, omega:  0.0605, action:  7.0000\n",
      "theta =  2.6889, omega:  0.1302, action:  2.0000\n",
      "theta =  2.6897, omega:  0.2092, action:  2.0000\n",
      "theta =  2.6976, omega:  0.3005, action:  2.0000\n",
      "theta =  2.6900, omega: -0.7450, action:  0.0000\n",
      "theta =  2.6839, omega:  0.0460, action:  7.0000\n",
      "theta =  2.6844, omega:  0.1118, action:  2.0000\n",
      "theta =  2.6904, omega:  0.1869, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2691, action:  2.0000\n",
      "theta =  2.7001, omega:  0.3693, action:  2.0000\n",
      "theta =  2.6981, omega: -0.6724, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0645, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1560, action:  2.0000\n",
      "theta =  2.7018, omega:  0.2568, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7736, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0264, action:  7.0000\n",
      "theta =  2.6848, omega:  0.0968, action:  2.0000\n",
      "theta =  2.6878, omega:  0.1693, action:  2.0000\n",
      "theta =  2.6932, omega:  0.2526, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3523, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6884, action:  0.0000\n",
      "theta =  2.6892, omega:  0.0439, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1321, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2227, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3305, action:  2.0000\n",
      "theta =  2.6977, omega: -0.7019, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0347, action:  7.0000\n",
      "theta =  2.6919, omega:  0.1244, action:  2.0000\n",
      "theta =  2.6978, omega:  0.2190, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3266, action:  2.0000\n",
      "theta =  2.6986, omega: -0.7022, action:  0.0000\n",
      "theta =  2.6911, omega:  0.0350, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1266, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2213, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3324, action:  2.0000\n",
      "theta =  2.7004, omega: -0.6967, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0442, action:  7.0000\n",
      "theta =  2.6951, omega:  0.1394, action:  2.0000\n",
      "theta =  2.7045, omega:  0.7036, action:  4.0000\n",
      "theta =  2.7069, omega: -0.3893, action:  0.0000\n",
      "theta =  2.7081, omega:  0.3134, action:  7.0000\n",
      "theta =  2.7045, omega: -0.7035, action:  0.0000\n",
      "theta =  2.6973, omega:  0.0468, action:  7.0000\n",
      "theta =  2.6976, omega:  0.1511, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2582, action:  2.0000\n",
      "theta =  2.6970, omega: -0.7612, action:  0.0000\n",
      "theta =  2.6881, omega:  0.0420, action:  7.0000\n",
      "theta =  2.6909, omega:  0.1225, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2083, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3092, action:  2.0000\n",
      "theta =  2.6958, omega: -0.7271, action:  0.0000\n",
      "theta =  2.6881, omega:  0.0936, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1740, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2622, action:  2.0000\n",
      "theta =  2.7059, omega:  0.3670, action:  2.0000\n",
      "theta =  2.6983, omega: -0.6698, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0706, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1678, action:  2.0000\n",
      "theta =  2.7026, omega:  0.2747, action:  2.0000\n",
      "theta =  2.6947, omega: -0.7539, action:  0.0000\n",
      "theta =  2.6870, omega:  0.0461, action:  7.0000\n",
      "theta =  2.6872, omega:  0.1255, action:  2.0000\n",
      "theta =  2.6931, omega:  0.2099, action:  2.0000\n",
      "theta =  2.6989, omega:  0.3068, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7322, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0826, action:  7.0000\n",
      "theta =  2.6881, omega:  0.1619, action:  2.0000\n",
      "theta =  2.6938, omega:  0.2441, action:  2.0000\n",
      "theta =  2.7022, omega:  0.3452, action:  2.0000\n",
      "theta =  2.6984, omega: -0.6921, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0412, action:  7.0000\n",
      "theta =  2.6921, omega:  0.1264, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2201, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3246, action:  2.0000\n",
      "theta =  2.6995, omega: -0.7061, action:  0.0000\n",
      "theta =  2.6884, omega:  0.0324, action:  7.0000\n",
      "theta =  2.6930, omega:  0.1202, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2137, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3200, action:  2.0000\n",
      "theta =  2.6972, omega: -0.7103, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0872, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1765, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2728, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7598, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0622, action:  7.0000\n",
      "theta =  2.6868, omega:  0.1334, action:  2.0000\n",
      "theta =  2.6904, omega:  0.2119, action:  2.0000\n",
      "theta =  2.6958, omega:  0.3018, action:  2.0000\n",
      "theta =  2.6912, omega: -0.7396, action:  0.0000\n",
      "theta =  2.6836, omega:  0.0499, action:  7.0000\n",
      "theta =  2.6874, omega:  0.1169, action:  2.0000\n",
      "theta =  2.6909, omega:  0.1920, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2785, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3824, action:  2.0000\n",
      "theta =  2.6986, omega: -0.6589, action:  0.0000\n",
      "theta =  2.6952, omega:  0.0835, action:  7.0000\n",
      "theta =  2.6955, omega:  0.1793, action:  2.0000\n",
      "theta =  2.7021, omega:  0.2864, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7387, action:  0.0000\n",
      "theta =  2.6894, omega:  0.0844, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1647, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2586, action:  2.0000\n",
      "theta =  2.7068, omega:  0.3659, action:  2.0000\n",
      "theta =  2.7008, omega: -0.6680, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0764, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1734, action:  2.0000\n",
      "theta =  2.7018, omega:  0.2818, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7419, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0757, action:  7.0000\n",
      "theta =  2.6921, omega:  0.1599, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2508, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3577, action:  2.0000\n",
      "theta =  2.7002, omega: -0.6775, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0661, action:  7.0000\n",
      "theta =  2.6962, omega:  0.1630, action:  2.0000\n",
      "theta =  2.7022, omega:  0.2645, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7598, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0386, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1152, action:  2.0000\n",
      "theta =  2.6921, omega:  0.1992, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2926, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7477, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0430, action:  7.0000\n",
      "theta =  2.6875, omega:  0.1114, action:  2.0000\n",
      "theta =  2.6899, omega:  0.1863, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2752, action:  2.0000\n",
      "theta =  2.7034, omega:  0.3797, action:  2.0000\n",
      "theta =  2.6980, omega: -0.6617, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0800, action:  7.0000\n",
      "theta =  2.6970, omega:  0.1783, action:  2.0000\n",
      "theta =  2.7019, omega:  0.2846, action:  2.0000\n",
      "theta =  2.7102, omega:  0.4092, action:  2.0000\n",
      "theta =  2.7089, omega: -0.6168, action:  0.0000\n",
      "theta =  2.7032, omega:  0.1372, action:  7.0000\n",
      "theta =  2.7058, omega:  0.2609, action:  2.0000\n",
      "theta =  2.7015, omega: -0.7477, action:  0.0000\n",
      "theta =  2.6933, omega:  0.0853, action:  7.0000\n",
      "theta =  2.6970, omega:  0.1810, action:  2.0000\n",
      "theta =  2.7022, omega:  0.2866, action:  2.0000\n",
      "theta =  2.6977, omega: -0.7393, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0840, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1677, action:  2.0000\n",
      "theta =  2.6977, omega:  0.2611, action:  2.0000\n",
      "theta =  2.7058, omega:  0.3685, action:  2.0000\n",
      "theta =  2.7011, omega: -0.6643, action:  0.0000\n",
      "theta =  2.6939, omega:  0.0817, action:  7.0000\n",
      "theta =  2.6981, omega:  0.1790, action:  2.0000\n",
      "theta =  2.7036, omega:  0.2907, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7324, action:  0.0000\n",
      "theta =  2.6904, omega:  0.0688, action:  7.0000\n",
      "theta =  2.6933, omega:  0.1552, action:  2.0000\n",
      "theta =  2.6992, omega:  0.2509, action:  2.0000\n",
      "theta =  2.7060, omega:  0.3620, action:  2.0000\n",
      "theta =  2.7007, omega: -0.6718, action:  0.0000\n",
      "theta =  2.6960, omega:  0.0748, action:  7.0000\n",
      "theta =  2.6987, omega:  0.1780, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2834, action:  2.0000\n",
      "theta =  2.6958, omega: -0.7382, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0857, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1734, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2671, action:  2.0000\n",
      "theta =  2.7064, omega:  0.3785, action:  2.0000\n",
      "theta =  2.7019, omega: -0.6552, action:  0.0000\n",
      "theta =  2.6959, omega:  0.0953, action:  7.0000\n",
      "theta =  2.6992, omega:  0.2026, action:  2.0000\n",
      "theta =  2.7063, omega:  0.3165, action:  2.0000\n",
      "theta =  2.7018, omega: -0.7048, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0434, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1388, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2477, action:  2.0000\n",
      "theta =  2.7077, omega:  0.3633, action:  2.0000\n",
      "theta =  2.7037, omega: -0.6596, action:  0.0000\n",
      "theta =  2.6994, omega:  0.0964, action:  7.0000\n",
      "theta =  2.7024, omega:  0.2050, action:  2.0000\n",
      "theta =  2.7085, omega:  0.3294, action:  2.0000\n",
      "theta =  2.7032, omega: -0.6901, action:  0.0000\n",
      "theta =  2.6981, omega:  0.0647, action:  7.0000\n",
      "theta =  2.6996, omega:  0.1698, action:  2.0000\n",
      "theta =  2.7063, omega:  0.2860, action:  2.0000\n",
      "theta =  2.7006, omega: -0.7311, action:  0.0000\n",
      "theta =  2.6926, omega:  0.0708, action:  7.0000\n",
      "theta =  2.6956, omega:  0.1647, action:  2.0000\n",
      "theta =  2.7010, omega:  0.2659, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7626, action:  0.0000\n",
      "theta =  2.6866, omega:  0.0645, action:  7.0000\n",
      "theta =  2.6864, omega:  0.1354, action:  2.0000\n",
      "theta =  2.6923, omega:  0.2171, action:  2.0000\n",
      "theta =  2.6981, omega:  0.3109, action:  2.0000\n",
      "theta =  2.6930, omega: -0.7311, action:  0.0000\n",
      "theta =  2.6851, omega:  0.0757, action:  7.0000\n",
      "theta =  2.6878, omega:  0.1480, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2321, action:  2.0000\n",
      "theta =  2.6983, omega:  0.3270, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7158, action:  0.0000\n",
      "theta =  2.6887, omega:  0.0731, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1506, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2392, action:  2.0000\n",
      "theta =  2.7017, omega:  0.3412, action:  2.0000\n",
      "theta =  2.6951, omega: -0.6965, action:  0.0000\n",
      "theta =  2.6889, omega:  0.0405, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1245, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2182, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3235, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7080, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0888, action:  7.0000\n",
      "theta =  2.6952, omega:  0.1755, action:  2.0000\n",
      "theta =  2.7013, omega:  0.2726, action:  2.0000\n",
      "theta =  2.6947, omega: -0.7595, action:  0.0000\n",
      "theta =  2.6832, omega:  0.0598, action:  7.0000\n",
      "theta =  2.6874, omega:  0.1305, action:  2.0000\n",
      "theta =  2.6921, omega:  0.2095, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2993, action:  2.0000\n",
      "theta =  2.6910, omega: -0.7440, action:  0.0000\n",
      "theta =  2.6813, omega:  0.0462, action:  7.0000\n",
      "theta =  2.6834, omega:  0.1120, action:  2.0000\n",
      "theta =  2.6892, omega:  0.1858, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2701, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3716, action:  2.0000\n",
      "theta =  2.6975, omega: -0.6704, action:  0.0000\n",
      "theta =  2.6907, omega:  0.0663, action:  7.0000\n",
      "theta =  2.6946, omega:  0.1587, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2583, action:  2.0000\n",
      "theta =  2.7060, omega:  0.3739, action:  2.0000\n",
      "theta =  2.7029, omega: -0.6531, action:  0.0000\n",
      "theta =  2.6971, omega:  0.0987, action:  7.0000\n",
      "theta =  2.7016, omega:  0.2053, action:  2.0000\n",
      "theta =  2.7074, omega:  0.3261, action:  2.0000\n",
      "theta =  2.7019, omega: -0.6916, action:  0.0000\n",
      "theta =  2.6954, omega:  0.0581, action:  7.0000\n",
      "theta =  2.6989, omega:  0.1622, action:  2.0000\n",
      "theta =  2.7033, omega:  0.2747, action:  2.0000\n",
      "theta =  2.6973, omega: -0.7457, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0605, action:  7.0000\n",
      "theta =  2.6917, omega:  0.1471, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2413, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3478, action:  2.0000\n",
      "theta =  2.7000, omega: -0.6845, action:  0.0000\n",
      "theta =  2.6926, omega:  0.0597, action:  7.0000\n",
      "theta =  2.6957, omega:  0.1542, action:  2.0000\n",
      "theta =  2.7000, omega:  0.2578, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7679, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0536, action:  7.0000\n",
      "theta =  2.6892, omega:  0.1248, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2062, action:  2.0000\n",
      "theta =  2.6978, omega:  0.2999, action:  2.0000\n",
      "theta =  2.6911, omega: -0.7403, action:  0.0000\n",
      "theta =  2.6856, omega:  0.0506, action:  7.0000\n",
      "theta =  2.6872, omega:  0.1201, action:  2.0000\n",
      "theta =  2.6903, omega:  0.1968, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2832, action:  2.0000\n",
      "theta =  2.6891, omega: -0.7597, action:  0.0000\n",
      "theta =  2.6818, omega:  0.0489, action:  7.0000\n",
      "theta =  2.6834, omega:  0.1106, action:  2.0000\n",
      "theta =  2.6871, omega:  0.1803, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2594, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3522, action:  2.0000\n",
      "theta =  2.6953, omega: -0.6914, action:  0.0000\n",
      "theta =  2.6888, omega:  0.0382, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1193, action:  2.0000\n",
      "theta =  2.6943, omega:  0.2096, action:  2.0000\n",
      "theta =  2.7009, omega:  0.3070, action:  2.0000\n",
      "theta =  2.6947, omega: -0.7282, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0912, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1693, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2583, action:  2.0000\n",
      "theta =  2.7040, omega:  0.3648, action:  2.0000\n",
      "theta =  2.6983, omega: -0.6735, action:  0.0000\n",
      "theta =  2.6933, omega:  0.0697, action:  7.0000\n",
      "theta =  2.6952, omega:  0.1650, action:  2.0000\n",
      "theta =  2.7027, omega:  0.2678, action:  2.0000\n",
      "theta =  2.6954, omega: -0.7587, action:  0.0000\n",
      "theta =  2.6864, omega:  0.0395, action:  7.0000\n",
      "theta =  2.6887, omega:  0.1164, action:  2.0000\n",
      "theta =  2.6943, omega:  0.1976, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2912, action:  2.0000\n",
      "theta =  2.6931, omega: -0.7471, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0432, action:  7.0000\n",
      "theta =  2.6867, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6904, omega:  0.1870, action:  2.0000\n",
      "theta =  2.6955, omega:  0.2748, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3769, action:  2.0000\n",
      "theta =  2.6994, omega: -0.6644, action:  0.0000\n",
      "theta =  2.6946, omega:  0.0774, action:  7.0000\n",
      "theta =  2.6964, omega:  0.1729, action:  2.0000\n",
      "theta =  2.7011, omega:  0.2768, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7490, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0506, action:  7.0000\n",
      "theta =  2.6891, omega:  0.1303, action:  2.0000\n",
      "theta =  2.6933, omega:  0.2133, action:  2.0000\n",
      "theta =  2.6996, omega:  0.3110, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7263, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0891, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1686, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2554, action:  2.0000\n",
      "theta =  2.7040, omega:  0.3595, action:  2.0000\n",
      "theta =  2.6971, omega: -0.6785, action:  0.0000\n",
      "theta =  2.6923, omega:  0.0607, action:  7.0000\n",
      "theta =  2.6950, omega:  0.1514, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2518, action:  2.0000\n",
      "theta =  2.7067, omega:  0.3675, action:  2.0000\n",
      "theta =  2.7032, omega: -0.6604, action:  0.0000\n",
      "theta =  2.6980, omega:  0.0921, action:  7.0000\n",
      "theta =  2.7007, omega:  0.2003, action:  2.0000\n",
      "theta =  2.7069, omega:  0.3173, action:  2.0000\n",
      "theta =  2.7015, omega: -0.6999, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0467, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1457, action:  2.0000\n",
      "theta =  2.7017, omega:  0.2530, action:  2.0000\n",
      "theta =  2.6941, omega: -0.7705, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0541, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1306, action:  2.0000\n",
      "theta =  2.6945, omega:  0.2135, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3106, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7292, action:  0.0000\n",
      "theta =  2.6858, omega:  0.0846, action:  7.0000\n",
      "theta =  2.6900, omega:  0.1619, action:  2.0000\n",
      "theta =  2.6942, omega:  0.2476, action:  2.0000\n",
      "theta =  2.7037, omega:  0.3484, action:  2.0000\n",
      "theta =  2.6978, omega: -0.6895, action:  0.0000\n",
      "theta =  2.6900, omega:  0.0474, action:  7.0000\n",
      "theta =  2.6897, omega:  0.1354, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2274, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3357, action:  2.0000\n",
      "theta =  2.7002, omega: -0.6936, action:  0.0000\n",
      "theta =  2.6926, omega:  0.0430, action:  7.0000\n",
      "theta =  2.6936, omega:  0.1364, action:  2.0000\n",
      "theta =  2.6980, omega:  0.2368, action:  2.0000\n",
      "theta =  2.7125, omega:  0.8153, action:  5.0000\n",
      "theta =  2.7180, omega: -0.2777, action:  0.0000\n",
      "theta =  2.7163, omega:  0.0678, action:  2.0000\n",
      "theta =  2.7202, omega:  0.2279, action:  2.0000\n",
      "theta =  2.7117, omega: -0.7401, action:  0.0000\n",
      "theta =  2.7043, omega:  0.0409, action:  7.0000\n",
      "theta =  2.7083, omega:  0.1691, action:  2.0000\n",
      "theta =  2.7139, omega:  0.3085, action:  2.0000\n",
      "theta =  2.7063, omega: -0.6922, action:  0.0000\n",
      "theta =  2.7009, omega:  0.0738, action:  7.0000\n",
      "theta =  2.7048, omega:  0.1935, action:  2.0000\n",
      "theta =  2.7099, omega:  0.3247, action:  2.0000\n",
      "theta =  2.7070, omega: -0.6845, action:  0.0000\n",
      "theta =  2.6983, omega:  0.0760, action:  7.0000\n",
      "theta =  2.7013, omega:  0.1872, action:  2.0000\n",
      "theta =  2.7080, omega:  0.3143, action:  2.0000\n",
      "theta =  2.7038, omega: -0.7003, action:  0.0000\n",
      "theta =  2.6980, omega:  0.0527, action:  7.0000\n",
      "theta =  2.7005, omega:  0.1563, action:  2.0000\n",
      "theta =  2.7034, omega:  0.2741, action:  2.0000\n",
      "theta =  2.6987, omega: -0.7461, action:  0.0000\n",
      "theta =  2.6894, omega:  0.0830, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1719, action:  2.0000\n",
      "theta =  2.7047, omega:  0.7363, action:  6.0000\n",
      "theta =  2.7067, omega: -0.3614, action:  0.0000\n",
      "theta =  2.7088, omega:  0.3344, action:  7.0000\n",
      "theta =  2.7039, omega: -0.6805, action:  0.0000\n",
      "theta =  2.6976, omega:  0.0740, action:  7.0000\n",
      "theta =  2.7017, omega:  0.1829, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3037, action:  2.0000\n",
      "theta =  2.7001, omega: -0.7131, action:  0.0000\n",
      "theta =  2.6952, omega:  0.0353, action:  7.0000\n",
      "theta =  2.6967, omega:  0.1338, action:  2.0000\n",
      "theta =  2.7015, omega:  0.2367, action:  2.0000\n",
      "theta =  2.6937, omega: -0.7862, action:  0.0000\n",
      "theta =  2.6855, omega:  0.0417, action:  7.0000\n",
      "theta =  2.6860, omega:  0.1131, action:  2.0000\n",
      "theta =  2.6899, omega:  0.1864, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2753, action:  2.0000\n",
      "theta =  2.7066, omega:  0.3804, action:  2.0000\n",
      "theta =  2.6987, omega: -0.6594, action:  0.0000\n",
      "theta =  2.6935, omega:  0.0825, action:  7.0000\n",
      "theta =  2.6973, omega:  0.1788, action:  2.0000\n",
      "theta =  2.7024, omega:  0.2870, action:  2.0000\n",
      "theta =  2.6959, omega: -0.7389, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0823, action:  7.0000\n",
      "theta =  2.6916, omega:  0.1659, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2573, action:  2.0000\n",
      "theta =  2.7054, omega:  0.3659, action:  2.0000\n",
      "theta =  2.7000, omega: -0.6682, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0752, action:  7.0000\n",
      "theta =  2.6966, omega:  0.1731, action:  2.0000\n",
      "theta =  2.7042, omega:  0.2812, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7429, action:  0.0000\n",
      "theta =  2.6881, omega:  0.0615, action:  7.0000\n",
      "theta =  2.6905, omega:  0.1431, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2332, action:  2.0000\n",
      "theta =  2.7107, omega:  0.8034, action:  8.0000\n",
      "theta =  2.7134, omega: -0.2955, action:  0.0000\n",
      "theta =  2.7140, omega:  0.0531, action:  2.0000\n",
      "theta =  2.7146, omega:  0.2028, action:  2.0000\n",
      "theta =  2.7070, omega: -0.7747, action:  0.0000\n",
      "theta =  2.7009, omega:  0.0627, action:  7.0000\n",
      "theta =  2.7036, omega:  0.1786, action:  2.0000\n",
      "theta =  2.7081, omega:  0.3005, action:  2.0000\n",
      "theta =  2.7018, omega: -0.7137, action:  0.0000\n",
      "theta =  2.6944, omega:  0.0362, action:  7.0000\n",
      "theta =  2.6977, omega:  0.1389, action:  2.0000\n",
      "theta =  2.7003, omega:  0.2466, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7747, action:  0.0000\n",
      "theta =  2.6858, omega:  0.0515, action:  7.0000\n",
      "theta =  2.6881, omega:  0.1276, action:  2.0000\n",
      "theta =  2.6935, omega:  0.2125, action:  2.0000\n",
      "theta =  2.7006, omega:  0.3092, action:  2.0000\n",
      "theta =  2.6941, omega: -0.7297, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0849, action:  7.0000\n",
      "theta =  2.6902, omega:  0.1604, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2464, action:  2.0000\n",
      "theta =  2.7001, omega:  0.3462, action:  2.0000\n",
      "theta =  2.6971, omega: -0.6931, action:  0.0000\n",
      "theta =  2.6884, omega:  0.0419, action:  7.0000\n",
      "theta =  2.6921, omega:  0.1255, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2183, action:  2.0000\n",
      "theta =  2.7028, omega:  0.3224, action:  2.0000\n",
      "theta =  2.6975, omega: -0.7078, action:  0.0000\n",
      "theta =  2.6906, omega:  0.1004, action:  7.0000\n",
      "theta =  2.6959, omega:  0.1870, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2883, action:  2.0000\n",
      "theta =  2.6951, omega: -0.7453, action:  0.0000\n",
      "theta =  2.6859, omega:  0.0505, action:  7.0000\n",
      "theta =  2.6877, omega:  0.1235, action:  2.0000\n",
      "theta =  2.6912, omega:  0.2054, action:  2.0000\n",
      "theta =  2.6997, omega:  0.2974, action:  2.0000\n",
      "theta =  2.6909, omega: -0.7408, action:  0.0000\n",
      "theta =  2.6832, omega:  0.0490, action:  7.0000\n",
      "theta =  2.6853, omega:  0.1178, action:  2.0000\n",
      "theta =  2.6935, omega:  0.1957, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2838, action:  2.0000\n",
      "theta =  2.6886, omega: -0.7601, action:  0.0000\n",
      "theta =  2.6824, omega:  0.0508, action:  7.0000\n",
      "theta =  2.6828, omega:  0.1129, action:  2.0000\n",
      "theta =  2.6878, omega:  0.1799, action:  2.0000\n",
      "theta =  2.6929, omega:  0.2587, action:  2.0000\n",
      "theta =  2.7008, omega:  0.3513, action:  2.0000\n",
      "theta =  2.6951, omega: -0.6909, action:  0.0000\n",
      "theta =  2.6882, omega:  0.0381, action:  7.0000\n",
      "theta =  2.6899, omega:  0.1210, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2087, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3074, action:  2.0000\n",
      "theta =  2.6947, omega: -0.7258, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0918, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1713, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2614, action:  2.0000\n",
      "theta =  2.7043, omega:  0.3675, action:  2.0000\n",
      "theta =  2.6992, omega: -0.6691, action:  0.0000\n",
      "theta =  2.6922, omega:  0.0725, action:  7.0000\n",
      "theta =  2.6969, omega:  0.1689, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2744, action:  2.0000\n",
      "theta =  2.6942, omega: -0.7541, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0495, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1268, action:  2.0000\n",
      "theta =  2.6923, omega:  0.2126, action:  2.0000\n",
      "theta =  2.6990, omega:  0.3083, action:  2.0000\n",
      "theta =  2.6937, omega: -0.7286, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0798, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1605, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2458, action:  2.0000\n",
      "theta =  2.7018, omega:  0.3462, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6896, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0458, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1348, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2295, action:  2.0000\n",
      "theta =  2.7043, omega:  0.3366, action:  2.0000\n",
      "theta =  2.6978, omega: -0.6959, action:  0.0000\n",
      "theta =  2.6909, omega:  0.0459, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1383, action:  2.0000\n",
      "theta =  2.7005, omega:  0.2373, action:  2.0000\n",
      "theta =  2.7056, omega:  0.3512, action:  2.0000\n",
      "theta =  2.7009, omega: -0.6734, action:  0.0000\n",
      "theta =  2.6947, omega:  0.0710, action:  7.0000\n",
      "theta =  2.6992, omega:  0.1725, action:  2.0000\n",
      "theta =  2.7045, omega:  0.2852, action:  2.0000\n",
      "theta =  2.6969, omega: -0.7368, action:  0.0000\n",
      "theta =  2.6913, omega:  0.0831, action:  7.0000\n",
      "theta =  2.6930, omega:  0.1696, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2669, action:  2.0000\n",
      "theta =  2.6906, omega: -0.7698, action:  0.0000\n",
      "theta =  2.6847, omega:  0.0454, action:  7.0000\n",
      "theta =  2.6864, omega:  0.1146, action:  2.0000\n",
      "theta =  2.6896, omega:  0.1899, action:  2.0000\n",
      "theta =  2.6959, omega:  0.2759, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3744, action:  2.0000\n",
      "theta =  2.6993, omega: -0.6624, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0766, action:  7.0000\n",
      "theta =  2.6964, omega:  0.1688, action:  2.0000\n",
      "theta =  2.7013, omega:  0.2734, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7554, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0424, action:  7.0000\n",
      "theta =  2.6873, omega:  0.1192, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2009, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2941, action:  2.0000\n",
      "theta =  2.6924, omega: -0.7464, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0438, action:  7.0000\n",
      "theta =  2.6865, omega:  0.1161, action:  2.0000\n",
      "theta =  2.6896, omega:  0.1938, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2797, action:  2.0000\n",
      "theta =  2.7045, omega:  0.3840, action:  2.0000\n",
      "theta =  2.7014, omega: -0.6554, action:  0.0000\n",
      "theta =  2.6953, omega:  0.0887, action:  7.0000\n",
      "theta =  2.6982, omega:  0.1890, action:  2.0000\n",
      "theta =  2.7029, omega:  0.2965, action:  2.0000\n",
      "theta =  2.6983, omega: -0.7296, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0703, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1589, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2537, action:  2.0000\n",
      "theta =  2.7054, omega:  0.3648, action:  2.0000\n",
      "theta =  2.7018, omega: -0.6678, action:  0.0000\n",
      "theta =  2.6948, omega:  0.0807, action:  7.0000\n",
      "theta =  2.6984, omega:  0.1830, action:  2.0000\n",
      "theta =  2.7053, omega:  0.2981, action:  2.0000\n",
      "theta =  2.6991, omega: -0.7250, action:  0.0000\n",
      "theta =  2.6909, omega:  0.0752, action:  3.0000\n",
      "theta =  2.6955, omega:  0.1650, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2627, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7671, action:  0.0000\n",
      "theta =  2.6836, omega:  0.0504, action:  7.0000\n",
      "theta =  2.6841, omega:  0.1228, action:  2.0000\n",
      "theta =  2.6929, omega:  0.1984, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2860, action:  2.0000\n",
      "theta =  2.6900, omega: -0.7572, action:  0.0000\n",
      "theta =  2.6813, omega:  0.0575, action:  7.0000\n",
      "theta =  2.6856, omega:  0.1198, action:  2.0000\n",
      "theta =  2.6872, omega:  0.1935, action:  2.0000\n",
      "theta =  2.6860, omega: -0.4079, action:  1.0000\n",
      "theta =  2.6827, omega:  0.2740, action:  7.0000\n",
      "theta =  2.6920, omega:  0.3437, action:  2.0000\n",
      "theta =  2.6862, omega: -0.7232, action:  0.0000\n",
      "theta =  2.6802, omega:  0.0741, action:  7.0000\n",
      "theta =  2.6808, omega:  0.1281, action:  2.0000\n",
      "theta =  2.6867, omega:  0.1883, action:  2.0000\n",
      "theta =  2.6890, omega:  0.2625, action:  2.0000\n",
      "theta =  2.6983, omega:  0.3497, action:  2.0000\n",
      "theta =  2.6939, omega: -0.6993, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0548, action:  7.0000\n",
      "theta =  2.6924, omega:  0.5985, action:  7.0000\n",
      "theta =  2.7153, omega:  1.1652, action:  5.0000\n",
      "theta =  2.7300, omega: -0.0515, action:  0.0000\n",
      "theta =  2.7331, omega:  0.1814, action:  2.0000\n",
      "theta =  2.7259, omega: -0.7438, action:  0.0000\n",
      "theta =  2.7166, omega:  0.0721, action:  7.0000\n",
      "theta =  2.7204, omega:  0.2363, action:  2.0000\n",
      "theta =  2.7137, omega: -0.7313, action:  0.0000\n",
      "theta =  2.7084, omega:  0.0549, action:  7.0000\n",
      "theta =  2.7084, omega:  0.1919, action:  2.0000\n",
      "theta =  2.7030, omega: -0.7973, action:  0.0000\n",
      "theta =  2.6943, omega:  0.0308, action:  7.0000\n",
      "theta =  2.6960, omega:  0.1283, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2266, action:  2.0000\n",
      "theta =  2.7078, omega:  0.3440, action:  2.0000\n",
      "theta =  2.7010, omega: -0.6802, action:  0.0000\n",
      "theta =  2.6939, omega:  0.0661, action:  7.0000\n",
      "theta =  2.6996, omega:  0.1674, action:  2.0000\n",
      "theta =  2.7034, omega:  0.2785, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7431, action:  0.0000\n",
      "theta =  2.6872, omega:  0.0812, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1678, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2633, action:  2.0000\n",
      "theta =  2.6900, omega: -0.7719, action:  0.0000\n",
      "theta =  2.6816, omega:  0.0252, action:  6.0000\n",
      "theta =  2.6849, omega:  0.0912, action:  2.0000\n",
      "theta =  2.6867, omega:  0.1602, action:  2.0000\n",
      "theta =  2.6925, omega:  0.2373, action:  2.0000\n",
      "theta =  2.6977, omega:  0.3338, action:  2.0000\n",
      "theta =  2.6933, omega: -0.7102, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0754, action:  7.0000\n",
      "theta =  2.6897, omega:  0.1534, action:  2.0000\n",
      "theta =  2.6946, omega:  0.2381, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3371, action:  2.0000\n",
      "theta =  2.6993, omega: -0.6999, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0334, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1188, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2062, action:  2.0000\n",
      "theta =  2.6998, omega:  0.3067, action:  2.0000\n",
      "theta =  2.6946, omega: -0.7242, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0671, action:  7.0000\n",
      "theta =  2.6896, omega:  0.1523, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2411, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3446, action:  2.0000\n",
      "theta =  2.6974, omega: -0.6914, action:  0.0000\n",
      "theta =  2.6914, omega:  0.0486, action:  7.0000\n",
      "theta =  2.6954, omega:  0.1413, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2376, action:  2.0000\n",
      "theta =  2.7070, omega:  0.3474, action:  2.0000\n",
      "theta =  2.7015, omega: -0.6799, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0656, action:  7.0000\n",
      "theta =  2.6979, omega:  0.1653, action:  2.0000\n",
      "theta =  2.7027, omega:  0.2712, action:  2.0000\n",
      "theta =  2.6977, omega: -0.7525, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0493, action:  7.0000\n",
      "theta =  2.6888, omega:  0.1309, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2182, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3186, action:  2.0000\n",
      "theta =  2.6945, omega: -0.7163, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0749, action:  7.0000\n",
      "theta =  2.6910, omega:  0.1578, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2476, action:  2.0000\n",
      "theta =  2.7041, omega:  0.3541, action:  2.0000\n",
      "theta =  2.6985, omega: -0.6836, action:  0.0000\n",
      "theta =  2.6934, omega:  0.0569, action:  7.0000\n",
      "theta =  2.6815, omega: -0.9573, action:  0.0000\n",
      "theta =  2.6666, omega: -0.1293, action:  7.0000\n",
      "theta =  2.6671, omega:  0.0114, action:  2.0000\n",
      "theta =  2.6677, omega:  0.0346, action:  2.0000\n",
      "theta =  2.6705, omega:  0.0570, action:  2.0000\n",
      "theta =  2.6695, omega:  0.0840, action:  2.0000\n",
      "theta =  2.6729, omega:  0.1139, action:  2.0000\n",
      "theta =  2.6754, omega:  0.1527, action:  2.0000\n",
      "theta =  2.6804, omega:  0.2001, action:  2.0000\n",
      "theta =  2.6859, omega:  0.2605, action:  2.0000\n",
      "theta =  2.6937, omega:  0.3367, action:  2.0000\n",
      "theta =  2.6862, omega: -0.7224, action:  0.0000\n",
      "theta =  2.6806, omega:  0.0723, action:  7.0000\n",
      "theta =  2.6839, omega:  0.1323, action:  2.0000\n",
      "theta =  2.6884, omega:  0.2004, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2805, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3784, action:  2.0000\n",
      "theta =  2.6977, omega: -0.6646, action:  0.0000\n",
      "theta =  2.6917, omega:  0.0712, action:  7.0000\n",
      "theta =  2.6961, omega:  0.1617, action:  2.0000\n",
      "theta =  2.7005, omega:  0.2637, action:  2.0000\n",
      "theta =  2.6934, omega: -0.7666, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0504, action:  7.0000\n",
      "theta =  2.6866, omega:  0.1211, action:  2.0000\n",
      "theta =  2.6900, omega:  0.1978, action:  2.0000\n",
      "theta =  2.6978, omega:  0.2872, action:  2.0000\n",
      "theta =  2.6899, omega: -0.7555, action:  0.0000\n",
      "theta =  2.6811, omega:  0.0594, action:  7.0000\n",
      "theta =  2.6837, omega:  0.1257, action:  2.0000\n",
      "theta =  2.6886, omega:  0.1938, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2765, action:  2.0000\n",
      "theta =  2.7008, omega:  0.3763, action:  2.0000\n",
      "theta =  2.6992, omega: -0.6697, action:  0.0000\n",
      "theta =  2.6897, omega:  0.0700, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1615, action:  2.0000\n",
      "theta =  2.7000, omega:  0.2603, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7692, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0477, action:  7.0000\n",
      "theta =  2.6866, omega:  0.1215, action:  2.0000\n",
      "theta =  2.6896, omega:  0.1983, action:  2.0000\n",
      "theta =  2.6967, omega:  0.2833, action:  2.0000\n",
      "theta =  2.6897, omega: -0.7590, action:  0.0000\n",
      "theta =  2.6810, omega:  0.0497, action:  7.0000\n",
      "theta =  2.6858, omega:  0.1142, action:  2.0000\n",
      "theta =  2.6861, omega:  0.1819, action:  2.0000\n",
      "theta =  2.6942, omega:  0.2611, action:  2.0000\n",
      "theta =  2.7007, omega:  0.3579, action:  2.0000\n",
      "theta =  2.6958, omega: -0.6880, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0423, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1264, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2153, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3185, action:  2.0000\n",
      "theta =  2.6975, omega: -0.7173, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0810, action:  7.0000\n",
      "theta =  2.6918, omega:  0.1623, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2552, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3638, action:  2.0000\n",
      "theta =  2.7013, omega: -0.6675, action:  0.0000\n",
      "theta =  2.6937, omega:  0.0768, action:  7.0000\n",
      "theta =  2.6988, omega:  0.1765, action:  2.0000\n",
      "theta =  2.7020, omega:  0.2862, action:  2.0000\n",
      "theta =  2.6960, omega: -0.7413, action:  0.0000\n",
      "theta =  2.6892, omega:  0.0833, action:  7.0000\n",
      "theta =  2.6966, omega:  0.6360, action:  6.0000\n",
      "theta =  2.6991, omega: -0.4657, action:  0.0000\n",
      "theta =  2.6962, omega:  0.2358, action:  7.0000\n",
      "theta =  2.7046, omega:  0.3440, action:  2.0000\n",
      "theta =  2.7006, omega: -0.6862, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0547, action:  7.0000\n",
      "theta =  2.6944, omega:  0.1514, action:  2.0000\n",
      "theta =  2.7004, omega:  0.2532, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7736, action:  0.0000\n",
      "theta =  2.6844, omega:  0.0484, action:  7.0000\n",
      "theta =  2.6863, omega:  0.1209, action:  2.0000\n",
      "theta =  2.6973, omega:  0.6652, action:  7.0000\n",
      "theta =  2.6994, omega: -0.4420, action:  0.0000\n",
      "theta =  2.6978, omega:  0.2390, action:  7.0000\n",
      "theta =  2.7041, omega:  0.3460, action:  2.0000\n",
      "theta =  2.6984, omega: -0.6858, action:  0.0000\n",
      "theta =  2.6919, omega:  0.0552, action:  7.0000\n",
      "theta =  2.6969, omega:  0.1501, action:  2.0000\n",
      "theta =  2.7000, omega:  0.2495, action:  2.0000\n",
      "theta =  2.6923, omega: -0.7743, action:  0.0000\n",
      "theta =  2.6841, omega:  0.0281, action:  7.0000\n",
      "theta =  2.6866, omega:  0.0962, action:  2.0000\n",
      "theta =  2.6974, omega:  0.6393, action:  3.0000\n",
      "theta =  2.6977, omega: -0.4680, action:  0.0000\n",
      "theta =  2.6940, omega:  0.2140, action:  7.0000\n",
      "theta =  2.7005, omega:  0.3133, action:  2.0000\n",
      "theta =  2.7145, omega:  0.8969, action:  7.0000\n",
      "theta =  2.7232, omega: -0.1980, action:  0.0000\n",
      "theta =  2.7241, omega:  0.1086, action:  2.0000\n",
      "theta =  2.7134, omega: -0.8279, action:  0.0000\n",
      "theta =  2.7035, omega:  0.0360, action:  7.0000\n",
      "theta =  2.7081, omega:  0.1641, action:  2.0000\n",
      "theta =  2.7124, omega:  0.3015, action:  2.0000\n",
      "theta =  2.7072, omega: -0.6987, action:  0.0000\n",
      "theta =  2.7007, omega:  0.0663, action:  7.0000\n",
      "theta =  2.7026, omega:  0.1822, action:  2.0000\n",
      "theta =  2.7106, omega:  0.3072, action:  2.0000\n",
      "theta =  2.7030, omega: -0.7035, action:  0.0000\n",
      "theta =  2.6982, omega:  0.0529, action:  7.0000\n",
      "theta =  2.7009, omega:  0.1608, action:  2.0000\n",
      "theta =  2.7048, omega:  0.2727, action:  2.0000\n",
      "theta =  2.7000, omega: -0.7432, action:  0.0000\n",
      "theta =  2.6916, omega:  0.0832, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1734, action:  2.0000\n",
      "theta =  2.7008, omega:  0.2714, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7578, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0463, action:  7.0000\n",
      "theta =  2.6852, omega:  0.1195, action:  2.0000\n",
      "theta =  2.6906, omega:  0.1970, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2897, action:  2.0000\n",
      "theta =  2.6895, omega: -0.7524, action:  0.0000\n",
      "theta =  2.6834, omega:  0.0645, action:  7.0000\n",
      "theta =  2.6848, omega:  0.1297, action:  2.0000\n",
      "theta =  2.6898, omega:  0.2027, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2874, action:  2.0000\n",
      "theta =  2.6883, omega: -0.7596, action:  0.0000\n",
      "theta =  2.6808, omega:  0.0479, action:  7.0000\n",
      "theta =  2.6812, omega:  0.1082, action:  2.0000\n",
      "theta =  2.6870, omega:  0.1739, action:  2.0000\n",
      "theta =  2.6926, omega:  0.2473, action:  2.0000\n",
      "theta =  2.6988, omega:  0.3377, action:  2.0000\n",
      "theta =  2.6945, omega: -0.7081, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0785, action:  7.0000\n",
      "theta =  2.6901, omega:  0.1534, action:  2.0000\n",
      "theta =  2.6936, omega:  0.2349, action:  2.0000\n",
      "theta =  2.7021, omega:  0.3350, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7017, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0532, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1376, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2271, action:  2.0000\n",
      "theta =  2.7016, omega:  0.3292, action:  2.0000\n",
      "theta =  2.6976, omega: -0.7054, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0345, action:  7.0000\n",
      "theta =  2.6900, omega:  0.1176, action:  2.0000\n",
      "theta =  2.6966, omega:  0.2107, action:  2.0000\n",
      "theta =  2.7010, omega:  0.3141, action:  2.0000\n",
      "theta =  2.6965, omega: -0.7173, action:  0.0000\n",
      "theta =  2.6905, omega:  0.0757, action:  7.0000\n",
      "theta =  2.6924, omega:  0.1619, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2552, action:  2.0000\n",
      "theta =  2.7053, omega:  0.3618, action:  2.0000\n",
      "theta =  2.7005, omega: -0.6705, action:  0.0000\n",
      "theta =  2.6954, omega:  0.0760, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1738, action:  2.0000\n",
      "theta =  2.7043, omega:  0.2841, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7402, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0835, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1667, action:  2.0000\n",
      "theta =  2.6979, omega:  0.2617, action:  2.0000\n",
      "theta =  2.7066, omega:  0.3728, action:  2.0000\n",
      "theta =  2.7006, omega: -0.6617, action:  0.0000\n",
      "theta =  2.6945, omega:  0.0864, action:  7.0000\n",
      "theta =  2.6987, omega:  0.1880, action:  2.0000\n",
      "theta =  2.7039, omega:  0.2988, action:  2.0000\n",
      "theta =  2.7000, omega: -0.7222, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0786, action:  7.0000\n",
      "theta =  2.6955, omega:  0.1690, action:  2.0000\n",
      "theta =  2.7020, omega:  0.2700, action:  2.0000\n",
      "theta =  2.6915, omega: -0.7625, action:  0.0000\n",
      "theta =  2.6859, omega:  0.0652, action:  7.0000\n",
      "theta =  2.6888, omega:  0.1357, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2152, action:  2.0000\n",
      "theta =  2.6979, omega:  0.3127, action:  2.0000\n",
      "theta =  2.6920, omega: -0.7303, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0836, action:  7.0000\n",
      "theta =  2.6881, omega:  0.1560, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2380, action:  2.0000\n",
      "theta =  2.6996, omega:  0.3347, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7084, action:  0.0000\n",
      "theta =  2.6874, omega:  0.0812, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1626, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2543, action:  2.0000\n",
      "theta =  2.7041, omega:  0.3588, action:  2.0000\n",
      "theta =  2.7009, omega: -0.6752, action:  0.0000\n",
      "theta =  2.6922, omega:  0.0660, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1602, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2634, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7648, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0638, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1344, action:  2.0000\n",
      "theta =  2.6935, omega:  0.2194, action:  2.0000\n",
      "theta =  2.6986, omega:  0.3122, action:  2.0000\n",
      "theta =  2.6915, omega: -0.7293, action:  0.0000\n",
      "theta =  2.6873, omega:  0.0870, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1613, action:  2.0000\n",
      "theta =  2.6934, omega:  0.2441, action:  2.0000\n",
      "theta =  2.7014, omega:  0.3425, action:  2.0000\n",
      "theta =  2.6950, omega: -0.6970, action:  0.0000\n",
      "theta =  2.6893, omega:  0.0338, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1195, action:  2.0000\n",
      "theta =  2.6934, omega:  0.2089, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3132, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7195, action:  0.0000\n",
      "theta =  2.6901, omega:  0.0727, action:  7.0000\n",
      "theta =  2.6924, omega:  0.1558, action:  2.0000\n",
      "theta =  2.6954, omega:  0.2484, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3520, action:  2.0000\n",
      "theta =  2.6991, omega: -0.6804, action:  0.0000\n",
      "theta =  2.6937, omega:  0.0634, action:  7.0000\n",
      "theta =  2.6947, omega:  0.1555, action:  2.0000\n",
      "theta =  2.7013, omega:  0.2586, action:  2.0000\n",
      "theta =  2.6940, omega: -0.7694, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0509, action:  7.0000\n",
      "theta =  2.6867, omega:  0.1240, action:  2.0000\n",
      "theta =  2.6902, omega:  0.2046, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2959, action:  2.0000\n",
      "theta =  2.6917, omega: -0.7460, action:  0.0000\n",
      "theta =  2.6822, omega:  0.0472, action:  7.0000\n",
      "theta =  2.6853, omega:  0.1132, action:  2.0000\n",
      "theta =  2.6909, omega:  0.1884, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2739, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3763, action:  2.0000\n",
      "theta =  2.6979, omega: -0.6663, action:  0.0000\n",
      "theta =  2.6924, omega:  0.0746, action:  7.0000\n",
      "theta =  2.6952, omega:  0.1669, action:  2.0000\n",
      "theta =  2.7014, omega:  0.2732, action:  2.0000\n",
      "theta =  2.6952, omega: -0.7562, action:  0.0000\n",
      "theta =  2.6871, omega:  0.0426, action:  7.0000\n",
      "theta =  2.6879, omega:  0.1183, action:  2.0000\n",
      "theta =  2.6932, omega:  0.2012, action:  2.0000\n",
      "theta =  2.6972, omega:  0.2939, action:  2.0000\n",
      "theta =  2.6915, omega: -0.7461, action:  0.0000\n",
      "theta =  2.6839, omega:  0.0465, action:  7.0000\n",
      "theta =  2.6848, omega:  0.1171, action:  2.0000\n",
      "theta =  2.6889, omega:  0.1916, action:  2.0000\n",
      "theta =  2.6965, omega:  0.2823, action:  2.0000\n",
      "theta =  2.6875, omega: -0.7633, action:  0.0000\n",
      "theta =  2.6803, omega:  0.0499, action:  7.0000\n",
      "theta =  2.6832, omega:  0.1079, action:  2.0000\n",
      "theta =  2.6866, omega:  0.1762, action:  2.0000\n",
      "theta =  2.6904, omega:  0.2546, action:  2.0000\n",
      "theta =  2.7002, omega:  0.3471, action:  2.0000\n",
      "theta =  2.6942, omega: -0.6994, action:  0.0000\n",
      "theta =  2.6863, omega:  0.0307, action:  7.0000\n",
      "theta =  2.6885, omega:  0.1092, action:  2.0000\n",
      "theta =  2.6924, omega:  0.1933, action:  2.0000\n",
      "theta =  2.6971, omega:  0.2871, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7494, action:  0.0000\n",
      "theta =  2.6840, omega:  0.0420, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1119, action:  2.0000\n",
      "theta =  2.6895, omega:  0.1874, action:  2.0000\n",
      "theta =  2.6952, omega:  0.2739, action:  2.0000\n",
      "theta =  2.7032, omega:  0.3766, action:  2.0000\n",
      "theta =  2.6978, omega: -0.6624, action:  0.0000\n",
      "theta =  2.6928, omega:  0.0790, action:  7.0000\n",
      "theta =  2.6972, omega:  0.1745, action:  2.0000\n",
      "theta =  2.7018, omega:  0.2803, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7462, action:  0.0000\n",
      "theta =  2.6908, omega:  0.0544, action:  7.0000\n",
      "theta =  2.6917, omega:  0.1364, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2225, action:  2.0000\n",
      "theta =  2.7008, omega:  0.3274, action:  2.0000\n",
      "theta =  2.6967, omega: -0.7111, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0821, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1664, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2579, action:  2.0000\n",
      "theta =  2.7056, omega:  0.3689, action:  2.0000\n",
      "theta =  2.7009, omega: -0.6650, action:  0.0000\n",
      "theta =  2.6949, omega:  0.0786, action:  7.0000\n",
      "theta =  2.6994, omega:  0.1788, action:  2.0000\n",
      "theta =  2.7033, omega:  0.2858, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7364, action:  0.0000\n",
      "theta =  2.6887, omega:  0.0802, action:  7.0000\n",
      "theta =  2.6931, omega:  0.1664, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2635, action:  2.0000\n",
      "theta =  2.6912, omega: -0.7726, action:  0.0000\n",
      "theta =  2.6846, omega:  0.0261, action:  7.0000\n",
      "theta =  2.6848, omega:  0.0913, action:  2.0000\n",
      "theta =  2.6878, omega:  0.1614, action:  2.0000\n",
      "theta =  2.6927, omega:  0.2426, action:  2.0000\n",
      "theta =  2.6999, omega:  0.3362, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7098, action:  0.0000\n",
      "theta =  2.6874, omega:  0.0777, action:  7.0000\n",
      "theta =  2.6903, omega:  0.1590, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2450, action:  2.0000\n",
      "theta =  2.7021, omega:  0.3463, action:  2.0000\n",
      "theta =  2.6974, omega: -0.6909, action:  0.0000\n",
      "theta =  2.6910, omega:  0.0435, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1324, action:  2.0000\n",
      "theta =  2.6957, omega:  0.2282, action:  2.0000\n",
      "theta =  2.7045, omega:  0.3371, action:  2.0000\n",
      "theta =  2.6996, omega: -0.6944, action:  0.0000\n",
      "theta =  2.6938, omega:  0.0469, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1386, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2393, action:  2.0000\n",
      "theta =  2.7061, omega:  0.3519, action:  2.0000\n",
      "theta =  2.7014, omega: -0.6773, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0725, action:  7.0000\n",
      "theta =  2.6971, omega:  0.1740, action:  2.0000\n",
      "theta =  2.7047, omega:  0.2871, action:  2.0000\n",
      "theta =  2.6981, omega: -0.7382, action:  0.0000\n",
      "theta =  2.6903, omega:  0.0922, action:  7.0000\n",
      "theta =  2.6955, omega:  0.1791, action:  2.0000\n",
      "theta =  2.6995, omega:  0.2762, action:  2.0000\n",
      "theta =  2.6936, omega: -0.7555, action:  0.0000\n",
      "theta =  2.6835, omega:  0.0394, action:  7.0000\n",
      "theta =  2.6867, omega:  0.1118, action:  2.0000\n",
      "theta =  2.6912, omega:  0.1897, action:  2.0000\n",
      "theta =  2.6983, omega:  0.2787, action:  2.0000\n",
      "theta =  2.6882, omega: -0.7634, action:  0.0000\n",
      "theta =  2.6811, omega:  0.0537, action:  7.0000\n",
      "theta =  2.6856, omega:  0.1160, action:  2.0000\n",
      "theta =  2.6857, omega:  0.1806, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2607, action:  2.0000\n",
      "theta =  2.6997, omega:  0.3552, action:  2.0000\n",
      "theta =  2.6939, omega: -0.6878, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0395, action:  7.0000\n",
      "theta =  2.6886, omega:  0.1208, action:  2.0000\n",
      "theta =  2.6933, omega:  0.2099, action:  2.0000\n",
      "theta =  2.7020, omega:  0.3099, action:  2.0000\n",
      "theta =  2.6968, omega: -0.7263, action:  0.0000\n",
      "theta =  2.6889, omega:  0.0733, action:  7.0000\n",
      "theta =  2.6897, omega:  0.1530, action:  2.0000\n",
      "theta =  2.6951, omega:  0.2405, action:  2.0000\n",
      "theta =  2.7027, omega:  0.3424, action:  2.0000\n",
      "theta =  2.6947, omega: -0.6940, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0423, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1306, action:  2.0000\n",
      "theta =  2.6964, omega:  0.2239, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3320, action:  2.0000\n",
      "theta =  2.6977, omega: -0.6996, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0391, action:  7.0000\n",
      "theta =  2.6920, omega:  0.1310, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2289, action:  2.0000\n",
      "theta =  2.7063, omega:  0.3387, action:  2.0000\n",
      "theta =  2.6990, omega: -0.6927, action:  0.0000\n",
      "theta =  2.6927, omega:  0.0539, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1485, action:  2.0000\n",
      "theta =  2.7023, omega:  0.2515, action:  2.0000\n",
      "theta =  2.6949, omega: -0.7758, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0294, action:  7.0000\n",
      "theta =  2.6867, omega:  0.0992, action:  2.0000\n",
      "theta =  2.6886, omega:  0.1782, action:  2.0000\n",
      "theta =  2.6953, omega:  0.2655, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3672, action:  2.0000\n",
      "theta =  2.7188, omega:  0.9593, action:  3.0000\n",
      "theta =  2.7286, omega: -0.1252, action:  0.0000\n",
      "theta =  2.7304, omega:  0.1492, action:  2.0000\n",
      "theta =  2.7210, omega: -0.7729, action:  0.0000\n",
      "theta =  2.7127, omega:  0.0950, action:  7.0000\n",
      "theta =  2.7170, omega:  0.2539, action:  2.0000\n",
      "theta =  2.7111, omega: -0.7243, action:  0.0000\n",
      "theta =  2.7043, omega:  0.0555, action:  7.0000\n",
      "theta =  2.7097, omega:  0.1857, action:  2.0000\n",
      "theta =  2.7009, omega: -0.8070, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0278, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1170, action:  2.0000\n",
      "theta =  2.6969, omega:  0.2105, action:  2.0000\n",
      "theta =  2.7038, omega:  0.3145, action:  2.0000\n",
      "theta =  2.6985, omega: -0.7126, action:  0.0000\n",
      "theta =  2.6884, omega:  0.0841, action:  7.0000\n",
      "theta =  2.6986, omega:  0.6390, action:  8.0000\n",
      "theta =  2.7009, omega: -0.4557, action:  0.0000\n",
      "theta =  2.6993, omega:  0.2429, action:  7.0000\n",
      "theta =  2.7063, omega:  0.3582, action:  2.0000\n",
      "theta =  2.7017, omega: -0.6693, action:  0.0000\n",
      "theta =  2.6923, omega: -0.2504, action:  2.0000\n",
      "theta =  2.6882, omega:  0.0306, action:  2.0000\n",
      "theta =  2.6902, omega:  0.1154, action:  2.0000\n",
      "theta =  2.6945, omega:  0.2013, action:  2.0000\n",
      "theta =  2.7015, omega:  0.3052, action:  2.0000\n",
      "theta =  2.6947, omega: -0.7309, action:  0.0000\n",
      "theta =  2.6863, omega:  0.0874, action:  7.0000\n",
      "theta =  2.6898, omega:  0.1644, action:  2.0000\n",
      "theta =  2.6955, omega:  0.2529, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3581, action:  2.0000\n",
      "theta =  2.6989, omega: -0.6779, action:  0.0000\n",
      "theta =  2.6907, omega:  0.0590, action:  7.0000\n",
      "theta =  2.6946, omega:  0.1544, action:  2.0000\n",
      "theta =  2.7009, omega:  0.2548, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7726, action:  0.0000\n",
      "theta =  2.6823, omega:  0.0300, action:  7.0000\n",
      "theta =  2.6874, omega:  0.0996, action:  2.0000\n",
      "theta =  2.6881, omega:  0.1747, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2606, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3580, action:  2.0000\n",
      "theta =  2.6961, omega: -0.6795, action:  0.0000\n",
      "theta =  2.6904, omega:  0.0571, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1468, action:  2.0000\n",
      "theta =  2.6974, omega:  0.2444, action:  2.0000\n",
      "theta =  2.7051, omega:  0.3536, action:  2.0000\n",
      "theta =  2.7014, omega: -0.6752, action:  0.0000\n",
      "theta =  2.6958, omega:  0.0707, action:  7.0000\n",
      "theta =  2.6988, omega:  0.1718, action:  2.0000\n",
      "theta =  2.7030, omega:  0.2801, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7443, action:  0.0000\n",
      "theta =  2.6892, omega:  0.0756, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1616, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2545, action:  2.0000\n",
      "theta =  2.7046, omega:  0.3627, action:  2.0000\n",
      "theta =  2.6997, omega: -0.6726, action:  0.0000\n",
      "theta =  2.6954, omega:  0.0733, action:  7.0000\n",
      "theta =  2.6952, omega:  0.1711, action:  2.0000\n",
      "theta =  2.7028, omega:  0.2804, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7460, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0575, action:  7.0000\n",
      "theta =  2.6907, omega:  0.1403, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2300, action:  2.0000\n",
      "theta =  2.7013, omega:  0.3342, action:  2.0000\n",
      "theta =  2.6958, omega: -0.6987, action:  0.0000\n",
      "theta =  2.6924, omega:  0.0354, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1250, action:  2.0000\n",
      "theta =  2.6968, omega:  0.2179, action:  2.0000\n",
      "theta =  2.7039, omega:  0.3231, action:  2.0000\n",
      "theta =  2.7001, omega: -0.7053, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0324, action:  7.0000\n",
      "theta =  2.6911, omega:  0.1223, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2143, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3202, action:  2.0000\n",
      "theta =  2.6979, omega: -0.7091, action:  0.0000\n",
      "theta =  2.6932, omega:  0.1092, action:  7.0000\n",
      "theta =  2.6940, omega:  0.1984, action:  2.0000\n",
      "theta =  2.7001, omega:  0.2993, action:  2.0000\n",
      "theta =  2.6950, omega: -0.7327, action:  0.0000\n",
      "theta =  2.6890, omega:  0.0850, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1663, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2546, action:  2.0000\n",
      "theta =  2.7026, omega:  0.3574, action:  2.0000\n",
      "theta =  2.6984, omega: -0.6780, action:  0.0000\n",
      "theta =  2.6930, omega:  0.0622, action:  7.0000\n",
      "theta =  2.6969, omega:  0.1549, action:  2.0000\n",
      "theta =  2.7011, omega:  0.2566, action:  2.0000\n",
      "theta =  2.6929, omega: -0.7718, action:  0.0000\n",
      "theta =  2.6845, omega:  0.0479, action:  7.0000\n",
      "theta =  2.6873, omega:  0.1205, action:  2.0000\n",
      "theta =  2.6902, omega:  0.1968, action:  2.0000\n",
      "theta =  2.6981, omega:  0.2868, action:  2.0000\n",
      "theta =  2.6918, omega: -0.7580, action:  0.0000\n",
      "theta =  2.6842, omega:  0.0607, action:  7.0000\n",
      "theta =  2.6844, omega:  0.1217, action:  2.0000\n",
      "theta =  2.6866, omega:  0.1935, action:  2.0000\n",
      "theta =  2.6922, omega:  0.2759, action:  2.0000\n",
      "theta =  2.7018, omega:  0.3737, action:  2.0000\n",
      "theta =  2.6990, omega: -0.6689, action:  0.0000\n",
      "theta =  2.6912, omega:  0.0682, action:  7.0000\n",
      "theta =  2.6958, omega:  0.1575, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2557, action:  2.0000\n",
      "theta =  2.7061, omega:  0.3699, action:  2.0000\n",
      "theta =  2.7040, omega: -0.6589, action:  0.0000\n",
      "theta =  2.6978, omega:  0.0916, action:  7.0000\n",
      "theta =  2.7011, omega:  0.1977, action:  2.0000\n",
      "theta =  2.7072, omega:  0.3150, action:  2.0000\n",
      "theta =  2.7003, omega: -0.7054, action:  0.0000\n",
      "theta =  2.6947, omega:  0.0414, action:  7.0000\n",
      "theta =  2.6991, omega:  0.1402, action:  2.0000\n",
      "theta =  2.7063, omega:  0.7120, action:  6.0000\n",
      "theta =  2.7088, omega: -0.3761, action:  0.0000\n",
      "theta =  2.7111, omega:  0.3274, action:  7.0000\n",
      "theta =  2.7062, omega: -0.6869, action:  0.0000\n",
      "theta =  2.6974, omega:  0.0750, action:  7.0000\n",
      "theta =  2.7017, omega:  0.1846, action:  2.0000\n",
      "theta =  2.7081, omega:  0.3064, action:  2.0000\n",
      "theta =  2.7020, omega: -0.7086, action:  0.0000\n",
      "theta =  2.6957, omega:  0.0389, action:  7.0000\n",
      "theta =  2.6992, omega:  0.1417, action:  2.0000\n",
      "theta =  2.7016, omega:  0.2502, action:  2.0000\n",
      "theta =  2.6964, omega: -0.7703, action:  0.0000\n",
      "theta =  2.6862, omega:  0.0540, action:  7.0000\n",
      "theta =  2.6907, omega:  0.1315, action:  2.0000\n",
      "theta =  2.6930, omega:  0.2175, action:  2.0000\n",
      "theta =  2.6999, omega:  0.3098, action:  2.0000\n",
      "theta =  2.6933, omega: -0.7272, action:  0.0000\n",
      "theta =  2.6849, omega:  0.0828, action:  7.0000\n",
      "theta =  2.6912, omega:  0.1614, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2481, action:  2.0000\n",
      "theta =  2.7030, omega:  0.3469, action:  2.0000\n",
      "theta =  2.6974, omega: -0.6890, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0470, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1335, action:  2.0000\n",
      "theta =  2.6973, omega:  0.2263, action:  2.0000\n",
      "theta =  2.7043, omega:  0.3353, action:  2.0000\n",
      "theta =  2.6994, omega: -0.6940, action:  0.0000\n",
      "theta =  2.6940, omega:  0.0448, action:  7.0000\n",
      "theta =  2.6952, omega:  0.1372, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2364, action:  2.0000\n",
      "theta =  2.7063, omega:  0.3479, action:  2.0000\n",
      "theta =  2.7016, omega: -0.6797, action:  0.0000\n",
      "theta =  2.6953, omega:  0.0706, action:  7.0000\n",
      "theta =  2.6982, omega:  0.1706, action:  2.0000\n",
      "theta =  2.7013, omega:  0.2804, action:  2.0000\n",
      "theta =  2.6970, omega: -0.7424, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0750, action:  7.0000\n",
      "theta =  2.6884, omega:  0.1610, action:  2.0000\n",
      "theta =  2.6989, omega:  0.2544, action:  2.0000\n",
      "theta =  2.7055, omega:  0.3656, action:  2.0000\n",
      "theta =  2.7000, omega: -0.6679, action:  0.0000\n",
      "theta =  2.6947, omega:  0.0792, action:  7.0000\n",
      "theta =  2.6983, omega:  0.1788, action:  2.0000\n",
      "theta =  2.7036, omega:  0.2882, action:  2.0000\n",
      "theta =  2.6971, omega: -0.7360, action:  0.0000\n",
      "theta =  2.6906, omega:  0.0884, action:  7.0000\n",
      "theta =  2.6930, omega:  0.1747, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2701, action:  2.0000\n",
      "theta =  2.6922, omega: -0.7650, action:  0.0000\n",
      "theta =  2.6838, omega:  0.0513, action:  7.0000\n",
      "theta =  2.6855, omega:  0.1210, action:  2.0000\n",
      "theta =  2.6921, omega:  0.1971, action:  2.0000\n",
      "theta =  2.6970, omega:  0.2827, action:  2.0000\n",
      "theta =  2.6895, omega: -0.7632, action:  0.0000\n",
      "theta =  2.6814, omega:  0.0493, action:  7.0000\n",
      "theta =  2.6838, omega:  0.1095, action:  2.0000\n",
      "theta =  2.6853, omega:  0.1734, action:  2.0000\n",
      "theta =  2.6917, omega:  0.2514, action:  2.0000\n",
      "theta =  2.6985, omega:  0.3441, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7038, action:  0.0000\n",
      "theta =  2.6885, omega:  0.0816, action:  7.0000\n",
      "theta =  2.6891, omega:  0.1602, action:  2.0000\n",
      "theta =  2.6958, omega:  0.2481, action:  2.0000\n",
      "theta =  2.7084, omega:  0.8176, action:  5.0000\n",
      "theta =  2.7137, omega: -0.2868, action:  0.0000\n",
      "theta =  2.7120, omega:  0.0552, action:  2.0000\n",
      "theta =  2.7158, omega:  0.2085, action:  2.0000\n",
      "theta =  2.7082, omega: -0.7701, action:  0.0000\n",
      "theta =  2.6989, omega:  0.0660, action:  7.0000\n",
      "theta =  2.7026, omega:  0.1814, action:  2.0000\n",
      "theta =  2.7099, omega:  0.3067, action:  2.0000\n",
      "theta =  2.7038, omega: -0.7071, action:  0.0000\n",
      "theta =  2.6953, omega:  0.0451, action:  7.0000\n",
      "theta =  2.6999, omega:  0.1486, action:  2.0000\n",
      "theta =  2.7031, omega:  0.2610, action:  2.0000\n",
      "theta =  2.6974, omega: -0.7578, action:  0.0000\n",
      "theta =  2.6888, omega:  0.0470, action:  7.0000\n",
      "theta =  2.6913, omega:  0.1305, action:  2.0000\n",
      "theta =  2.6944, omega:  0.2208, action:  2.0000\n",
      "theta =  2.7016, omega:  0.3245, action:  2.0000\n",
      "theta =  2.6961, omega: -0.7119, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0844, action:  7.0000\n",
      "theta =  2.6926, omega:  0.1675, action:  2.0000\n",
      "theta =  2.6987, omega:  0.2632, action:  2.0000\n",
      "theta =  2.6909, omega: -0.7735, action:  0.0000\n",
      "theta =  2.6830, omega:  0.0261, action:  7.0000\n",
      "theta =  2.6844, omega:  0.0917, action:  2.0000\n",
      "theta =  2.6861, omega:  0.1613, action:  2.0000\n",
      "theta =  2.6937, omega:  0.2411, action:  2.0000\n",
      "theta =  2.7005, omega:  0.3347, action:  2.0000\n",
      "theta =  2.6925, omega: -0.7091, action:  0.0000\n",
      "theta =  2.6852, omega:  0.0776, action:  7.0000\n",
      "theta =  2.6903, omega:  0.1561, action:  2.0000\n",
      "theta =  2.6937, omega:  0.2434, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3432, action:  2.0000\n",
      "theta =  2.6976, omega: -0.6937, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0405, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1269, action:  2.0000\n",
      "theta =  2.6951, omega:  0.2207, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3288, action:  2.0000\n",
      "theta =  2.6987, omega: -0.7025, action:  0.0000\n",
      "theta =  2.6918, omega:  0.0341, action:  7.0000\n",
      "theta =  2.6908, omega:  0.1222, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2184, action:  2.0000\n",
      "theta =  2.7029, omega:  0.3259, action:  2.0000\n",
      "theta =  2.6988, omega: -0.7047, action:  0.0000\n",
      "theta =  2.6902, omega:  0.0336, action:  7.0000\n",
      "theta =  2.6941, omega:  0.1242, action:  2.0000\n",
      "theta =  2.6963, omega:  0.2219, action:  2.0000\n",
      "theta =  2.7024, omega:  0.3287, action:  2.0000\n",
      "theta =  2.7004, omega: -0.6997, action:  0.0000\n",
      "theta =  2.6923, omega:  0.0435, action:  7.0000\n",
      "theta =  2.6948, omega:  0.1322, action:  2.0000\n",
      "theta =  2.7004, omega:  0.2336, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3440, action:  2.0000\n",
      "theta =  2.7009, omega: -0.6841, action:  0.0000\n",
      "theta =  2.6950, omega:  0.0622, action:  7.0000\n",
      "theta =  2.6978, omega:  0.1615, action:  2.0000\n",
      "theta =  2.7027, omega:  0.2697, action:  2.0000\n",
      "theta =  2.6954, omega: -0.7545, action:  0.0000\n",
      "theta =  2.6861, omega:  0.0478, action:  7.0000\n",
      "theta =  2.6893, omega:  0.1262, action:  2.0000\n",
      "theta =  2.6944, omega:  0.2131, action:  2.0000\n",
      "theta =  2.6998, omega:  0.3120, action:  2.0000\n",
      "theta =  2.6963, omega: -0.7243, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0659, action:  7.0000\n",
      "theta =  2.6904, omega:  0.1461, action:  2.0000\n",
      "theta =  2.6956, omega:  0.2334, action:  2.0000\n",
      "theta =  2.7011, omega:  0.3355, action:  2.0000\n",
      "theta =  2.6970, omega: -0.7010, action:  0.0000\n",
      "theta =  2.6895, omega:  0.0313, action:  7.0000\n",
      "theta =  2.6915, omega:  0.1167, action:  2.0000\n",
      "theta =  2.6960, omega:  0.2079, action:  2.0000\n",
      "theta =  2.7019, omega:  0.3094, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7247, action:  0.0000\n",
      "theta =  2.6876, omega:  0.0686, action:  7.0000\n",
      "theta =  2.6917, omega:  0.1511, action:  2.0000\n",
      "theta =  2.6950, omega:  0.2422, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3465, action:  2.0000\n",
      "theta =  2.6991, omega: -0.6890, action:  0.0000\n",
      "theta =  2.6935, omega:  0.0518, action:  7.0000\n",
      "theta =  2.6951, omega:  0.1438, action:  2.0000\n",
      "theta =  2.7006, omega:  0.2426, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7867, action:  0.0000\n",
      "theta =  2.6817, omega:  0.0393, action:  7.0000\n",
      "theta =  2.6846, omega:  0.1051, action:  2.0000\n",
      "theta =  2.6873, omega:  0.1771, action:  2.0000\n",
      "theta =  2.6949, omega:  0.2579, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3546, action:  2.0000\n",
      "theta =  2.6961, omega: -0.6888, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0439, action:  7.0000\n",
      "theta =  2.6907, omega:  0.1288, action:  2.0000\n",
      "theta =  2.6962, omega:  0.2181, action:  2.0000\n",
      "theta =  2.7017, omega:  0.3227, action:  2.0000\n",
      "theta =  2.6960, omega: -0.7134, action:  0.0000\n",
      "theta =  2.6891, omega:  0.0814, action:  7.0000\n",
      "theta =  2.6922, omega:  0.1654, action:  2.0000\n",
      "theta =  2.6972, omega:  0.2622, action:  2.0000\n",
      "theta =  2.7061, omega:  0.3728, action:  2.0000\n",
      "theta =  2.7011, omega: -0.6575, action:  0.0000\n",
      "theta =  2.6958, omega:  0.0882, action:  7.0000\n",
      "theta =  2.7009, omega:  0.1921, action:  2.0000\n",
      "theta =  2.7048, omega:  0.3063, action:  2.0000\n",
      "theta =  2.6999, omega: -0.7166, action:  0.0000\n",
      "theta =  2.6911, omega:  0.0883, action:  7.0000\n",
      "theta =  2.6968, omega:  0.1814, action:  2.0000\n",
      "theta =  2.7032, omega:  0.2859, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7438, action:  0.0000\n",
      "theta =  2.6886, omega:  0.0585, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1384, action:  2.0000\n",
      "theta =  2.6948, omega:  0.2242, action:  2.0000\n",
      "theta =  2.7016, omega:  0.3240, action:  2.0000\n",
      "theta =  2.6964, omega: -0.7119, action:  0.0000\n",
      "theta =  2.6898, omega:  0.0801, action:  7.0000\n",
      "theta =  2.6927, omega:  0.1666, action:  2.0000\n",
      "theta =  2.6988, omega:  0.2582, action:  2.0000\n",
      "theta =  2.6909, omega: -0.7791, action:  0.0000\n",
      "theta =  2.6814, omega:  0.0277, action:  7.0000\n",
      "theta =  2.6810, omega:  0.0934, action:  2.0000\n",
      "theta =  2.6868, omega:  0.1576, action:  2.0000\n",
      "theta =  2.6910, omega:  0.2362, action:  2.0000\n",
      "theta =  2.6971, omega:  0.3258, action:  2.0000\n",
      "theta =  2.6928, omega: -0.7200, action:  0.0000\n",
      "theta =  2.6863, omega:  0.0662, action:  7.0000\n",
      "theta =  2.6894, omega:  0.1406, action:  2.0000\n",
      "theta =  2.6928, omega:  0.2230, action:  2.0000\n",
      "theta =  2.6995, omega:  0.3168, action:  2.0000\n",
      "theta =  2.6932, omega: -0.7227, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0841, action:  7.0000\n",
      "theta =  2.6815, omega: -0.4959, action:  1.0000\n",
      "theta =  2.6783, omega:  0.2109, action:  7.0000\n",
      "theta =  2.6841, omega:  0.2644, action:  2.0000\n",
      "theta =  2.6913, omega:  0.3337, action:  2.0000\n",
      "theta =  2.7010, omega:  0.4241, action:  2.0000\n",
      "theta =  2.6959, omega: -0.6299, action:  0.0000\n",
      "theta =  2.6934, omega:  0.1446, action:  7.0000\n",
      "theta =  2.6982, omega:  0.2406, action:  2.0000\n",
      "theta =  2.7042, omega:  0.3459, action:  2.0000\n",
      "theta =  2.7015, omega: -0.6846, action:  0.0000\n",
      "theta =  2.6932, omega:  0.0579, action:  7.0000\n",
      "theta =  2.6947, omega:  0.1538, action:  2.0000\n",
      "theta =  2.6992, omega:  0.2557, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7689, action:  0.0000\n",
      "theta =  2.6854, omega:  0.0513, action:  7.0000\n",
      "theta =  2.6864, omega:  0.1252, action:  2.0000\n",
      "theta =  2.6905, omega:  0.2051, action:  2.0000\n",
      "theta =  2.6976, omega:  0.2937, action:  2.0000\n",
      "theta =  2.6925, omega: -0.7462, action:  0.0000\n",
      "theta =  2.6837, omega:  0.0432, action:  7.0000\n",
      "theta =  2.6862, omega:  0.1144, action:  2.0000\n",
      "theta =  2.6887, omega:  0.1880, action:  2.0000\n",
      "theta =  2.6947, omega:  0.2737, action:  2.0000\n",
      "theta =  2.7047, omega:  0.3730, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6652, action:  0.0000\n",
      "theta =  2.6924, omega:  0.0719, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1674, action:  2.0000\n",
      "theta =  2.7005, omega:  0.2697, action:  2.0000\n",
      "theta =  2.6944, omega: -0.7571, action:  0.0000\n",
      "theta =  2.6883, omega:  0.0410, action:  7.0000\n",
      "theta =  2.6875, omega:  0.1149, action:  2.0000\n",
      "theta =  2.6918, omega:  0.1968, action:  2.0000\n",
      "theta =  2.6984, omega:  0.2893, action:  2.0000\n",
      "theta =  2.6913, omega: -0.7502, action:  0.0000\n",
      "theta =  2.6810, omega:  0.0396, action:  7.0000\n",
      "theta =  2.6861, omega:  0.1080, action:  2.0000\n",
      "theta =  2.6897, omega:  0.1819, action:  2.0000\n",
      "theta =  2.6942, omega:  0.2654, action:  2.0000\n",
      "theta =  2.7004, omega:  0.3662, action:  2.0000\n",
      "theta =  2.6970, omega: -0.6746, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0624, action:  7.0000\n",
      "theta =  2.6939, omega:  0.1522, action:  2.0000\n",
      "theta =  2.6996, omega:  0.2499, action:  2.0000\n",
      "theta =  2.7090, omega:  0.3638, action:  2.0000\n",
      "theta =  2.7035, omega: -0.6648, action:  0.0000\n",
      "theta =  2.6938, omega:  0.0850, action:  7.0000\n",
      "theta =  2.6995, omega:  0.1898, action:  2.0000\n",
      "theta =  2.7049, omega:  0.3050, action:  2.0000\n",
      "theta =  2.7003, omega: -0.7158, action:  0.0000\n",
      "theta =  2.6925, omega:  0.0884, action:  7.0000\n",
      "theta =  2.6975, omega:  0.1829, action:  2.0000\n",
      "theta =  2.7023, omega:  0.2862, action:  2.0000\n",
      "theta =  2.6955, omega: -0.7376, action:  0.0000\n",
      "theta =  2.6875, omega:  0.0757, action:  7.0000\n",
      "theta =  2.6914, omega:  0.1577, action:  2.0000\n",
      "theta =  2.6982, omega:  0.2488, action:  2.0000\n",
      "theta =  2.7031, omega:  0.3538, action:  2.0000\n",
      "theta =  2.6995, omega: -0.6808, action:  0.0000\n",
      "theta =  2.6931, omega:  0.0595, action:  7.0000\n",
      "theta =  2.6971, omega:  0.1541, action:  2.0000\n",
      "theta =  2.6997, omega:  0.2545, action:  2.0000\n",
      "theta =  2.6936, omega: -0.7735, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0291, action:  7.0000\n",
      "theta =  2.6870, omega:  0.0994, action:  2.0000\n",
      "theta =  2.6898, omega:  0.1726, action:  2.0000\n",
      "theta =  2.6951, omega:  0.2603, action:  2.0000\n",
      "theta =  2.7036, omega:  0.3622, action:  2.0000\n",
      "theta =  2.6981, omega: -0.6767, action:  0.0000\n",
      "theta =  2.6911, omega:  0.0587, action:  7.0000\n",
      "theta =  2.6938, omega:  0.1504, action:  2.0000\n",
      "theta =  2.6994, omega:  0.2476, action:  2.0000\n",
      "theta =  2.7078, omega:  0.3629, action:  2.0000\n",
      "theta =  2.7023, omega: -0.6677, action:  0.0000\n",
      "theta =  2.6965, omega:  0.0821, action:  7.0000\n",
      "theta =  2.6992, omega:  0.1853, action:  2.0000\n",
      "theta =  2.7066, omega:  0.2983, action:  2.0000\n",
      "theta =  2.6993, omega: -0.7212, action:  0.0000\n",
      "theta =  2.6923, omega:  0.0792, action:  7.0000\n",
      "theta =  2.6960, omega:  0.1709, action:  2.0000\n",
      "theta =  2.7021, omega:  0.2726, action:  2.0000\n",
      "theta =  2.6935, omega: -0.7549, action:  0.0000\n",
      "theta =  2.6867, omega:  0.0430, action:  7.0000\n",
      "theta =  2.6873, omega:  0.1182, action:  2.0000\n",
      "theta =  2.6919, omega:  0.1969, action:  2.0000\n",
      "theta =  2.7031, omega:  0.7571, action:  7.0000\n",
      "theta =  2.7064, omega: -0.3490, action:  0.0000\n",
      "theta =  2.7058, omega:  0.0271, action:  2.0000\n",
      "theta =  2.7060, omega:  0.1578, action:  2.0000\n",
      "theta =  2.7130, omega:  0.2920, action:  2.0000\n",
      "theta =  2.7067, omega: -0.7086, action:  0.0000\n",
      "theta =  2.6996, omega:  0.0544, action:  7.0000\n",
      "theta =  2.7031, omega:  0.1703, action:  2.0000\n",
      "theta =  2.7084, omega:  0.2914, action:  2.0000\n",
      "theta =  2.7042, omega: -0.7218, action:  0.0000\n",
      "theta =  2.6947, omega:  0.0892, action:  7.0000\n",
      "theta =  2.6998, omega:  0.1903, action:  2.0000\n",
      "theta =  2.7025, omega:  0.3022, action:  2.0000\n",
      "theta =  2.6990, omega: -0.7221, action:  0.0000\n",
      "theta =  2.6920, omega:  0.0781, action:  7.0000\n",
      "theta =  2.6953, omega:  0.1699, action:  2.0000\n",
      "theta =  2.7002, omega:  0.2721, action:  2.0000\n",
      "theta =  2.6927, omega: -0.7590, action:  0.0000\n",
      "theta =  2.6869, omega:  0.0664, action:  7.0000\n",
      "theta =  2.6873, omega:  0.1371, action:  2.0000\n",
      "theta =  2.6941, omega:  0.2181, action:  2.0000\n",
      "theta =  2.6974, omega:  0.3119, action:  2.0000\n",
      "theta =  2.6938, omega: -0.7291, action:  0.0000\n",
      "theta =  2.6860, omega:  0.0825, action:  7.0000\n",
      "theta =  2.6890, omega:  0.1570, action:  2.0000\n",
      "theta =  2.6924, omega:  0.2378, action:  2.0000\n",
      "theta =  2.7000, omega:  0.3356, action:  2.0000\n",
      "theta =  2.6956, omega: -0.7052, action:  0.0000\n",
      "theta =  2.6887, omega:  0.0859, action:  7.0000\n",
      "theta =  2.6929, omega:  0.1670, action:  2.0000\n",
      "theta =  2.6975, omega:  0.2593, action:  2.0000\n",
      "theta =  2.7037, omega:  0.3645, action:  2.0000\n",
      "theta =  2.6990, omega: -0.6697, action:  0.0000\n",
      "theta =  2.6935, omega:  0.0753, action:  7.0000\n",
      "theta =  2.6974, omega:  0.1730, action:  2.0000\n",
      "theta =  2.7023, omega:  0.2789, action:  2.0000\n",
      "theta =  2.6957, omega: -0.7439, action:  0.0000\n",
      "theta =  2.6882, omega:  0.0549, action:  7.0000\n",
      "theta =  2.6925, omega:  0.1371, action:  2.0000\n",
      "theta =  2.6940, omega:  0.2255, action:  2.0000\n",
      "theta =  2.7017, omega:  0.3296, action:  2.0000\n",
      "theta =  2.6964, omega: -0.7075, action:  0.0000\n",
      "theta =  2.6906, omega:  0.1016, action:  7.0000\n",
      "theta =  2.6932, omega:  0.1891, action:  2.0000\n",
      "theta =  2.6986, omega:  0.2874, action:  2.0000\n",
      "theta =  2.6943, omega: -0.7476, action:  0.0000\n",
      "theta =  2.6840, omega:  0.0467, action:  7.0000\n",
      "theta =  2.6885, omega:  0.1187, action:  2.0000\n",
      "theta =  2.6907, omega:  0.1987, action:  2.0000\n",
      "theta =  2.6985, omega:  0.2874, action:  2.0000\n",
      "theta =  2.6890, omega: -0.7517, action:  0.0000\n",
      "theta =  2.6645, omega: -1.2994, action:  1.0000\n"
     ]
    }
   ],
   "source": [
    "env = DQN_UnbalancedDisk(randomize_friction=False)\n",
    "# best trial 11\n",
    "# Trial 11 finished with value: 1425.5780135999998 and parameters: {'learning_rate': 0.002910910188933282, 'gamma': 0.9629183426032542, 'batch_size': 256, 'n_actions': 10, 'net_arch_style': 'medium', 'activation_fn': 'relu'}\n",
    "model = DQN.load('optuna_dqn2_trials/optuna_best_model_trial_6/best_model.zip')\n",
    "obs, _ = env.reset()\n",
    "for i in range(5000):\n",
    "    action, _states = model.predict(obs)  # policy\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    t = (obs[0] + np.pi)%(2*np.pi) - np.pi\n",
    "    print( f'theta = {t: .4f}, omega: {obs[1]: .4f}, action: {action: .4f}')\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a9e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -2.08e+03 |\n",
      "|    exploration_rate | 0.981     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 244       |\n",
      "|    time_elapsed     | 8         |\n",
      "|    total_timesteps  | 2000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00691   |\n",
      "|    n_updates        | 474       |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -2.04e+03 |\n",
      "|    exploration_rate | 0.962     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 284       |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 4000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00942   |\n",
      "|    n_updates        | 974       |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-526.94 +/- 6.99\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -527     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00639  |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -2.02e+03 |\n",
      "|    exploration_rate | 0.943     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 255       |\n",
      "|    time_elapsed     | 23        |\n",
      "|    total_timesteps  | 6000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00615   |\n",
      "|    n_updates        | 1474      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.99e+03 |\n",
      "|    exploration_rate | 0.924     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 266       |\n",
      "|    time_elapsed     | 30        |\n",
      "|    total_timesteps  | 8000      |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.00424   |\n",
      "|    n_updates        | 1974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-565.89 +/- 3.62\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -566     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.94e+03 |\n",
      "|    exploration_rate | 0.905     |\n",
      "| time/               |           |\n",
      "|    episodes         | 20        |\n",
      "|    fps              | 257       |\n",
      "|    time_elapsed     | 38        |\n",
      "|    total_timesteps  | 10000     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -1.9e+03 |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 270      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.85e+03 |\n",
      "|    exploration_rate | 0.867     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 281       |\n",
      "|    time_elapsed     | 49        |\n",
      "|    total_timesteps  | 14000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0236    |\n",
      "|    n_updates        | 3474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-81.07 +/- 16.91\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -81.1    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 3724     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.84e+03 |\n",
      "|    exploration_rate | 0.848     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 274       |\n",
      "|    time_elapsed     | 58        |\n",
      "|    total_timesteps  | 16000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0131    |\n",
      "|    n_updates        | 3974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.81e+03 |\n",
      "|    exploration_rate | 0.829     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 284       |\n",
      "|    time_elapsed     | 63        |\n",
      "|    total_timesteps  | 18000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0218    |\n",
      "|    n_updates        | 4474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-7.76 +/- 143.90\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -7.76    |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 4974     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.79e+03 |\n",
      "|    exploration_rate | 0.81      |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 278       |\n",
      "|    time_elapsed     | 71        |\n",
      "|    total_timesteps  | 20000     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.76e+03 |\n",
      "|    exploration_rate | 0.791     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 286       |\n",
      "|    time_elapsed     | 76        |\n",
      "|    total_timesteps  | 22000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0203    |\n",
      "|    n_updates        | 5474      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.73e+03 |\n",
      "|    exploration_rate | 0.772     |\n",
      "| time/               |           |\n",
      "|    episodes         | 48        |\n",
      "|    fps              | 293       |\n",
      "|    time_elapsed     | 81        |\n",
      "|    total_timesteps  | 24000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0273    |\n",
      "|    n_updates        | 5974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=-263.38 +/- 37.13\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -263     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 6224     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.69e+03 |\n",
      "|    exploration_rate | 0.753     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 288       |\n",
      "|    time_elapsed     | 90        |\n",
      "|    total_timesteps  | 26000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0243    |\n",
      "|    n_updates        | 6474      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.66e+03 |\n",
      "|    exploration_rate | 0.734     |\n",
      "| time/               |           |\n",
      "|    episodes         | 56        |\n",
      "|    fps              | 295       |\n",
      "|    time_elapsed     | 94        |\n",
      "|    total_timesteps  | 28000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0248    |\n",
      "|    n_updates        | 6974      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-509.66 +/- 4.87\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -510     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 7474     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.63e+03 |\n",
      "|    exploration_rate | 0.715     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 290       |\n",
      "|    time_elapsed     | 103       |\n",
      "|    total_timesteps  | 30000     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.59e+03 |\n",
      "|    exploration_rate | 0.696     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 295       |\n",
      "|    time_elapsed     | 108       |\n",
      "|    total_timesteps  | 32000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.054     |\n",
      "|    n_updates        | 7974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.56e+03 |\n",
      "|    exploration_rate | 0.677     |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 300       |\n",
      "|    time_elapsed     | 113       |\n",
      "|    total_timesteps  | 34000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0213    |\n",
      "|    n_updates        | 8474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-434.71 +/- 9.48\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -435     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 8724     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.53e+03 |\n",
      "|    exploration_rate | 0.658     |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 294       |\n",
      "|    time_elapsed     | 122       |\n",
      "|    total_timesteps  | 36000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0509    |\n",
      "|    n_updates        | 8974      |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.51e+03 |\n",
      "|    exploration_rate | 0.639     |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 298       |\n",
      "|    time_elapsed     | 127       |\n",
      "|    total_timesteps  | 38000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0389    |\n",
      "|    n_updates        | 9474      |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-208.81 +/- 8.86\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -209     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0658   |\n",
      "|    n_updates        | 9974     |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.47e+03 |\n",
      "|    exploration_rate | 0.62      |\n",
      "| time/               |           |\n",
      "|    episodes         | 80        |\n",
      "|    fps              | 293       |\n",
      "|    time_elapsed     | 136       |\n",
      "|    total_timesteps  | 40000     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.45e+03 |\n",
      "|    exploration_rate | 0.601     |\n",
      "| time/               |           |\n",
      "|    episodes         | 84        |\n",
      "|    fps              | 295       |\n",
      "|    time_elapsed     | 142       |\n",
      "|    total_timesteps  | 42000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0335    |\n",
      "|    n_updates        | 10474     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.42e+03 |\n",
      "|    exploration_rate | 0.582     |\n",
      "| time/               |           |\n",
      "|    episodes         | 88        |\n",
      "|    fps              | 298       |\n",
      "|    time_elapsed     | 147       |\n",
      "|    total_timesteps  | 44000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0331    |\n",
      "|    n_updates        | 10974     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-468.18 +/- 7.85\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -468     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 11224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -1.4e+03 |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 46000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 11474    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.38e+03 |\n",
      "|    exploration_rate | 0.544     |\n",
      "| time/               |           |\n",
      "|    episodes         | 96        |\n",
      "|    fps              | 298       |\n",
      "|    time_elapsed     | 160       |\n",
      "|    total_timesteps  | 48000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.062     |\n",
      "|    n_updates        | 11974     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-186.71 +/- 12.67\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -187     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00684  |\n",
      "|    n_updates        | 12474    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.35e+03 |\n",
      "|    exploration_rate | 0.525     |\n",
      "| time/               |           |\n",
      "|    episodes         | 100       |\n",
      "|    fps              | 294       |\n",
      "|    time_elapsed     | 169       |\n",
      "|    total_timesteps  | 50000     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -1.3e+03 |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 296      |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 52000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 12974    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.26e+03 |\n",
      "|    exploration_rate | 0.487     |\n",
      "| time/               |           |\n",
      "|    episodes         | 108       |\n",
      "|    fps              | 297       |\n",
      "|    time_elapsed     | 181       |\n",
      "|    total_timesteps  | 54000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0173    |\n",
      "|    n_updates        | 13474     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-518.94 +/- 1.29\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -519     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0374   |\n",
      "|    n_updates        | 13724    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.21e+03 |\n",
      "|    exploration_rate | 0.468     |\n",
      "| time/               |           |\n",
      "|    episodes         | 112       |\n",
      "|    fps              | 292       |\n",
      "|    time_elapsed     | 191       |\n",
      "|    total_timesteps  | 56000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0221    |\n",
      "|    n_updates        | 13974     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.17e+03 |\n",
      "|    exploration_rate | 0.449     |\n",
      "| time/               |           |\n",
      "|    episodes         | 116       |\n",
      "|    fps              | 293       |\n",
      "|    time_elapsed     | 197       |\n",
      "|    total_timesteps  | 58000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.172     |\n",
      "|    n_updates        | 14474     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-530.22 +/- 2.62\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -530     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 14974    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.13e+03 |\n",
      "|    exploration_rate | 0.43      |\n",
      "| time/               |           |\n",
      "|    episodes         | 120       |\n",
      "|    fps              | 291       |\n",
      "|    time_elapsed     | 206       |\n",
      "|    total_timesteps  | 60000     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.09e+03 |\n",
      "|    exploration_rate | 0.411     |\n",
      "| time/               |           |\n",
      "|    episodes         | 124       |\n",
      "|    fps              | 293       |\n",
      "|    time_elapsed     | 211       |\n",
      "|    total_timesteps  | 62000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0312    |\n",
      "|    n_updates        | 15474     |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.06e+03 |\n",
      "|    exploration_rate | 0.392     |\n",
      "| time/               |           |\n",
      "|    episodes         | 128       |\n",
      "|    fps              | 295       |\n",
      "|    time_elapsed     | 216       |\n",
      "|    total_timesteps  | 64000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.024     |\n",
      "|    n_updates        | 15974     |\n",
      "-----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-267.38 +/- 34.17\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -267     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 16224    |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 500       |\n",
      "|    ep_rew_mean      | -1.02e+03 |\n",
      "|    exploration_rate | 0.373     |\n",
      "| time/               |           |\n",
      "|    episodes         | 132       |\n",
      "|    fps              | 293       |\n",
      "|    time_elapsed     | 225       |\n",
      "|    total_timesteps  | 66000     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.001     |\n",
      "|    loss             | 0.0165    |\n",
      "|    n_updates        | 16474     |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -987     |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 68000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 16974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-513.22 +/- 7.01\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -513     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 17474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -950     |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 70000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -918     |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 72000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 17974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -892     |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 74000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 18474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=-519.87 +/- 3.01\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -520     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 18724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -868     |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 76000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 18974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -844     |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 294      |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 78000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 19474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-418.96 +/- 45.29\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -419     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 19974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -825     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 80000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -807     |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 294      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 82000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 20474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -791     |\n",
      "|    exploration_rate | 0.202    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 295      |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 84000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 20974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-523.50 +/- 4.91\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -524     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.193    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0322   |\n",
      "|    n_updates        | 21224    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -771     |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 86000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 21474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -752     |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 294      |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 88000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0421   |\n",
      "|    n_updates        | 21974    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-521.73 +/- 5.53\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -522     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 22474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -743     |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 90000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -725     |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 92000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0297   |\n",
      "|    n_updates        | 22974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -709     |\n",
      "|    exploration_rate | 0.107    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 294      |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 94000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0286   |\n",
      "|    n_updates        | 23474    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-346.83 +/- 68.05\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -347     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0975   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 95000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 23724    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -694     |\n",
      "|    exploration_rate | 0.088    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 292      |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 96000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 23974    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 500      |\n",
      "|    ep_rew_mean      | -680     |\n",
      "|    exploration_rate | 0.069    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 293      |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 98000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 24474    |\n",
      "----------------------------------\n",
      "Stopping training with a total of 100000 steps because the DQN model reached max_episodes=200, by playing for 200 episodes \n",
      "Eval num_timesteps=100000, episode_reward=-493.13 +/- 3.33\n",
      "Episode length: 500.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 500      |\n",
      "|    mean_reward      | -493     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 24974    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x2b5e5c9fcd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnMaxEpisodes\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "policy_kwargs = dict(activation_fn=nn.GELU,\n",
    "                     net_arch=[128, 256, 128])\n",
    "\n",
    "actions = [10,20, 50]\n",
    "\n",
    "# Create and wrap your env\n",
    "env = DQN_UnbalancedDisk(umax=3.0, dt=0.025, n_actions=20)\n",
    "env = TimeLimit(env, max_episode_steps=500)\n",
    "env = Monitor(env)\n",
    "\n",
    "eval_env = DQN_UnbalancedDisk(umax=3.0, dt=0.025, n_actions=20)\n",
    "eval_env = TimeLimit(eval_env, max_episode_steps=500)\n",
    "eval_env = Monitor(eval_env)\n",
    "\n",
    "# Instantiate and train DQN\n",
    "stop_cb = StopTrainingOnMaxEpisodes(max_episodes=200, verbose=1)\n",
    "\n",
    "# Save best model based on mean reward\n",
    "eval_cb = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./best_dqn_model\",\n",
    "    log_path=\"./logs\",\n",
    "    eval_freq=5000,\n",
    "    deterministic=True,\n",
    "    render=False\n",
    ")\n",
    "\n",
    "# Chain both callbacks\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "callback = CallbackList([stop_cb, eval_cb])\n",
    "\n",
    "# Model\n",
    "model_dqn = DQN(\n",
    "    policy='MlpPolicy',\n",
    "    env=env,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=1,\n",
    "    policy_kwargs=policy_kwargs\n",
    ")\n",
    "\n",
    "# Train\n",
    "model_dqn.learn(\n",
    "    total_timesteps=1_000_000,\n",
    "    callback=callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f83d9782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  0.0235, omega:  1.9021\n",
      "theta =  0.0920, omega:  3.5932\n",
      "theta =  0.2013, omega:  4.9465\n",
      "theta =  0.3363, omega:  5.8763\n",
      "theta =  0.4932, omega:  6.3420\n",
      "theta =  0.6502, omega:  6.3529\n",
      "theta =  0.8045, omega:  5.9685\n",
      "theta =  0.9447, omega:  5.2712\n",
      "theta =  1.0663, omega:  4.3506\n",
      "theta =  1.1402, omega:  1.4606\n",
      "theta =  1.1418, omega: -1.2047\n",
      "theta =  1.0816, omega: -3.6230\n",
      "theta =  0.9665, omega: -5.3699\n",
      "theta =  0.8310, omega: -5.4438\n",
      "theta =  0.6982, omega: -5.2263\n",
      "theta =  0.5719, omega: -4.7044\n",
      "theta =  0.4664, omega: -3.8872\n",
      "theta =  0.3575, omega: -4.6456\n",
      "theta =  0.2370, omega: -5.0423\n",
      "theta =  0.1103, omega: -5.0387\n",
      "theta = -0.0121, omega: -4.6408\n",
      "theta = -0.1194, omega: -3.8952\n",
      "theta = -0.1817, omega: -1.0493\n",
      "theta = -0.1726, omega:  1.5729\n",
      "theta = -0.1044, omega:  3.9022\n",
      "theta =  0.0163, omega:  5.8521\n",
      "theta =  0.1598, omega:  5.4583\n",
      "theta =  0.3102, omega:  6.4755\n",
      "theta =  0.4778, omega:  6.9765\n",
      "theta =  0.6546, omega:  6.9776\n",
      "theta =  0.8241, omega:  6.5447\n",
      "theta =  0.9807, omega:  5.7747\n",
      "theta =  1.1125, omega:  4.7749\n",
      "theta =  1.1953, omega:  1.8046\n",
      "theta =  1.2014, omega: -0.9644\n",
      "theta =  1.1475, omega: -3.4759\n",
      "theta =  1.0362, omega: -5.3295\n",
      "theta =  0.9004, omega: -5.5353\n",
      "theta =  0.7616, omega: -5.4606\n",
      "theta =  0.6301, omega: -5.0801\n",
      "theta =  0.4878, omega: -6.2157\n",
      "theta =  0.3237, omega: -6.8785\n",
      "theta =  0.1483, omega: -7.0108\n",
      "theta = -0.0229, omega: -6.5929\n",
      "theta = -0.1780, omega: -5.6720\n",
      "theta = -0.3050, omega: -4.3453\n",
      "theta = -0.3689, omega: -0.9146\n",
      "theta = -0.3508, omega:  2.2365\n",
      "theta = -0.2589, omega:  5.0565\n",
      "theta = -0.1272, omega:  5.5814\n",
      "theta =  0.0148, omega:  5.6536\n",
      "theta =  0.1521, omega:  5.2800\n",
      "theta =  0.2994, omega:  6.3315\n",
      "theta =  0.4647, omega:  6.8733\n",
      "theta =  0.6365, omega:  6.9187\n",
      "theta =  0.8082, omega:  6.5257\n",
      "theta =  0.9655, omega:  5.7895\n",
      "theta =  1.0946, omega:  4.8146\n",
      "theta =  1.1764, omega:  1.8617\n",
      "theta =  1.1896, omega: -0.8969\n",
      "theta =  1.1352, omega: -3.3933\n",
      "theta =  1.0292, omega: -5.2384\n",
      "theta =  0.8929, omega: -5.4297\n",
      "theta =  0.7585, omega: -5.3474\n",
      "theta =  0.6288, omega: -4.9650\n",
      "theta =  0.4876, omega: -6.1025\n",
      "theta =  0.3278, omega: -6.7784\n",
      "theta =  0.1524, omega: -6.9298\n",
      "theta = -0.0160, omega: -6.5390\n",
      "theta = -0.1697, omega: -5.6497\n",
      "theta = -0.2945, omega: -4.3520\n",
      "theta = -0.3600, omega: -0.9481\n",
      "theta = -0.3430, omega:  2.1830\n",
      "theta = -0.2536, omega:  4.9845\n",
      "theta = -0.1219, omega:  5.4927\n",
      "theta =  0.0186, omega:  5.5573\n",
      "theta =  0.1529, omega:  5.1861\n",
      "theta =  0.2973, omega:  6.2459\n",
      "theta =  0.4608, omega:  6.8015\n",
      "theta =  0.6316, omega:  6.8640\n",
      "theta =  0.8020, omega:  6.4906\n",
      "theta =  0.9523, omega:  5.7696\n",
      "theta =  1.0862, omega:  4.8087\n",
      "theta =  1.1699, omega:  1.8704\n",
      "theta =  1.1817, omega: -0.8812\n",
      "theta =  1.1295, omega: -3.3709\n",
      "theta =  1.0221, omega: -5.2041\n",
      "theta =  0.8862, omega: -5.3836\n",
      "theta =  0.7535, omega: -5.2924\n",
      "theta =  0.6266, omega: -4.9012\n",
      "theta =  0.4886, omega: -6.0341\n",
      "theta =  0.3272, omega: -6.7118\n",
      "theta =  0.1549, omega: -6.8688\n",
      "theta = -0.0120, omega: -6.4844\n",
      "theta = -0.1625, omega: -5.6121\n",
      "theta = -0.2871, omega: -4.3273\n",
      "theta = -0.3552, omega: -0.9404\n",
      "theta = -0.3378, omega:  2.1703\n",
      "theta = -0.2477, omega:  4.9592\n",
      "theta = -0.1174, omega:  5.4555\n",
      "theta =  0.0185, omega:  5.5110\n",
      "theta =  0.1550, omega:  5.1315\n",
      "theta =  0.2961, omega:  6.1891\n",
      "theta =  0.4602, omega:  6.7491\n",
      "theta =  0.6295, omega:  6.8172\n",
      "theta =  0.7972, omega:  6.4512\n",
      "theta =  0.9514, omega:  5.7390\n",
      "theta =  1.0798, omega:  4.7878\n",
      "theta =  1.1654, omega:  1.8548\n",
      "theta =  1.1760, omega: -0.8873\n",
      "theta =  1.1223, omega: -3.3681\n",
      "theta =  1.0136, omega: -5.1940\n",
      "theta =  0.8827, omega: -5.3675\n",
      "theta =  0.7464, omega: -5.2641\n",
      "theta =  0.6229, omega: -4.8635\n",
      "theta =  0.5071, omega: -4.1674\n",
      "theta =  0.3937, omega: -5.0293\n",
      "theta =  0.2608, omega: -5.4982\n",
      "theta =  0.1202, omega: -5.5363\n",
      "theta = -0.0113, omega: -5.1407\n",
      "theta = -0.1347, omega: -4.3564\n",
      "theta = -0.2297, omega: -3.2571\n",
      "theta = -0.2704, omega: -0.1250\n",
      "theta = -0.2624, omega:  0.8208\n",
      "theta = -0.2070, omega:  3.4736\n",
      "theta = -0.1078, omega:  4.4032\n",
      "theta =  0.0039, omega:  4.5053\n",
      "theta =  0.1129, omega:  4.2510\n",
      "theta =  0.2343, omega:  5.4946\n",
      "theta =  0.3835, omega:  6.2777\n",
      "theta =  0.5463, omega:  6.5808\n",
      "theta =  0.7111, omega:  6.4340\n",
      "theta =  0.8658, omega:  5.9077\n",
      "theta =  1.0030, omega:  5.0964\n",
      "theta =  1.1167, omega:  4.0938\n",
      "theta =  1.1840, omega:  1.1473\n",
      "theta =  1.1781, omega: -1.5314\n",
      "theta =  1.1079, omega: -3.9848\n",
      "theta =  1.0053, omega: -4.3798\n",
      "theta =  0.8909, omega: -4.5783\n",
      "theta =  0.7760, omega: -4.5429\n",
      "theta =  0.6654, omega: -4.2575\n",
      "theta =  0.5430, omega: -5.5377\n",
      "theta =  0.3946, omega: -6.4057\n",
      "theta =  0.2253, omega: -6.7795\n",
      "theta =  0.0566, omega: -6.6252\n",
      "theta = -0.0998, omega: -5.9532\n",
      "theta = -0.2375, omega: -4.8436\n",
      "theta = -0.3409, omega: -3.3998\n",
      "theta = -0.3802, omega:  0.0656\n",
      "theta = -0.3402, omega:  3.1232\n",
      "theta = -0.2273, omega:  5.8494\n",
      "theta = -0.0791, omega:  6.2188\n",
      "theta =  0.0801, omega:  6.0886\n",
      "theta =  0.2484, omega:  7.3090\n",
      "theta =  0.4411, omega:  7.9334\n",
      "theta =  0.6386, omega:  7.9776\n",
      "theta =  0.8347, omega:  7.5168\n",
      "theta =  1.0118, omega:  6.6751\n",
      "theta =  1.1654, omega:  5.5802\n",
      "theta =  1.2902, omega:  4.3429\n",
      "theta =  1.3595, omega:  1.2125\n",
      "theta =  1.3547, omega: -1.6279\n",
      "theta =  1.2806, omega: -4.2578\n",
      "theta =  1.1654, omega: -4.8690\n",
      "theta =  1.0379, omega: -5.2996\n",
      "theta =  0.8982, omega: -5.5094\n",
      "theta =  0.7656, omega: -5.4396\n",
      "theta =  0.6317, omega: -5.0652\n",
      "theta =  0.4903, omega: -6.2070\n",
      "theta =  0.3261, omega: -6.8801\n",
      "theta =  0.1506, omega: -7.0191\n",
      "theta = -0.0216, omega: -6.6124\n",
      "theta = -0.1746, omega: -5.6987\n",
      "theta = -0.3015, omega: -4.3775\n",
      "theta = -0.3677, omega: -0.9459\n",
      "theta = -0.3511, omega:  2.2069\n",
      "theta = -0.2605, omega:  5.0314\n",
      "theta = -0.1283, omega:  5.5585\n",
      "theta =  0.0120, omega:  5.6383\n",
      "theta =  0.1488, omega:  5.2752\n",
      "theta =  0.2964, omega:  6.3302\n",
      "theta =  0.4622, omega:  6.8802\n",
      "theta =  0.6364, omega:  6.9313\n",
      "theta =  0.8038, omega:  6.5406\n",
      "theta =  0.9608, omega:  5.8076\n",
      "theta =  1.0924, omega:  4.8354\n",
      "theta =  1.1775, omega:  1.8828\n",
      "theta =  1.1905, omega: -0.8784\n",
      "theta =  1.1355, omega: -3.3779\n",
      "theta =  1.0280, omega: -5.2248\n",
      "theta =  0.8952, omega: -5.4163\n",
      "theta =  0.7589, omega: -5.3378\n",
      "theta =  0.6286, omega: -4.9606\n",
      "theta =  0.4910, omega: -6.1022\n",
      "theta =  0.3298, omega: -6.7873\n",
      "theta =  0.1551, omega: -6.9411\n",
      "theta = -0.0152, omega: -6.5538\n",
      "theta = -0.1684, omega: -5.6690\n",
      "theta = -0.2944, omega: -4.3703\n",
      "theta = -0.3601, omega: -0.9659\n",
      "theta = -0.3428, omega:  2.1669\n",
      "theta = -0.2546, omega:  4.9710\n",
      "theta = -0.1225, omega:  5.4840\n",
      "theta =  0.0153, omega:  5.5549\n",
      "theta =  0.1505, omega:  5.1862\n",
      "theta =  0.2945, omega:  6.2485\n",
      "theta =  0.4614, omega:  6.8082\n",
      "theta =  0.6319, omega:  6.8720\n",
      "theta =  0.8002, omega:  6.5019\n",
      "theta =  0.9532, omega:  5.7825\n",
      "theta =  1.0862, omega:  4.8229\n",
      "theta =  1.1703, omega:  1.8816\n",
      "theta =  1.1818, omega: -0.8703\n",
      "theta =  1.1277, omega: -3.3597\n",
      "theta =  1.0217, omega: -5.1957\n",
      "theta =  0.8862, omega: -5.3800\n",
      "theta =  0.7369, omega: -6.6623\n",
      "theta =  0.5774, omega: -6.1410\n",
      "theta =  0.4106, omega: -7.0628\n",
      "theta =  0.2258, omega: -7.4431\n",
      "theta =  0.0427, omega: -7.2429\n",
      "theta = -0.1287, omega: -6.4800\n",
      "theta = -0.2761, omega: -5.2419\n",
      "theta = -0.3895, omega: -3.6466\n",
      "theta = -0.4333, omega: -0.0159\n",
      "theta = -0.3966, omega:  3.2025\n",
      "theta = -0.2774, omega:  6.0822\n",
      "theta = -0.1183, omega:  6.5877\n",
      "theta =  0.0472, omega:  6.5632\n",
      "theta =  0.2285, omega:  7.8450\n",
      "theta =  0.4346, omega:  8.4875\n",
      "theta =  0.6471, omega:  8.5069\n",
      "theta =  0.8547, omega:  7.9971\n",
      "theta =  1.0447, omega:  7.0858\n",
      "theta =  1.2061, omega:  5.9248\n",
      "theta =  1.3406, omega:  4.6347\n",
      "theta =  1.4401, omega:  3.2982\n",
      "theta =  1.4809, omega:  0.1275\n",
      "theta =  1.4492, omega: -2.6527\n",
      "theta =  1.3491, omega: -5.3049\n",
      "theta =  1.2105, omega: -5.9321\n",
      "theta =  1.0558, omega: -6.3738\n",
      "theta =  0.8936, omega: -6.5524\n",
      "theta =  0.7294, omega: -6.4005\n",
      "theta =  0.5538, omega: -7.7074\n",
      "theta =  0.3514, omega: -8.4543\n",
      "theta =  0.1341, omega: -8.5524\n",
      "theta = -0.0731, omega: -7.9868\n",
      "theta = -0.2611, omega: -6.8150\n",
      "theta = -0.4113, omega: -5.1653\n",
      "theta = -0.4896, omega: -1.3729\n",
      "theta = -0.4803, omega:  2.1771\n",
      "theta = -0.3848, omega:  5.3778\n",
      "theta = -0.2395, omega:  6.2553\n",
      "theta = -0.0757, omega:  6.6270\n",
      "theta =  0.0890, omega:  6.4704\n",
      "theta =  0.2672, omega:  7.6355\n",
      "theta =  0.4656, omega:  8.1869\n",
      "theta =  0.6716, omega:  8.1478\n",
      "theta =  0.8676, omega:  7.6058\n",
      "theta =  1.0451, omega:  6.6964\n",
      "theta =  1.2026, omega:  5.5501\n",
      "theta =  1.3227, omega:  4.2818\n",
      "theta =  1.3920, omega:  1.1276\n",
      "theta =  1.3832, omega: -1.7211\n",
      "theta =  1.3069, omega: -4.3707\n",
      "theta =  1.1887, omega: -5.0012\n",
      "theta =  1.0578, omega: -5.4621\n",
      "theta =  0.9164, omega: -5.6946\n",
      "theta =  0.7748, omega: -5.6489\n",
      "theta =  0.6382, omega: -5.2900\n",
      "theta =  0.4910, omega: -6.4321\n",
      "theta =  0.3208, omega: -7.0896\n",
      "theta =  0.1408, omega: -7.1985\n",
      "theta = -0.0334, omega: -6.7431\n",
      "theta = -0.1926, omega: -5.7782\n",
      "theta = -0.3197, omega: -4.3986\n",
      "theta = -0.3853, omega: -0.9122\n",
      "theta = -0.3673, omega:  2.2860\n",
      "theta = -0.2746, omega:  5.1551\n",
      "theta = -0.1374, omega:  5.7159\n",
      "theta =  0.0065, omega:  5.8184\n",
      "theta =  0.1498, omega:  5.4583\n",
      "theta =  0.2987, omega:  6.5092\n",
      "theta =  0.4714, omega:  7.0380\n",
      "theta =  0.6470, omega:  7.0602\n",
      "theta =  0.8170, omega:  6.6359\n",
      "theta =  0.9769, omega:  5.8716\n",
      "theta =  1.1099, omega:  4.8717\n",
      "theta =  1.1961, omega:  1.8973\n",
      "theta =  1.2064, omega: -0.8865\n",
      "theta =  1.1515, omega: -3.4052\n",
      "theta =  1.0435, omega: -5.2736\n",
      "theta =  0.9086, omega: -5.4943\n",
      "theta =  0.7721, omega: -5.4420\n",
      "theta =  0.6390, omega: -5.0855\n",
      "theta =  0.4946, omega: -6.2427\n",
      "theta =  0.3319, omega: -6.9327\n",
      "theta =  0.1571, omega: -7.0859\n",
      "theta = -0.0179, omega: -6.6842\n",
      "theta = -0.1746, omega: -5.7738\n",
      "theta = -0.3042, omega: -4.4462\n",
      "theta = -0.3718, omega: -1.0058\n",
      "theta = -0.3585, omega:  2.1631\n",
      "theta = -0.2653, omega:  5.0038\n",
      "theta = -0.1334, omega:  5.5509\n",
      "theta =  0.0091, omega:  5.6486\n",
      "theta =  0.1454, omega:  5.2997\n",
      "theta =  0.2924, omega:  6.3738\n",
      "theta =  0.4615, omega:  6.9322\n",
      "theta =  0.6355, omega:  6.9877\n",
      "theta =  0.8060, omega:  6.5994\n",
      "theta =  0.9635, omega:  5.8643\n",
      "theta =  1.0954, omega:  4.8850\n",
      "theta =  1.1797, omega:  1.9277\n",
      "theta =  1.1933, omega: -0.8435\n",
      "theta =  1.1403, omega: -3.3491\n",
      "theta =  1.0331, omega: -5.2027\n",
      "theta =  0.9027, omega: -5.4111\n",
      "theta =  0.7660, omega: -5.3449\n",
      "theta =  0.6364, omega: -4.9829\n",
      "theta =  0.4980, omega: -6.1394\n",
      "theta =  0.3332, omega: -6.8301\n",
      "theta =  0.1603, omega: -6.9977\n",
      "theta = -0.0109, omega: -6.6166\n",
      "theta = -0.1685, omega: -5.7281\n",
      "theta = -0.2950, omega: -4.4254\n",
      "theta = -0.3651, omega: -1.0143\n",
      "theta = -0.3489, omega:  2.1318\n",
      "theta = -0.2595, omega:  4.9530\n",
      "theta = -0.1302, omega:  5.4801\n",
      "theta =  0.0346, omega:  7.3866\n",
      "theta =  0.2352, omega:  8.6511\n",
      "theta =  0.4611, omega:  9.2196\n",
      "theta =  0.6921, omega:  9.1235\n",
      "theta =  0.9108, omega:  8.4773\n",
      "theta =  1.1118, omega:  7.4439\n",
      "theta =  1.2824, omega:  6.1820\n",
      "theta =  1.4218, omega:  4.8203\n",
      "theta =  1.5248, omega:  3.4425\n",
      "theta =  1.5933, omega:  2.0962\n",
      "theta =  1.6263, omega:  0.7940\n",
      "theta =  1.6336, omega: -0.3042\n",
      "theta =  1.6172, omega: -1.2247\n",
      "theta =  1.5729, omega: -2.1223\n",
      "theta =  1.4863, omega: -4.8300\n",
      "theta =  1.3549, omega: -5.5730\n",
      "theta =  1.2073, omega: -6.1954\n",
      "theta =  1.0465, omega: -6.6216\n",
      "theta =  0.8796, omega: -6.7707\n",
      "theta =  0.7123, omega: -6.5795\n",
      "theta =  0.5317, omega: -7.8268\n",
      "theta =  0.3245, omega: -8.5006\n",
      "theta =  0.1102, omega: -8.5251\n",
      "theta = -0.0935, omega: -7.8828\n",
      "theta = -0.2783, omega: -6.6506\n",
      "theta = -0.4239, omega: -4.9515\n",
      "theta = -0.5008, omega: -1.1324\n",
      "theta = -0.4845, omega:  2.4126\n",
      "theta = -0.3841, omega:  5.6041\n",
      "theta = -0.2308, omega:  6.4574\n",
      "theta = -0.0646, omega:  6.7922\n",
      "theta =  0.1040, omega:  6.5849\n",
      "theta =  0.2841, omega:  7.6904\n",
      "theta =  0.4825, omega:  8.1842\n",
      "theta =  0.6890, omega:  8.0946\n",
      "theta =  0.8846, omega:  7.5177\n",
      "theta =  1.0607, omega:  6.5829\n",
      "theta =  1.2133, omega:  5.4243\n",
      "theta =  1.3313, omega:  4.1529\n",
      "theta =  1.4196, omega:  2.8397\n",
      "theta =  1.4507, omega: -0.2865\n",
      "theta =  1.4087, omega: -3.0315\n",
      "theta =  1.2972, omega: -5.6434\n",
      "theta =  1.1509, omega: -6.2060\n",
      "theta =  0.9917, omega: -6.5525\n",
      "theta =  0.8269, omega: -6.6037\n",
      "theta =  0.6642, omega: -6.3026\n",
      "theta =  0.4920, omega: -7.4446\n",
      "theta =  0.2969, omega: -8.0347\n",
      "theta =  0.0957, omega: -8.0033\n",
      "theta = -0.0983, omega: -7.3513\n",
      "theta = -0.2686, omega: -6.1436\n",
      "theta = -0.4020, omega: -4.5125\n",
      "theta = -0.4662, omega: -0.7846\n",
      "theta = -0.4431, omega:  2.6272\n",
      "theta = -0.3397, omega:  5.6948\n",
      "theta = -0.1860, omega:  6.4145\n",
      "theta = -0.0237, omega:  6.6169\n",
      "theta =  0.1385, omega:  6.2963\n",
      "theta =  0.3116, omega:  7.3188\n",
      "theta =  0.4998, omega:  7.7602\n",
      "theta =  0.6952, omega:  7.6541\n",
      "theta =  0.8792, omega:  7.0909\n",
      "theta =  1.0443, omega:  6.1916\n",
      "theta =  1.1875, omega:  5.0713\n",
      "theta =  1.2736, omega:  2.0006\n",
      "theta =  1.2865, omega: -0.8687\n",
      "theta =  1.2336, omega: -3.4759\n",
      "theta =  1.1220, omega: -5.4448\n",
      "theta =  0.9802, omega: -5.7856\n",
      "theta =  0.8347, omega: -5.8606\n",
      "theta =  0.6878, omega: -5.6240\n",
      "theta =  0.5329, omega: -6.8790\n",
      "theta =  0.3501, omega: -7.6266\n",
      "theta =  0.1561, omega: -7.7870\n",
      "theta = -0.0341, omega: -7.3426\n",
      "theta = -0.2060, omega: -6.3358\n",
      "theta = -0.3459, omega: -4.8752\n",
      "theta = -0.4233, omega: -1.2826\n",
      "theta = -0.4136, omega:  2.0715\n",
      "theta = -0.3222, omega:  5.0852\n",
      "theta = -0.1855, omega:  5.7975\n",
      "theta = -0.0362, omega:  6.0384\n",
      "theta =  0.1138, omega:  5.8032\n",
      "theta =  0.2742, omega:  6.9403\n",
      "theta =  0.4551, omega:  7.5174\n",
      "theta =  0.6432, omega:  7.5508\n",
      "theta =  0.8283, omega:  7.1047\n",
      "theta =  0.9954, omega:  6.2981\n",
      "theta =  1.1409, omega:  5.2451\n",
      "theta =  1.2346, omega:  2.2167\n",
      "theta =  1.2543, omega: -0.6366\n",
      "theta =  1.2051, omega: -3.2197\n",
      "theta =  1.0987, omega: -5.1650\n",
      "theta =  0.9659, omega: -5.4832\n",
      "theta =  0.8274, omega: -5.5471\n",
      "theta =  0.6921, omega: -5.3122\n",
      "theta =  0.5399, omega: -6.5880\n",
      "theta =  0.3654, omega: -7.3757\n",
      "theta =  0.1765, omega: -7.6021\n",
      "theta = -0.0088, omega: -7.2309\n",
      "theta = -0.1796, omega: -6.3063\n",
      "theta = -0.3215, omega: -4.9270\n",
      "theta = -0.4008, omega: -1.4013\n",
      "theta = -0.3938, omega:  1.9009\n",
      "theta = -0.3074, omega:  4.8707\n",
      "theta = -0.1741, omega:  5.5544\n",
      "theta = -0.0331, omega:  5.7858\n",
      "theta =  0.1090, omega:  5.5592\n",
      "theta =  0.2621, omega:  6.7245\n",
      "theta =  0.4401, omega:  7.3471\n",
      "theta =  0.6272, omega:  7.4252\n",
      "theta =  0.8072, omega:  7.0298\n",
      "theta =  0.9744, omega:  6.2668\n",
      "theta =  1.1185, omega:  5.2468\n",
      "theta =  1.2113, omega:  2.2423\n",
      "theta =  1.2328, omega: -0.5869\n",
      "theta =  1.1852, omega: -3.1498\n",
      "theta =  1.0799, omega: -5.0728\n",
      "theta =  0.9504, omega: -5.3681\n",
      "theta =  0.8154, omega: -5.4084\n",
      "theta =  0.6808, omega: -5.1582\n",
      "theta =  0.5361, omega: -6.4239\n",
      "theta =  0.3662, omega: -7.2144\n",
      "theta =  0.1828, omega: -7.4516\n",
      "theta = -0.0026, omega: -7.1039\n",
      "theta = -0.1685, omega: -6.2161\n",
      "theta = -0.3080, omega: -4.8718\n",
      "theta = -0.3880, omega: -1.3880\n",
      "theta = -0.3777, omega:  1.8768\n",
      "theta = -0.2963, omega:  4.8095\n",
      "theta = -0.1650, omega:  5.4591\n",
      "theta = -0.0272, omega:  5.6678\n",
      "theta =  0.1129, omega:  5.4270\n",
      "theta =  0.2654, omega:  6.5867\n",
      "theta =  0.4362, omega:  7.2137\n",
      "theta =  0.6198, omega:  7.3098\n",
      "theta =  0.7980, omega:  6.9368\n",
      "theta =  0.9644, omega:  6.1938\n",
      "theta =  1.1075, omega:  5.1976\n",
      "theta =  1.2002, omega:  2.2095\n",
      "theta =  1.2191, omega: -0.6058\n",
      "theta =  1.1705, omega: -3.1534\n",
      "theta =  1.0675, omega: -5.0595\n",
      "theta =  0.9389, omega: -5.3332\n",
      "theta =  0.8037, omega: -5.3478\n",
      "theta =  0.6737, omega: -5.0718\n",
      "theta =  0.5299, omega: -6.3193\n",
      "theta =  0.3622, omega: -7.0933\n",
      "theta =  0.1775, omega: -7.3245\n",
      "theta = -0.0011, omega: -6.9820\n",
      "theta = -0.1655, omega: -6.1040\n",
      "theta = -0.3012, omega: -4.7838\n",
      "theta = -0.3775, omega: -1.3237\n",
      "theta = -0.3712, omega:  1.9070\n",
      "theta = -0.2847, omega:  4.8071\n",
      "theta = -0.1566, omega:  5.4298\n",
      "theta = -0.0187, omega:  5.6076\n",
      "theta =  0.1176, omega:  5.3430\n",
      "theta =  0.2682, omega:  6.4911\n",
      "theta =  0.4408, omega:  7.1130\n",
      "theta =  0.6190, omega:  7.2079\n",
      "theta =  0.7973, omega:  6.8405\n",
      "theta =  0.9594, omega:  6.1109\n",
      "theta =  1.0980, omega:  5.1247\n",
      "theta =  1.1896, omega:  2.1509\n",
      "theta =  1.2088, omega: -0.6521\n",
      "theta =  1.1589, omega: -3.1835\n",
      "theta =  1.0551, omega: -5.0740\n",
      "theta =  0.9266, omega: -5.3261\n",
      "theta =  0.7932, omega: -5.3196\n",
      "theta =  0.6623, omega: -5.0185\n",
      "theta =  0.5205, omega: -6.2413\n",
      "theta =  0.3538, omega: -6.9969\n",
      "theta =  0.1749, omega: -7.2157\n",
      "theta = -0.0021, omega: -6.8680\n",
      "theta = -0.1620, omega: -5.9951\n",
      "theta = -0.2993, omega: -4.6856\n",
      "theta = -0.3731, omega: -1.2469\n",
      "theta = -0.3625, omega:  1.9574\n",
      "theta = -0.2772, omega:  4.8278\n",
      "theta = -0.1488, omega:  5.4205\n",
      "theta = -0.0096, omega:  5.5755\n",
      "theta =  0.1261, omega:  5.2833\n",
      "theta =  0.2729, omega:  6.4136\n",
      "theta =  0.4436, omega:  7.0233\n",
      "theta =  0.6206, omega:  7.1162\n",
      "theta =  0.7958, omega:  6.7506\n",
      "theta =  0.9553, omega:  6.0271\n",
      "theta =  1.0941, omega:  5.0522\n",
      "theta =  1.1852, omega:  2.0887\n",
      "theta =  1.1989, omega: -0.7043\n",
      "theta =  1.1502, omega: -3.2263\n",
      "theta =  1.0456, omega: -5.0981\n",
      "theta =  0.9159, omega: -5.3325\n",
      "theta =  0.7809, omega: -5.3002\n",
      "theta =  0.6536, omega: -4.9774\n",
      "theta =  0.5126, omega: -6.1804\n",
      "theta =  0.3475, omega: -6.9165\n",
      "theta =  0.1698, omega: -7.1188\n",
      "theta =  0.0190, omega: -4.9442\n",
      "theta = -0.0967, omega: -4.2764\n",
      "theta = -0.1912, omega: -3.2935\n",
      "theta = -0.2375, omega: -0.2699\n",
      "theta = -0.2093, omega:  2.4018\n",
      "theta = -0.1174, omega:  4.7795\n",
      "theta =  0.0040, omega:  4.8867\n",
      "theta =  0.1231, omega:  4.6072\n",
      "theta =  0.2536, omega:  5.8007\n",
      "theta =  0.4075, omega:  6.5150\n",
      "theta =  0.5755, omega:  6.7346\n",
      "theta =  0.7416, omega:  6.5059\n",
      "theta =  0.8968, omega:  5.9087\n",
      "theta =  1.0331, omega:  5.0379\n",
      "theta =  1.1256, omega:  2.1585\n",
      "theta =  1.1417, omega: -0.5647\n",
      "theta =  1.1001, omega: -3.0207\n",
      "theta =  0.9936, omega: -5.2845\n",
      "theta =  0.8600, omega: -5.4133\n",
      "theta =  0.7251, omega: -5.2583\n",
      "theta =  0.5993, omega: -4.8013\n",
      "theta =  0.4655, omega: -5.8735\n",
      "theta =  0.3091, omega: -6.4967\n",
      "theta =  0.1452, omega: -6.6128\n",
      "theta = -0.0164, omega: -6.2136\n",
      "theta = -0.1637, omega: -5.3399\n",
      "theta = -0.2812, omega: -4.0825\n",
      "theta = -0.3424, omega: -0.7342\n",
      "theta = -0.3214, omega:  2.3114\n",
      "theta = -0.2266, omega:  5.0329\n",
      "theta = -0.0961, omega:  5.4596\n",
      "theta =  0.0404, omega:  5.4489\n",
      "theta =  0.1736, omega:  5.0110\n",
      "theta =  0.3123, omega:  6.0202\n",
      "theta =  0.4687, omega:  6.5482\n",
      "theta =  0.6358, omega:  6.6011\n",
      "theta =  0.7963, omega:  6.2362\n",
      "theta =  0.9442, omega:  5.5364\n",
      "theta =  1.0722, omega:  4.6069\n",
      "theta =  1.1506, omega:  1.6977\n",
      "theta =  1.1562, omega: -1.0081\n",
      "theta =  1.1008, omega: -3.4628\n",
      "theta =  0.9923, omega: -5.2497\n",
      "theta =  0.8588, omega: -5.3747\n",
      "theta =  0.7249, omega: -5.2223\n",
      "theta =  0.6000, omega: -4.7666\n",
      "theta =  0.4651, omega: -5.8432\n",
      "theta =  0.3123, omega: -6.4721\n",
      "theta =  0.1474, omega: -6.5989\n",
      "theta = -0.0138, omega: -6.2086\n",
      "theta = -0.1592, omega: -5.3449\n",
      "theta = -0.2779, omega: -4.0955\n",
      "theta = -0.3397, omega: -0.7557\n",
      "theta = -0.3172, omega:  2.2856\n",
      "theta = -0.2294, omega:  5.0048\n",
      "theta = -0.0951, omega:  5.4345\n",
      "theta =  0.0418, omega:  5.4229\n",
      "theta =  0.1717, omega:  4.9835\n",
      "theta =  0.3096, omega:  5.9994\n",
      "theta =  0.4689, omega:  6.5344\n",
      "theta =  0.6320, omega:  6.5921\n",
      "theta =  0.7935, omega:  6.2330\n",
      "theta =  0.9425, omega:  5.5426\n",
      "theta =  1.0697, omega:  4.6145\n",
      "theta =  1.1484, omega:  1.7065\n",
      "theta =  1.1565, omega: -0.9961\n",
      "theta =  1.1001, omega: -3.4472\n",
      "theta =  0.9894, omega: -5.2329\n",
      "theta =  0.8576, omega: -5.3586\n",
      "theta =  0.7256, omega: -5.2051\n",
      "theta =  0.5996, omega: -4.7504\n",
      "theta =  0.4672, omega: -5.8275\n",
      "theta =  0.3111, omega: -6.4594\n",
      "theta =  0.1492, omega: -6.5901\n",
      "theta = -0.0125, omega: -6.2034\n",
      "theta = -0.1347, omega: -3.5225\n",
      "theta = -0.1882, omega: -0.6574\n",
      "theta = -0.1708, omega:  1.9192\n",
      "theta = -0.0941, omega:  4.2144\n",
      "theta =  0.0126, omega:  4.2838\n",
      "theta =  0.1182, omega:  4.0137\n",
      "theta =  0.2358, omega:  5.2617\n",
      "theta =  0.3781, omega:  6.0667\n",
      "theta =  0.5356, omega:  6.4052\n",
      "theta =  0.6941, omega:  6.2995\n",
      "theta =  0.8316, omega:  4.4474\n",
      "theta =  0.9299, omega:  3.7881\n",
      "theta =  0.9935, omega:  1.1401\n",
      "theta =  0.9907, omega: -1.2708\n",
      "theta =  0.9326, omega: -3.4520\n",
      "theta =  0.8255, omega: -4.9363\n",
      "theta =  0.7049, omega: -4.7372\n",
      "theta =  0.5925, omega: -4.2608\n",
      "theta =  0.4702, omega: -5.3498\n",
      "theta =  0.3278, omega: -6.0251\n",
      "theta =  0.1736, omega: -6.2330\n",
      "theta =  0.0220, omega: -5.9480\n",
      "theta = -0.1201, omega: -5.2103\n",
      "theta = -0.2372, omega: -4.0909\n",
      "theta = -0.2988, omega: -0.8728\n",
      "theta = -0.2854, omega:  2.0677\n",
      "theta = -0.2001, omega:  4.6957\n",
      "theta = -0.0749, omega:  5.0561\n",
      "theta =  0.0515, omega:  5.0114\n",
      "theta =  0.1710, omega:  4.5727\n",
      "theta =  0.3002, omega:  5.6145\n",
      "theta =  0.4474, omega:  6.2050\n",
      "theta =  0.6080, omega:  6.3362\n",
      "theta =  0.7604, omega:  6.0566\n",
      "theta =  0.9054, omega:  5.4418\n",
      "theta =  1.0312, omega:  4.5798\n",
      "theta =  1.1121, omega:  1.7265\n",
      "theta =  1.1196, omega: -0.9335\n",
      "theta =  1.0682, omega: -3.3383\n",
      "theta =  0.9775, omega: -3.7029\n",
      "theta =  0.8654, omega: -5.2618\n",
      "theta =  0.7332, omega: -5.1314\n",
      "theta =  0.6115, omega: -4.7045\n",
      "theta =  0.4790, omega: -5.8119\n",
      "theta =  0.3459, omega: -4.6587\n",
      "theta =  0.2249, omega: -5.0194\n",
      "theta =  0.1007, omega: -4.9847\n",
      "theta = -0.0183, omega: -4.5628\n",
      "theta = -0.1046, omega: -1.9754\n",
      "theta = -0.1207, omega:  0.5386\n",
      "theta = -0.0769, omega:  2.7751\n",
      "theta =  0.0163, omega:  4.7173\n",
      "theta =  0.1324, omega:  4.4060\n",
      "theta =  0.2567, omega:  5.5844\n",
      "theta =  0.4070, omega:  6.3004\n",
      "theta =  0.5675, omega:  6.5421\n",
      "theta =  0.7331, omega:  6.3408\n",
      "theta =  0.8805, omega:  5.7768\n",
      "theta =  1.0177, omega:  4.9393\n",
      "theta =  1.1044, omega:  2.0923\n",
      "theta =  1.1233, omega: -0.6023\n",
      "theta =  1.0996, omega: -1.1937\n",
      "theta =  1.0400, omega: -3.5542\n",
      "theta =  0.9299, omega: -5.2354\n",
      "theta =  0.7982, omega: -5.2419\n",
      "theta =  0.6701, omega: -4.9602\n",
      "theta =  0.5300, omega: -6.2076\n",
      "theta =  0.3624, omega: -6.9921\n",
      "theta =  0.1840, omega: -7.2373\n",
      "theta =  0.0064, omega: -6.9187\n",
      "theta = -0.1556, omega: -6.0669\n",
      "theta = -0.2909, omega: -4.7741\n",
      "theta = -0.3706, omega: -1.3422\n",
      "theta = -0.3632, omega:  1.8662\n",
      "theta = -0.2787, omega:  4.7451\n",
      "theta = -0.1521, omega:  5.3484\n",
      "theta = -0.0150, omega:  5.5171\n",
      "theta =  0.1190, omega:  5.2499\n",
      "theta =  0.2682, omega:  6.4012\n",
      "theta =  0.4370, omega:  7.0333\n",
      "theta =  0.6150, omega:  7.1458\n",
      "theta =  0.7889, omega:  6.7937\n",
      "theta =  0.9523, omega:  6.0805\n",
      "theta =  1.0908, omega:  5.1063\n",
      "theta =  1.1819, omega:  2.1466\n",
      "theta =  1.1993, omega: -0.6485\n",
      "theta =  1.1537, omega: -3.1686\n",
      "theta =  1.0492, omega: -5.0479\n",
      "theta =  0.9179, omega: -5.2896\n",
      "theta =  0.7853, omega: -5.2700\n",
      "theta =  0.6564, omega: -4.9572\n",
      "theta =  0.5179, omega: -6.1737\n",
      "theta =  0.3533, omega: -6.9268\n",
      "theta =  0.1773, omega: -7.1452\n",
      "theta =  0.0008, omega: -6.8065\n",
      "theta = -0.1604, omega: -5.9454\n",
      "theta = -0.2776, omega: -3.2846\n",
      "theta = -0.3161, omega: -0.0073\n",
      "theta = -0.2816, omega:  2.8689\n",
      "theta = -0.1752, omega:  5.4326\n",
      "theta = -0.0355, omega:  5.6718\n",
      "theta =  0.1024, omega:  5.4589\n",
      "theta =  0.2562, omega:  6.6492\n",
      "theta =  0.4318, omega:  7.2945\n",
      "theta =  0.6167, omega:  7.4012\n",
      "theta =  0.7977, omega:  7.0332\n",
      "theta =  0.9651, omega:  6.2877\n",
      "theta =  1.1100, omega:  5.2853\n",
      "theta =  1.2046, omega:  2.2925\n",
      "theta =  1.2467, omega:  1.1636\n",
      "theta =  1.2403, omega: -1.5826\n",
      "theta =  1.1708, omega: -4.1098\n",
      "theta =  1.0598, omega: -4.5902\n",
      "theta =  0.9438, omega: -4.8770\n",
      "theta =  0.8205, omega: -4.9286\n",
      "theta =  0.6956, omega: -4.7140\n",
      "theta =  0.5847, omega: -4.2243\n",
      "theta =  0.4642, omega: -5.2959\n",
      "theta =  0.3242, omega: -5.9607\n",
      "theta =  0.1710, omega: -6.1619\n",
      "theta =  0.0203, omega: -5.8799\n",
      "theta = -0.1170, omega: -5.1442\n",
      "theta = -0.2331, omega: -4.0328\n",
      "theta = -0.2959, omega: -0.8311\n",
      "theta = -0.2786, omega:  2.0923\n",
      "theta = -0.1921, omega:  4.7039\n",
      "theta = -0.0706, omega:  5.0448\n",
      "theta =  0.0567, omega:  4.9822\n",
      "theta =  0.1771, omega:  4.5289\n",
      "theta =  0.3033, omega:  5.5643\n",
      "theta =  0.4520, omega:  6.1477\n",
      "theta =  0.6075, omega:  6.2790\n",
      "theta =  0.7606, omega:  6.0020\n",
      "theta =  0.9042, omega:  5.3921\n",
      "theta =  1.0268, omega:  4.5387\n",
      "theta =  1.1055, omega:  1.6915\n",
      "theta =  1.1134, omega: -0.9599\n",
      "theta =  1.0596, omega: -3.3525\n",
      "theta =  0.9530, omega: -5.0802\n",
      "theta =  0.8281, omega: -5.1430\n",
      "theta =  0.7014, omega: -4.9319\n",
      "theta =  0.5823, omega: -4.4321\n",
      "theta =  0.4567, omega: -5.4816\n",
      "theta =  0.3118, omega: -6.1076\n",
      "theta =  0.1566, omega: -6.2572\n",
      "theta =  0.0035, omega: -5.9197\n",
      "theta = -0.1376, omega: -5.1291\n",
      "theta = -0.2492, omega: -3.9654\n",
      "theta = -0.3102, omega: -0.7145\n",
      "theta = -0.2886, omega:  2.2336\n",
      "theta = -0.2007, omega:  4.8685\n",
      "theta = -0.0741, omega:  5.2243\n",
      "theta =  0.0565, omega:  5.1558\n",
      "theta =  0.1823, omega:  4.6883\n",
      "theta =  0.3130, omega:  5.6938\n",
      "theta =  0.4622, omega:  6.2427\n",
      "theta =  0.6190, omega:  6.3342\n",
      "theta =  0.7763, omega:  6.0219\n",
      "theta =  0.9194, omega:  5.3802\n",
      "theta =  1.0426, omega:  4.4988\n",
      "theta =  1.1201, omega:  1.6364\n",
      "theta =  1.1480, omega:  0.6415\n",
      "theta =  1.1309, omega: -1.9292\n",
      "theta =  1.0539, omega: -4.3003\n",
      "theta =  0.9405, omega: -4.5876\n",
      "theta =  0.8265, omega: -4.6548\n",
      "theta =  0.7108, omega: -4.4709\n",
      "theta =  0.6043, omega: -4.0280\n",
      "theta =  0.4892, omega: -5.1636\n",
      "theta =  0.3477, omega: -5.9022\n",
      "theta =  0.1960, omega: -6.1808\n",
      "theta =  0.0440, omega: -5.9754\n",
      "theta = -0.0986, omega: -5.3076\n",
      "theta = -0.1954, omega: -2.4292\n",
      "theta = -0.2195, omega:  0.5066\n",
      "theta = -0.1745, omega:  3.0454\n",
      "theta = -0.0702, omega:  5.2704\n",
      "theta =  0.0630, omega:  5.1884\n",
      "theta =  0.1871, omega:  4.7017\n",
      "theta =  0.3177, omega:  5.6889\n",
      "theta =  0.4675, omega:  6.2223\n",
      "theta =  0.6253, omega:  6.3018\n",
      "theta =  0.7800, omega:  5.9797\n",
      "theta =  0.9203, omega:  5.3327\n",
      "theta =  1.0438, omega:  4.4507\n",
      "theta =  1.1185, omega:  1.5870\n",
      "theta =  1.1256, omega: -1.0684\n",
      "theta =  1.0678, omega: -3.4728\n",
      "theta =  0.9757, omega: -3.8313\n",
      "theta =  0.8724, omega: -4.4681\n",
      "theta =  0.7593, omega: -4.3956\n",
      "theta =  0.6547, omega: -4.0804\n",
      "theta =  0.5364, omega: -5.3458\n",
      "theta =  0.3897, omega: -6.2060\n",
      "theta =  0.2307, omega: -6.5844\n",
      "theta =  0.0660, omega: -6.4503\n",
      "theta = -0.0890, omega: -5.8195\n",
      "theta = -0.2223, omega: -4.7502\n",
      "theta = -0.3250, omega: -3.3528\n",
      "theta = -0.3704, omega: -0.3863\n",
      "theta = -0.3413, omega:  2.6987\n",
      "theta = -0.2380, omega:  5.4551\n",
      "theta = -0.0947, omega:  5.8848\n",
      "theta =  0.0523, omega:  5.8401\n",
      "theta =  0.1954, omega:  5.3412\n",
      "theta =  0.3387, omega:  6.2668\n",
      "theta =  0.5018, omega:  6.6991\n",
      "theta =  0.6699, omega:  6.6579\n",
      "theta =  0.8298, omega:  6.2096\n",
      "theta =  0.9780, omega:  5.4443\n",
      "theta =  1.1007, omega:  4.4654\n",
      "theta =  1.1771, omega:  1.5189\n",
      "theta =  1.1806, omega: -1.1947\n",
      "theta =  1.1189, omega: -3.6648\n",
      "theta =  1.0048, omega: -5.4676\n",
      "theta =  0.8664, omega: -5.6061\n",
      "theta =  0.7253, omega: -5.4535\n",
      "theta =  0.5953, omega: -4.9837\n",
      "theta =  0.4560, omega: -6.0314\n",
      "theta =  0.2977, omega: -6.6175\n",
      "theta =  0.1307, omega: -6.6901\n",
      "theta = -0.0332, omega: -6.2381\n",
      "theta = -0.1787, omega: -5.3132\n",
      "theta = -0.2961, omega: -4.0092\n",
      "theta = -0.3528, omega: -0.6224\n",
      "theta = -0.3295, omega:  2.4414\n",
      "theta = -0.2333, omega:  5.1860\n",
      "theta = -0.0966, omega:  5.6191\n",
      "theta =  0.0418, omega:  5.6017\n",
      "theta =  0.1774, omega:  5.1456\n",
      "theta =  0.3213, omega:  6.1281\n",
      "theta =  0.4809, omega:  6.6226\n",
      "theta =  0.6450, omega:  6.6432\n",
      "theta =  0.8094, omega:  6.2470\n",
      "theta =  0.9577, omega:  5.5213\n",
      "theta =  1.0830, omega:  4.5715\n",
      "theta =  1.1609, omega:  1.6451\n",
      "theta =  1.1685, omega: -1.0679\n",
      "theta =  1.1333, omega: -1.6974\n",
      "theta =  1.0614, omega: -4.0809\n",
      "theta =  0.9538, omega: -4.3934\n",
      "theta =  0.8415, omega: -4.4972\n",
      "theta =  0.7303, omega: -4.3598\n",
      "theta =  0.6256, omega: -3.9759\n",
      "theta =  0.5109, omega: -5.1727\n",
      "theta =  0.3706, omega: -5.9756\n",
      "theta =  0.2156, omega: -6.3157\n",
      "theta =  0.0586, omega: -6.1602\n",
      "theta = -0.0869, omega: -5.5285\n",
      "theta = -0.2131, omega: -4.4844\n",
      "theta = -0.2866, omega: -1.3110\n",
      "theta = -0.2807, omega:  1.6524\n",
      "theta = -0.2056, omega:  4.3037\n",
      "theta = -0.0920, omega:  4.7152\n",
      "theta =  0.0271, omega:  4.7469\n",
      "theta =  0.1421, omega:  4.4021\n",
      "theta =  0.2693, omega:  5.5496\n",
      "theta =  0.4154, omega:  6.2408\n",
      "theta =  0.5738, omega:  6.4616\n",
      "theta =  0.7356, omega:  6.2502\n",
      "theta =  0.8840, omega:  5.6786\n",
      "theta =  1.0155, omega:  4.8441\n",
      "theta =  1.1016, omega:  2.0024\n",
      "theta =  1.1177, omega: -0.6814\n",
      "theta =  1.0708, omega: -3.0962\n",
      "theta =  0.9646, omega: -5.3091\n",
      "theta =  0.8309, omega: -5.3815\n",
      "theta =  0.6961, omega: -5.1634\n",
      "theta =  0.5752, omega: -4.6424\n",
      "theta =  0.4450, omega: -5.6609\n",
      "theta =  0.2969, omega: -6.2380\n",
      "theta =  0.1383, omega: -6.3311\n",
      "theta = -0.0165, omega: -5.9280\n",
      "theta = -0.1548, omega: -5.0747\n",
      "theta = -0.2671, omega: -3.8554\n",
      "theta = -0.3234, omega: -0.5635\n",
      "theta = -0.2992, omega:  2.4070\n",
      "theta = -0.2057, omega:  5.0576\n",
      "theta = -0.0734, omega:  5.4146\n",
      "theta =  0.0608, omega:  5.3373\n",
      "theta =  0.1883, omega:  4.8421\n",
      "theta =  0.3239, omega:  5.8124\n",
      "theta =  0.4747, omega:  6.3191\n",
      "theta =  0.6349, omega:  6.3699\n",
      "theta =  0.7924, omega:  6.0148\n",
      "theta =  0.9331, omega:  5.3416\n",
      "theta =  1.0577, omega:  4.4376\n",
      "theta =  1.1331, omega:  1.5575\n",
      "theta =  1.1356, omega: -1.1101\n",
      "theta =  1.0776, omega: -3.5277\n",
      "theta =  0.9670, omega: -5.2742\n",
      "theta =  0.8333, omega: -5.3532\n",
      "theta =  0.6844, omega: -6.5163\n",
      "theta =  0.5064, omega: -7.6980\n",
      "theta =  0.3055, omega: -8.3134\n",
      "theta =  0.0962, omega: -8.2882\n",
      "theta = -0.1057, omega: -7.6168\n",
      "theta = -0.2815, omega: -6.3747\n",
      "theta = -0.4171, omega: -4.6911\n",
      "theta = -0.4901, omega: -0.9009\n",
      "theta = -0.4691, omega:  2.5824\n",
      "theta = -0.3646, omega:  5.7185\n",
      "theta = -0.2105, omega:  6.5065\n",
      "theta = -0.0419, omega:  6.7680\n",
      "theta =  0.1244, omega:  6.4954\n",
      "theta =  0.3010, omega:  7.5456\n",
      "theta =  0.4961, omega:  7.9974\n",
      "theta =  0.6963, omega:  7.8846\n",
      "theta =  0.8880, omega:  7.3038\n",
      "theta =  1.0589, omega:  6.3754\n",
      "theta =  1.2066, omega:  5.2277\n",
      "theta =  1.2972, omega:  2.1306\n",
      "theta =  1.3113, omega: -0.7700\n",
      "theta =  1.2596, omega: -3.4050\n",
      "theta =  1.1492, omega: -5.4044\n",
      "theta =  1.0093, omega: -5.7898\n",
      "theta =  0.8614, omega: -5.9182\n",
      "theta =  0.7152, omega: -5.7376\n",
      "theta =  0.5553, omega: -7.0499\n",
      "theta =  0.3673, omega: -7.8488\n",
      "theta =  0.1680, omega: -8.0450\n",
      "theta = -0.0300, omega: -7.6136\n",
      "theta = -0.2074, omega: -6.5990\n",
      "theta = -0.3562, omega: -5.1135\n",
      "theta = -0.4373, omega: -1.4782\n",
      "theta = -0.4312, omega:  1.9409\n",
      "theta = -0.3441, omega:  5.0168\n",
      "theta = -0.2072, omega:  5.7982\n",
      "theta = -0.0576, omega:  6.1060\n",
      "theta =  0.0931, omega:  5.9315\n",
      "theta =  0.2581, omega:  7.1164\n",
      "theta =  0.4434, omega:  7.7260\n",
      "theta =  0.6397, omega:  7.7692\n",
      "theta =  0.8295, omega:  7.3226\n",
      "theta =  1.0017, omega:  6.5001\n",
      "theta =  1.1508, omega:  5.4271\n",
      "theta =  1.2730, omega:  4.2164\n",
      "theta =  1.3398, omega:  1.1005\n",
      "theta =  1.3321, omega: -1.7117\n",
      "theta =  1.2545, omega: -4.3220\n",
      "theta =  1.1387, omega: -4.8995\n",
      "theta =  1.0116, omega: -5.2915\n",
      "theta =  0.8755, omega: -5.4540\n",
      "theta =  0.7403, omega: -5.3341\n",
      "theta =  0.6121, omega: -4.9109\n",
      "theta =  0.4751, omega: -6.0094\n",
      "theta =  0.3181, omega: -6.6486\n",
      "theta =  0.1462, omega: -6.7754\n",
      "theta = -0.0200, omega: -6.3706\n",
      "theta = -0.1666, omega: -5.4813\n",
      "theta = -0.2920, omega: -4.1965\n",
      "theta = -0.3513, omega: -0.8174\n",
      "theta = -0.3326, omega:  2.2725\n",
      "theta = -0.2415, omega:  5.0352\n",
      "theta = -0.1089, omega:  5.5041\n",
      "theta =  0.0316, omega:  5.5278\n",
      "theta =  0.1644, omega:  5.1169\n",
      "theta =  0.3070, omega:  6.1467\n",
      "theta =  0.4661, omega:  6.6805\n",
      "theta =  0.6369, omega:  6.7334\n",
      "theta =  0.8000, omega:  6.3555\n",
      "theta =  0.9524, omega:  5.6433\n",
      "theta =  1.0819, omega:  4.6951\n",
      "theta =  1.1628, omega:  1.7689\n",
      "theta =  1.1708, omega: -0.9588\n",
      "theta =  1.1159, omega: -3.4308\n",
      "theta =  1.0051, omega: -5.2418\n",
      "theta =  0.8730, omega: -5.3954\n",
      "theta =  0.7398, omega: -5.2721\n",
      "theta =  0.6130, omega: -4.8480\n",
      "theta =  0.4768, omega: -5.9479\n",
      "theta =  0.3178, omega: -6.5967\n",
      "theta =  0.1502, omega: -6.7342\n",
      "theta = -0.0148, omega: -6.3455\n",
      "theta = -0.1638, omega: -5.4709\n",
      "theta = -0.2841, omega: -4.2000\n",
      "theta = -0.3471, omega: -0.8346\n",
      "theta = -0.3274, omega:  2.2422\n",
      "theta = -0.2388, omega:  4.9968\n",
      "theta = -0.1052, omega:  5.4580\n",
      "theta =  0.0566, omega:  7.2953\n",
      "theta =  0.2533, omega:  8.5071\n",
      "theta =  0.4732, omega:  9.0328\n",
      "theta =  0.6990, omega:  8.9146\n",
      "theta =  0.9144, omega:  8.2661\n",
      "theta =  1.1112, omega:  7.2394\n",
      "theta =  1.2775, omega:  5.9891\n",
      "theta =  1.4081, omega:  4.6403\n",
      "theta =  1.5067, omega:  3.2731\n",
      "theta =  1.5737, omega:  1.9336\n",
      "theta =  1.6042, omega:  0.6351\n",
      "theta =  1.6060, omega: -0.4344\n",
      "theta =  1.5599, omega: -3.2026\n",
      "theta =  1.4710, omega: -4.0268\n",
      "theta =  1.3594, omega: -4.7923\n",
      "theta =  1.2316, omega: -5.4541\n",
      "theta =  1.0869, omega: -5.9461\n",
      "theta =  0.9348, omega: -6.2039\n",
      "theta =  0.7787, omega: -6.1642\n",
      "theta =  0.6315, omega: -5.7806\n",
      "theta =  0.4708, omega: -6.8687\n",
      "theta =  0.2905, omega: -7.4424\n",
      "theta =  0.1021, omega: -7.4327\n",
      "theta = -0.0762, omega: -6.8496\n",
      "theta = -0.2361, omega: -5.7480\n",
      "theta = -0.3609, omega: -4.2432\n",
      "theta = -0.4208, omega: -0.6550\n",
      "theta = -0.3975, omega:  2.6110\n",
      "theta = -0.2925, omega:  5.5378\n",
      "theta = -0.1474, omega:  6.1302\n",
      "theta =  0.0093, omega:  6.2252\n",
      "theta =  0.1610, omega:  5.8333\n",
      "theta =  0.3193, omega:  6.8216\n",
      "theta =  0.4978, omega:  7.2699\n",
      "theta =  0.6797, omega:  7.2049\n",
      "theta =  0.8544, omega:  6.7007\n",
      "theta =  1.0111, omega:  5.8671\n",
      "theta =  1.1443, omega:  4.8126\n",
      "theta =  1.2285, omega:  1.7985\n",
      "theta =  1.2368, omega: -1.0031\n",
      "theta =  1.1805, omega: -3.5524\n",
      "theta =  1.0650, omega: -5.4496\n",
      "theta =  0.9254, omega: -5.6980\n",
      "theta =  0.7838, omega: -5.6720\n",
      "theta =  0.6457, omega: -5.3298\n",
      "theta =  0.4977, omega: -6.4900\n",
      "theta =  0.3259, omega: -7.1626\n",
      "theta =  0.1445, omega: -7.2791\n",
      "theta = -0.0345, omega: -6.8292\n",
      "theta = -0.1955, omega: -5.8604\n",
      "theta = -0.3240, omega: -4.4710\n",
      "theta = -0.3923, omega: -0.9702\n",
      "theta = -0.3746, omega:  2.2499\n",
      "theta = -0.2821, omega:  5.1384\n",
      "theta = -0.1448, omega:  5.7208\n",
      "theta =  0.0245, omega:  7.6626\n",
      "theta =  0.2326, omega:  8.9407\n",
      "theta =  0.4659, omega:  9.4980\n",
      "theta =  0.7003, omega:  9.3726\n",
      "theta =  0.9276, omega:  8.6908\n",
      "theta =  1.1339, omega:  7.6196\n",
      "theta =  1.3083, omega:  6.3268\n",
      "theta =  1.4492, omega:  4.9442\n",
      "theta =  1.5554, omega:  3.5540\n",
      "theta =  1.6266, omega:  2.2046\n",
      "theta =  1.6664, omega:  0.9072\n",
      "theta =  1.6733, omega: -0.2037\n",
      "theta =  1.6553, omega: -1.1205\n",
      "theta =  1.5935, omega: -3.8587\n",
      "theta =  1.4849, omega: -4.6672\n",
      "theta =  1.3607, omega: -5.4171\n",
      "theta =  1.2161, omega: -6.0511\n",
      "theta =  1.0597, omega: -6.4973\n",
      "theta =  0.8957, omega: -6.6780\n",
      "theta =  0.7285, omega: -6.5263\n",
      "theta =  0.5492, omega: -7.8216\n",
      "theta =  0.3429, omega: -8.5491\n",
      "theta =  0.1265, omega: -8.6246\n",
      "theta = -0.0822, omega: -8.0276\n",
      "theta = -0.2683, omega: -6.8216\n",
      "theta = -0.4188, omega: -5.1402\n",
      "theta = -0.5022, omega: -1.3202\n",
      "theta = -0.4872, omega:  2.2473\n",
      "theta = -0.3913, omega:  5.4642\n",
      "theta = -0.2426, omega:  6.3514\n",
      "theta = -0.0779, omega:  6.7294\n",
      "theta =  0.0906, omega:  6.5679\n",
      "theta =  0.2709, omega:  7.7205\n",
      "theta =  0.4709, omega:  8.2540\n",
      "theta =  0.6778, omega:  8.1924\n",
      "theta =  0.8784, omega:  7.6341\n",
      "theta =  1.0556, omega:  6.7078\n",
      "theta =  1.2086, omega:  5.5516\n",
      "theta =  1.3332, omega:  4.2724\n",
      "theta =  1.3973, omega:  1.1152\n",
      "theta =  1.3910, omega: -1.7373\n",
      "theta =  1.3141, omega: -4.3906\n",
      "theta =  1.1947, omega: -5.0274\n",
      "theta =  1.0644, omega: -5.4950\n",
      "theta =  0.9232, omega: -5.7409\n",
      "theta =  0.7797, omega: -5.7029\n",
      "theta =  0.6408, omega: -5.3490\n",
      "theta =  0.4919, omega: -6.4941\n",
      "theta =  0.3187, omega: -7.1506\n",
      "theta =  0.1407, omega: -7.2525\n",
      "theta = -0.0383, omega: -6.7904\n",
      "theta = -0.1962, omega: -5.8123\n",
      "theta = -0.3257, omega: -4.4166\n",
      "theta = -0.3927, omega: -0.9170\n",
      "theta = -0.3738, omega:  2.2988\n",
      "theta = -0.2791, omega:  5.1795\n",
      "theta = -0.1438, omega:  5.7529\n",
      "theta =  0.0061, omega:  5.8641\n",
      "theta =  0.1692, omega:  7.3282\n",
      "theta =  0.3666, omega:  8.1828\n",
      "theta =  0.5747, omega:  8.4096\n",
      "theta =  0.7811, omega:  8.0789\n",
      "theta =  0.9766, omega:  7.3058\n",
      "theta =  1.1449, omega:  6.2327\n",
      "theta =  1.2864, omega:  4.9916\n",
      "theta =  1.3709, omega:  1.8350\n",
      "theta =  1.3772, omega: -1.0817\n",
      "theta =  1.3184, omega: -3.7538\n",
      "theta =  1.2139, omega: -4.4212\n",
      "theta =  1.0973, omega: -4.9453\n",
      "theta =  0.9707, omega: -5.2755\n",
      "theta =  0.8358, omega: -5.3582\n",
      "theta =  0.7040, omega: -5.1563\n",
      "theta =  0.5836, omega: -4.6534\n",
      "theta =  0.4519, omega: -5.6855\n",
      "theta =  0.3008, omega: -6.2789\n",
      "theta =  0.1412, omega: -6.3858\n",
      "theta = -0.0147, omega: -5.9912\n",
      "theta = -0.1542, omega: -5.1394\n",
      "theta = -0.2696, omega: -3.9187\n",
      "theta = -0.3252, omega: -0.6200\n",
      "theta = -0.3025, omega:  2.3644\n",
      "theta = -0.2096, omega:  5.0318\n",
      "theta = -0.0786, omega:  5.4013\n",
      "theta =  0.0792, omega:  7.1595\n",
      "theta =  0.2747, omega:  8.3019\n",
      "theta =  0.4887, omega:  8.7811\n",
      "theta =  0.7080, omega:  8.6378\n",
      "theta =  0.9174, omega:  7.9858\n",
      "theta =  1.1037, omega:  6.9729\n",
      "theta =  1.2622, omega:  5.7397\n",
      "theta =  1.3907, omega:  4.4094\n",
      "theta =  1.4840, omega:  3.0587\n",
      "theta =  1.5446, omega:  1.7278\n",
      "theta =  1.5492, omega: -1.2322\n",
      "theta =  1.4835, omega: -3.9716\n",
      "theta =  1.3745, omega: -4.7440\n",
      "theta =  1.2463, omega: -5.4205\n",
      "theta =  1.1032, omega: -5.9339\n",
      "theta =  0.9512, omega: -6.2211\n",
      "theta =  0.7953, omega: -6.2147\n",
      "theta =  0.6444, omega: -5.8664\n",
      "theta =  0.4815, omega: -6.9882\n",
      "theta =  0.2993, omega: -7.5837\n",
      "theta =  0.1077, omega: -7.5933\n",
      "theta = -0.0753, omega: -7.0120\n",
      "theta = -0.2372, omega: -5.9014\n",
      "theta = -0.3680, omega: -4.3763\n",
      "theta = -0.4321, omega: -0.7569\n",
      "theta = -0.4091, omega:  2.5486\n",
      "theta = -0.3044, omega:  5.5127\n",
      "theta = -0.1612, omega:  6.1472\n",
      "theta = -0.0027, omega:  6.2806\n",
      "theta =  0.1504, omega:  5.9218\n",
      "theta =  0.3117, omega:  6.9355\n",
      "theta =  0.4930, omega:  7.4014\n",
      "theta =  0.6777, omega:  7.3394\n",
      "theta =  0.8570, omega:  6.8311\n",
      "theta =  1.0174, omega:  5.9839\n",
      "theta =  1.1551, omega:  4.9178\n",
      "theta =  1.2397, omega:  1.8886\n",
      "theta =  1.2464, omega: -0.9344\n",
      "theta =  1.1929, omega: -3.4984\n",
      "theta =  1.0814, omega: -5.4155\n",
      "theta =  0.9410, omega: -5.6922\n",
      "theta =  0.8005, omega: -5.6962\n",
      "theta =  0.6595, omega: -5.3911\n",
      "theta =  0.5095, omega: -6.5805\n",
      "theta =  0.3356, omega: -7.2812\n",
      "theta =  0.1496, omega: -7.4190\n",
      "theta = -0.0316, omega: -6.9790\n",
      "theta = -0.1950, omega: -6.0065\n",
      "theta = -0.3286, omega: -4.6052\n",
      "theta = -0.4011, omega: -1.0821\n",
      "theta = -0.3859, omega:  2.1770\n",
      "theta = -0.2942, omega:  5.0981\n",
      "theta = -0.1579, omega:  5.7203\n",
      "theta = -0.0115, omega:  5.8805\n",
      "theta =  0.1345, omega:  5.5721\n",
      "theta =  0.2884, omega:  6.6630\n",
      "theta =  0.4609, omega:  7.2165\n",
      "theta =  0.6443, omega:  7.2470\n",
      "theta =  0.8195, omega:  6.8238\n",
      "theta =  0.9820, omega:  6.0455\n",
      "theta =  1.1213, omega:  5.0262\n",
      "theta =  1.2083, omega:  2.0316\n",
      "theta =  1.2241, omega: -0.7813\n",
      "theta =  1.1721, omega: -3.3234\n",
      "theta =  1.0646, omega: -5.2226\n",
      "theta =  0.9296, omega: -5.4783\n",
      "theta =  0.7911, omega: -5.4735\n",
      "theta =  0.6591, omega: -5.1630\n",
      "theta =  0.5154, omega: -6.3690\n",
      "theta =  0.3467, omega: -7.0982\n",
      "theta =  0.1634, omega: -7.2785\n",
      "theta = -0.0147, omega: -6.8945\n",
      "theta = -0.1747, omega: -5.9781\n",
      "theta = -0.3081, omega: -4.6325\n",
      "theta = -0.3823, omega: -1.1606\n",
      "theta = -0.3706, omega:  2.0595\n",
      "theta = -0.2810, omega:  4.9491\n",
      "theta = -0.1493, omega:  5.5469\n",
      "theta = -0.0080, omega:  5.6960\n",
      "theta =  0.1306, omega:  5.3931\n",
      "theta =  0.2791, omega:  6.5024\n",
      "theta =  0.4522, omega:  7.0859\n",
      "theta =  0.6320, omega:  7.1518\n",
      "theta =  0.8045, omega:  6.7634\n",
      "theta =  0.9662, omega:  6.0143\n",
      "theta =  1.1043, omega:  5.0266\n",
      "theta =  1.1918, omega:  2.0521\n",
      "theta =  1.2080, omega: -0.7478\n",
      "theta =  1.1583, omega: -3.2763\n",
      "theta =  1.0512, omega: -5.1547\n",
      "theta =  0.9191, omega: -5.3965\n",
      "theta =  0.7840, omega: -5.3716\n",
      "theta =  0.6542, omega: -5.0481\n",
      "theta =  0.5354, omega: -4.4230\n",
      "theta =  0.4110, omega: -5.3417\n",
      "theta =  0.2694, omega: -5.8437\n",
      "theta =  0.1218, omega: -5.8879\n",
      "theta = -0.0194, omega: -5.4763\n",
      "theta = -0.1473, omega: -4.6450\n",
      "theta = -0.2486, omega: -3.4815\n",
      "theta = -0.2973, omega: -0.2722\n",
      "theta = -0.2685, omega:  2.5795\n",
      "theta = -0.1695, omega:  5.1238\n",
      "theta = -0.0380, omega:  5.3631\n",
      "theta =  0.0926, omega:  5.1780\n",
      "theta =  0.2399, omega:  6.4118\n",
      "theta =  0.4112, omega:  7.1232\n",
      "theta =  0.5915, omega:  7.2992\n",
      "theta =  0.7732, omega:  6.9910\n",
      "theta =  0.9388, omega:  6.3018\n",
      "theta =  1.0858, omega:  5.3392\n",
      "theta =  1.2029, omega:  4.2099\n",
      "theta =  1.2709, omega:  1.1591\n",
      "theta =  1.2639, omega: -1.6080\n",
      "theta =  1.1912, omega: -4.1596\n",
      "theta =  1.0828, omega: -4.6667\n",
      "theta =  0.9620, omega: -4.9832\n",
      "theta =  0.8346, omega: -5.0658\n",
      "theta =  0.7115, omega: -4.8776\n",
      "theta =  0.5931, omega: -4.4043\n",
      "theta =  0.4674, omega: -5.4857\n",
      "theta =  0.3196, omega: -6.1453\n",
      "theta =  0.1653, omega: -6.3256\n",
      "theta =  0.0102, omega: -6.0098\n",
      "theta = -0.1325, omega: -5.2358\n",
      "theta = -0.2481, omega: -4.0784\n",
      "theta = -0.3122, omega: -0.8265\n",
      "theta = -0.2909, omega:  2.1399\n",
      "theta = -0.2041, omega:  4.7919\n",
      "theta = -0.0807, omega:  5.1682\n",
      "theta =  0.0502, omega:  5.1258\n",
      "theta =  0.1715, omega:  4.6850\n",
      "theta =  0.3040, omega:  5.7192\n",
      "theta =  0.4556, omega:  6.2922\n",
      "theta =  0.6149, omega:  6.3979\n",
      "theta =  0.7717, omega:  6.0962\n",
      "theta =  0.9156, omega:  5.4581\n",
      "theta =  1.0426, omega:  4.5776\n",
      "theta =  1.1193, omega:  1.7113\n",
      "theta =  1.1294, omega: -0.9594\n",
      "theta =  1.0752, omega: -3.3756\n",
      "theta =  0.9670, omega: -5.1261\n",
      "theta =  0.8398, omega: -5.2149\n",
      "theta =  0.7103, omega: -5.0252\n",
      "theta =  0.5889, omega: -4.5434\n",
      "theta =  0.4619, omega: -5.6041\n",
      "theta =  0.3124, omega: -6.2367\n",
      "theta =  0.1539, omega: -6.3819\n",
      "theta = -0.0018, omega: -6.0279\n",
      "theta = -0.1426, omega: -5.2147\n",
      "theta = -0.2367, omega: -2.2008\n",
      "theta = -0.2539, omega:  0.7433\n",
      "theta = -0.2013, omega:  3.3732\n",
      "theta = -0.1046, omega:  4.2950\n",
      "theta =  0.0049, omega:  4.3955\n",
      "theta =  0.1124, omega:  4.1472\n",
      "theta =  0.2320, omega:  5.4063\n",
      "theta =  0.3772, omega:  6.2097\n",
      "theta =  0.5378, omega:  6.5373\n",
      "theta =  0.7016, omega:  6.4131\n",
      "theta =  0.8593, omega:  5.9080\n",
      "theta =  0.9955, omega:  5.1135\n",
      "theta =  1.1108, omega:  4.1241\n",
      "theta =  1.1790, omega:  1.1850\n",
      "theta =  1.1709, omega: -1.4886\n",
      "theta =  1.1036, omega: -3.9328\n",
      "theta =  0.9997, omega: -4.3251\n",
      "theta =  0.8877, omega: -4.5194\n",
      "theta =  0.7743, omega: -4.4817\n",
      "theta =  0.6659, omega: -4.1957\n",
      "theta =  0.5476, omega: -5.4827\n",
      "theta =  0.3968, omega: -6.3590\n",
      "theta =  0.2303, omega: -6.7456\n",
      "theta =  0.0623, omega: -6.6061\n",
      "theta = -0.0949, omega: -5.9519\n",
      "theta = -0.2324, omega: -4.8578\n",
      "theta = -0.3341, omega: -3.4263\n",
      "theta = -0.3787, omega:  0.0324\n",
      "theta = -0.3394, omega:  3.0830\n",
      "theta = -0.2246, omega:  5.8064\n",
      "theta = -0.0759, omega:  6.1721\n",
      "theta =  0.0790, omega:  6.0460\n",
      "theta =  0.2467, omega:  7.2706\n",
      "theta =  0.4371, omega:  7.9022\n",
      "theta =  0.6350, omega:  7.9535\n",
      "theta =  0.8306, omega:  7.5038\n",
      "theta =  1.0100, omega:  6.6690\n",
      "theta =  1.1613, omega:  5.5810\n",
      "theta =  1.2866, omega:  4.3489\n",
      "theta =  1.3554, omega:  1.2199\n",
      "theta =  1.3487, omega: -1.6201\n",
      "theta =  1.2748, omega: -4.2468\n",
      "theta =  1.1631, omega: -4.8512\n",
      "theta =  1.0347, omega: -5.2824\n",
      "theta =  0.8984, omega: -5.4852\n",
      "theta =  0.7626, omega: -5.4161\n",
      "theta =  0.6307, omega: -5.0387\n",
      "theta =  0.4898, omega: -6.1778\n",
      "theta =  0.3282, omega: -6.8534\n",
      "theta =  0.1512, omega: -6.9968\n",
      "theta = -0.0173, omega: -6.5948\n",
      "theta = -0.1728, omega: -5.6873\n",
      "theta = -0.3015, omega: -4.3695\n",
      "theta = -0.3673, omega: -0.9474\n",
      "theta = -0.3496, omega:  2.1992\n",
      "theta = -0.2596, omega:  5.0165\n",
      "theta = -0.1258, omega:  5.5408\n",
      "theta =  0.0149, omega:  5.6172\n",
      "theta =  0.1533, omega:  5.2488\n",
      "theta =  0.2973, omega:  6.3088\n",
      "theta =  0.4620, omega:  6.8604\n",
      "theta =  0.6363, omega:  6.9140\n",
      "theta =  0.8037, omega:  6.5281\n",
      "theta =  0.9591, omega:  5.7961\n",
      "theta =  1.0906, omega:  4.8271\n",
      "theta =  1.1756, omega:  1.8821\n",
      "theta =  1.1863, omega: -0.8783\n",
      "theta =  1.1354, omega: -3.3758\n",
      "theta =  1.0263, omega: -5.2146\n",
      "theta =  0.8938, omega: -5.4078\n",
      "theta =  0.7560, omega: -5.3277\n",
      "theta =  0.6288, omega: -4.9433\n",
      "theta =  0.4897, omega: -6.0859\n",
      "theta =  0.3294, omega: -6.7676\n",
      "theta =  0.1551, omega: -6.9241\n",
      "theta = -0.0126, omega: -6.5386\n",
      "theta = -0.1656, omega: -5.6537\n",
      "theta = -0.2927, omega: -4.3602\n",
      "theta = -0.3590, omega: -0.9600\n",
      "theta = -0.3429, omega:  2.1670\n",
      "theta = -0.2528, omega:  4.9676\n",
      "theta = -0.1248, omega:  5.4753\n",
      "theta =  0.0162, omega:  5.5443\n",
      "theta =  0.1511, omega:  5.1737\n",
      "theta =  0.2949, omega:  6.2337\n",
      "theta =  0.4610, omega:  6.7951\n",
      "theta =  0.6310, omega:  6.8595\n",
      "theta =  0.7978, omega:  6.4889\n",
      "theta =  0.9523, omega:  5.7714\n",
      "theta =  1.0864, omega:  4.8149\n",
      "theta =  1.1684, omega:  1.8753\n",
      "theta =  1.1811, omega: -0.8745\n",
      "theta =  1.1502, omega: -1.5291\n",
      "theta =  1.0808, omega: -3.9459\n",
      "theta =  0.9720, omega: -4.7591\n",
      "theta =  0.8500, omega: -4.8777\n",
      "theta =  0.7312, omega: -4.7378\n",
      "theta =  0.6158, omega: -4.3256\n",
      "theta =  0.4949, omega: -5.4737\n",
      "theta =  0.3462, omega: -6.2046\n",
      "theta =  0.1870, omega: -6.4557\n",
      "theta =  0.0271, omega: -6.2005\n",
      "theta = -0.0958, omega: -3.6468\n",
      "theta = -0.1526, omega: -0.8909\n",
      "theta = -0.1425, omega:  1.6169\n",
      "theta = -0.0720, omega:  3.8473\n",
      "theta =  0.0279, omega:  4.3348\n",
      "theta =  0.1332, omega:  4.0140\n",
      "theta =  0.2491, omega:  5.2121\n",
      "theta =  0.3906, omega:  5.9764\n",
      "theta =  0.5458, omega:  6.2816\n",
      "theta =  0.7009, omega:  6.1561\n",
      "theta =  0.8494, omega:  5.6636\n",
      "theta =  0.9814, omega:  4.8933\n",
      "theta =  1.0937, omega:  3.9374\n",
      "theta =  1.1562, omega:  1.0283\n",
      "theta =  1.1483, omega: -1.6002\n",
      "theta =  1.0751, omega: -4.0083\n",
      "theta =  0.9740, omega: -4.3527\n",
      "theta =  0.8615, omega: -4.4938\n",
      "theta =  0.7496, omega: -4.3972\n",
      "theta =  0.6440, omega: -4.0546\n",
      "theta =  0.5263, omega: -5.2905\n",
      "theta =  0.3809, omega: -6.1250\n",
      "theta =  0.2231, omega: -6.4872\n",
      "theta =  0.0623, omega: -6.3389\n",
      "theta = -0.0900, omega: -5.7009\n",
      "theta = -0.2192, omega: -4.6386\n",
      "theta = -0.2953, omega: -1.4376\n",
      "theta = -0.2923, omega:  1.5737\n",
      "theta = -0.2202, omega:  4.2661\n",
      "theta = -0.1062, omega:  4.7214\n",
      "theta =  0.0123, omega:  4.7941\n",
      "theta =  0.1296, omega:  4.4879\n",
      "theta =  0.2562, omega:  5.6651\n",
      "theta =  0.4095, omega:  6.3756\n",
      "theta =  0.5733, omega:  6.6027\n",
      "theta =  0.7378, omega:  6.3872\n",
      "theta =  0.8886, omega:  5.8078\n",
      "theta =  1.0236, omega:  4.9594\n",
      "theta =  1.1125, omega:  2.0980\n",
      "theta =  1.1303, omega: -0.6079\n",
      "theta =  1.0846, omega: -3.0425\n",
      "theta =  1.0035, omega: -3.4515\n",
      "theta =  0.8946, omega: -5.0705\n",
      "theta =  0.7689, omega: -5.0161\n",
      "theta =  0.6467, omega: -4.6788\n",
      "theta =  0.5155, omega: -5.8857\n",
      "theta =  0.3573, omega: -6.6500\n",
      "theta =  0.1861, omega: -6.8982\n",
      "theta =  0.0180, omega: -6.6082\n",
      "theta = -0.1391, omega: -5.8089\n",
      "theta = -0.2686, omega: -4.5872\n",
      "theta = -0.3419, omega: -1.2331\n",
      "theta = -0.3348, omega:  1.8870\n",
      "theta = -0.2510, omega:  4.6816\n",
      "theta = -0.1249, omega:  5.2076\n",
      "theta =  0.0049, omega:  5.3101\n",
      "theta =  0.1354, omega:  4.9933\n",
      "theta =  0.2753, omega:  6.1182\n",
      "theta =  0.4353, omega:  6.7489\n",
      "theta =  0.6074, omega:  6.8779\n",
      "theta =  0.7776, omega:  6.5591\n",
      "theta =  0.9343, omega:  5.8841\n",
      "theta =  1.0696, omega:  4.9552\n",
      "theta =  1.1565, omega:  2.0298\n",
      "theta =  1.1917, omega:  0.9703\n",
      "theta =  1.1839, omega: -1.6954\n",
      "theta =  1.1327, omega: -2.3166\n",
      "theta =  1.0460, omega: -4.6681\n",
      "theta =  0.9236, omega: -4.9260\n",
      "theta =  0.8036, omega: -4.9381\n",
      "theta =  0.6806, omega: -4.6830\n",
      "theta =  0.5700, omega: -4.1540\n",
      "theta =  0.4506, omega: -5.1852\n",
      "theta =  0.3376, omega: -3.9971\n",
      "theta =  0.2313, omega: -4.3740\n",
      "theta =  0.1200, omega: -4.4028\n",
      "theta =  0.0137, omega: -4.0889\n",
      "theta = -0.0818, omega: -3.4652\n",
      "theta = -0.1350, omega: -0.7683\n",
      "theta = -0.1232, omega:  1.6645\n",
      "theta = -0.0536, omega:  3.8246\n",
      "theta =  0.0486, omega:  4.2523\n",
      "theta =  0.1515, omega:  3.8729\n",
      "theta =  0.2632, omega:  5.0302\n",
      "theta =  0.3983, omega:  5.7681\n",
      "theta =  0.5480, omega:  6.0647\n",
      "theta =  0.7014, omega:  5.9473\n",
      "theta =  0.8430, omega:  5.4742\n",
      "theta =  0.9699, omega:  4.7304\n",
      "theta =  1.0538, omega:  1.9663\n",
      "theta =  1.0696, omega: -0.6465\n",
      "theta =  1.0226, omega: -2.9916\n",
      "theta =  0.9221, omega: -5.1338\n",
      "theta =  0.7937, omega: -5.1295\n",
      "theta =  0.6687, omega: -4.8428\n",
      "theta =  0.5510, omega: -4.2629\n",
      "theta =  0.4348, omega: -5.2477\n",
      "theta =  0.2944, omega: -5.8232\n",
      "theta =  0.1479, omega: -5.9400\n",
      "theta =  0.0024, omega: -5.5943\n",
      "theta = -0.1292, omega: -4.8227\n",
      "theta = -0.2369, omega: -3.6998\n",
      "theta = -0.2916, omega: -0.5090\n",
      "theta = -0.2651, omega:  2.3557\n",
      "theta = -0.1738, omega:  4.9091\n",
      "theta = -0.0458, omega:  5.1826\n",
      "theta =  0.0823, omega:  5.0399\n",
      "theta =  0.2007, omega:  4.5030\n",
      "theta =  0.3258, omega:  5.4635\n",
      "theta =  0.4712, omega:  5.9879\n",
      "theta =  0.6223, omega:  6.0761\n",
      "theta =  0.7730, omega:  5.7742\n",
      "theta =  0.9079, omega:  5.1550\n",
      "theta =  1.0286, omega:  4.3031\n",
      "theta =  1.1006, omega:  1.4714\n",
      "theta =  1.1048, omega: -1.1393\n",
      "theta =  1.0433, omega: -3.5073\n",
      "theta =  0.9343, omega: -5.1998\n",
      "theta =  0.8033, omega: -5.2161\n",
      "theta =  0.6772, omega: -4.9486\n",
      "theta =  0.5587, omega: -4.3880\n",
      "theta =  0.4366, omega: -5.3791\n",
      "theta =  0.2938, omega: -5.9512\n",
      "theta =  0.1444, omega: -6.0590\n",
      "theta = -0.0060, omega: -5.6929\n",
      "theta = -0.1403, omega: -4.8937\n",
      "theta = -0.2478, omega: -3.7382\n",
      "theta = -0.2989, omega: -0.5160\n",
      "theta = -0.2769, omega:  2.3803\n",
      "theta = -0.1839, omega:  4.9662\n",
      "theta = -0.0548, omega:  5.2625\n",
      "theta =  0.0763, omega:  5.1358\n",
      "theta =  0.1987, omega:  4.6124\n",
      "theta =  0.3281, omega:  5.5717\n",
      "theta =  0.4730, omega:  6.0884\n",
      "theta =  0.6287, omega:  6.1616\n",
      "theta =  0.7782, omega:  5.8429\n",
      "theta =  0.9174, omega:  5.2076\n",
      "theta =  1.0368, omega:  4.3393\n",
      "theta =  1.1115, omega:  1.4929\n",
      "theta =  1.1135, omega: -1.1361\n",
      "theta =  1.0560, omega: -3.5201\n",
      "theta =  0.9432, omega: -5.2281\n",
      "theta =  0.8127, omega: -5.2629\n",
      "theta =  0.6838, omega: -5.0139\n",
      "theta =  0.5655, omega: -4.4676\n",
      "theta =  0.4388, omega: -5.4658\n",
      "theta =  0.3168, omega: -4.2200\n",
      "theta =  0.2081, omega: -4.5259\n",
      "theta =  0.0958, omega: -4.4714\n",
      "theta = -0.0114, omega: -4.0723\n",
      "theta = -0.1076, omega: -3.3619\n",
      "theta = -0.1563, omega: -0.5970\n",
      "theta = -0.1415, omega:  1.8806\n",
      "theta = -0.0657, omega:  4.0777\n",
      "theta =  0.0432, omega:  4.5204\n",
      "theta =  0.1523, omega:  4.1381\n",
      "theta =  0.2729, omega:  5.2727\n",
      "theta =  0.4115, omega:  5.9656\n",
      "theta =  0.5606, omega:  5.7566\n",
      "theta =  0.7037, omega:  5.6273\n",
      "theta =  0.8391, omega:  5.1628\n",
      "theta =  0.9603, omega:  4.4451\n",
      "theta =  1.0346, omega:  1.7139\n",
      "theta =  1.0475, omega: -0.8421\n",
      "theta =  0.9981, omega: -3.1380\n",
      "theta =  0.8922, omega: -5.2239\n",
      "theta =  0.7596, omega: -5.1489\n",
      "theta =  0.6373, omega: -4.7844\n",
      "theta =  0.5007, omega: -5.9561\n",
      "theta =  0.3414, omega: -6.6755\n",
      "theta =  0.1707, omega: -6.8792\n",
      "theta =  0.0026, omega: -6.5455\n",
      "theta = -0.1534, omega: -5.7103\n",
      "theta = -0.2813, omega: -4.4582\n",
      "theta = -0.3478, omega: -1.0892\n",
      "theta = -0.3363, omega:  2.0270\n",
      "theta = -0.2486, omega:  4.8156\n",
      "theta = -0.1232, omega:  5.3255\n",
      "theta =  0.0135, omega:  5.4057\n",
      "theta =  0.1439, omega:  5.0588\n",
      "theta =  0.2859, omega:  6.1507\n",
      "theta =  0.4485, omega:  6.7432\n",
      "theta =  0.6166, omega:  6.8450\n",
      "theta =  0.7855, omega:  6.5012\n",
      "theta =  0.9407, omega:  5.8113\n",
      "theta =  1.0745, omega:  4.8722\n",
      "theta =  1.1593, omega:  1.9433\n",
      "theta =  1.1725, omega: -0.8053\n",
      "theta =  1.1207, omega: -3.2879\n",
      "theta =  1.0182, omega: -5.1160\n",
      "theta =  0.8846, omega: -5.2941\n",
      "theta =  0.7550, omega: -5.2048\n",
      "theta =  0.6284, omega: -4.8200\n",
      "theta =  0.4915, omega: -5.9637\n",
      "theta =  0.3337, omega: -6.6592\n",
      "theta =  0.1650, omega: -6.8401\n",
      "theta = -0.0068, omega: -6.4809\n",
      "theta = -0.1547, omega: -5.6298\n",
      "theta = -0.2587, omega: -2.5459\n",
      "theta = -0.2849, omega:  0.5391\n",
      "theta = -0.2344, omega:  3.2782\n",
      "theta = -0.1225, omega:  5.6714\n",
      "theta =  0.0213, omega:  5.7264\n",
      "theta =  0.1590, omega:  5.3291\n",
      "theta =  0.3071, omega:  6.3561\n",
      "theta =  0.4735, omega:  6.8750\n",
      "theta =  0.6472, omega:  6.8968\n",
      "theta =  0.8161, omega:  6.4845\n",
      "theta =  0.9676, omega:  5.7393\n",
      "theta =  1.0994, omega:  4.7574\n",
      "theta =  1.1812, omega:  1.8021\n",
      "theta =  1.1916, omega: -0.9530\n",
      "theta =  1.1360, omega: -3.4512\n",
      "theta =  1.0261, omega: -5.2916\n",
      "theta =  0.8910, omega: -5.4792\n",
      "theta =  0.7544, omega: -5.3905\n",
      "theta =  0.6241, omega: -4.9959\n",
      "theta =  0.4846, omega: -6.1182\n",
      "theta =  0.3204, omega: -6.7804\n",
      "theta =  0.1499, omega: -6.9144\n",
      "theta = -0.0202, omega: -6.5110\n",
      "theta = -0.1732, omega: -5.6098\n",
      "theta = -0.2966, omega: -4.3014\n",
      "theta = -0.3625, omega: -0.8931\n",
      "theta = -0.3424, omega:  2.2319\n",
      "theta = -0.2515, omega:  5.0280\n",
      "theta = -0.1196, omega:  5.5314\n",
      "theta =  0.0193, omega:  5.5861\n",
      "theta =  0.1565, omega:  5.2035\n",
      "theta =  0.3004, omega:  6.2495\n",
      "theta =  0.4655, omega:  6.7940\n",
      "theta =  0.6361, omega:  6.8448\n",
      "theta =  0.8038, omega:  6.4625\n",
      "theta =  0.9551, omega:  5.7401\n",
      "theta =  1.0868, omega:  4.7773\n",
      "theta =  1.1936, omega:  3.6702\n",
      "theta =  1.2480, omega:  0.6537\n",
      "theta =  1.2304, omega: -2.0331\n",
      "theta =  1.1481, omega: -4.5250\n",
      "theta =  1.0277, omega: -4.9499\n",
      "theta =  0.9015, omega: -5.1616\n",
      "theta =  0.7741, omega: -5.1147\n",
      "theta =  0.6483, omega: -4.7819\n",
      "theta =  0.5137, omega: -5.9824\n",
      "theta =  0.3523, omega: -6.7382\n",
      "theta =  0.1821, omega: -6.9694\n",
      "theta =  0.0077, omega: -6.6561\n",
      "theta = -0.1461, omega: -5.8330\n",
      "theta = -0.2785, omega: -4.5847\n",
      "theta = -0.3512, omega: -1.2068\n",
      "theta = -0.3412, omega:  1.9301\n",
      "theta = -0.2576, omega:  4.7431\n",
      "theta = -0.1298, omega:  5.2827\n",
      "theta =  0.0020, omega:  5.3927\n",
      "theta =  0.1335, omega:  5.0758\n",
      "theta =  0.2762, omega:  6.1976\n",
      "theta =  0.4390, omega:  6.8116\n",
      "theta =  0.6144, omega:  6.9278\n",
      "theta =  0.7815, omega:  6.5952\n",
      "theta =  0.9402, omega:  5.9035\n",
      "theta =  1.0757, omega:  4.9606\n",
      "theta =  1.1870, omega:  3.8612\n",
      "theta =  1.2439, omega:  0.8441\n",
      "theta =  1.2294, omega: -1.8634\n",
      "theta =  1.1537, omega: -4.3640\n",
      "theta =  1.0369, omega: -4.8090\n",
      "theta =  0.9139, omega: -5.0458\n",
      "theta =  0.7890, omega: -5.0344\n",
      "theta =  0.6655, omega: -4.7394\n",
      "theta =  0.5307, omega: -5.9918\n",
      "theta =  0.3702, omega: -6.7925\n",
      "theta =  0.1957, omega: -7.0715\n",
      "theta =  0.0206, omega: -6.7953\n",
      "theta = -0.1235, omega: -4.6355\n",
      "theta = -0.2243, omega: -3.5474\n",
      "theta = -0.2737, omega: -0.4025\n",
      "theta = -0.2486, omega:  2.4022\n",
      "theta = -0.1572, omega:  4.9033\n",
      "theta = -0.0301, omega:  5.1236\n",
      "theta =  0.0940, omega:  4.9331\n",
      "theta =  0.2350, omega:  6.1842\n",
      "theta =  0.4008, omega:  6.9270\n",
      "theta =  0.5772, omega:  7.1411\n",
      "theta =  0.7533, omega:  6.8809\n",
      "theta =  0.9173, omega:  6.2366\n",
      "theta =  1.0646, omega:  5.3143\n",
      "theta =  1.1818, omega:  4.2128\n",
      "theta =  1.2482, omega:  1.1843\n",
      "theta =  1.2441, omega: -1.5654\n",
      "theta =  1.1735, omega: -4.0969\n",
      "theta =  1.0625, omega: -4.5804\n",
      "theta =  0.9453, omega: -4.8739\n",
      "theta =  0.8231, omega: -4.9314\n",
      "theta =  0.7007, omega: -4.7236\n",
      "theta =  0.5907, omega: -4.2412\n",
      "theta =  0.4674, omega: -5.3185\n",
      "theta =  0.3241, omega: -5.9905\n",
      "theta =  0.1727, omega: -6.1927\n",
      "theta =  0.0208, omega: -5.9106\n",
      "theta = -0.1189, omega: -5.1758\n",
      "theta = -0.2364, omega: -4.0605\n",
      "theta = -0.2977, omega: -0.8508\n",
      "theta = -0.2810, omega:  2.0812\n",
      "theta = -0.1945, omega:  4.7004\n",
      "theta = -0.0736, omega:  5.0515\n",
      "theta =  0.0539, omega:  4.9945\n",
      "theta =  0.1747, omega:  4.5469\n",
      "theta =  0.3022, omega:  5.5871\n",
      "theta =  0.4494, omega:  6.1721\n",
      "theta =  0.6073, omega:  6.3059\n",
      "theta =  0.7611, omega:  6.0252\n",
      "theta =  0.9051, omega:  5.4151\n",
      "theta =  1.0297, omega:  4.5573\n",
      "theta =  1.1086, omega:  1.7067\n",
      "theta =  1.1185, omega: -0.9490\n",
      "theta =  1.0634, omega: -3.3470\n",
      "theta =  0.9585, omega: -5.0752\n",
      "theta =  0.8293, omega: -5.1464\n",
      "theta =  0.7025, omega: -4.9412\n",
      "theta =  0.5839, omega: -4.4464\n",
      "theta =  0.4601, omega: -5.4999\n",
      "theta =  0.3110, omega: -6.1313\n",
      "theta =  0.1570, omega: -6.2841\n",
      "theta =  0.0016, omega: -5.9441\n",
      "theta = -0.1361, omega: -5.1515\n",
      "theta = -0.2526, omega: -3.9836\n",
      "theta = -0.3102, omega: -0.7269\n",
      "theta = -0.2920, omega:  2.2288\n",
      "theta = -0.2022, omega:  4.8686\n",
      "theta = -0.0522, omega:  7.0489\n",
      "theta =  0.1228, omega:  6.7846\n",
      "theta =  0.3062, omega:  7.8249\n",
      "theta =  0.5097, omega:  8.2453\n",
      "theta =  0.7141, omega:  8.0875\n",
      "theta =  0.9064, omega:  7.4565\n",
      "theta =  1.0833, omega:  6.4841\n",
      "theta =  1.2295, omega:  5.3012\n",
      "theta =  1.3477, omega:  4.0153\n",
      "theta =  1.4085, omega:  0.8599\n",
      "theta =  1.3931, omega: -1.9708\n",
      "theta =  1.3117, omega: -4.6177\n",
      "theta =  1.1883, omega: -5.2390\n",
      "theta =  1.0500, omega: -5.6860\n",
      "theta =  0.9041, omega: -5.8947\n",
      "theta =  0.7601, omega: -5.8111\n",
      "theta =  0.6181, omega: -5.3968\n",
      "theta =  0.4675, omega: -6.4777\n",
      "theta =  0.2968, omega: -7.0684\n",
      "theta =  0.1187, omega: -7.1097\n",
      "theta = -0.0529, omega: -6.5961\n",
      "theta = -0.2076, omega: -5.5831\n",
      "theta = -0.3284, omega: -4.1733\n",
      "theta = -0.3908, omega: -0.6790\n",
      "theta = -0.3658, omega:  2.4985\n",
      "theta = -0.2672, omega:  5.3466\n",
      "theta = -0.1270, omega:  5.8712\n",
      "theta =  0.0206, omega:  5.9244\n",
      "theta =  0.1675, omega:  5.5115\n",
      "theta =  0.3196, omega:  6.5044\n",
      "theta =  0.4857, omega:  6.9821\n",
      "theta =  0.6624, omega:  6.9617\n",
      "theta =  0.8307, omega:  6.5116\n",
      "theta =  0.9878, omega:  5.7308\n",
      "theta =  1.1175, omega:  4.7245\n",
      "theta =  1.2186, omega:  3.5825\n",
      "theta =  1.2724, omega:  0.5456\n",
      "theta =  1.2507, omega: -2.1495\n",
      "theta =  1.1635, omega: -4.6619\n",
      "theta =  1.0444, omega: -5.1069\n",
      "theta =  0.9133, omega: -5.3356\n",
      "theta =  0.7774, omega: -5.2977\n",
      "theta =  0.6488, omega: -4.9672\n",
      "theta =  0.5077, omega: -6.1589\n",
      "theta =  0.3449, omega: -6.8910\n",
      "theta =  0.1699, omega: -7.0880\n",
      "theta = -0.0043, omega: -6.7338\n",
      "theta = -0.1627, omega: -5.8626\n",
      "theta = -0.2943, omega: -4.5649\n",
      "theta = -0.3654, omega: -1.1440\n",
      "theta = -0.3529, omega:  2.0249\n",
      "theta = -0.2659, omega:  4.8660\n",
      "theta = -0.1374, omega:  5.4254\n",
      "theta =  0.0007, omega:  5.5451\n",
      "theta =  0.1366, omega:  5.2220\n",
      "theta =  0.2819, omega:  6.3270\n",
      "theta =  0.4463, omega:  6.9226\n",
      "theta =  0.6248, omega:  7.0070\n",
      "theta =  0.7949, omega:  6.6456\n",
      "theta =  0.9528, omega:  5.9272\n",
      "theta =  1.0897, omega:  4.9625\n",
      "theta =  1.1776, omega:  2.0090\n",
      "theta =  1.2134, omega:  0.9252\n",
      "theta =  1.2030, omega: -1.7559\n",
      "theta =  1.1254, omega: -4.2296\n",
      "theta =  1.0148, omega: -4.6406\n",
      "theta =  0.8949, omega: -4.8462\n",
      "theta =  0.7748, omega: -4.8053\n",
      "theta =  0.6572, omega: -4.4980\n",
      "theta =  0.5295, omega: -5.7444\n",
      "theta =  0.3752, omega: -6.5614\n",
      "theta =  0.2067, omega: -6.8700\n",
      "theta =  0.0367, omega: -6.6434\n",
      "theta = -0.1197, omega: -5.9025\n",
      "theta = -0.2558, omega: -4.7277\n",
      "theta = -0.3325, omega: -1.4102\n",
      "theta = -0.3281, omega:  1.7012\n",
      "theta = -0.2508, omega:  4.4918\n",
      "theta = -0.1299, omega:  5.0241\n",
      "theta = -0.0022, omega:  5.1487\n",
      "theta =  0.1237, omega:  4.8663\n",
      "theta =  0.2618, omega:  6.0369\n",
      "theta =  0.4207, omega:  6.7089\n",
      "theta =  0.5929, omega:  6.8821\n",
      "theta =  0.7623, omega:  6.6025\n",
      "theta =  0.9189, omega:  5.9545\n",
      "theta =  1.0576, omega:  5.0438\n",
      "theta =  1.1483, omega:  2.1304\n",
      "theta =  1.1652, omega: -0.6200\n",
      "theta =  1.1181, omega: -3.1017\n",
      "theta =  1.0104, omega: -5.3909\n",
      "theta =  0.8730, omega: -5.5476\n",
      "theta =  0.7372, omega: -5.4180\n",
      "theta =  0.6069, omega: -4.9762\n",
      "theta =  0.4666, omega: -6.0531\n",
      "theta =  0.3056, omega: -6.6693\n",
      "theta =  0.1340, omega: -6.7690\n",
      "theta = -0.0278, omega: -6.3382\n",
      "theta = -0.1743, omega: -5.4244\n",
      "theta = -0.2957, omega: -4.1195\n",
      "theta = -0.3570, omega: -0.7319\n",
      "theta = -0.3365, omega:  2.3580\n",
      "theta = -0.2405, omega:  5.1173\n",
      "theta = -0.1044, omega:  5.5774\n",
      "theta =  0.0344, omega:  5.5884\n",
      "theta =  0.1690, omega:  5.1589\n",
      "theta =  0.3136, omega:  6.1658\n",
      "theta =  0.4743, omega:  6.6809\n",
      "theta =  0.6420, omega:  6.7147\n",
      "theta =  0.8052, omega:  6.3267\n",
      "theta =  0.9571, omega:  5.6034\n",
      "theta =  1.0844, omega:  4.6489\n",
      "theta =  1.1634, omega:  1.7182\n",
      "theta =  1.1715, omega: -1.0052\n",
      "theta =  1.1153, omega: -3.4781\n",
      "theta =  1.0065, omega: -5.2853\n",
      "theta =  0.8725, omega: -5.4358\n",
      "theta =  0.7355, omega: -5.3058\n",
      "theta =  0.6072, omega: -4.8699\n",
      "theta =  0.4712, omega: -5.9629\n",
      "theta =  0.3139, omega: -6.5988\n",
      "theta =  0.1464, omega: -6.7238\n",
      "theta = -0.0192, omega: -6.3218\n",
      "theta = -0.1653, omega: -5.4372\n",
      "theta = -0.2850, omega: -4.1616\n",
      "theta = -0.3475, omega: -0.7903\n",
      "theta = -0.3288, omega:  2.2817\n",
      "theta = -0.2365, omega:  5.0343\n",
      "theta = -0.1041, omega:  5.4894\n",
      "theta =  0.0345, omega:  5.5000\n",
      "theta =  0.1679, omega:  5.0799\n",
      "theta =  0.3097, omega:  6.1046\n",
      "theta =  0.4687, omega:  6.6348\n",
      "theta =  0.6338, omega:  6.6893\n",
      "theta =  0.7976, omega:  6.3159\n",
      "theta =  0.9483, omega:  5.6114\n",
      "theta =  1.0770, omega:  4.6666\n",
      "theta =  1.1592, omega:  1.7458\n",
      "theta =  1.1654, omega: -0.9736\n",
      "theta =  1.1125, omega: -3.4402\n",
      "theta =  1.0017, omega: -5.2426\n",
      "theta =  0.8696, omega: -5.3885\n",
      "theta =  0.7316, omega: -5.2560\n",
      "theta =  0.6087, omega: -4.8202\n",
      "theta =  0.4718, omega: -5.9127\n",
      "theta =  0.3160, omega: -6.5580\n",
      "theta =  0.1714, omega: -4.8699\n",
      "theta =  0.0528, omega: -4.6832\n",
      "theta = -0.0572, omega: -4.1344\n",
      "theta = -0.1509, omega: -3.2809\n",
      "theta = -0.1992, omega: -0.3787\n",
      "theta = -0.1739, omega:  2.1910\n",
      "theta = -0.0913, omega:  4.4759\n",
      "theta =  0.0228, omega:  4.5173\n",
      "theta =  0.1341, omega:  4.2034\n",
      "theta =  0.2506, omega:  5.3930\n",
      "theta =  0.3979, omega:  6.1328\n",
      "theta =  0.5546, omega:  6.4079\n",
      "theta =  0.7158, omega:  6.2500\n",
      "theta =  0.8629, omega:  5.7223\n",
      "theta =  0.9968, omega:  4.9226\n",
      "theta =  1.0867, omega:  2.1002\n",
      "theta =  1.1051, omega: -0.5700\n",
      "theta =  1.0590, omega: -2.9706\n",
      "theta =  0.9571, omega: -5.1748\n",
      "theta =  0.8260, omega: -5.2409\n",
      "theta =  0.6979, omega: -5.0263\n",
      "theta =  0.5777, omega: -4.5162\n",
      "theta =  0.4522, omega: -5.5495\n",
      "theta =  0.3026, omega: -6.1561\n",
      "theta =  0.1481, omega: -6.2856\n",
      "theta = -0.0066, omega: -5.9198\n",
      "theta = -0.1439, omega: -5.1010\n",
      "theta = -0.2566, omega: -3.9157\n",
      "theta = -0.3140, omega: -0.6487\n",
      "theta = -0.2933, omega:  2.3075\n",
      "theta = -0.2024, omega:  4.9484\n",
      "theta = -0.0727, omega:  5.3012\n",
      "theta =  0.0588, omega:  5.2283\n",
      "theta =  0.1850, omega:  4.7468\n",
      "theta =  0.3162, omega:  5.7363\n",
      "theta =  0.4677, omega:  6.2691\n",
      "theta =  0.6275, omega:  6.3428\n",
      "theta =  0.7823, omega:  6.0156\n",
      "theta =  0.9261, omega:  5.3604\n",
      "theta =  1.0478, omega:  4.4698\n",
      "theta =  1.1245, omega:  1.5985\n",
      "theta =  1.1340, omega: -0.6273\n",
      "theta =  1.0889, omega: -3.0681\n",
      "theta =  0.9824, omega: -5.3126\n",
      "theta =  0.8471, omega: -5.4210\n",
      "theta =  0.7144, omega: -5.2436\n",
      "theta =  0.5894, omega: -4.7614\n",
      "theta =  0.4562, omega: -5.8060\n",
      "theta =  0.3019, omega: -6.4082\n",
      "theta =  0.1389, omega: -6.5104\n",
      "theta = -0.0192, omega: -6.1037\n",
      "theta = -0.1623, omega: -5.2335\n",
      "theta = -0.2773, omega: -3.9843\n",
      "theta = -0.3339, omega: -0.6537\n",
      "theta = -0.3130, omega:  2.3654\n",
      "theta = -0.2200, omega:  5.0613\n",
      "theta = -0.0869, omega:  5.4632\n",
      "theta =  0.0493, omega:  5.4244\n",
      "theta =  0.1797, omega:  4.9575\n",
      "theta =  0.3168, omega:  5.9487\n",
      "theta =  0.4746, omega:  6.4641\n",
      "theta =  0.6370, omega:  6.5132\n",
      "theta =  0.7959, omega:  6.1495\n",
      "theta =  0.9416, omega:  5.4587\n",
      "theta =  1.0661, omega:  4.5350\n",
      "theta =  1.1441, omega:  1.6355\n",
      "theta =  1.1524, omega: -1.0562\n",
      "theta =  1.0929, omega: -3.4968\n",
      "theta =  0.9831, omega: -5.2681\n",
      "theta =  0.8478, omega: -5.3765\n",
      "theta =  0.7180, omega: -5.2033\n",
      "theta =  0.5924, omega: -4.7276\n",
      "theta =  0.4592, omega: -5.7828\n",
      "theta =  0.3056, omega: -6.3956\n",
      "theta =  0.1444, omega: -6.5093\n",
      "theta = -0.0147, omega: -6.1179\n",
      "theta = -0.1596, omega: -5.2575\n",
      "theta = -0.2755, omega: -4.0173\n",
      "theta = -0.3341, omega: -0.6928\n",
      "theta = -0.3114, omega:  2.3275\n",
      "theta = -0.2186, omega:  5.0222\n",
      "theta = -0.0878, omega:  5.4275\n",
      "theta =  0.0468, omega:  5.3941\n",
      "theta =  0.1792, omega:  4.9378\n",
      "theta =  0.3153, omega:  5.9401\n",
      "theta =  0.4705, omega:  6.4638\n",
      "theta =  0.6340, omega:  6.5190\n",
      "theta =  0.7930, omega:  6.1605\n",
      "theta =  0.9383, omega:  5.4773\n",
      "theta =  1.0663, omega:  4.5553\n",
      "theta =  1.1434, omega:  1.6559\n",
      "theta =  1.1485, omega: -1.0330\n",
      "theta =  1.0934, omega: -3.4728\n",
      "theta =  0.9839, omega: -5.2475\n",
      "theta =  0.8507, omega: -5.3590\n",
      "theta =  0.7187, omega: -5.1877\n",
      "theta =  0.5929, omega: -4.7141\n",
      "theta =  0.4622, omega: -5.7765\n",
      "theta =  0.3075, omega: -6.3926\n",
      "theta =  0.1468, omega: -6.5133\n",
      "theta = -0.0127, omega: -6.1263\n",
      "theta = -0.1551, omega: -5.2717\n",
      "theta = -0.2736, omega: -4.0346\n",
      "theta = -0.3331, omega: -0.7129\n",
      "theta = -0.3125, omega:  2.3087\n",
      "theta = -0.2201, omega:  5.0070\n",
      "theta = -0.0884, omega:  5.4108\n",
      "theta =  0.0445, omega:  5.3818\n",
      "theta =  0.1754, omega:  4.9307\n",
      "theta =  0.3140, omega:  5.9337\n",
      "theta =  0.4688, omega:  6.4614\n",
      "theta =  0.6328, omega:  6.5230\n",
      "theta =  0.7933, omega:  6.1697\n",
      "theta =  0.9382, omega:  5.4842\n",
      "theta =  1.0650, omega:  4.5684\n",
      "theta =  1.1419, omega:  1.6655\n",
      "theta =  1.1491, omega: -1.0247\n",
      "theta =  1.0930, omega: -3.4646\n",
      "theta =  0.9843, omega: -5.2376\n",
      "theta =  0.8511, omega: -5.3516\n",
      "theta =  0.7174, omega: -5.1823\n",
      "theta =  0.5952, omega: -4.7120\n",
      "theta =  0.4614, omega: -5.7731\n",
      "theta =  0.3101, omega: -6.3960\n",
      "theta =  0.1461, omega: -6.5183\n",
      "theta = -0.0123, omega: -6.1342\n",
      "theta = -0.1587, omega: -5.2786\n",
      "theta = -0.2742, omega: -4.0461\n",
      "theta = -0.3326, omega: -0.7223\n",
      "theta = -0.3109, omega:  2.2973\n",
      "theta = -0.2203, omega:  4.9993\n",
      "theta = -0.0889, omega:  5.4061\n",
      "theta =  0.0456, omega:  5.3757\n",
      "theta =  0.1772, omega:  4.9284\n",
      "theta =  0.3133, omega:  5.9365\n",
      "theta =  0.4684, omega:  6.4657\n",
      "theta =  0.6339, omega:  6.5284\n",
      "theta =  0.7889, omega:  6.1770\n",
      "theta =  0.9392, omega:  5.4935\n",
      "theta =  1.0633, omega:  4.5743\n",
      "theta =  1.1436, omega:  1.6734\n",
      "theta =  1.1492, omega: -1.0161\n",
      "theta =  1.0928, omega: -3.4606\n",
      "theta =  0.9845, omega: -5.2348\n",
      "theta =  0.8501, omega: -5.3467\n",
      "theta =  0.7204, omega: -5.1773\n",
      "theta =  0.5947, omega: -4.7097\n",
      "theta =  0.4617, omega: -5.7762\n",
      "theta =  0.3094, omega: -6.4004\n",
      "theta =  0.1476, omega: -6.5254\n",
      "theta = -0.0126, omega: -6.1381\n",
      "theta = -0.1578, omega: -5.2851\n",
      "theta = -0.2724, omega: -4.0500\n",
      "theta = -0.3328, omega: -0.7267\n",
      "theta = -0.3117, omega:  2.2951\n",
      "theta = -0.2212, omega:  4.9947\n",
      "theta = -0.0915, omega:  5.4041\n",
      "theta =  0.0466, omega:  5.3757\n",
      "theta =  0.1750, omega:  4.9308\n",
      "theta =  0.3112, omega:  5.9371\n",
      "theta =  0.4681, omega:  6.4694\n",
      "theta =  0.6323, omega:  6.5326\n",
      "theta =  0.7902, omega:  6.1804\n",
      "theta =  0.9390, omega:  5.4971\n",
      "theta =  1.0642, omega:  4.5786\n",
      "theta =  1.1432, omega:  1.6772\n",
      "theta =  1.1505, omega: -1.0157\n",
      "theta =  1.0947, omega: -3.4567\n",
      "theta =  0.9849, omega: -5.2315\n",
      "theta =  0.8506, omega: -5.3471\n",
      "theta =  0.7182, omega: -5.1785\n",
      "theta =  0.5971, omega: -4.7105\n",
      "theta =  0.4628, omega: -5.7755\n",
      "theta =  0.3094, omega: -6.4006\n",
      "theta =  0.1487, omega: -6.5281\n",
      "theta =  0.0110, omega: -4.3208\n",
      "theta = -0.0638, omega: -1.8523\n",
      "theta = -0.0824, omega:  0.5743\n",
      "theta = -0.0406, omega:  2.6889\n",
      "theta =  0.0515, omega:  4.5216\n",
      "theta =  0.1597, omega:  4.1219\n",
      "theta =  0.2760, omega:  5.2341\n",
      "theta =  0.4181, omega:  5.9172\n",
      "theta =  0.5674, omega:  6.1563\n",
      "theta =  0.7216, omega:  5.9783\n",
      "theta =  0.8639, omega:  5.4531\n",
      "theta =  0.9922, omega:  4.6686\n",
      "theta =  1.0743, omega:  1.8721\n",
      "theta =  1.0850, omega: -0.7602\n",
      "theta =  1.0385, omega: -3.1199\n",
      "theta =  0.9543, omega: -3.4522\n",
      "theta =  0.8495, omega: -4.9830\n",
      "theta =  0.7256, omega: -4.8321\n",
      "theta =  0.6097, omega: -4.4042\n",
      "theta =  0.4851, omega: -5.5313\n",
      "theta =  0.3369, omega: -6.2384\n",
      "theta =  0.1778, omega: -6.4561\n",
      "theta =  0.0183, omega: -6.1694\n",
      "theta = -0.1274, omega: -5.4095\n",
      "theta = -0.2502, omega: -4.2540\n",
      "theta = -0.3138, omega: -0.9886\n",
      "theta = -0.2997, omega:  2.0099\n",
      "theta = -0.2158, omega:  4.6963\n",
      "theta = -0.0913, omega:  5.1097\n",
      "theta =  0.0351, omega:  5.1131\n",
      "theta =  0.1650, omega:  5.1706\n",
      "theta =  0.3069, omega:  6.1916\n",
      "theta =  0.4713, omega:  6.7171\n",
      "theta =  0.6411, omega:  6.7559\n",
      "theta =  0.8048, omega:  6.3702\n",
      "theta =  0.9566, omega:  5.6483\n",
      "theta =  1.0846, omega:  4.6907\n",
      "theta =  1.1885, omega:  3.5938\n",
      "theta =  1.2424, omega:  0.5855\n",
      "theta =  1.2211, omega: -2.0864\n",
      "theta =  1.1389, omega: -4.5652\n",
      "theta =  1.0173, omega: -4.9781\n",
      "theta =  0.8914, omega: -5.1687\n",
      "theta =  0.7633, omega: -5.1002\n",
      "theta =  0.6401, omega: -4.7430\n",
      "theta =  0.5043, omega: -5.9235\n",
      "theta =  0.3466, omega: -6.6564\n",
      "theta =  0.1768, omega: -6.8748\n",
      "theta =  0.0044, omega: -6.5561\n",
      "theta = -0.1453, omega: -5.7329\n",
      "theta = -0.2755, omega: -4.4923\n",
      "theta = -0.3470, omega: -1.1306\n",
      "theta = -0.3354, omega:  1.9838\n",
      "theta = -0.2498, omega:  4.7713\n",
      "theta = -0.1246, omega:  5.2839\n",
      "theta =  0.0112, omega:  5.3661\n",
      "theta =  0.1432, omega:  5.0292\n",
      "theta =  0.2825, omega:  6.1317\n",
      "theta =  0.4433, omega:  6.7374\n",
      "theta =  0.6157, omega:  6.8472\n",
      "theta =  0.7831, omega:  6.5139\n",
      "theta =  0.9375, omega:  5.8288\n",
      "theta =  1.0745, omega:  4.8921\n",
      "theta =  1.1576, omega:  1.9666\n",
      "theta =  1.1721, omega: -0.7825\n",
      "theta =  1.1194, omega: -3.2656\n",
      "theta =  1.0160, omega: -5.0887\n",
      "theta =  0.8851, omega: -5.2718\n",
      "theta =  0.7548, omega: -5.1836\n",
      "theta =  0.6294, omega: -4.8013\n",
      "theta =  0.5169, omega: -4.1285\n",
      "theta =  0.4019, omega: -5.0182\n",
      "theta =  0.2694, omega: -5.5176\n",
      "theta =  0.1524, omega: -3.7590\n",
      "theta =  0.0612, omega: -3.5905\n",
      "theta = -0.0253, omega: -3.1471\n",
      "theta = -0.0711, omega: -0.6487\n",
      "theta = -0.0579, omega:  1.5785\n",
      "theta =  0.0050, omega:  3.5538\n",
      "theta =  0.0991, omega:  3.8200\n",
      "theta =  0.2086, omega:  5.1426\n",
      "theta =  0.3505, omega:  6.0272\n",
      "theta =  0.5081, omega:  6.4449\n",
      "theta =  0.6698, omega:  6.4001\n",
      "theta =  0.8235, omega:  5.9698\n",
      "theta =  0.9657, omega:  5.2316\n",
      "theta =  1.0831, omega:  4.2808\n",
      "theta =  1.1550, omega:  1.3702\n",
      "theta =  1.1547, omega: -1.3021\n",
      "theta =  1.0935, omega: -3.7378\n",
      "theta =  0.9875, omega: -4.5792\n",
      "theta =  0.8707, omega: -4.7366\n",
      "theta =  0.7531, omega: -4.6451\n",
      "theta =  0.6407, omega: -4.2945\n",
      "theta =  0.5165, omega: -5.5088\n",
      "theta =  0.3672, omega: -6.3038\n",
      "theta =  0.2053, omega: -6.6131\n",
      "theta =  0.0413, omega: -6.4060\n",
      "theta = -0.1113, omega: -5.7019\n",
      "theta = -0.2407, omega: -4.5762\n",
      "theta = -0.3143, omega: -1.3202\n",
      "theta = -0.3063, omega:  1.7249\n",
      "theta = -0.2273, omega:  4.4496\n",
      "theta = -0.1101, omega:  4.9239\n",
      "theta =  0.0122, omega:  4.9984\n",
      "theta =  0.1360, omega:  4.6780\n",
      "theta =  0.2668, omega:  5.8258\n",
      "theta =  0.4231, omega:  6.4965\n",
      "theta =  0.5892, omega:  6.6808\n",
      "theta =  0.7525, omega:  6.4219\n",
      "theta =  0.9061, omega:  5.8043\n",
      "theta =  1.0403, omega:  4.9254\n",
      "theta =  1.1281, omega:  2.0437\n",
      "theta =  1.1432, omega: -0.6800\n",
      "theta =  1.0951, omega: -3.1306\n",
      "theta =  0.9890, omega: -5.3845\n",
      "theta =  0.8522, omega: -5.4988\n",
      "theta =  0.7162, omega: -5.3230\n",
      "theta =  0.5902, omega: -4.8410\n",
      "theta =  0.4558, omega: -5.8796\n",
      "theta =  0.2991, omega: -6.4712\n",
      "theta =  0.1364, omega: -6.5561\n",
      "theta = -0.0260, omega: -6.1299\n",
      "theta = -0.1683, omega: -5.2377\n",
      "theta = -0.2823, omega: -3.9702\n",
      "theta = -0.3397, omega: -0.6236\n",
      "theta = -0.3178, omega:  2.4098\n",
      "theta = -0.2229, omega:  5.1180\n",
      "theta = -0.0886, omega:  5.5249\n",
      "theta =  0.0494, omega:  5.4870\n",
      "theta =  0.1827, omega:  5.0211\n",
      "theta =  0.3200, omega:  6.0049\n",
      "theta =  0.4782, omega:  6.5090\n",
      "theta =  0.6418, omega:  6.5449\n",
      "theta =  0.8018, omega:  6.1664\n",
      "theta =  0.9457, omega:  5.4630\n",
      "theta =  1.0723, omega:  4.5297\n",
      "theta =  1.1505, omega:  1.6237\n",
      "theta =  1.1787, omega:  0.5897\n",
      "theta =  1.1781, omega: -0.2578\n",
      "theta =  1.1429, omega: -2.7762\n",
      "theta =  1.0428, omega: -5.1198\n",
      "theta =  0.9118, omega: -5.3479\n",
      "theta =  0.7792, omega: -5.3082\n",
      "theta =  0.6490, omega: -4.9745\n",
      "theta =  0.5079, omega: -6.1649\n",
      "theta =  0.3441, omega: -6.8925\n",
      "theta =  0.1662, omega: -7.0877\n",
      "theta = -0.0043, omega: -6.7296\n",
      "theta = -0.1618, omega: -5.8546\n",
      "theta = -0.2943, omega: -4.5567\n",
      "theta = -0.3669, omega: -1.1367\n",
      "theta = -0.3538, omega:  2.0354\n",
      "theta = -0.2672, omega:  4.8758\n",
      "theta = -0.1371, omega:  5.4336\n",
      "theta =  0.0011, omega:  5.5527\n",
      "theta =  0.1368, omega:  5.2283\n",
      "theta =  0.2829, omega:  6.3308\n",
      "theta =  0.4496, omega:  6.9194\n",
      "theta =  0.6255, omega:  7.0063\n",
      "theta =  0.7950, omega:  6.6413\n",
      "theta =  0.9532, omega:  5.9229\n",
      "theta =  1.0903, omega:  4.9579\n",
      "theta =  1.1766, omega:  2.0020\n",
      "theta =  1.1914, omega: -0.7712\n",
      "theta =  1.1622, omega: -1.4430\n",
      "theta =  1.0937, omega: -3.8809\n",
      "theta =  0.9881, omega: -4.7234\n",
      "theta =  0.8694, omega: -4.8726\n",
      "theta =  0.7484, omega: -4.7701\n",
      "theta =  0.6325, omega: -4.3971\n",
      "theta =  0.5059, omega: -5.5809\n",
      "theta =  0.3559, omega: -6.3425\n",
      "theta =  0.1933, omega: -6.6113\n",
      "theta =  0.0549, omega: -4.5432\n",
      "theta = -0.0540, omega: -4.0055\n",
      "theta = -0.1456, omega: -3.1759\n",
      "theta = -0.1898, omega: -0.3043\n",
      "theta = -0.1640, omega:  2.2278\n",
      "theta = -0.0805, omega:  4.4805\n",
      "theta =  0.0339, omega:  4.4831\n",
      "theta =  0.1434, omega:  4.1367\n",
      "theta =  0.2629, omega:  5.3032\n",
      "theta =  0.4036, omega:  6.0295\n",
      "theta =  0.5610, omega:  6.2961\n",
      "theta =  0.7150, omega:  6.1381\n",
      "theta =  0.8619, omega:  5.6175\n",
      "theta =  0.9934, omega:  4.8280\n",
      "theta =  1.0781, omega:  2.0221\n",
      "theta =  1.0950, omega: -0.6331\n",
      "theta =  1.0485, omega: -3.0161\n",
      "theta =  0.9464, omega: -5.1984\n",
      "theta =  0.8129, omega: -5.2415\n",
      "theta =  0.6856, omega: -4.9992\n",
      "theta =  0.5690, omega: -4.4638\n",
      "theta =  0.4420, omega: -5.4694\n",
      "theta =  0.2966, omega: -6.0551\n",
      "theta =  0.1416, omega: -6.1693\n",
      "theta = -0.0047, omega: -5.8005\n",
      "theta = -0.1435, omega: -4.9880\n",
      "theta = -0.2528, omega: -3.8164\n",
      "theta = -0.3080, omega: -0.5721\n",
      "theta = -0.2843, omega:  2.3563\n",
      "theta = -0.1921, omega:  4.9680\n",
      "theta = -0.0623, omega:  5.2919\n",
      "theta =  0.0691, omega:  5.1902\n",
      "theta =  0.1922, omega:  4.6875\n",
      "theta =  0.3235, omega:  5.6573\n",
      "theta =  0.4738, omega:  6.1778\n",
      "theta =  0.6256, omega:  6.2511\n",
      "theta =  0.7818, omega:  5.9246\n",
      "theta =  0.9216, omega:  5.2748\n",
      "theta =  1.0430, omega:  4.3968\n",
      "theta =  1.1400, omega:  3.3710\n",
      "theta =  1.1878, omega:  0.4316\n",
      "theta =  1.1657, omega: -2.1608\n",
      "theta =  1.0794, omega: -4.5681\n",
      "theta =  0.9618, omega: -4.8882\n",
      "theta =  0.8397, omega: -4.9782\n",
      "theta =  0.7148, omega: -4.8060\n",
      "theta =  0.6001, omega: -4.3522\n",
      "theta =  0.4772, omega: -5.4577\n",
      "theta =  0.3321, omega: -6.1446\n",
      "theta =  0.1739, omega: -6.3518\n",
      "theta =  0.0170, omega: -6.0627\n",
      "theta = -0.1262, omega: -5.3079\n",
      "theta = -0.2423, omega: -4.1657\n",
      "theta = -0.3091, omega: -0.9201\n",
      "theta = -0.2922, omega:  2.0536\n",
      "theta = -0.2079, omega:  4.7138\n",
      "theta = -0.0850, omega:  5.1036\n",
      "theta =  0.0440, omega:  5.0790\n",
      "theta =  0.1672, omega:  4.6586\n",
      "theta =  0.2956, omega:  5.7110\n",
      "theta =  0.4486, omega:  6.3046\n",
      "theta =  0.6075, omega:  6.4328\n",
      "theta =  0.7663, omega:  6.1396\n",
      "theta =  0.9131, omega:  5.5102\n",
      "theta =  1.0391, omega:  4.6384\n",
      "theta =  1.1189, omega:  1.7690\n",
      "theta =  1.1296, omega: -0.9096\n",
      "theta =  1.0766, omega: -3.3272\n",
      "theta =  0.9704, omega: -5.0795\n",
      "theta =  0.8426, omega: -5.1769\n",
      "theta =  0.7138, omega: -4.9985\n",
      "theta =  0.5952, omega: -4.5297\n",
      "theta =  0.4663, omega: -5.6072\n",
      "theta =  0.3176, omega: -6.2527\n",
      "theta =  0.1565, omega: -6.4125\n",
      "theta =  0.0011, omega: -6.0713\n",
      "theta = -0.1414, omega: -5.2650\n",
      "theta = -0.2589, omega: -4.0745\n",
      "theta = -0.3196, omega: -0.7939\n",
      "theta = -0.3020, omega:  2.1969\n",
      "theta = -0.2126, omega:  4.8722\n",
      "theta = -0.0854, omega:  5.2614\n",
      "theta =  0.0460, omega:  5.2276\n",
      "theta =  0.1729, omega:  4.7855\n",
      "theta =  0.3069, omega:  5.8115\n",
      "theta =  0.4594, omega:  6.3669\n",
      "theta =  0.6193, omega:  6.4605\n",
      "theta =  0.7812, omega:  6.1347\n",
      "theta =  0.9257, omega:  5.4780\n",
      "theta =  1.0507, omega:  4.5830\n",
      "theta =  1.1273, omega:  1.7003\n",
      "theta =  1.1373, omega: -0.9807\n",
      "theta =  1.0820, omega: -3.4064\n",
      "theta =  0.9753, omega: -5.1639\n",
      "theta =  0.8431, omega: -5.2660\n",
      "theta =  0.7141, omega: -5.0864\n",
      "theta =  0.5917, omega: -4.6134\n",
      "theta =  0.4631, omega: -5.6771\n",
      "theta =  0.3183, omega: -5.8538\n",
      "theta =  0.1683, omega: -6.0389\n",
      "theta =  0.0204, omega: -5.7553\n",
      "theta = -0.1159, omega: -5.0276\n",
      "theta = -0.2284, omega: -3.9349\n",
      "theta = -0.2880, omega: -0.7526\n",
      "theta = -0.2700, omega:  2.1383\n",
      "theta = -0.1832, omega:  4.7188\n",
      "theta = -0.0604, omega:  5.0298\n",
      "theta =  0.0648, omega:  4.9381\n",
      "theta =  0.1834, omega:  4.4603\n",
      "theta =  0.3089, omega:  5.4769\n",
      "theta =  0.4553, omega:  6.0489\n",
      "theta =  0.6080, omega:  6.1808\n",
      "theta =  0.7593, omega:  5.9074\n",
      "theta =  0.9010, omega:  5.3058\n",
      "theta =  1.0237, omega:  4.4640\n",
      "theta =  1.0978, omega:  1.6320\n",
      "theta =  1.1053, omega: -0.9997\n",
      "theta =  1.0520, omega: -3.3797\n",
      "theta =  0.9451, omega: -5.0894\n",
      "theta =  0.8164, omega: -5.1326\n",
      "theta =  0.6878, omega: -4.8965\n",
      "theta =  0.5735, omega: -4.3737\n",
      "theta =  0.4503, omega: -5.4036\n",
      "theta =  0.3054, omega: -6.0189\n",
      "theta =  0.1538, omega: -6.1593\n",
      "theta =  0.0025, omega: -5.8206\n",
      "theta = -0.1336, omega: -5.0340\n",
      "theta = -0.2469, omega: -3.8845\n",
      "theta = -0.3040, omega: -0.6554\n",
      "theta = -0.2795, omega:  2.2686\n",
      "theta = -0.1914, omega:  4.8766\n",
      "theta = -0.0640, omega:  5.2058\n",
      "theta =  0.0661, omega:  5.1160\n",
      "theta =  0.1880, omega:  4.6251\n",
      "theta =  0.3162, omega:  5.6202\n",
      "theta =  0.4635, omega:  6.1615\n",
      "theta =  0.6214, omega:  6.2540\n",
      "theta =  0.7745, omega:  5.9442\n",
      "theta =  0.9144, omega:  5.3096\n",
      "theta =  1.0398, omega:  4.4385\n",
      "theta =  1.1128, omega:  1.5863\n",
      "theta =  1.1190, omega: -1.0579\n",
      "theta =  1.0602, omega: -3.4540\n",
      "theta =  0.9534, omega: -5.1775\n",
      "theta =  0.8241, omega: -5.2355\n",
      "theta =  0.6943, omega: -5.0072\n",
      "theta =  0.5741, omega: -4.4883\n",
      "theta =  0.4502, omega: -5.5146\n",
      "theta =  0.3022, omega: -6.1158\n",
      "theta =  0.1475, omega: -6.2386\n",
      "theta = -0.0046, omega: -5.8723\n",
      "theta = -0.1408, omega: -5.0608\n",
      "theta = -0.2562, omega: -3.8802\n",
      "theta = -0.3120, omega: -0.6243\n",
      "theta = -0.2900, omega:  2.3208\n",
      "theta = -0.1984, omega:  4.9486\n",
      "theta = -0.0462, omega:  7.1128\n",
      "theta =  0.1278, omega:  6.8269\n",
      "theta =  0.3126, omega:  7.8403\n",
      "theta =  0.5167, omega:  8.2379\n",
      "theta =  0.7231, omega:  8.0628\n",
      "theta =  0.9153, omega:  7.4165\n",
      "theta =  1.0903, omega:  6.4345\n",
      "theta =  1.2340, omega:  5.2468\n",
      "theta =  1.3290, omega:  2.1213\n",
      "theta =  1.3428, omega: -0.7997\n",
      "theta =  1.2890, omega: -3.4578\n",
      "theta =  1.1761, omega: -5.4903\n",
      "theta =  1.0326, omega: -5.9096\n",
      "theta =  0.8819, omega: -6.0748\n",
      "theta =  0.7345, omega: -5.9353\n",
      "theta =  0.5888, omega: -5.4533\n",
      "theta =  0.4396, omega: -6.4530\n",
      "theta =  0.2707, omega: -6.9626\n",
      "theta =  0.0967, omega: -6.9293\n",
      "theta = -0.0708, omega: -6.3604\n",
      "theta = -0.2162, omega: -5.3064\n",
      "theta = -0.3344, omega: -3.8847\n",
      "theta = -0.3874, omega: -0.3980\n",
      "theta = -0.3563, omega:  2.7350\n",
      "theta = -0.2540, omega:  5.5359\n",
      "theta = -0.1081, omega:  6.0051\n",
      "theta =  0.0439, omega:  5.9883\n",
      "theta =  0.1878, omega:  5.5039\n",
      "theta =  0.3401, omega:  6.4331\n",
      "theta =  0.5030, omega:  6.8569\n",
      "theta =  0.6775, omega:  6.7959\n",
      "theta =  0.8429, omega:  6.3206\n",
      "theta =  0.9915, omega:  5.5306\n",
      "theta =  1.1159, omega:  4.5258\n",
      "theta =  1.1924, omega:  1.5583\n",
      "theta =  1.1961, omega: -1.1796\n",
      "theta =  1.1363, omega: -3.6723\n",
      "theta =  1.0320, omega: -4.5845\n",
      "theta =  0.9154, omega: -4.8188\n",
      "theta =  0.7918, omega: -4.8193\n",
      "theta =  0.6765, omega: -4.5489\n",
      "theta =  0.5437, omega: -5.8354\n",
      "theta =  0.3865, omega: -6.6888\n",
      "theta =  0.2156, omega: -7.0256\n",
      "theta =  0.0392, omega: -6.8129\n",
      "theta = -0.1223, omega: -6.0741\n",
      "theta = -0.2364, omega: -3.0675\n",
      "theta = -0.2759, omega:  0.0706\n",
      "theta = -0.2389, omega:  2.8133\n",
      "theta = -0.1371, omega:  5.2487\n",
      "theta = -0.0048, omega:  5.3759\n",
      "theta =  0.1284, omega:  5.0758\n",
      "theta =  0.2706, omega:  6.2164\n",
      "theta =  0.4360, omega:  6.8478\n",
      "theta =  0.6099, omega:  6.9734\n",
      "theta =  0.7788, omega:  6.6457\n",
      "theta =  0.9372, omega:  5.9565\n",
      "theta =  1.0760, omega:  5.0129\n",
      "theta =  1.1656, omega:  2.0763\n",
      "theta =  1.1801, omega: -0.6942\n",
      "theta =  1.1333, omega: -3.1921\n",
      "theta =  1.0293, omega: -5.0415\n",
      "theta =  0.8992, omega: -5.2474\n",
      "theta =  0.7703, omega: -5.1882\n",
      "theta =  0.6447, omega: -4.8440\n",
      "theta =  0.5035, omega: -6.0247\n",
      "theta =  0.3449, omega: -6.7540\n",
      "theta =  0.1718, omega: -6.9610\n",
      "theta =  0.0001, omega: -6.6260\n",
      "theta = -0.1559, omega: -5.7787\n",
      "theta = -0.2841, omega: -4.5151\n",
      "theta = -0.3548, omega: -1.1289\n",
      "theta = -0.3432, omega:  2.0072\n",
      "theta = -0.2552, omega:  4.8195\n",
      "theta = -0.1288, omega:  5.3497\n",
      "theta =  0.0079, omega:  5.4441\n",
      "theta =  0.1399, omega:  5.1141\n",
      "theta =  0.2829, omega:  6.2151\n",
      "theta =  0.4470, omega:  6.8124\n",
      "theta =  0.6177, omega:  6.9114\n",
      "theta =  0.7879, omega:  6.5634\n",
      "theta =  0.9427, omega:  5.8640\n",
      "theta =  1.0768, omega:  4.9154\n",
      "theta =  1.1665, omega:  1.9774\n",
      "theta =  1.1786, omega: -0.7806\n",
      "theta =  1.1276, omega: -3.2714\n",
      "theta =  1.0231, omega: -5.1109\n",
      "theta =  0.8930, omega: -5.3064\n",
      "theta =  0.7589, omega: -5.2299\n",
      "theta =  0.6333, omega: -4.8577\n",
      "theta =  0.4964, omega: -6.0174\n",
      "theta =  0.3365, omega: -6.7237\n",
      "theta =  0.1644, omega: -6.9066\n",
      "theta = -0.0043, omega: -6.5516\n",
      "theta = -0.1585, omega: -5.6949\n",
      "theta = -0.2871, omega: -4.4225\n",
      "theta = -0.3543, omega: -1.0376\n",
      "theta = -0.3389, omega:  2.0828\n",
      "theta = -0.2523, omega:  4.8811\n",
      "theta = -0.1236, omega:  5.3947\n",
      "theta =  0.0140, omega:  5.4681\n",
      "theta =  0.1706, omega:  6.9345\n",
      "theta =  0.3535, omega:  7.8149\n",
      "theta =  0.5558, omega:  8.0961\n",
      "theta =  0.7573, omega:  7.8286\n",
      "theta =  0.9434, omega:  7.1233\n",
      "theta =  1.1093, omega:  6.1093\n",
      "theta =  1.2474, omega:  4.9135\n",
      "theta =  1.3316, omega:  1.7909\n",
      "theta =  1.3387, omega: -1.0985\n",
      "theta =  1.2777, omega: -3.7411\n",
      "theta =  1.1752, omega: -4.3703\n",
      "theta =  1.0605, omega: -4.8451\n",
      "theta =  0.9367, omega: -5.1177\n",
      "theta =  0.8076, omega: -5.1443\n",
      "theta =  0.6814, omega: -4.8903\n",
      "theta =  0.5649, omega: -4.3461\n",
      "theta =  0.4420, omega: -5.3524\n",
      "theta =  0.2996, omega: -5.9486\n",
      "theta =  0.1739, omega: -4.2582\n",
      "theta =  0.0674, omega: -4.1148\n",
      "theta = -0.0296, omega: -3.6542\n",
      "theta = -0.0902, omega: -1.1028\n",
      "theta = -0.0872, omega:  1.2497\n",
      "theta = -0.0287, omega:  3.3307\n",
      "theta =  0.0702, omega:  4.6317\n",
      "theta =  0.1822, omega:  4.1604\n",
      "theta =  0.2998, omega:  5.2042\n",
      "theta =  0.4375, omega:  5.8219\n",
      "theta =  0.5878, omega:  6.0086\n",
      "theta =  0.7344, omega:  5.8003\n",
      "theta =  0.8731, omega:  5.2539\n",
      "theta =  0.9946, omega:  4.4623\n",
      "theta =  1.0894, omega:  3.0475\n",
      "theta =  1.1323, omega:  0.1880\n",
      "theta =  1.1041, omega: -2.3044\n",
      "theta =  1.0169, omega: -4.6124\n",
      "theta =  0.8975, omega: -4.8191\n",
      "theta =  0.7760, omega: -4.7859\n",
      "theta =  0.6604, omega: -4.4842\n",
      "theta =  0.5322, omega: -5.7387\n",
      "theta =  0.3781, omega: -6.5640\n",
      "theta =  0.2100, omega: -6.8820\n",
      "theta =  0.0375, omega: -6.6609\n",
      "theta = -0.1216, omega: -5.9295\n",
      "theta = -0.2563, omega: -4.7581\n",
      "theta = -0.3327, omega: -1.4410\n",
      "theta = -0.3290, omega:  1.6741\n",
      "theta = -0.2510, omega:  4.4637\n",
      "theta = -0.1321, omega:  5.0041\n",
      "theta = -0.0054, omega:  5.1360\n",
      "theta =  0.1216, omega:  4.8620\n",
      "theta =  0.2584, omega:  6.0358\n",
      "theta =  0.4182, omega:  6.7167\n",
      "theta =  0.5908, omega:  6.8953\n",
      "theta =  0.7591, omega:  6.6188\n",
      "theta =  0.9178, omega:  5.9742\n",
      "theta =  1.0572, omega:  5.0648\n",
      "theta =  1.1479, omega:  2.1484\n",
      "theta =  1.1640, omega: -0.6013\n",
      "theta =  1.1186, omega: -3.0830\n",
      "theta =  1.0125, omega: -5.3753\n",
      "theta =  0.8769, omega: -5.5345\n",
      "theta =  0.7380, omega: -5.4085\n",
      "theta =  0.6062, omega: -4.9749\n",
      "theta =  0.4696, omega: -6.0557\n",
      "theta =  0.3091, omega: -6.6772\n",
      "theta =  0.1382, omega: -6.7817\n",
      "theta = -0.0260, omega: -6.3546\n",
      "theta = -0.1736, omega: -5.4463\n",
      "theta = -0.2942, omega: -4.1449\n",
      "theta = -0.3547, omega: -0.7506\n",
      "theta = -0.3350, omega:  2.3390\n",
      "theta = -0.2419, omega:  5.1058\n",
      "theta = -0.1077, omega:  5.5679\n",
      "theta =  0.0332, omega:  5.5826\n",
      "theta =  0.1690, omega:  5.1608\n",
      "theta =  0.3124, omega:  6.1726\n",
      "theta =  0.4729, omega:  6.6914\n",
      "theta =  0.6415, omega:  6.7247\n",
      "theta =  0.8051, omega:  6.3383\n",
      "theta =  0.9564, omega:  5.6178\n",
      "theta =  1.0851, omega:  4.6639\n",
      "theta =  1.1666, omega:  1.7298\n",
      "theta =  1.1745, omega: -0.9957\n",
      "theta =  1.1163, omega: -3.4687\n",
      "theta =  1.0058, omega: -5.2762\n",
      "theta =  0.8714, omega: -5.4319\n",
      "theta =  0.7372, omega: -5.3051\n",
      "theta =  0.6090, omega: -4.8738\n",
      "theta =  0.4743, omega: -5.9672\n",
      "theta =  0.3149, omega: -6.6089\n",
      "theta =  0.1468, omega: -6.7342\n",
      "theta = -0.0174, omega: -6.3360\n",
      "theta = -0.1653, omega: -5.4512\n",
      "theta = -0.2869, omega: -4.1758\n",
      "theta = -0.3497, omega: -0.8047\n",
      "theta = -0.3288, omega:  2.2712\n",
      "theta = -0.2369, omega:  5.0255\n",
      "theta = -0.1067, omega:  5.4839\n",
      "theta =  0.0340, omega:  5.5010\n",
      "theta =  0.1664, omega:  5.0821\n",
      "theta =  0.3050, omega:  6.1101\n",
      "theta =  0.4685, omega:  6.6454\n",
      "theta =  0.6337, omega:  6.7012\n",
      "theta =  0.7964, omega:  6.3294\n",
      "theta =  0.9497, omega:  5.6228\n",
      "theta =  1.0799, omega:  4.6792\n",
      "theta =  1.1568, omega:  1.7559\n",
      "theta =  1.1663, omega: -0.9662\n",
      "theta =  1.1347, omega: -1.6002\n",
      "theta =  1.0630, omega: -3.9893\n",
      "theta =  0.9564, omega: -4.7751\n",
      "theta =  0.8332, omega: -4.8562\n",
      "theta =  0.7149, omega: -4.6803\n",
      "theta =  0.6020, omega: -4.2303\n",
      "theta =  0.4838, omega: -5.3471\n",
      "theta =  0.3376, omega: -6.0534\n",
      "theta =  0.1819, omega: -6.2896\n",
      "theta =  0.0284, omega: -6.0323\n",
      "theta = -0.1166, omega: -5.3111\n",
      "theta = -0.2362, omega: -4.2004\n",
      "theta = -0.2999, omega: -0.9807\n",
      "theta = -0.2850, omega:  1.9759\n",
      "theta = -0.2019, omega:  4.6207\n",
      "theta = -0.0832, omega:  4.9991\n",
      "theta =  0.0466, omega:  4.9762\n",
      "theta =  0.1643, omega:  4.5639\n",
      "theta =  0.2930, omega:  5.6315\n",
      "theta =  0.4411, omega:  6.2448\n",
      "theta =  0.6002, omega:  6.3934\n",
      "theta =  0.7575, omega:  6.1245\n",
      "theta =  0.9050, omega:  5.5139\n",
      "theta =  1.0319, omega:  4.6539\n",
      "theta =  1.1108, omega:  1.7984\n",
      "theta =  1.1204, omega: -0.8724\n",
      "theta =  1.0700, omega: -3.2828\n",
      "theta =  0.9655, omega: -5.0312\n",
      "theta =  0.8380, omega: -5.1194\n",
      "theta =  0.7112, omega: -4.9362\n",
      "theta =  0.5938, omega: -4.4662\n",
      "theta =  0.4674, omega: -5.5450\n",
      "theta =  0.3222, omega: -6.1979\n",
      "theta =  0.1625, omega: -6.3694\n",
      "theta =  0.0045, omega: -6.0440\n",
      "theta = -0.1351, omega: -5.2555\n",
      "theta = -0.2540, omega: -4.0813\n",
      "theta = -0.3136, omega: -0.8138\n",
      "theta = -0.2968, omega:  2.1639\n",
      "theta = -0.2091, omega:  4.8305\n",
      "theta = -0.0821, omega:  5.2145\n",
      "theta =  0.0459, omega:  5.1786\n",
      "theta =  0.1716, omega:  4.7359\n",
      "theta =  0.3053, omega:  5.7638\n",
      "theta =  0.4574, omega:  6.3308\n",
      "theta =  0.6179, omega:  6.4296\n",
      "theta =  0.7741, omega:  6.1172\n",
      "theta =  0.9206, omega:  5.4708\n",
      "theta =  1.0471, omega:  4.5825\n",
      "theta =  1.1272, omega:  1.7081\n",
      "theta =  1.1321, omega: -0.9672\n",
      "theta =  1.0788, omega: -3.3901\n",
      "theta =  0.9714, omega: -5.1441\n",
      "theta =  0.8424, omega: -5.2396\n",
      "theta =  0.7133, omega: -5.0571\n",
      "theta =  0.5906, omega: -4.5784\n",
      "theta =  0.4635, omega: -5.6412\n",
      "theta =  0.3116, omega: -6.2727\n",
      "theta =  0.1536, omega: -6.4160\n",
      "theta = -0.0027, omega: -6.0587\n",
      "theta = -0.1473, omega: -5.2344\n",
      "theta = -0.2614, omega: -4.0324\n",
      "theta = -0.3245, omega: -0.7426\n",
      "theta = -0.3030, omega:  2.2502\n",
      "theta = -0.2117, omega:  4.9232\n",
      "theta = -0.0845, omega:  5.3107\n",
      "theta =  0.0494, omega:  5.2702\n",
      "theta =  0.1757, omega:  4.8204\n",
      "theta =  0.3107, omega:  5.8328\n",
      "theta =  0.4644, omega:  6.3751\n",
      "theta =  0.6199, omega:  5.9998\n",
      "theta =  0.7663, omega:  5.7081\n",
      "theta =  0.9023, omega:  5.1012\n",
      "theta =  1.0181, omega:  4.2682\n",
      "theta =  1.0902, omega:  1.4490\n",
      "theta =  1.0941, omega: -1.1502\n",
      "theta =  1.0374, omega: -3.5061\n",
      "theta =  0.9258, omega: -5.1825\n",
      "theta =  0.7973, omega: -5.1842\n",
      "theta =  0.6682, omega: -4.9043\n",
      "theta =  0.5535, omega: -4.3251\n",
      "theta =  0.4331, omega: -5.3045\n",
      "theta =  0.2921, omega: -5.8743\n",
      "theta =  0.1420, omega: -5.9806\n",
      "theta = -0.0016, omega: -5.6219\n",
      "theta = -0.1335, omega: -4.8338\n",
      "theta = -0.2411, omega: -3.6946\n",
      "theta = -0.2952, omega: -0.4917\n",
      "theta = -0.2693, omega:  2.3838\n",
      "theta = -0.1771, omega:  4.9498\n",
      "theta = -0.0500, omega:  5.2293\n",
      "theta =  0.0793, omega:  5.0900\n",
      "theta =  0.2012, omega:  4.5557\n",
      "theta =  0.3298, omega:  5.5107\n",
      "theta =  0.4726, omega:  6.0246\n",
      "theta =  0.6278, omega:  6.1025\n",
      "theta =  0.7744, omega:  5.7898\n",
      "theta =  0.9128, omega:  5.1622\n",
      "theta =  1.0326, omega:  4.3048\n",
      "theta =  1.1021, omega:  1.4666\n",
      "theta =  1.1063, omega: -1.1492\n",
      "theta =  1.0481, omega: -3.5236\n",
      "theta =  0.9363, omega: -5.2197\n",
      "theta =  0.8068, omega: -5.2424\n",
      "theta =  0.6777, omega: -4.9789\n",
      "theta =  0.5358, omega: -6.2483\n",
      "theta =  0.3680, omega: -7.0486\n",
      "theta =  0.1889, omega: -7.3094\n",
      "theta =  0.0103, omega: -6.9978\n",
      "theta = -0.1567, omega: -6.1506\n",
      "theta = -0.2924, omega: -4.8535\n",
      "theta = -0.3733, omega: -1.4090\n",
      "theta = -0.3662, omega:  1.8178\n",
      "theta = -0.2841, omega:  4.7135\n",
      "theta = -0.1582, omega:  5.3390\n",
      "theta = -0.0225, omega:  5.5291\n",
      "theta =  0.1176, omega:  5.2789\n",
      "theta =  0.2618, omega:  6.4461\n",
      "theta =  0.4339, omega:  7.0888\n",
      "theta =  0.6128, omega:  7.2084\n",
      "theta =  0.7899, omega:  6.8598\n",
      "theta =  0.9556, omega:  6.1411\n",
      "theta =  1.0937, omega:  5.1653\n",
      "theta =  1.1851, omega:  2.1985\n",
      "theta =  1.2287, omega:  1.0957\n",
      "theta =  1.2180, omega: -1.6232\n",
      "theta =  1.1484, omega: -4.1211\n",
      "theta =  1.0362, omega: -4.5710\n",
      "theta =  0.9228, omega: -4.8204\n",
      "theta =  0.8009, omega: -4.8313\n",
      "theta =  0.6805, omega: -4.5783\n",
      "theta =  0.5735, omega: -4.0541\n",
      "theta =  0.4577, omega: -5.1031\n",
      "theta =  0.3209, omega: -5.7578\n",
      "theta =  0.1737, omega: -5.9636\n",
      "theta =  0.0276, omega: -5.7017\n",
      "theta = -0.1076, omega: -4.9989\n",
      "theta = -0.2228, omega: -3.9338\n",
      "theta = -0.2795, omega: -0.7781\n",
      "theta = -0.2605, omega:  2.0935\n",
      "theta = -0.1765, omega:  4.6537\n",
      "theta = -0.0586, omega:  4.9508\n",
      "theta =  0.0669, omega:  4.8502\n",
      "theta =  0.1840, omega:  4.3743\n",
      "theta =  0.3078, omega:  5.3975\n",
      "theta =  0.4495, omega:  5.9829\n",
      "theta =  0.6028, omega:  6.1258\n",
      "theta =  0.7535, omega:  5.8701\n",
      "theta =  0.8923, omega:  5.2862\n",
      "theta =  1.0148, omega:  4.4595\n",
      "theta =  1.0915, omega:  1.6372\n",
      "theta =  1.0981, omega: -0.9862\n",
      "theta =  1.0429, omega: -3.3555\n",
      "theta =  0.9372, omega: -5.0506\n",
      "theta =  0.8111, omega: -5.0848\n",
      "theta =  0.6843, omega: -4.8437\n",
      "theta =  0.5712, omega: -4.3135\n",
      "theta =  0.4480, omega: -5.3415\n",
      "theta =  0.3056, omega: -5.9554\n",
      "theta =  0.1547, omega: -6.1041\n",
      "theta =  0.0055, omega: -5.7781\n",
      "theta = -0.1289, omega: -5.0064\n",
      "theta = -0.2418, omega: -3.8696\n",
      "theta = -0.2995, omega: -0.6564\n",
      "theta = -0.2769, omega:  2.2495\n",
      "theta = -0.1893, omega:  4.8470\n",
      "theta = -0.0617, omega:  5.1637\n",
      "theta =  0.0647, omega:  5.0654\n",
      "theta =  0.1896, omega:  4.5751\n",
      "theta =  0.3158, omega:  5.5691\n",
      "theta =  0.4632, omega:  6.1148\n",
      "theta =  0.6030, omega:  4.8446\n",
      "theta =  0.7204, omega:  4.6738\n",
      "theta =  0.8318, omega:  4.2297\n",
      "theta =  0.9081, omega:  1.7452\n",
      "theta =  0.9205, omega: -0.6019\n",
      "theta =  0.8781, omega: -2.6836\n",
      "theta =  0.7877, omega: -4.5651\n",
      "theta =  0.6750, omega: -4.3001\n",
      "theta =  0.5521, omega: -5.6047\n",
      "theta =  0.3985, omega: -6.4938\n",
      "theta =  0.2365, omega: -6.4251\n",
      "theta =  0.0748, omega: -6.3262\n",
      "theta = -0.0741, omega: -5.7370\n",
      "theta = -0.2061, omega: -4.7162\n",
      "theta = -0.3073, omega: -3.3660\n",
      "theta = -0.3503, omega:  0.0092\n",
      "theta = -0.3118, omega:  2.9833\n",
      "theta = -0.2035, omega:  5.6348\n",
      "theta = -0.0588, omega:  5.9448\n",
      "theta =  0.0897, omega:  5.7796\n",
      "theta =  0.2504, omega:  6.9914\n",
      "theta =  0.4344, omega:  7.6314\n",
      "theta =  0.6272, omega:  7.7073\n",
      "theta =  0.8161, omega:  7.2932\n",
      "theta =  0.9884, omega:  6.4981\n",
      "theta =  1.1392, omega:  5.4483\n",
      "theta =  1.2594, omega:  4.2485\n",
      "theta =  1.3266, omega:  1.1463\n",
      "theta =  1.3190, omega: -1.6684\n",
      "theta =  1.2455, omega: -4.2660\n",
      "theta =  1.1318, omega: -4.8358\n",
      "theta =  1.0032, omega: -5.2217\n",
      "theta =  0.8725, omega: -5.3749\n",
      "theta =  0.7368, omega: -5.2494\n",
      "theta =  0.6127, omega: -4.8241\n",
      "theta =  0.4777, omega: -5.9278\n",
      "theta =  0.3182, omega: -6.5801\n",
      "theta =  0.1521, omega: -6.7217\n",
      "theta = -0.0122, omega: -6.3372\n",
      "theta = -0.1636, omega: -5.4686\n",
      "theta = -0.2819, omega: -4.2063\n",
      "theta = -0.3454, omega: -0.8450\n",
      "theta = -0.3289, omega:  2.2290\n",
      "theta = -0.2388, omega:  4.9784\n",
      "theta = -0.1041, omega:  5.4380\n",
      "theta =  0.0309, omega:  5.4568\n",
      "theta =  0.1646, omega:  5.0491\n",
      "theta =  0.3059, omega:  6.0850\n",
      "theta =  0.4639, omega:  6.6324\n",
      "theta =  0.6284, omega:  6.6939\n",
      "theta =  0.7961, omega:  6.3328\n",
      "theta =  0.9459, omega:  5.6327\n",
      "theta =  1.0749, omega:  4.6963\n",
      "theta =  1.1560, omega:  1.7760\n",
      "theta =  1.1644, omega: -0.9456\n",
      "theta =  1.1106, omega: -3.4117\n",
      "theta =  1.0031, omega: -5.2137\n",
      "theta =  0.8693, omega: -5.3615\n",
      "theta =  0.7361, omega: -5.2307\n",
      "theta =  0.6096, omega: -4.8020\n",
      "theta =  0.4752, omega: -5.9021\n",
      "theta =  0.3171, omega: -6.5520\n",
      "theta =  0.1519, omega: -6.6945\n",
      "theta = -0.0114, omega: -6.3103\n",
      "theta = -0.1606, omega: -5.4462\n",
      "theta = -0.2824, omega: -4.1913\n",
      "theta = -0.3441, omega: -0.8367\n",
      "theta = -0.3254, omega:  2.2319\n",
      "theta = -0.2346, omega:  4.9731\n",
      "theta = -0.1011, omega:  5.4264\n",
      "theta =  0.0330, omega:  5.4394\n",
      "theta =  0.1664, omega:  5.0281\n",
      "theta =  0.3032, omega:  6.0614\n",
      "theta =  0.4629, omega:  6.6071\n",
      "theta =  0.6314, omega:  6.6734\n",
      "theta =  0.7952, omega:  6.3127\n",
      "theta =  0.9443, omega:  5.6184\n",
      "theta =  1.0728, omega:  4.6831\n",
      "theta =  1.1540, omega:  1.7684\n",
      "theta =  1.1629, omega: -0.9508\n",
      "theta =  1.1068, omega: -3.4124\n",
      "theta =  0.9980, omega: -5.2122\n",
      "theta =  0.8659, omega: -5.3546\n",
      "theta =  0.7347, omega: -5.2189\n",
      "theta =  0.6079, omega: -4.7868\n",
      "theta =  0.4743, omega: -5.8828\n",
      "theta =  0.3188, omega: -6.5311\n",
      "theta =  0.1534, omega: -6.6705\n",
      "theta = -0.0097, omega: -6.2899\n",
      "theta = -0.1573, omega: -5.4281\n",
      "theta = -0.2819, omega: -4.1731\n",
      "theta = -0.3428, omega: -0.8253\n",
      "theta = -0.3225, omega:  2.2364\n",
      "theta = -0.2331, omega:  4.9729\n",
      "theta = -0.1034, omega:  5.4184\n",
      "theta =  0.0360, omega:  5.4306\n",
      "theta =  0.1656, omega:  5.0144\n",
      "theta =  0.3047, omega:  6.0431\n",
      "theta =  0.4636, omega:  6.5874\n",
      "theta =  0.6302, omega:  6.6549\n",
      "theta =  0.7951, omega:  6.2943\n",
      "theta =  0.9429, omega:  5.6018\n",
      "theta =  1.0698, omega:  4.6723\n",
      "theta =  1.1694, omega:  3.1317\n",
      "theta =  1.2104, omega:  0.1676\n",
      "theta =  1.2045, omega: -0.6046\n",
      "theta =  1.1565, omega: -3.1351\n",
      "theta =  1.0496, omega: -5.4803\n",
      "theta =  0.9083, omega: -5.6965\n",
      "theta =  0.7684, omega: -5.6346\n",
      "theta =  0.6310, omega: -5.2514\n",
      "theta =  0.4836, omega: -6.3748\n",
      "theta =  0.3157, omega: -7.0170\n",
      "theta =  0.1376, omega: -7.1140\n",
      "theta = -0.0352, omega: -6.6563\n",
      "theta = -0.1904, omega: -5.6941\n",
      "theta = -0.3186, omega: -4.3204\n",
      "theta = -0.3845, omega: -0.8518\n",
      "theta = -0.3624, omega:  2.3285\n",
      "theta = -0.2675, omega:  5.1742\n",
      "theta = -0.1300, omega:  5.7160\n",
      "theta =  0.0159, omega:  5.7940\n",
      "theta =  0.1541, omega:  5.4181\n",
      "theta =  0.3051, omega:  6.4521\n",
      "theta =  0.4729, omega:  6.9691\n",
      "theta =  0.6481, omega:  6.9840\n",
      "theta =  0.8180, omega:  6.5679\n",
      "theta =  0.9744, omega:  5.8055\n",
      "theta =  1.1074, omega:  4.8132\n",
      "theta =  1.1912, omega:  1.8452\n",
      "theta =  1.2007, omega: -0.9266\n",
      "theta =  1.1463, omega: -3.4373\n",
      "theta =  1.0350, omega: -5.2913\n",
      "theta =  0.9005, omega: -5.4971\n",
      "theta =  0.7643, omega: -5.4282\n",
      "theta =  0.6319, omega: -5.0559\n",
      "theta =  0.4895, omega: -6.1957\n",
      "theta =  0.3278, omega: -6.8713\n",
      "theta =  0.1514, omega: -7.0134\n",
      "theta = -0.0197, omega: -6.6072\n",
      "theta = -0.1756, omega: -5.6966\n",
      "theta = -0.3022, omega: -4.3757\n",
      "theta = -0.3683, omega: -0.9488\n",
      "theta = -0.3515, omega:  2.2015\n",
      "theta = -0.2602, omega:  5.0235\n",
      "theta = -0.1271, omega:  5.5527\n",
      "theta =  0.0123, omega:  5.6307\n",
      "theta =  0.1504, omega:  5.2641\n",
      "theta =  0.2956, omega:  6.3243\n",
      "theta =  0.4629, omega:  6.8739\n",
      "theta =  0.6371, omega:  6.9259\n",
      "theta =  0.8050, omega:  6.5395\n",
      "theta =  0.9606, omega:  5.8077\n",
      "theta =  1.0941, omega:  4.8359\n",
      "theta =  1.1777, omega:  1.8823\n",
      "theta =  1.1887, omega: -0.8755\n",
      "theta =  1.1349, omega: -3.3762\n",
      "theta =  1.0273, omega: -5.2192\n",
      "theta =  0.8934, omega: -5.4116\n",
      "theta =  0.7602, omega: -5.3361\n",
      "theta =  0.6303, omega: -4.9546\n",
      "theta =  0.4916, omega: -6.0989\n",
      "theta =  0.3280, omega: -6.7812\n",
      "theta =  0.1577, omega: -6.9349\n",
      "theta = -0.0137, omega: -6.5494\n",
      "theta = -0.1660, omega: -5.6632\n",
      "theta = -0.2944, omega: -4.3703\n",
      "theta = -0.3602, omega: -0.9675\n",
      "theta = -0.3431, omega:  2.1652\n",
      "theta = -0.2553, omega:  4.9694\n",
      "theta = -0.1219, omega:  5.4804\n",
      "theta =  0.0153, omega:  5.5488\n",
      "theta =  0.1509, omega:  5.1830\n",
      "theta =  0.2950, omega:  6.2437\n",
      "theta =  0.4570, omega:  6.8038\n",
      "theta =  0.6298, omega:  6.8697\n",
      "theta =  0.8004, omega:  6.4977\n",
      "theta =  0.9528, omega:  5.7798\n",
      "theta =  1.0857, omega:  4.8209\n",
      "theta =  1.1685, omega:  1.8793\n",
      "theta =  1.1823, omega: -0.8720\n",
      "theta =  1.1294, omega: -3.3599\n",
      "theta =  1.0197, omega: -5.1934\n",
      "theta =  0.8875, omega: -5.3775\n",
      "theta =  0.7561, omega: -5.2882\n",
      "theta =  0.6254, omega: -4.8969\n",
      "theta =  0.4898, omega: -6.0346\n",
      "theta =  0.3281, omega: -6.7149\n",
      "theta =  0.1575, omega: -6.8725\n",
      "theta = -0.0110, omega: -6.4956\n",
      "theta = -0.1636, omega: -5.6212\n",
      "theta = -0.2900, omega: -4.3398\n",
      "theta = -0.3545, omega: -0.9518\n",
      "theta = -0.3395, omega:  2.1625\n",
      "theta = -0.2480, omega:  4.9503\n",
      "theta = -0.1192, omega:  5.4485\n",
      "theta =  0.0204, omega:  5.5071\n",
      "theta =  0.1554, omega:  5.1338\n",
      "theta =  0.2965, omega:  6.1922\n",
      "theta =  0.4595, omega:  6.7516\n",
      "theta =  0.6304, omega:  6.8231\n",
      "theta =  0.7966, omega:  6.4574\n",
      "theta =  0.9490, omega:  5.7469\n",
      "theta =  1.0814, omega:  4.7956\n",
      "theta =  1.1646, omega:  1.8609\n",
      "theta =  1.1751, omega: -0.8833\n",
      "theta =  1.1241, omega: -3.3645\n",
      "theta =  1.0148, omega: -5.1888\n",
      "theta =  0.8836, omega: -5.3623\n",
      "theta =  0.7499, omega: -5.2637\n",
      "theta =  0.6221, omega: -4.8619\n",
      "theta =  0.4865, omega: -5.9911\n",
      "theta =  0.3260, omega: -6.6668\n",
      "theta =  0.1573, omega: -6.8247\n",
      "theta = -0.0087, omega: -6.4471\n",
      "theta = -0.1611, omega: -5.5782\n",
      "theta = -0.2853, omega: -4.3056\n",
      "theta = -0.3525, omega: -0.9279\n",
      "theta = -0.3351, omega:  2.1732\n",
      "theta = -0.2457, omega:  4.9501\n",
      "theta = -0.1151, omega:  5.4364\n",
      "theta =  0.0209, omega:  5.4809\n",
      "theta =  0.1557, omega:  5.0983\n",
      "theta =  0.2974, omega:  6.1500\n",
      "theta =  0.4610, omega:  6.7119\n",
      "theta =  0.6302, omega:  6.7811\n",
      "theta =  0.7953, omega:  6.4168\n",
      "theta =  0.9490, omega:  5.7142\n",
      "theta =  1.0789, omega:  4.7680\n",
      "theta =  1.1605, omega:  1.8403\n",
      "theta =  1.1714, omega: -0.8970\n",
      "theta =  1.1154, omega: -3.3752\n",
      "theta =  1.0120, omega: -5.1918\n",
      "theta =  0.8776, omega: -5.3545\n",
      "theta =  0.7459, omega: -5.2467\n",
      "theta =  0.6200, omega: -4.8401\n",
      "theta =  0.4829, omega: -5.9586\n",
      "theta =  0.3238, omega: -6.6275\n",
      "theta =  0.1793, omega: -4.9588\n",
      "theta =  0.0770, omega: -2.9661\n",
      "theta =  0.0314, omega: -0.8041\n",
      "theta =  0.0364, omega:  1.1363\n",
      "theta =  0.0875, omega:  2.8374\n",
      "theta =  0.1771, omega:  4.2642\n",
      "theta =  0.2975, omega:  5.3152\n",
      "theta =  0.4398, omega:  5.9344\n",
      "theta =  0.5911, omega:  6.1129\n",
      "theta =  0.7424, omega:  5.8868\n",
      "theta =  0.8836, omega:  5.3246\n",
      "theta =  1.0060, omega:  4.5151\n",
      "theta =  1.0843, omega:  1.7067\n",
      "theta =  1.0906, omega: -0.9133\n",
      "theta =  1.0385, omega: -3.2750\n",
      "theta =  0.9367, omega: -4.9705\n",
      "theta =  0.8097, omega: -5.0028\n",
      "theta =  0.6871, omega: -4.7633\n",
      "theta =  0.5729, omega: -4.2434\n",
      "theta =  0.4549, omega: -5.2827\n",
      "theta =  0.3124, omega: -5.9173\n",
      "theta =  0.1611, omega: -6.0874\n",
      "theta =  0.0111, omega: -5.7813\n",
      "theta = -0.1213, omega: -5.0333\n",
      "theta = -0.2366, omega: -3.9176\n",
      "theta = -0.2953, omega: -0.7155\n",
      "theta = -0.2732, omega:  2.1868\n",
      "theta = -0.1858, omega:  4.7803\n",
      "theta = -0.0614, omega:  5.0982\n",
      "theta =  0.0637, omega:  5.0060\n",
      "theta =  0.1855, omega:  4.5253\n",
      "theta =  0.3128, omega:  5.5339\n",
      "theta =  0.4575, omega:  6.0939\n",
      "theta =  0.6126, omega:  6.2088\n",
      "theta =  0.7647, omega:  5.9222\n",
      "theta =  0.9058, omega:  5.3092\n",
      "theta =  1.0283, omega:  4.4562\n",
      "theta =  1.1057, omega:  1.6138\n",
      "theta =  1.1135, omega: -1.0239\n",
      "theta =  1.0575, omega: -3.4095\n",
      "theta =  0.9487, omega: -5.1231\n",
      "theta =  0.8174, omega: -5.1712\n",
      "theta =  0.6927, omega: -4.9410\n",
      "theta =  0.5738, omega: -4.4202\n",
      "theta =  0.4507, omega: -5.4484\n",
      "theta =  0.3043, omega: -6.0561\n",
      "theta =  0.1506, omega: -6.1908\n",
      "theta =  0.0009, omega: -5.8415\n",
      "theta = -0.1376, omega: -5.0468\n",
      "theta = -0.2500, omega: -3.8825\n",
      "theta = -0.3060, omega: -0.6443\n",
      "theta = -0.2860, omega:  2.2881\n",
      "theta = -0.1946, omega:  4.9050\n",
      "theta = -0.0690, omega:  5.2385\n",
      "theta =  0.0644, omega:  5.1525\n",
      "theta =  0.1865, omega:  4.6633\n",
      "theta =  0.3167, omega:  5.6545\n",
      "theta =  0.4685, omega:  6.1907\n",
      "theta =  0.6212, omega:  6.2767\n",
      "theta =  0.7767, omega:  5.9579\n",
      "theta =  0.9184, omega:  5.3195\n",
      "theta =  1.0408, omega:  4.4438\n",
      "theta =  1.1138, omega:  1.5842\n",
      "theta =  1.1229, omega: -1.0643\n",
      "theta =  1.0635, omega: -3.4663\n",
      "theta =  0.9568, omega: -5.1913\n",
      "theta =  0.8250, omega: -5.2529\n",
      "theta =  0.6967, omega: -5.0341\n",
      "theta =  0.5759, omega: -4.5137\n",
      "theta =  0.4511, omega: -5.5394\n",
      "theta =  0.3014, omega: -6.1405\n",
      "theta =  0.1457, omega: -6.2606\n",
      "theta = -0.0081, omega: -5.8934\n",
      "theta = -0.1445, omega: -5.0734\n",
      "theta = -0.2592, omega: -3.8871\n",
      "theta = -0.3141, omega: -0.6231\n",
      "theta = -0.2919, omega:  2.3263\n",
      "theta = -0.1993, omega:  4.9624\n",
      "theta = -0.0701, omega:  5.3097\n",
      "theta =  0.0629, omega:  5.2287\n",
      "theta =  0.1863, omega:  4.7415\n",
      "theta =  0.3210, omega:  5.7261\n",
      "theta =  0.4687, omega:  6.2533\n",
      "theta =  0.6293, omega:  6.3247\n",
      "theta =  0.7840, omega:  5.9938\n",
      "theta =  0.9250, omega:  5.3407\n",
      "theta =  1.0463, omega:  4.4512\n",
      "theta =  1.1465, omega:  3.4162\n",
      "theta =  1.1955, omega:  0.4662\n",
      "theta =  1.1729, omega: -2.1409\n",
      "theta =  1.0884, omega: -4.5563\n",
      "theta =  0.9714, omega: -4.8924\n",
      "theta =  0.8462, omega: -4.9982\n",
      "theta =  0.7218, omega: -4.8395\n",
      "theta =  0.6050, omega: -4.4054\n",
      "theta =  0.4810, omega: -5.5205\n",
      "theta =  0.3340, omega: -6.2193\n",
      "theta =  0.1749, omega: -6.4308\n",
      "theta =  0.0175, omega: -6.1381\n",
      "theta = -0.1274, omega: -5.3763\n",
      "theta = -0.2496, omega: -4.2187\n",
      "theta = -0.3313, omega: -2.3241\n",
      "theta = -0.3697, omega: -0.7737\n",
      "theta = -0.3491, omega:  2.3588\n",
      "theta = -0.2537, omega:  5.1644\n",
      "theta = -0.1194, omega:  5.6625\n",
      "theta =  0.0247, omega:  5.7027\n",
      "theta =  0.1644, omega:  5.2956\n",
      "theta =  0.3091, omega:  6.3137\n",
      "theta =  0.4768, omega:  6.8276\n",
      "theta =  0.6455, omega:  6.8499\n",
      "theta =  0.8156, omega:  6.4396\n",
      "theta =  0.9660, omega:  5.6973\n",
      "theta =  1.0982, omega:  4.7218\n",
      "theta =  1.1781, omega:  1.7696\n",
      "theta =  1.1870, omega: -0.9777\n",
      "theta =  1.1315, omega: -3.4667\n",
      "theta =  1.0217, omega: -5.2985\n",
      "theta =  0.8856, omega: -5.4773\n",
      "theta =  0.7500, omega: -5.3772\n",
      "theta =  0.6180, omega: -4.9689\n",
      "theta =  0.4797, omega: -6.0847\n",
      "theta =  0.3185, omega: -6.7358\n",
      "theta =  0.1476, omega: -6.8663\n",
      "theta = -0.0214, omega: -6.4596\n",
      "theta = -0.1706, omega: -5.5594\n",
      "theta = -0.2953, omega: -4.2608\n",
      "theta = -0.3578, omega: -0.8618\n",
      "theta = -0.3412, omega:  2.2517\n",
      "theta = -0.2481, omega:  5.0367\n",
      "theta = -0.1138, omega:  5.5300\n",
      "theta =  0.0257, omega:  5.5707\n",
      "theta =  0.1816, omega:  6.9982\n",
      "theta =  0.3684, omega:  7.8379\n",
      "theta =  0.5709, omega:  8.0801\n",
      "theta =  0.7684, omega:  7.7803\n",
      "theta =  0.9543, omega:  7.0516\n",
      "theta =  1.1181, omega:  6.0236\n",
      "theta =  1.2540, omega:  4.8175\n",
      "theta =  1.3365, omega:  1.6962\n",
      "theta =  1.3424, omega: -1.1831\n",
      "theta =  1.2790, omega: -3.8246\n",
      "theta =  1.1734, omega: -4.4517\n",
      "theta =  1.0576, omega: -4.9193\n",
      "theta =  0.9289, omega: -5.1826\n",
      "theta =  0.8003, omega: -5.1905\n",
      "theta =  0.6729, omega: -4.9196\n",
      "theta =  0.5327, omega: -6.1749\n",
      "theta =  0.3663, omega: -6.9732\n",
      "theta =  0.1873, omega: -7.2329\n",
      "theta =  0.0106, omega: -6.9293\n",
      "theta = -0.1520, omega: -6.0908\n",
      "theta = -0.2877, omega: -4.8097\n",
      "theta = -0.3676, omega: -1.3854\n",
      "theta = -0.3610, omega:  1.8209\n",
      "theta = -0.2784, omega:  4.6974\n",
      "theta = -0.1539, omega:  5.3047\n",
      "theta = -0.0181, omega:  5.4821\n",
      "theta =  0.1181, omega:  5.2224\n",
      "theta =  0.2637, omega:  6.3834\n",
      "theta =  0.4320, omega:  7.0273\n",
      "theta =  0.6107, omega:  7.1496\n",
      "theta =  0.7874, omega:  6.8076\n",
      "theta =  0.9493, omega:  6.0982\n",
      "theta =  1.0886, omega:  5.1308\n",
      "theta =  1.1799, omega:  2.1728\n",
      "theta =  1.1989, omega: -0.6206\n",
      "theta =  1.1512, omega: -3.1428\n",
      "theta =  1.0405, omega: -5.4809\n",
      "theta =  0.9016, omega: -5.6860\n",
      "theta =  0.7617, omega: -5.6097\n",
      "theta =  0.6236, omega: -5.2172\n",
      "theta =  0.4864, omega: -5.8719\n",
      "theta =  0.3289, omega: -6.5532\n",
      "theta =  0.1612, omega: -6.7258\n",
      "theta = -0.0018, omega: -6.3728\n",
      "theta = -0.1537, omega: -5.5336\n",
      "theta = -0.2777, omega: -4.2919\n",
      "theta = -0.3407, omega: -0.9424\n",
      "theta = -0.3273, omega:  2.1330\n",
      "theta = -0.2356, omega:  4.8847\n",
      "theta = -0.1089, omega:  5.3503\n",
      "theta =  0.0271, omega:  5.3866\n",
      "theta =  0.1809, omega:  6.8187\n",
      "theta =  0.3628, omega:  7.6784\n",
      "theta =  0.5600, omega:  7.9502\n",
      "theta =  0.7544, omega:  7.6840\n",
      "theta =  0.9395, omega:  6.9867\n",
      "theta =  1.1025, omega:  5.9884\n",
      "theta =  1.2367, omega:  4.8038\n",
      "theta =  1.3192, omega:  1.6959\n",
      "theta =  1.3233, omega: -1.1730\n",
      "theta =  1.2609, omega: -3.8001\n",
      "theta =  1.1594, omega: -4.4075\n",
      "theta =  1.0425, omega: -4.8573\n",
      "theta =  0.9186, omega: -5.0991\n",
      "theta =  0.7892, omega: -5.0886\n",
      "theta =  0.6648, omega: -4.7960\n",
      "theta =  0.5289, omega: -6.0430\n",
      "theta =  0.3895, omega: -5.0130\n",
      "theta =  0.2587, omega: -5.4785\n",
      "theta =  0.1191, omega: -5.5119\n",
      "theta = -0.0134, omega: -5.1182\n",
      "theta = -0.1332, omega: -4.3339\n",
      "theta = -0.2291, omega: -3.2348\n",
      "theta = -0.2690, omega: -0.1064\n",
      "theta = -0.2378, omega:  2.6420\n",
      "theta = -0.1408, omega:  5.0874\n",
      "theta = -0.0115, omega:  5.2393\n",
      "theta =  0.1190, omega:  4.9770\n",
      "theta =  0.2597, omega:  6.1526\n",
      "theta =  0.4207, omega:  6.8271\n",
      "theta =  0.5943, omega:  6.9925\n",
      "theta =  0.7688, omega:  6.6956\n",
      "theta =  0.9282, omega:  6.0310\n",
      "theta =  1.0669, omega:  5.1006\n",
      "theta =  1.1581, omega:  2.1718\n",
      "theta =  1.1767, omega: -0.5937\n",
      "theta =  1.1298, omega: -3.0906\n",
      "theta =  1.0233, omega: -5.3991\n",
      "theta =  0.8865, omega: -5.5754\n",
      "theta =  0.7476, omega: -5.4694\n",
      "theta =  0.6164, omega: -5.0516\n",
      "theta =  0.4742, omega: -6.1495\n",
      "theta =  0.3119, omega: -6.7813\n",
      "theta =  0.1416, omega: -6.8833\n",
      "theta = -0.0286, omega: -6.4483\n",
      "theta = -0.1799, omega: -5.5205\n",
      "theta = -0.2996, omega: -4.2014\n",
      "theta = -0.3623, omega: -0.7872\n",
      "theta = -0.3424, omega:  2.3299\n",
      "theta = -0.2486, omega:  5.1202\n",
      "theta = -0.1147, omega:  5.6093\n",
      "theta =  0.0497, omega:  7.4637\n",
      "theta =  0.2540, omega:  8.6739\n",
      "theta =  0.4779, omega:  9.1865\n",
      "theta =  0.7076, omega:  9.0499\n",
      "theta =  0.9266, omega:  8.3765\n",
      "theta =  1.1223, omega:  7.3248\n",
      "theta =  1.2913, omega:  6.0563\n",
      "theta =  1.4254, omega:  4.6925\n",
      "theta =  1.5244, omega:  3.3194\n",
      "theta =  1.5893, omega:  1.9766\n",
      "theta =  1.6254, omega:  0.6801\n",
      "theta =  1.6276, omega: -0.3964\n",
      "theta =  1.5802, omega: -3.1612\n",
      "theta =  1.4930, omega: -3.9938\n",
      "theta =  1.3828, omega: -4.7703\n",
      "theta =  1.2555, omega: -5.4507\n",
      "theta =  1.1117, omega: -5.9746\n",
      "theta =  0.9594, omega: -6.2697\n",
      "theta =  0.8008, omega: -6.2726\n",
      "theta =  0.6472, omega: -5.9311\n",
      "theta =  0.4824, omega: -7.0573\n",
      "theta =  0.2993, omega: -7.6539\n",
      "theta =  0.1076, omega: -7.6565\n",
      "theta = -0.0787, omega: -7.0633\n",
      "theta = -0.2411, omega: -5.9399\n",
      "theta = -0.3735, omega: -4.3974\n",
      "theta = -0.4360, omega: -0.7641\n",
      "theta = -0.4144, omega:  2.5606\n",
      "theta = -0.3098, omega:  5.5419\n",
      "theta = -0.1647, omega:  6.1855\n",
      "theta = -0.0073, omega:  6.3320\n",
      "theta =  0.1493, omega:  5.9789\n",
      "theta =  0.3136, omega:  6.9934\n",
      "theta =  0.4928, omega:  7.4553\n",
      "theta =  0.6815, omega:  7.3861\n",
      "theta =  0.8595, omega:  6.8696\n",
      "theta =  1.0207, omega:  6.0155\n",
      "theta =  1.1580, omega:  4.9425\n",
      "theta =  1.2430, omega:  1.9060\n",
      "theta =  1.2541, omega: -0.9239\n",
      "theta =  1.1987, omega: -3.4955\n",
      "theta =  1.0885, omega: -5.4218\n",
      "theta =  0.9477, omega: -5.7066\n",
      "theta =  0.8020, omega: -5.7216\n",
      "theta =  0.6632, omega: -5.4227\n",
      "theta =  0.5126, omega: -6.6258\n",
      "theta =  0.3368, omega: -7.3329\n",
      "theta =  0.1497, omega: -7.4749\n",
      "theta = -0.0342, omega: -7.0325\n",
      "theta = -0.1961, omega: -6.0551\n",
      "theta = -0.3296, omega: -4.6447\n",
      "theta = -0.4033, omega: -1.1111\n",
      "theta = -0.3911, omega:  2.1610\n",
      "theta = -0.2985, omega:  5.0972\n",
      "theta = -0.1614, omega:  5.7346\n",
      "theta = -0.0156, omega:  5.9052\n",
      "theta =  0.1307, omega:  5.6058\n",
      "theta =  0.2861, omega:  6.7053\n",
      "theta =  0.4608, omega:  7.2627\n",
      "theta =  0.6445, omega:  7.2926\n",
      "theta =  0.8214, omega:  6.8638\n",
      "theta =  0.9837, omega:  6.0818\n",
      "theta =  1.1230, omega:  5.0593\n",
      "theta =  1.2139, omega:  2.0580\n",
      "theta =  1.2524, omega:  0.9331\n",
      "theta =  1.2375, omega: -1.7877\n",
      "theta =  1.1629, omega: -4.3009\n",
      "theta =  1.0484, omega: -4.7605\n",
      "theta =  0.9258, omega: -5.0179\n",
      "theta =  0.7989, omega: -5.0269\n",
      "theta =  0.6766, omega: -4.7624\n",
      "theta =  0.5637, omega: -4.2144\n",
      "theta =  0.4457, omega: -5.2271\n",
      "theta =  0.3061, omega: -5.8394\n",
      "theta =  0.1558, omega: -5.9921\n",
      "theta =  0.0097, omega: -5.6753\n",
      "theta = -0.1015, omega: -3.1055\n",
      "theta = -0.1452, omega: -0.3746\n",
      "theta = -0.1223, omega:  2.0307\n",
      "theta = -0.0426, omega:  4.1661\n",
      "theta =  0.0650, omega:  4.5417\n",
      "theta =  0.1959, omega:  5.9131\n",
      "theta =  0.3559, omega:  6.7865\n",
      "theta =  0.5326, omega:  7.1355\n",
      "theta =  0.7090, omega:  6.9904\n",
      "theta =  0.8771, omega:  6.4298\n",
      "theta =  1.0293, omega:  5.5682\n",
      "theta =  1.1545, omega:  4.5041\n",
      "theta =  1.2287, omega:  1.4924\n",
      "theta =  1.2325, omega: -1.2762\n",
      "theta =  1.1658, omega: -3.8026\n",
      "theta =  1.0655, omega: -4.2967\n",
      "theta =  0.9527, omega: -4.6047\n",
      "theta =  0.8374, omega: -4.6987\n",
      "theta =  0.7235, omega: -4.5399\n",
      "theta =  0.6124, omega: -4.1178\n",
      "theta =  0.4962, omega: -5.2681\n",
      "theta =  0.3519, omega: -6.0179\n",
      "theta =  0.1970, omega: -6.2993\n",
      "theta =  0.0413, omega: -6.0862\n",
      "theta = -0.1029, omega: -5.4047\n",
      "theta = -0.2235, omega: -4.3240\n",
      "theta = -0.2945, omega: -1.1264\n",
      "theta = -0.2832, omega:  1.8346\n",
      "theta = -0.2034, omega:  4.4818\n",
      "theta = -0.0884, omega:  4.8742\n",
      "theta =  0.0359, omega:  4.8734\n",
      "theta =  0.1532, omega:  4.4903\n",
      "theta =  0.2816, omega:  5.5933\n",
      "theta =  0.4313, omega:  6.2405\n",
      "theta =  0.5890, omega:  6.4205\n",
      "theta =  0.7481, omega:  6.1787\n",
      "theta =  0.8960, omega:  5.5847\n",
      "theta =  1.0231, omega:  4.7341\n",
      "theta =  1.1069, omega:  1.8872\n",
      "theta =  1.1197, omega: -0.7911\n",
      "theta =  1.0696, omega: -3.2003\n",
      "theta =  0.9789, omega: -4.0374\n",
      "theta =  0.8703, omega: -4.6657\n",
      "theta =  0.7521, omega: -4.5782\n",
      "theta =  0.6433, omega: -4.2342\n",
      "theta =  0.5212, omega: -5.4599\n",
      "theta =  0.3733, omega: -6.2692\n",
      "theta =  0.2119, omega: -6.5955\n",
      "theta =  0.0462, omega: -6.4052\n",
      "theta = -0.1027, omega: -5.7215\n",
      "theta = -0.2345, omega: -4.6117\n",
      "theta = -0.3106, omega: -1.3684\n",
      "theta = -0.3036, omega:  1.6721\n",
      "theta = -0.2283, omega:  4.3933\n",
      "theta = -0.1128, omega:  4.8674\n",
      "theta =  0.0117, omega:  4.9446\n",
      "theta =  0.1334, omega:  4.6331\n",
      "theta =  0.2659, omega:  5.7920\n",
      "theta =  0.4181, omega:  6.4785\n",
      "theta =  0.5741, omega:  6.2171\n",
      "theta =  0.7336, omega:  6.0127\n",
      "theta =  0.8778, omega:  5.4674\n",
      "theta =  1.0045, omega:  4.6610\n",
      "theta =  1.0843, omega:  1.8495\n",
      "theta =  1.0976, omega: -0.7931\n",
      "theta =  1.0451, omega: -3.1704\n",
      "theta =  0.9406, omega: -5.3390\n",
      "theta =  0.8045, omega: -5.3608\n",
      "theta =  0.6737, omega: -5.0869\n",
      "theta =  0.5310, omega: -6.3336\n",
      "theta =  0.3606, omega: -7.1127\n",
      "theta =  0.1797, omega: -7.3415\n",
      "theta = -0.0005, omega: -6.9978\n",
      "theta = -0.1659, omega: -6.1182\n",
      "theta = -0.3034, omega: -4.7942\n",
      "theta = -0.3803, omega: -1.3316\n",
      "theta = -0.3718, omega:  1.9040\n",
      "theta = -0.2867, omega:  4.8102\n",
      "theta = -0.1590, omega:  5.4363\n",
      "theta = -0.0192, omega:  5.6185\n",
      "theta =  0.1197, omega:  5.3559\n",
      "theta =  0.2689, omega:  6.5048\n",
      "theta =  0.4393, omega:  7.1278\n",
      "theta =  0.6213, omega:  7.2210\n",
      "theta =  0.7958, omega:  6.8545\n",
      "theta =  0.9594, omega:  6.1190\n",
      "theta =  1.1001, omega:  5.1338\n",
      "theta =  1.1933, omega:  2.1580\n",
      "theta =  1.2106, omega: -0.6471\n",
      "theta =  1.1615, omega: -3.1816\n",
      "theta =  1.0565, omega: -5.0725\n",
      "theta =  0.9283, omega: -5.3276\n",
      "theta =  0.7926, omega: -5.3227\n",
      "theta =  0.6629, omega: -5.0267\n",
      "theta =  0.5460, omega: -4.4277\n",
      "theta =  0.4221, omega: -5.3760\n",
      "theta =  0.2779, omega: -5.9071\n",
      "theta =  0.1303, omega: -5.9732\n",
      "theta = -0.0153, omega: -5.5751\n",
      "theta = -0.1456, omega: -4.7530\n",
      "theta = -0.2519, omega: -3.5904\n",
      "theta = -0.3001, omega: -0.3685\n",
      "theta = -0.2729, omega:  2.5068\n",
      "theta = -0.1775, omega:  5.0707\n",
      "theta = -0.0452, omega:  5.3368\n",
      "theta =  0.0873, omega:  5.1770\n",
      "theta =  0.2326, omega:  6.4389\n",
      "theta =  0.4024, omega:  7.1698\n",
      "theta =  0.5874, omega:  7.3620\n",
      "theta =  0.7691, omega:  7.0626\n",
      "theta =  0.9377, omega:  6.3757\n",
      "theta =  1.0847, omega:  5.4146\n",
      "theta =  1.2070, omega:  4.2834\n",
      "theta =  1.2745, omega:  1.2253\n",
      "theta =  1.2709, omega: -1.5525\n",
      "theta =  1.2006, omega: -4.1104\n",
      "theta =  1.0875, omega: -4.6276\n",
      "theta =  0.9677, omega: -4.9596\n",
      "theta =  0.8435, omega: -5.0596\n",
      "theta =  0.7179, omega: -4.8883\n",
      "theta =  0.6018, omega: -4.4377\n",
      "theta =  0.4740, omega: -5.5359\n",
      "theta =  0.3261, omega: -6.2133\n",
      "theta =  0.1680, omega: -6.4045\n",
      "theta =  0.0107, omega: -6.0955\n",
      "theta = -0.1334, omega: -5.3186\n",
      "theta = -0.2522, omega: -4.1547\n",
      "theta = -0.3159, omega: -0.8884\n",
      "theta = -0.2958, omega:  2.0985\n",
      "theta = -0.2118, omega:  4.7714\n",
      "theta = -0.0854, omega:  5.1688\n",
      "theta =  0.0412, omega:  5.1477\n",
      "theta =  0.1674, omega:  4.7274\n",
      "theta =  0.2984, omega:  5.7710\n",
      "theta =  0.4505, omega:  6.3523\n",
      "theta =  0.6131, omega:  6.4649\n",
      "theta =  0.7744, omega:  6.1624\n",
      "theta =  0.8992, omega:  4.1484\n",
      "theta =  0.9720, omega:  1.5349\n",
      "theta =  0.9805, omega: -0.8932\n",
      "theta =  0.9283, omega: -3.0733\n",
      "theta =  0.8273, omega: -5.0316\n",
      "theta =  0.7042, omega: -4.8302\n",
      "theta =  0.5901, omega: -4.3443\n",
      "theta =  0.4650, omega: -5.4176\n",
      "theta =  0.3224, omega: -6.0737\n",
      "theta =  0.1658, omega: -6.2546\n",
      "theta =  0.0130, omega: -5.9474\n",
      "theta = -0.1276, omega: -5.1846\n",
      "theta = -0.2459, omega: -4.0433\n",
      "theta = -0.3077, omega: -0.8086\n",
      "theta = -0.2868, omega:  2.1408\n",
      "theta = -0.1997, omega:  4.7729\n",
      "theta = -0.0740, omega:  5.1333\n",
      "theta =  0.0520, omega:  5.0816\n",
      "theta =  0.1768, omega:  4.6320\n",
      "theta =  0.3060, omega:  5.6597\n",
      "theta =  0.4355, omega:  4.8650\n",
      "theta =  0.5627, omega:  5.1149\n",
      "theta =  0.6906, omega:  5.0216\n",
      "theta =  0.8130, omega:  4.6236\n",
      "theta =  0.9198, omega:  3.9882\n",
      "theta =  1.0091, omega:  3.1840\n",
      "theta =  1.0555, omega:  0.4374\n",
      "theta =  1.0346, omega: -1.9746\n",
      "theta =  0.9567, omega: -4.1914\n",
      "theta =  0.8509, omega: -4.3133\n",
      "theta =  0.7442, omega: -4.2062\n",
      "theta =  0.6419, omega: -3.8616\n",
      "theta =  0.5298, omega: -5.1073\n",
      "theta =  0.3904, omega: -5.9655\n",
      "theta =  0.2343, omega: -6.3640\n",
      "theta =  0.0762, omega: -6.2627\n",
      "theta = -0.0745, omega: -5.6745\n",
      "theta = -0.2038, omega: -4.6667\n",
      "theta = -0.3029, omega: -3.3258\n",
      "theta = -0.3465, omega:  0.0332\n",
      "theta = -0.3072, omega:  2.9925\n",
      "theta = -0.1993, omega:  5.6286\n",
      "theta = -0.0545, omega:  5.9235\n",
      "theta =  0.0945, omega:  5.7455\n",
      "theta =  0.2539, omega:  6.9441\n",
      "theta =  0.4368, omega:  7.5796\n",
      "theta =  0.6275, omega:  7.6543\n",
      "theta =  0.8147, omega:  7.2460\n",
      "theta =  0.9864, omega:  6.4544\n",
      "theta =  1.1327, omega:  5.4077\n",
      "theta =  1.2555, omega:  4.2134\n",
      "theta =  1.3205, omega:  1.1137\n",
      "theta =  1.3146, omega: -1.6889\n",
      "theta =  1.2391, omega: -4.2842\n",
      "theta =  1.1239, omega: -4.8442\n",
      "theta =  0.9979, omega: -5.2210\n",
      "theta =  0.8647, omega: -5.3622\n",
      "theta =  0.7320, omega: -5.2238\n",
      "theta =  0.6060, omega: -4.7873\n",
      "theta =  0.4727, omega: -5.8782\n",
      "theta =  0.3161, omega: -6.5235\n",
      "theta =  0.1509, omega: -6.6643\n",
      "theta = -0.0125, omega: -6.2779\n",
      "theta = -0.1591, omega: -5.4140\n",
      "theta = -0.2793, omega: -4.1624\n",
      "theta = -0.3429, omega: -0.8108\n",
      "theta = -0.3225, omega:  2.2443\n",
      "theta = -0.2322, omega:  4.9802\n",
      "theta = -0.1019, omega:  5.4233\n",
      "theta =  0.0360, omega:  5.4310\n",
      "theta =  0.1892, omega:  6.8319\n",
      "theta =  0.3715, omega:  7.6615\n",
      "theta =  0.5674, omega:  7.9065\n",
      "theta =  0.7644, omega:  7.6207\n",
      "theta =  0.9453, omega:  6.9135\n",
      "theta =  1.1053, omega:  5.9069\n",
      "theta =  1.2391, omega:  4.7232\n",
      "theta =  1.3196, omega:  1.6161\n",
      "theta =  1.3461, omega:  0.4172\n",
      "theta =  1.3197, omega: -2.3246\n",
      "theta =  1.2518, omega: -3.0583\n",
      "theta =  1.1440, omega: -5.5272\n",
      "theta =  0.9999, omega: -5.8976\n",
      "theta =  0.8504, omega: -6.0051\n",
      "theta =  0.7035, omega: -5.7994\n",
      "theta =  0.5411, omega: -7.0746\n",
      "theta =  0.3525, omega: -7.8336\n",
      "theta =  0.1549, omega: -7.9913\n",
      "theta = -0.0402, omega: -7.5261\n",
      "theta = -0.2185, omega: -6.4859\n",
      "theta = -0.3611, omega: -4.9844\n",
      "theta = -0.4415, omega: -1.3417\n",
      "theta = -0.4305, omega:  2.0630\n",
      "theta = -0.3389, omega:  5.1241\n",
      "theta = -0.2011, omega:  5.8868\n",
      "theta = -0.0481, omega:  6.1700\n",
      "theta =  0.1040, omega:  5.9619\n",
      "theta =  0.2681, omega:  7.1134\n",
      "theta =  0.4528, omega:  7.6925\n",
      "theta =  0.6478, omega:  7.7119\n",
      "theta =  0.8356, omega:  7.2489\n",
      "theta =  1.0083, omega:  6.4152\n",
      "theta =  1.1559, omega:  5.3414\n",
      "theta =  1.2501, omega:  2.2908\n",
      "theta =  1.2696, omega: -0.5789\n",
      "theta =  1.2211, omega: -3.1832\n",
      "theta =  1.1179, omega: -5.1551\n",
      "theta =  0.9855, omega: -5.5046\n",
      "theta =  0.8453, omega: -5.6007\n",
      "theta =  0.7051, omega: -5.4070\n",
      "theta =  0.5773, omega: -4.8947\n",
      "theta =  0.4418, omega: -5.9021\n",
      "theta =  0.2859, omega: -6.4549\n",
      "theta =  0.1243, omega: -6.5042\n",
      "theta = -0.0342, omega: -6.0494\n",
      "theta = -0.1745, omega: -5.1322\n",
      "theta = -0.2862, omega: -3.8484\n",
      "theta = -0.3426, omega: -0.4967\n",
      "theta = -0.3159, omega:  2.5229\n",
      "theta = -0.2183, omega:  5.2171\n",
      "theta = -0.0825, omega:  5.6042\n",
      "theta =  0.0822, omega:  7.3607\n",
      "theta =  0.2795, omega:  8.4839\n",
      "theta =  0.5001, omega:  8.9368\n",
      "theta =  0.7225, omega:  8.7574\n",
      "theta =  0.9332, omega:  8.0717\n",
      "theta =  1.1227, omega:  7.0268\n",
      "theta =  1.2831, omega:  5.7727\n",
      "theta =  1.4091, omega:  4.4288\n",
      "theta =  1.5015, omega:  3.0685\n",
      "theta =  1.5642, omega:  1.7335\n",
      "theta =  1.5899, omega:  0.4417\n",
      "theta =  1.5873, omega: -0.5873\n",
      "theta =  1.5397, omega: -3.3506\n",
      "theta =  1.4463, omega: -4.1667\n",
      "theta =  1.3303, omega: -4.9148\n",
      "theta =  1.2000, omega: -5.5425\n",
      "theta =  1.0554, omega: -5.9913\n",
      "theta =  0.9024, omega: -6.1908\n",
      "theta =  0.7476, omega: -6.0822\n",
      "theta =  0.5999, omega: -5.6272\n",
      "theta =  0.4463, omega: -6.6484\n",
      "theta =  0.2726, omega: -7.1644\n",
      "theta =  0.0944, omega: -7.1232\n",
      "theta = -0.0815, omega: -6.5268\n",
      "theta = -0.2297, omega: -5.4408\n",
      "theta = -0.3484, omega: -3.9720\n",
      "theta = -0.4034, omega: -0.4394\n",
      "theta = -0.3721, omega:  2.7437\n",
      "theta = -0.2689, omega:  5.5957\n",
      "theta = -0.1218, omega:  6.1074\n",
      "theta =  0.0320, omega:  6.1239\n",
      "theta =  0.1795, omega:  5.6619\n",
      "theta =  0.3350, omega:  6.6013\n",
      "theta =  0.5070, omega:  7.0201\n",
      "theta =  0.6826, omega:  6.9468\n",
      "theta =  0.8512, omega:  6.4507\n",
      "theta =  1.0042, omega:  5.6342\n",
      "theta =  1.1294, omega:  4.6058\n",
      "theta =  1.2103, omega:  1.6182\n",
      "theta =  1.2143, omega: -1.1428\n",
      "theta =  1.1501, omega: -3.6592\n",
      "theta =  1.0534, omega: -4.1378\n",
      "theta =  0.9481, omega: -4.4415\n",
      "theta =  0.8343, omega: -4.5281\n",
      "theta =  0.7239, omega: -4.3749\n",
      "theta =  0.6175, omega: -3.9686\n",
      "theta =  0.5023, omega: -5.1455\n",
      "theta =  0.3642, omega: -5.9307\n",
      "theta =  0.2128, omega: -6.2538\n",
      "theta =  0.0538, omega: -6.0863\n",
      "theta = -0.0887, omega: -5.4496\n",
      "theta = -0.2130, omega: -4.4073\n",
      "theta = -0.2832, omega: -1.2390\n",
      "theta = -0.2775, omega:  1.7099\n",
      "theta = -0.2022, omega:  4.3440\n",
      "theta = -0.0860, omega:  4.7347\n",
      "theta =  0.0326, omega:  4.7488\n",
      "theta =  0.1473, omega:  4.3829\n",
      "theta =  0.2728, omega:  5.5147\n",
      "theta =  0.4211, omega:  6.1915\n",
      "theta =  0.5770, omega:  6.4033\n",
      "theta =  0.7364, omega:  6.1894\n",
      "theta =  0.8849, omega:  5.6209\n",
      "theta =  1.0159, omega:  4.7898\n",
      "theta =  1.0986, omega:  1.9499\n",
      "theta =  1.1118, omega: -0.7232\n",
      "theta =  1.0653, omega: -3.1277\n",
      "theta =  0.9578, omega: -5.3347\n",
      "theta =  0.8245, omega: -5.3919\n",
      "theta =  0.6918, omega: -5.1623\n",
      "theta =  0.5680, omega: -4.6263\n",
      "theta =  0.4404, omega: -5.6253\n",
      "theta =  0.2934, omega: -6.1920\n",
      "theta =  0.1336, omega: -6.2752\n",
      "theta = -0.0190, omega: -5.8690\n",
      "theta = -0.1556, omega: -5.0144\n",
      "theta = -0.2664, omega: -3.7992\n",
      "theta = -0.3204, omega: -0.5151\n",
      "theta = -0.2955, omega:  2.4386\n",
      "theta = -0.2008, omega:  5.0789\n",
      "theta = -0.0694, omega:  5.4203\n",
      "theta =  0.0664, omega:  5.3243\n",
      "theta =  0.1921, omega:  4.8156\n",
      "theta =  0.3277, omega:  5.7749\n",
      "theta =  0.4803, omega:  6.2754\n",
      "theta =  0.6362, omega:  6.3235\n",
      "theta =  0.7917, omega:  5.9683\n",
      "theta =  0.9341, omega:  5.2971\n",
      "theta =  1.0544, omega:  4.3979\n",
      "theta =  1.1285, omega:  1.5209\n",
      "theta =  1.1314, omega: -1.1368\n",
      "theta =  1.0730, omega: -3.5477\n",
      "theta =  0.9629, omega: -5.2869\n",
      "theta =  0.8291, omega: -5.3561\n",
      "theta =  0.6970, omega: -5.1376\n",
      "theta =  0.5751, omega: -4.6159\n",
      "theta =  0.4449, omega: -5.6325\n",
      "theta =  0.2951, omega: -6.2171\n",
      "theta =  0.1386, omega: -6.3158\n",
      "theta = -0.0135, omega: -5.9221\n",
      "theta = -0.1521, omega: -5.0727\n",
      "theta = -0.2662, omega: -3.8600\n",
      "theta = -0.3230, omega: -0.5754\n",
      "theta = -0.2978, omega:  2.3916\n",
      "theta = -0.2041, omega:  5.0392\n",
      "theta = -0.0729, omega:  5.3923\n",
      "theta =  0.0616, omega:  5.3115\n",
      "theta =  0.1890, omega:  4.8197\n",
      "theta =  0.3246, omega:  5.7906\n",
      "theta =  0.4763, omega:  6.3029\n",
      "theta =  0.6336, omega:  6.3581\n",
      "theta =  0.7893, omega:  6.0107\n",
      "theta =  0.9310, omega:  5.3395\n",
      "theta =  1.0555, omega:  4.4407\n",
      "theta =  1.1307, omega:  1.5619\n",
      "theta =  1.1340, omega: -1.1059\n",
      "theta =  1.0768, omega: -3.5192\n",
      "theta =  0.9657, omega: -5.2617\n",
      "theta =  0.8327, omega: -5.3378\n",
      "theta =  0.6991, omega: -5.1319\n",
      "theta =  0.5773, omega: -4.6225\n",
      "theta =  0.4511, omega: -5.6511\n",
      "theta =  0.3241, omega: -4.4236\n",
      "theta =  0.2087, omega: -4.7264\n",
      "theta =  0.0877, omega: -4.6622\n",
      "theta = -0.0227, omega: -4.2308\n",
      "theta = -0.0955, omega: -1.6631\n",
      "theta = -0.1063, omega:  0.7914\n",
      "theta = -0.0594, omega:  2.9644\n",
      "theta =  0.0391, omega:  4.8346\n",
      "theta =  0.1570, omega:  4.4457\n",
      "theta =  0.2816, omega:  5.5427\n",
      "theta =  0.4289, omega:  6.1887\n",
      "theta =  0.5882, omega:  6.3762\n",
      "theta =  0.7459, omega:  6.1373\n",
      "theta =  0.8942, omega:  5.5516\n",
      "theta =  1.0197, omega:  4.7111\n",
      "theta =  1.1027, omega:  1.8689\n",
      "theta =  1.1166, omega: -0.8002\n",
      "theta =  1.0637, omega: -3.2020\n",
      "theta =  0.9568, omega: -5.4022\n",
      "theta =  0.8199, omega: -5.4541\n",
      "theta =  0.6878, omega: -5.2107\n",
      "theta =  0.5387, omega: -6.4835\n",
      "theta =  0.3661, omega: -7.2765\n",
      "theta =  0.1811, omega: -7.5085\n",
      "theta = -0.0045, omega: -7.1558\n",
      "theta = -0.1510, omega: -4.4370\n",
      "theta = -0.2470, omega: -3.2796\n",
      "theta = -0.2880, omega: -0.0900\n",
      "theta = -0.2565, omega:  2.7152\n",
      "theta = -0.1558, omega:  5.2118\n",
      "theta = -0.0211, omega:  5.4053\n",
      "theta =  0.1101, omega:  5.1665\n",
      "theta =  0.2546, omega:  6.3556\n",
      "theta =  0.4231, omega:  7.0219\n",
      "theta =  0.6029, omega:  7.1680\n",
      "theta =  0.7802, omega:  6.8438\n",
      "theta =  0.9427, omega:  6.1484\n",
      "theta =  1.0837, omega:  5.1906\n",
      "theta =  1.1750, omega:  2.2350\n",
      "theta =  1.1969, omega: -0.5572\n",
      "theta =  1.1516, omega: -3.0814\n",
      "theta =  1.0440, omega: -5.4210\n",
      "theta =  0.9055, omega: -5.6322\n",
      "theta =  0.7653, omega: -5.5639\n",
      "theta =  0.6280, omega: -5.1830\n",
      "theta =  0.4839, omega: -6.3064\n",
      "theta =  0.3174, omega: -6.9592\n",
      "theta =  0.1413, omega: -7.0705\n",
      "theta = -0.0312, omega: -6.6311\n",
      "theta = -0.1855, omega: -5.6834\n",
      "theta = -0.3121, omega: -4.3323\n",
      "theta = -0.3769, omega: -0.8760\n",
      "theta = -0.3579, omega:  2.2937\n",
      "theta = -0.2664, omega:  5.1278\n",
      "theta = -0.1308, omega:  5.6613\n",
      "theta =  0.0158, omega:  5.7373\n",
      "theta =  0.1558, omega:  5.3606\n",
      "theta =  0.3030, omega:  6.4035\n",
      "theta =  0.4697, omega:  6.9312\n",
      "theta =  0.6452, omega:  6.9580\n",
      "theta =  0.8159, omega:  6.5494\n",
      "theta =  0.9689, omega:  5.8006\n",
      "theta =  1.1036, omega:  4.8148\n",
      "theta =  1.1860, omega:  1.8527\n",
      "theta =  1.1966, omega: -0.9139\n",
      "theta =  1.1438, omega: -3.4191\n",
      "theta =  1.0315, omega: -5.2694\n",
      "theta =  0.8982, omega: -5.4697\n",
      "theta =  0.7600, omega: -5.3965\n",
      "theta =  0.6303, omega: -5.0180\n",
      "theta =  0.4894, omega: -6.1577\n",
      "theta =  0.3246, omega: -6.8334\n",
      "theta =  0.1505, omega: -6.9790\n",
      "theta = -0.0184, omega: -6.5781\n",
      "theta = -0.1730, omega: -5.6774\n",
      "theta = -0.2980, omega: -4.3675\n",
      "theta = -0.3647, omega: -0.9473\n",
      "theta = -0.3482, omega:  2.1938\n",
      "theta = -0.2574, omega:  5.0077\n",
      "theta = -0.1244, omega:  5.5292\n",
      "theta =  0.0156, omega:  5.6014\n",
      "theta =  0.1530, omega:  5.2326\n",
      "theta =  0.2951, omega:  6.2908\n",
      "theta =  0.4621, omega:  6.8446\n",
      "theta =  0.6343, omega:  6.9004\n",
      "theta =  0.8033, omega:  6.5175\n",
      "theta =  0.9574, omega:  5.7917\n",
      "theta =  1.0920, omega:  4.8258\n",
      "theta =  1.1754, omega:  1.8766\n",
      "theta =  1.1865, omega: -0.8786\n",
      "theta =  1.1316, omega: -3.3750\n",
      "theta =  1.0226, omega: -5.2114\n",
      "theta =  0.8916, omega: -5.4011\n",
      "theta =  0.7568, omega: -5.3177\n",
      "theta =  0.6297, omega: -4.9320\n",
      "theta =  0.4885, omega: -6.0718\n",
      "theta =  0.3266, omega: -6.7526\n",
      "theta =  0.1560, omega: -6.9082\n",
      "theta = -0.0115, omega: -6.5225\n",
      "theta = -0.1652, omega: -5.6431\n",
      "theta = -0.2917, omega: -4.3513\n",
      "theta = -0.3588, omega: -0.9561\n",
      "theta = -0.3418, omega:  2.1688\n",
      "theta = -0.2512, omega:  4.9654\n",
      "theta = -0.1213, omega:  5.4692\n",
      "theta =  0.0419, omega:  7.3526\n",
      "theta =  0.2438, omega:  8.6016\n",
      "theta =  0.4648, omega:  9.1527\n",
      "theta =  0.6946, omega:  9.0504\n",
      "theta =  0.9148, omega:  8.4039\n",
      "theta =  1.1121, omega:  7.3746\n",
      "theta =  1.2801, omega:  6.1163\n",
      "theta =  1.4165, omega:  4.7583\n",
      "theta =  1.5200, omega:  3.3835\n",
      "theta =  1.5841, omega:  2.0402\n",
      "theta =  1.6226, omega:  0.7389\n",
      "theta =  1.6239, omega: -0.3474\n",
      "theta =  1.5803, omega: -3.1187\n",
      "theta =  1.4916, omega: -3.9487\n",
      "theta =  1.3841, omega: -4.7289\n",
      "theta =  1.2570, omega: -5.4104\n",
      "theta =  1.1139, omega: -5.9364\n",
      "theta =  0.9617, omega: -6.2399\n",
      "theta =  0.8065, omega: -6.2508\n",
      "theta =  0.6518, omega: -5.9214\n",
      "theta =  0.5131, omega: -5.2336\n",
      "theta =  0.3704, omega: -6.0343\n",
      "theta =  0.2138, omega: -6.3666\n",
      "theta =  0.0562, omega: -6.2009\n",
      "theta = -0.0933, omega: -5.5541\n",
      "theta = -0.2181, omega: -4.4969\n",
      "theta = -0.2896, omega: -1.3068\n",
      "theta = -0.2854, omega:  1.6714\n",
      "theta = -0.2082, omega:  4.3340\n",
      "theta = -0.0959, omega:  4.7553\n",
      "theta =  0.0244, omega:  4.7926\n",
      "theta =  0.1403, omega:  4.4519\n",
      "theta =  0.2665, omega:  5.5965\n",
      "theta =  0.4164, omega:  6.2847\n",
      "theta =  0.5775, omega:  6.4977\n",
      "theta =  0.7383, omega:  6.2783\n",
      "theta =  0.8876, omega:  5.6984\n",
      "theta =  1.0210, omega:  4.8559\n",
      "theta =  1.1081, omega:  2.0043\n",
      "theta =  1.1219, omega: -0.6864\n",
      "theta =  1.0751, omega: -3.1058\n",
      "theta =  0.9667, omega: -5.3270\n",
      "theta =  0.8348, omega: -5.4043\n",
      "theta =  0.7006, omega: -5.1942\n",
      "theta =  0.5747, omega: -4.6800\n",
      "theta =  0.4448, omega: -5.6976\n",
      "theta =  0.2945, omega: -6.2776\n",
      "theta =  0.1366, omega: -6.3672\n",
      "theta = -0.0170, omega: -5.9610\n",
      "theta = -0.1567, omega: -5.1013\n",
      "theta = -0.2696, omega: -3.8722\n",
      "theta = -0.3267, omega: -0.5723\n",
      "theta = -0.3031, omega:  2.4099\n",
      "theta = -0.2080, omega:  5.0706\n",
      "theta = -0.0758, omega:  5.4371\n",
      "theta =  0.0607, omega:  5.3651\n",
      "theta =  0.1889, omega:  4.8737\n",
      "theta =  0.3231, omega:  5.8432\n",
      "theta =  0.4767, omega:  6.3504\n",
      "theta =  0.6379, omega:  6.3982\n",
      "theta =  0.7961, omega:  6.0407\n",
      "theta =  0.9371, omega:  5.3597\n",
      "theta =  1.0599, omega:  4.4512\n",
      "theta =  1.1336, omega:  1.5656\n",
      "theta =  1.1389, omega: -1.1052\n",
      "theta =  1.0822, omega: -3.5293\n",
      "theta =  0.9716, omega: -5.2802\n",
      "theta =  0.8382, omega: -5.3652\n",
      "theta =  0.7045, omega: -5.1628\n",
      "theta =  0.5825, omega: -4.6608\n",
      "theta =  0.4744, omega: -3.8701\n",
      "theta =  0.3900, omega: -2.8337\n",
      "theta =  0.3334, omega: -1.6288\n",
      "theta =  0.3070, omega: -0.3402\n",
      "theta =  0.2932, omega: -0.8915\n",
      "theta =  0.2670, omega: -1.3588\n",
      "theta =  0.2274, omega: -1.7026\n",
      "theta =  0.1810, omega: -1.9098\n",
      "theta =  0.1317, omega: -1.9606\n",
      "theta =  0.1057, omega: -0.0369\n",
      "theta =  0.1270, omega:  1.5352\n",
      "theta =  0.1832, omega:  2.9320\n",
      "theta =  0.2724, omega:  4.0607\n",
      "theta =  0.3819, omega:  4.8416\n",
      "theta =  0.5095, omega:  5.2468\n",
      "theta =  0.6416, omega:  5.2816\n",
      "theta =  0.7715, omega:  4.9826\n",
      "theta =  0.8892, omega:  4.4094\n",
      "theta =  0.9676, omega:  1.8044\n",
      "theta =  0.9810, omega: -0.6532\n",
      "theta =  0.9365, omega: -2.8457\n",
      "theta =  0.8622, omega: -3.0019\n",
      "theta =  0.7650, omega: -4.8278\n",
      "theta =  0.6474, omega: -4.4934\n",
      "theta =  0.5195, omega: -5.7098\n",
      "theta =  0.3648, omega: -6.4969\n",
      "theta =  0.1995, omega: -6.7815\n",
      "theta =  0.0302, omega: -6.5379\n",
      "theta = -0.1267, omega: -5.7863\n",
      "theta = -0.2532, omega: -4.6132\n",
      "theta = -0.3312, omega: -1.3047\n",
      "theta = -0.3235, omega:  1.7863\n",
      "theta = -0.2419, omega:  4.5509\n",
      "theta = -0.1233, omega:  5.0595\n",
      "theta =  0.0272, omega:  6.9748\n",
      "theta =  0.2232, omega:  8.2824\n",
      "theta =  0.4381, omega:  8.9149\n",
      "theta =  0.6624, omega:  8.8998\n",
      "theta =  0.8793, omega:  8.3322\n",
      "theta =  1.0752, omega:  7.3648\n",
      "theta =  1.2453, omega:  6.1504\n",
      "theta =  1.3822, omega:  4.8187\n",
      "theta =  1.4841, omega:  3.4533\n",
      "theta =  1.5555, omega:  2.1079\n",
      "theta =  1.5930, omega:  0.8055\n",
      "theta =  1.5968, omega: -0.3007\n",
      "theta =  1.5530, omega: -3.0731\n",
      "theta =  1.4681, omega: -3.9017\n",
      "theta =  1.3584, omega: -4.6712\n",
      "theta =  1.2333, omega: -5.3389\n",
      "theta =  1.0930, omega: -5.8400\n",
      "theta =  0.9430, omega: -6.1133\n",
      "theta =  0.7926, omega: -6.0988\n",
      "theta =  0.6420, omega: -5.7446\n",
      "theta =  0.4830, omega: -6.8675\n",
      "theta =  0.3036, omega: -7.4746\n",
      "theta =  0.1128, omega: -7.5011\n",
      "theta = -0.0680, omega: -6.9468\n",
      "theta = -0.2286, omega: -5.8641\n",
      "theta = -0.3575, omega: -4.3714\n",
      "theta = -0.4216, omega: -0.7812\n",
      "theta = -0.3974, omega:  2.5000\n",
      "theta = -0.2998, omega:  5.4437\n",
      "theta = -0.1544, omega:  6.0596\n",
      "theta =  0.0002, omega:  6.1863\n",
      "theta =  0.1730, omega:  7.6452\n",
      "theta =  0.3773, omega:  8.4648\n",
      "theta =  0.5908, omega:  8.6454\n",
      "theta =  0.8057, omega:  8.2561\n",
      "theta =  1.0014, omega:  7.4303\n",
      "theta =  1.1738, omega:  6.3132\n",
      "theta =  1.3174, omega:  5.0368\n",
      "theta =  1.4249, omega:  3.6977\n",
      "theta =  1.5008, omega:  2.3608\n",
      "theta =  1.5201, omega: -0.6545\n",
      "theta =  1.4687, omega: -3.4058\n",
      "theta =  1.3727, omega: -4.1953\n",
      "theta =  1.2612, omega: -4.8941\n",
      "theta =  1.1313, omega: -5.4499\n",
      "theta =  0.9879, omega: -5.8024\n",
      "theta =  0.8429, omega: -5.8930\n",
      "theta =  0.6988, omega: -5.6729\n",
      "theta =  0.5378, omega: -6.9429\n",
      "theta =  0.3542, omega: -7.7018\n",
      "theta =  0.1589, omega: -7.8709\n",
      "theta = -0.0344, omega: -7.4262\n",
      "theta = -0.2088, omega: -6.4131\n",
      "theta = -0.3520, omega: -4.9430\n",
      "theta = -0.4291, omega: -1.3301\n",
      "theta = -0.4189, omega:  2.0448\n",
      "theta = -0.3312, omega:  5.0764\n",
      "theta = -0.1920, omega:  5.8086\n",
      "theta = -0.0410, omega:  6.0752\n",
      "theta =  0.1076, omega:  5.8535\n",
      "theta =  0.2693, omega:  7.0021\n",
      "theta =  0.4509, omega:  7.5894\n",
      "theta =  0.6436, omega:  7.6210\n",
      "theta =  0.8295, omega:  7.1721\n",
      "theta =  0.9971, omega:  6.3590\n",
      "theta =  1.1446, omega:  5.2955\n",
      "theta =  1.2416, omega:  2.2601\n",
      "theta =  1.2586, omega: -0.6009\n",
      "theta =  1.2132, omega: -3.1920\n",
      "theta =  1.1082, omega: -5.1466\n",
      "theta =  0.9741, omega: -5.4805\n",
      "theta =  0.8349, omega: -5.5586\n",
      "theta =  0.7001, omega: -5.3417\n",
      "theta =  0.5682, omega: -4.8119\n",
      "theta =  0.4361, omega: -5.8054\n",
      "theta =  0.2836, omega: -6.3532\n",
      "theta =  0.1241, omega: -6.4028\n",
      "theta = -0.0329, omega: -5.9539\n",
      "theta = -0.1716, omega: -5.0552\n",
      "theta = -0.2803, omega: -3.7902\n",
      "theta = -0.3361, omega: -0.4610\n",
      "theta = -0.3087, omega:  2.5277\n",
      "theta = -0.2106, omega:  5.1970\n",
      "theta = -0.0771, omega:  5.5594\n",
      "theta =  0.0632, omega:  5.4774\n",
      "theta =  0.1965, omega:  4.9666\n",
      "theta =  0.3325, omega:  5.9129\n",
      "theta =  0.4862, omega:  6.3908\n",
      "theta =  0.6469, omega:  6.4109\n",
      "theta =  0.8035, omega:  6.0278\n",
      "theta =  0.9477, omega:  5.3264\n",
      "theta =  1.0685, omega:  4.4041\n",
      "theta =  1.1432, omega:  1.5089\n",
      "theta =  1.1445, omega: -1.1661\n",
      "theta =  1.0857, omega: -3.5940\n",
      "theta =  0.9739, omega: -5.3472\n",
      "theta =  0.8378, omega: -5.4318\n",
      "theta =  0.7029, omega: -5.2300\n",
      "theta =  0.5771, omega: -4.7239\n",
      "theta =  0.4489, omega: -5.7431\n",
      "theta =  0.2945, omega: -6.3246\n",
      "theta =  0.1355, omega: -6.4115\n",
      "theta = -0.0214, omega: -5.9961\n",
      "theta = -0.1613, omega: -5.1281\n",
      "theta = -0.2738, omega: -3.8880\n",
      "theta = -0.3307, omega: -0.5757\n",
      "theta = -0.3055, omega:  2.4173\n",
      "theta = -0.2133, omega:  5.0885\n",
      "theta = -0.0792, omega:  5.4637\n",
      "theta =  0.0591, omega:  5.3973\n",
      "theta =  0.1865, omega:  4.9119\n",
      "theta =  0.3251, omega:  5.8848\n",
      "theta =  0.4774, omega:  6.3868\n",
      "theta =  0.6397, omega:  6.4302\n",
      "theta =  0.7963, omega:  6.0654\n",
      "theta =  0.9393, omega:  5.3803\n",
      "theta =  1.0637, omega:  4.4654\n",
      "theta =  1.1398, omega:  1.5717\n",
      "theta =  1.1421, omega: -1.1008\n",
      "theta =  1.0882, omega: -3.5311\n",
      "theta =  0.9756, omega: -5.2875\n",
      "theta =  0.8397, omega: -5.3792\n",
      "theta =  0.7068, omega: -5.1860\n",
      "theta =  0.5836, omega: -4.6876\n",
      "theta =  0.4532, omega: -5.7235\n",
      "theta =  0.3002, omega: -6.3218\n",
      "theta =  0.1410, omega: -6.4270\n",
      "theta = -0.0160, omega: -6.0297\n",
      "theta = -0.1569, omega: -5.1708\n",
      "theta = -0.2727, omega: -3.9423\n",
      "theta = -0.3281, omega: -0.6336\n",
      "theta = -0.3059, omega:  2.3631\n",
      "theta = -0.2121, omega:  5.0409\n",
      "theta = -0.0826, omega:  5.4220\n",
      "theta =  0.0775, omega:  7.1888\n",
      "theta =  0.2736, omega:  8.3342\n",
      "theta =  0.4874, omega:  8.8152\n",
      "theta =  0.7085, omega:  8.6723\n",
      "theta =  0.9183, omega:  8.0183\n",
      "theta =  1.1054, omega:  7.0008\n",
      "theta =  1.2676, omega:  5.7643\n",
      "theta =  1.3909, omega:  4.4316\n",
      "theta =  1.4877, omega:  3.0775\n",
      "theta =  1.5487, omega:  1.7472\n",
      "theta =  1.5742, omega:  0.4532\n",
      "theta =  1.5522, omega: -2.3763\n",
      "theta =  1.4588, omega: -5.0720\n",
      "theta =  1.3208, omega: -5.7891\n",
      "theta =  1.1683, omega: -6.3699\n",
      "theta =  1.0045, omega: -6.7309\n",
      "theta =  0.8343, omega: -6.7993\n",
      "theta =  0.6674, omega: -6.5031\n",
      "theta =  0.4916, omega: -7.6430\n",
      "theta =  0.2909, omega: -8.2152\n",
      "theta =  0.0845, omega: -8.1523\n",
      "theta = -0.1127, omega: -7.4556\n",
      "theta = -0.2830, omega: -6.2015\n",
      "theta = -0.4189, omega: -4.5203\n",
      "theta = -0.4837, omega: -0.7468\n",
      "theta = -0.4583, omega:  2.7059\n",
      "theta = -0.3526, omega:  5.8078\n",
      "theta = -0.1974, omega:  6.5561\n",
      "theta = -0.0270, omega:  6.7778\n",
      "theta =  0.1389, omega:  6.4621\n",
      "theta =  0.3151, omega:  7.4730\n",
      "theta =  0.5079, omega:  7.8946\n",
      "theta =  0.7048, omega:  7.7655\n",
      "theta =  0.8916, omega:  7.1729\n",
      "theta =  1.0607, omega:  6.2451\n",
      "theta =  1.2017, omega:  5.1038\n",
      "theta =  1.2909, omega:  2.0178\n",
      "theta =  1.3028, omega: -0.8669\n",
      "theta =  1.2741, omega: -1.6515\n",
      "theta =  1.1968, omega: -4.2086\n",
      "theta =  1.0873, omega: -4.7231\n",
      "theta =  0.9650, omega: -5.0450\n",
      "theta =  0.8381, omega: -5.1323\n",
      "theta =  0.7119, omega: -4.9435\n",
      "theta =  0.5917, omega: -4.4684\n",
      "theta =  0.4653, omega: -5.5392\n",
      "theta =  0.3184, omega: -6.1900\n",
      "theta =  0.1616, omega: -6.3565\n",
      "theta =  0.0039, omega: -6.0253\n",
      "theta = -0.1374, omega: -5.2338\n",
      "theta = -0.2540, omega: -4.0562\n",
      "theta = -0.3157, omega: -0.7956\n",
      "theta = -0.2964, omega:  2.1839\n",
      "theta = -0.2087, omega:  4.8412\n",
      "theta = -0.0813, omega:  5.2214\n",
      "theta =  0.0714, omega:  6.9984\n",
      "theta =  0.2635, omega:  8.1743\n",
      "theta =  0.4757, omega:  8.6923\n",
      "theta =  0.6936, omega:  8.5911\n",
      "theta =  0.9021, omega:  7.9732\n",
      "theta =  1.0881, omega:  6.9846\n",
      "theta =  1.2492, omega:  5.7738\n",
      "theta =  1.3757, omega:  4.4530\n",
      "theta =  1.4698, omega:  3.1050\n",
      "theta =  1.5304, omega:  1.7759\n",
      "theta =  1.5362, omega: -1.1873\n",
      "theta =  1.4731, omega: -3.9245\n",
      "theta =  1.3648, omega: -4.6982\n",
      "theta =  1.2378, omega: -5.3666\n",
      "theta =  1.0989, omega: -5.8765\n",
      "theta =  0.9483, omega: -6.1575\n",
      "theta =  0.7939, omega: -6.1449\n",
      "theta =  0.6447, omega: -5.7973\n",
      "theta =  0.4847, omega: -6.9186\n",
      "theta =  0.3038, omega: -7.5256\n",
      "theta =  0.1127, omega: -7.5455\n",
      "theta = -0.0712, omega: -6.9809\n",
      "theta = -0.2315, omega: -5.8870\n",
      "theta = -0.3613, omega: -4.3795\n",
      "theta = -0.4259, omega: -0.7782\n",
      "theta = -0.4037, omega:  2.5172\n",
      "theta = -0.3023, omega:  5.4694\n",
      "theta = -0.1564, omega:  6.0960\n",
      "theta = -0.0022, omega:  6.2274\n",
      "theta =  0.1481, omega:  5.8683\n",
      "theta =  0.3118, omega:  6.8844\n",
      "theta =  0.4908, omega:  7.3552\n",
      "theta =  0.6744, omega:  7.3055\n",
      "theta =  0.8512, omega:  6.8048\n",
      "theta =  0.9942, omega:  4.6000\n",
      "theta =  1.0745, omega:  1.8022\n",
      "theta =  1.0865, omega: -0.8192\n",
      "theta =  1.0514, omega: -1.8059\n",
      "theta =  0.9759, omega: -4.0589\n",
      "theta =  0.8702, omega: -4.6876\n",
      "theta =  0.7538, omega: -4.5976\n",
      "theta =  0.6406, omega: -4.2485\n",
      "theta =  0.5200, omega: -5.4674\n",
      "theta =  0.3727, omega: -6.2722\n",
      "theta =  0.2091, omega: -6.5922\n",
      "theta =  0.0456, omega: -6.3975\n",
      "theta = -0.1072, omega: -5.7083\n",
      "theta = -0.2339, omega: -4.5938\n",
      "theta = -0.3105, omega: -1.3456\n",
      "theta = -0.3045, omega:  1.6919\n",
      "theta = -0.2277, omega:  4.4118\n",
      "theta = -0.1096, omega:  4.8847\n",
      "theta =  0.0125, omega:  4.9598\n",
      "theta =  0.1331, omega:  4.6431\n",
      "theta =  0.2650, omega:  5.7968\n",
      "theta =  0.4203, omega:  6.4744\n",
      "theta =  0.5855, omega:  6.6677\n",
      "theta =  0.7486, omega:  6.4183\n",
      "theta =  0.9041, omega:  5.8094\n",
      "theta =  1.0369, omega:  4.9346\n",
      "theta =  1.1248, omega:  2.0544\n",
      "theta =  1.1421, omega: -0.6642\n",
      "theta =  1.0922, omega: -3.1111\n",
      "theta =  0.9869, omega: -5.3642\n",
      "theta =  0.8519, omega: -5.4760\n",
      "theta =  0.7175, omega: -5.3002\n",
      "theta =  0.5905, omega: -4.8185\n",
      "theta =  0.4541, omega: -5.8595\n",
      "theta =  0.2978, omega: -6.4548\n",
      "theta =  0.1353, omega: -6.5431\n",
      "theta = -0.0223, omega: -6.1237\n",
      "theta = -0.1656, omega: -5.2379\n",
      "theta = -0.2818, omega: -3.9761\n",
      "theta = -0.3384, omega: -0.6339\n",
      "theta = -0.3143, omega:  2.3951\n",
      "theta = -0.2237, omega:  5.1004\n",
      "theta = -0.0873, omega:  5.5071\n",
      "theta =  0.0483, omega:  5.4671\n",
      "theta =  0.1802, omega:  5.0044\n",
      "theta =  0.2970, omega:  4.1669\n",
      "theta =  0.4079, omega:  4.8682\n",
      "theta =  0.5360, omega:  5.1955\n",
      "theta =  0.6672, omega:  5.1616\n",
      "theta =  0.7938, omega:  4.8109\n",
      "theta =  0.9058, omega:  4.2035\n",
      "theta =  0.9775, omega:  1.5834\n",
      "theta =  0.9854, omega: -0.8617\n",
      "theta =  0.9364, omega: -3.0528\n",
      "theta =  0.8563, omega: -3.1988\n",
      "theta =  0.7533, omega: -5.0034\n",
      "theta =  0.6330, omega: -4.6323\n",
      "theta =  0.5010, omega: -5.8061\n",
      "theta =  0.3483, omega: -6.5419\n",
      "theta =  0.1782, omega: -6.7679\n",
      "theta =  0.0127, omega: -6.4667\n",
      "theta = -0.1394, omega: -5.6688\n",
      "theta = -0.2682, omega: -4.4539\n",
      "theta = -0.3368, omega: -1.1209\n",
      "theta = -0.3238, omega:  1.9637\n",
      "theta = -0.2414, omega:  4.7242\n",
      "theta = -0.1156, omega:  5.2157\n",
      "theta =  0.0139, omega:  5.2832\n",
      "theta =  0.1442, omega:  4.9343\n",
      "theta =  0.2836, omega:  6.0365\n",
      "theta =  0.4440, omega:  6.6452\n",
      "theta =  0.6100, omega:  6.7669\n",
      "theta =  0.7776, omega:  6.4491\n",
      "theta =  0.9305, omega:  5.7780\n",
      "theta =  1.0631, omega:  4.8567\n",
      "theta =  1.1478, omega:  1.9446\n",
      "theta =  1.1620, omega: -0.7900\n",
      "theta =  1.1106, omega: -3.2597\n",
      "theta =  1.0063, omega: -5.0718\n",
      "theta =  0.8776, omega: -5.2369\n",
      "theta =  0.7490, omega: -5.1316\n",
      "theta =  0.6219, omega: -4.7366\n",
      "theta =  0.4892, omega: -5.8756\n",
      "theta =  0.3319, omega: -6.5683\n",
      "theta =  0.1667, omega: -6.7511\n",
      "theta = -0.0014, omega: -6.4089\n",
      "theta = -0.1507, omega: -5.5740\n",
      "theta = -0.2746, omega: -4.3344\n",
      "theta = -0.3437, omega: -0.9853\n",
      "theta = -0.3269, omega:  2.0963\n",
      "theta = -0.2391, omega:  4.8555\n",
      "theta = -0.1131, omega:  5.3301\n",
      "theta =  0.0217, omega:  5.3763\n",
      "theta =  0.1535, omega:  4.9988\n",
      "theta =  0.2938, omega:  6.0671\n",
      "theta =  0.4533, omega:  6.6462\n",
      "theta =  0.6199, omega:  6.7371\n",
      "theta =  0.7866, omega:  6.3964\n",
      "theta =  0.9374, omega:  5.7117\n",
      "theta =  1.0698, omega:  4.7785\n",
      "theta =  1.1524, omega:  1.8620\n",
      "theta =  1.1643, omega: -0.8664\n",
      "theta =  1.1127, omega: -3.3335\n",
      "theta =  1.0053, omega: -5.1455\n",
      "theta =  0.8733, omega: -5.3008\n",
      "theta =  0.7415, omega: -5.1841\n",
      "theta =  0.6162, omega: -4.7730\n",
      "theta =  0.4836, omega: -5.8955\n",
      "theta =  0.3236, omega: -6.5648\n",
      "theta =  0.1600, omega: -6.7286\n",
      "theta = -0.0040, omega: -6.3663\n",
      "theta = -0.1568, omega: -5.5162\n",
      "theta = -0.2797, omega: -4.2652\n",
      "theta = -0.3439, omega: -0.9105\n",
      "theta = -0.3264, omega:  2.1626\n",
      "theta = -0.2377, omega:  4.9139\n",
      "theta = -0.1070, omega:  5.3812\n",
      "theta =  0.0290, omega:  5.4099\n",
      "theta =  0.1584, omega:  5.0165\n",
      "theta =  0.2964, omega:  6.0696\n",
      "theta =  0.4573, omega:  6.6300\n",
      "theta =  0.6268, omega:  6.7098\n",
      "theta =  0.7884, omega:  6.3605\n",
      "theta =  0.9422, omega:  5.6666\n",
      "theta =  1.0718, omega:  4.7356\n",
      "theta =  1.1531, omega:  1.8193\n",
      "theta =  1.1633, omega: -0.9068\n",
      "theta =  1.1088, omega: -3.3723\n",
      "theta =  1.0028, omega: -5.1773\n",
      "theta =  0.8700, omega: -5.3298\n",
      "theta =  0.7385, omega: -5.2055\n",
      "theta =  0.6136, omega: -4.7822\n",
      "theta =  0.4795, omega: -5.8899\n",
      "theta =  0.3221, omega: -6.5545\n",
      "theta =  0.1554, omega: -6.7039\n",
      "theta = -0.0092, omega: -6.3323\n",
      "theta = -0.1575, omega: -5.4754\n",
      "theta = -0.2777, omega: -4.2243\n",
      "theta = -0.3446, omega: -0.8708\n",
      "theta = -0.3270, omega:  2.1983\n",
      "theta = -0.2344, omega:  4.9432\n",
      "theta = -0.1046, omega:  5.4010\n",
      "theta =  0.0314, omega:  5.4228\n",
      "theta =  0.1625, omega:  5.0152\n",
      "theta =  0.3011, omega:  6.0589\n",
      "theta =  0.4629, omega:  6.6128\n",
      "theta =  0.6297, omega:  6.6856\n",
      "theta =  0.7915, omega:  6.3306\n",
      "theta =  0.9416, omega:  5.6378\n",
      "theta =  1.0714, omega:  4.7062\n",
      "theta =  1.1764, omega:  3.6245\n",
      "theta =  1.2289, omega:  0.6306\n",
      "theta =  1.2098, omega: -2.0342\n",
      "theta =  1.1296, omega: -4.5046\n",
      "theta =  1.0093, omega: -4.9044\n",
      "theta =  0.8854, omega: -5.0864\n",
      "theta =  0.7596, omega: -5.0080\n",
      "theta =  0.6358, omega: -4.6470\n",
      "theta =  0.5035, omega: -5.8318\n",
      "theta =  0.3477, omega: -6.5704\n",
      "theta =  0.1804, omega: -6.8039\n",
      "theta =  0.0130, omega: -6.5077\n",
      "theta = -0.1399, omega: -5.7081\n",
      "theta = -0.2680, omega: -4.4926\n",
      "theta = -0.3399, omega: -1.1550\n",
      "theta = -0.3274, omega:  1.9411\n",
      "theta = -0.2426, omega:  4.7134\n",
      "theta = -0.1183, omega:  5.2109\n",
      "theta =  0.0364, omega:  7.1113\n",
      "theta =  0.2309, omega:  8.3925\n",
      "theta =  0.4480, omega:  8.9899\n",
      "theta =  0.6748, omega:  8.9355\n",
      "theta =  0.8939, omega:  8.3400\n",
      "theta =  1.0891, omega:  7.3463\n",
      "theta =  1.2588, omega:  6.1175\n",
      "theta =  1.3953, omega:  4.7765\n",
      "theta =  1.4964, omega:  3.4094\n",
      "theta =  1.5647, omega:  2.0650\n",
      "theta =  1.5989, omega:  0.7612\n",
      "theta =  1.6031, omega: -0.3312\n",
      "theta =  1.5600, omega: -3.1023\n",
      "theta =  1.4722, omega: -3.9347\n",
      "theta =  1.3641, omega: -4.7046\n",
      "theta =  1.2371, omega: -5.3728\n",
      "theta =  1.0975, omega: -5.8799\n",
      "theta =  0.9476, omega: -6.1560\n",
      "theta =  0.7917, omega: -6.1436\n",
      "theta =  0.6439, omega: -5.7909\n",
      "theta =  0.4822, omega: -6.9110\n",
      "theta =  0.2994, omega: -7.5122\n",
      "theta =  0.1126, omega: -7.5298\n",
      "theta = -0.0711, omega: -6.9650\n",
      "theta = -0.2317, omega: -5.8711\n",
      "theta = -0.3603, omega: -4.3654\n",
      "theta = -0.4246, omega: -0.7647\n",
      "theta = -0.4011, omega:  2.5227\n",
      "theta = -0.3017, omega:  5.4738\n",
      "theta = -0.1570, omega:  6.0959\n",
      "theta = -0.0012, omega:  6.2229\n",
      "theta =  0.1515, omega:  5.8597\n",
      "theta =  0.3113, omega:  6.8752\n",
      "theta =  0.4914, omega:  7.3443\n",
      "theta =  0.6732, omega:  7.2917\n",
      "theta =  0.8510, omega:  6.7939\n",
      "theta =  1.0113, omega:  5.9589\n",
      "theta =  1.1478, omega:  4.9011\n",
      "theta =  1.2321, omega:  1.8788\n",
      "theta =  1.2419, omega: -0.9351\n",
      "theta =  1.1870, omega: -3.4938\n",
      "theta =  1.0749, omega: -5.4043\n",
      "theta =  0.9353, omega: -5.6705\n",
      "theta =  0.7935, omega: -5.6645\n",
      "theta =  0.6566, omega: -5.3488\n",
      "theta =  0.5268, omega: -4.7077\n",
      "theta =  0.3997, omega: -5.5947\n",
      "theta =  0.2506, omega: -6.0465\n",
      "theta =  0.1000, omega: -6.0238\n",
      "theta = -0.0427, omega: -5.5354\n",
      "theta = -0.1723, omega: -4.6264\n",
      "theta = -0.2729, omega: -3.3879\n",
      "theta = -0.3161, omega: -0.1143\n",
      "theta = -0.2837, omega:  2.7726\n",
      "theta = -0.1808, omega:  5.3468\n",
      "theta = -0.0409, omega:  5.6053\n",
      "theta =  0.0961, omega:  5.4180\n",
      "theta =  0.2466, omega:  6.6314\n",
      "theta =  0.4231, omega:  7.3040\n",
      "theta =  0.6073, omega:  7.4294\n",
      "theta =  0.7923, omega:  7.0775\n",
      "theta =  0.9602, omega:  6.3427\n",
      "theta =  1.0847, omega:  3.5119\n",
      "theta =  1.1346, omega:  0.6404\n",
      "theta =  1.1196, omega: -1.9128\n",
      "theta =  1.0400, omega: -4.2632\n",
      "theta =  0.9299, omega: -4.5335\n",
      "theta =  0.8157, omega: -4.5809\n",
      "theta =  0.7032, omega: -4.3802\n",
      "theta =  0.6007, omega: -3.9241\n",
      "theta =  0.4869, omega: -5.0520\n",
      "theta =  0.3474, omega: -5.7908\n",
      "theta =  0.2024, omega: -6.0801\n",
      "theta =  0.0507, omega: -5.8903\n",
      "theta = -0.0902, omega: -5.2452\n",
      "theta = -0.2114, omega: -4.2119\n",
      "theta = -0.2764, omega: -1.0708\n",
      "theta = -0.2655, omega:  1.8304\n",
      "theta = -0.1867, omega:  4.4202\n",
      "theta = -0.0693, omega:  4.7635\n",
      "theta =  0.0497, omega:  4.7260\n",
      "theta =  0.1637, omega:  4.3159\n",
      "theta =  0.2834, omega:  5.4065\n",
      "theta =  0.4302, omega:  6.0563\n",
      "theta =  0.5830, omega:  6.2528\n",
      "theta =  0.7374, omega:  6.0339\n",
      "theta =  0.8833, omega:  5.4695\n",
      "theta =  1.0095, omega:  4.6500\n",
      "theta =  1.0918, omega:  1.8286\n",
      "theta =  1.1040, omega: -0.8185\n",
      "theta =  1.0506, omega: -3.2019\n",
      "theta =  0.9416, omega: -5.3804\n",
      "theta =  0.8099, omega: -5.4047\n",
      "theta =  0.6746, omega: -5.1349\n",
      "theta =  0.5326, omega: -6.3855\n",
      "theta =  0.3626, omega: -7.1617\n",
      "theta =  0.1780, omega: -7.3853\n",
      "theta = -0.0048, omega: -7.0317\n",
      "theta = -0.1474, omega: -4.3195\n",
      "theta = -0.2174, omega: -1.3610\n",
      "theta = -0.2175, omega:  1.4098\n",
      "theta = -0.1495, omega:  3.8793\n",
      "theta = -0.0429, omega:  4.6051\n",
      "theta =  0.0717, omega:  4.4862\n",
      "theta =  0.1797, omega:  4.0211\n",
      "theta =  0.2948, omega:  5.0849\n",
      "theta =  0.4300, omega:  5.7300\n",
      "theta =  0.5750, omega:  5.9471\n",
      "theta =  0.7223, omega:  5.7650\n",
      "theta =  0.8612, omega:  5.2483\n",
      "theta =  0.9842, omega:  4.4815\n",
      "theta =  1.0613, omega:  1.7072\n",
      "theta =  1.0698, omega: -0.8819\n",
      "theta =  1.0180, omega: -3.2140\n",
      "theta =  0.9111, omega: -5.3357\n",
      "theta =  0.7784, omega: -5.2966\n",
      "theta =  0.6495, omega: -4.9650\n",
      "theta =  0.5071, omega: -6.1551\n",
      "theta =  0.3459, omega: -6.8854\n",
      "theta =  0.1707, omega: -7.0826\n",
      "theta = -0.0047, omega: -6.7239\n",
      "theta = -0.1623, omega: -5.8560\n",
      "theta = -0.2927, omega: -4.5585\n",
      "theta = -0.3654, omega: -1.1414\n",
      "theta = -0.3526, omega:  2.0294\n",
      "theta = -0.2658, omega:  4.8678\n",
      "theta = -0.1380, omega:  5.4259\n",
      "theta =  0.0010, omega:  5.5424\n",
      "theta =  0.1370, omega:  5.2195\n",
      "theta =  0.2817, omega:  6.3247\n",
      "theta =  0.4503, omega:  6.9170\n",
      "theta =  0.6235, omega:  7.0019\n",
      "theta =  0.7966, omega:  6.6386\n",
      "theta =  0.9520, omega:  5.9213\n",
      "theta =  1.0889, omega:  4.9573\n",
      "theta =  1.1775, omega:  2.0050\n",
      "theta =  1.2115, omega:  0.9215\n",
      "theta =  1.2020, omega: -1.7609\n",
      "theta =  1.1263, omega: -4.2320\n",
      "theta =  1.0158, omega: -4.6428\n",
      "theta =  0.8936, omega: -4.8467\n",
      "theta =  0.7738, omega: -4.8033\n",
      "theta =  0.6416, omega: -5.8645\n",
      "theta =  0.4792, omega: -6.9744\n",
      "theta =  0.2964, omega: -7.5622\n",
      "theta =  0.1067, omega: -7.5627\n",
      "theta = -0.0772, omega: -6.9750\n",
      "theta = -0.2378, omega: -5.8602\n",
      "theta = -0.3669, omega: -4.3392\n",
      "theta = -0.4315, omega: -0.7231\n",
      "theta = -0.4070, omega:  2.5747\n",
      "theta = -0.3044, omega:  5.5334\n",
      "theta = -0.1566, omega:  6.1576\n",
      "theta =  0.0239, omega:  8.1049\n",
      "theta =  0.2424, omega:  9.3539\n",
      "theta =  0.4858, omega:  9.8549\n",
      "theta =  0.7312, omega:  9.6566\n",
      "theta =  0.9636, omega:  8.9007\n",
      "theta =  1.1714, omega:  7.7661\n",
      "theta =  1.3481, omega:  6.4284\n",
      "theta =  1.4930, omega:  5.0185\n",
      "theta =  1.6013, omega:  3.6211\n",
      "theta =  1.6724, omega:  2.2752\n",
      "theta =  1.7146, omega:  0.9921\n",
      "theta =  1.7229, omega: -0.1800\n",
      "theta =  1.7089, omega: -1.0783\n",
      "theta =  1.6696, omega: -1.9569\n",
      "theta =  1.5874, omega: -4.6685\n",
      "theta =  1.4598, omega: -5.4465\n",
      "theta =  1.3146, omega: -6.1496\n",
      "theta =  1.1532, omega: -6.7087\n",
      "theta =  0.9815, omega: -7.0299\n",
      "theta =  0.8047, omega: -7.0354\n",
      "theta =  0.6332, omega: -6.6578\n",
      "theta =  0.4514, omega: -7.6953\n",
      "theta =  0.2548, omega: -8.1556\n",
      "theta =  0.0494, omega: -7.9856\n",
      "theta = -0.1412, omega: -7.1925\n",
      "theta = -0.3047, omega: -5.8681\n",
      "theta = -0.4320, omega: -4.1486\n",
      "theta = -0.4864, omega: -0.3655\n",
      "theta = -0.4549, omega:  3.0455\n",
      "theta = -0.3387, omega:  6.1088\n",
      "theta = -0.1522, omega:  8.6170\n",
      "theta =  0.0630, omega:  8.5515\n",
      "theta =  0.2940, omega:  9.6459\n",
      "theta =  0.5406, omega:  9.9810\n",
      "theta =  0.7854, omega:  9.6356\n",
      "theta =  1.0165, omega:  8.7669\n",
      "theta =  1.2216, omega:  7.5612\n",
      "theta =  1.3947, omega:  6.1849\n",
      "theta =  1.5301, omega:  4.7701\n",
      "theta =  1.6329, omega:  3.3800\n",
      "theta =  1.6996, omega:  2.0502\n",
      "theta =  1.7336, omega:  0.7823\n",
      "theta =  1.7394, omega: -0.2773\n",
      "theta =  1.7230, omega: -1.1645\n",
      "theta =  1.6835, omega: -2.0347\n",
      "theta =  1.5979, omega: -4.7405\n",
      "theta =  1.4704, omega: -5.5192\n",
      "theta =  1.3218, omega: -6.2235\n",
      "theta =  1.1597, omega: -6.7843\n",
      "theta =  0.9844, omega: -7.1132\n",
      "theta =  0.8070, omega: -7.1163\n",
      "theta =  0.6321, omega: -6.7374\n",
      "theta =  0.4496, omega: -7.7686\n",
      "theta =  0.2483, omega: -8.2137\n",
      "theta =  0.0464, omega: -8.0242\n",
      "theta = -0.1484, omega: -7.2133\n",
      "theta = -0.3121, omega: -5.8679\n",
      "theta = -0.4375, omega: -4.1299\n",
      "theta = -0.4939, omega: -0.3289\n",
      "theta = -0.4572, omega:  3.0956\n",
      "theta = -0.3410, omega:  6.1699\n",
      "theta = -0.1772, omega:  6.8579\n",
      "theta = -0.0010, omega:  6.9993\n",
      "theta =  0.1919, omega:  8.4084\n",
      "theta =  0.4120, omega:  9.1227\n",
      "theta =  0.6429, omega:  9.1617\n",
      "theta =  0.8640, omega:  8.6259\n",
      "theta =  1.0686, omega:  7.6670\n",
      "theta =  1.2447, omega:  6.4458\n",
      "theta =  1.3911, omega:  5.0991\n",
      "theta =  1.5002, omega:  3.7205\n",
      "theta =  1.5779, omega:  2.3655\n",
      "theta =  1.6200, omega:  1.0548\n",
      "theta =  1.6296, omega: -0.1556\n",
      "theta =  1.6158, omega: -1.0845\n",
      "theta =  1.5516, omega: -3.8291\n",
      "theta =  1.4479, omega: -4.6310\n",
      "theta =  1.3234, omega: -5.3607\n",
      "theta =  1.1800, omega: -5.9629\n",
      "theta =  1.0254, omega: -6.3619\n",
      "theta =  0.8650, omega: -6.4883\n",
      "theta =  0.7040, omega: -6.2780\n",
      "theta =  0.5287, omega: -7.5275\n",
      "theta =  0.3342, omega: -8.2230\n",
      "theta =  0.1303, omega: -7.8324\n",
      "theta = -0.0600, omega: -7.3003\n",
      "theta = -0.2297, omega: -6.2171\n",
      "theta = -0.3656, omega: -4.6949\n",
      "theta = -0.4393, omega: -1.0499\n",
      "theta = -0.4433, omega:  0.5576\n",
      "theta = -0.3899, omega:  3.7666\n",
      "theta = -0.2824, omega:  4.7711\n",
      "theta = -0.1553, omega:  5.3840\n",
      "theta = -0.0153, omega:  5.5597\n",
      "theta =  0.1196, omega:  5.2931\n",
      "theta =  0.2677, omega:  6.4434\n",
      "theta =  0.4389, omega:  7.0712\n",
      "theta =  0.6178, omega:  7.1755\n",
      "theta =  0.7928, omega:  6.8205\n",
      "theta =  0.9556, omega:  6.0984\n",
      "theta =  1.0965, omega:  5.1198\n",
      "theta =  1.1877, omega:  2.1523\n",
      "theta =  1.2063, omega: -0.6468\n",
      "theta =  1.1576, omega: -3.1738\n",
      "theta =  1.0524, omega: -5.0584\n",
      "theta =  0.9217, omega: -5.3041\n",
      "theta =  0.7900, omega: -5.2918\n",
      "theta =  0.6594, omega: -4.9862\n",
      "theta =  0.5178, omega: -6.2057\n",
      "theta =  0.3540, omega: -6.9616\n",
      "theta =  0.1760, omega: -7.1788\n",
      "theta = -0.0007, omega: -6.8391\n",
      "theta = -0.1602, omega: -5.9721\n",
      "theta = -0.2957, omega: -4.6724\n",
      "theta = -0.3705, omega: -1.2391\n",
      "theta = -0.3591, omega:  1.9543\n",
      "theta = -0.2740, omega:  4.8171\n",
      "theta = -0.1450, omega:  5.4041\n",
      "theta = -0.0064, omega:  5.5498\n",
      "theta =  0.1281, omega:  5.2556\n",
      "theta =  0.2741, omega:  6.3825\n",
      "theta =  0.4423, omega:  6.9928\n",
      "theta =  0.6206, omega:  7.0878\n",
      "theta =  0.7934, omega:  6.7285\n",
      "theta =  0.9528, omega:  6.0101\n",
      "theta =  1.0921, omega:  5.0370\n",
      "theta =  1.1828, omega:  2.0764\n",
      "theta =  1.1972, omega: -0.7097\n",
      "theta =  1.1489, omega: -3.2262\n",
      "theta =  1.0433, omega: -5.0944\n",
      "theta =  0.9115, omega: -5.3233\n",
      "theta =  0.7777, omega: -5.2888\n",
      "theta =  0.6505, omega: -4.9588\n",
      "theta =  0.5109, omega: -6.1547\n",
      "theta =  0.3697, omega: -5.0647\n",
      "theta =  0.2371, omega: -5.4658\n",
      "theta =  0.1002, omega: -5.4354\n",
      "theta = -0.0083, omega: -3.1628\n",
      "theta = -0.0565, omega: -0.7145\n",
      "theta = -0.0463, omega:  1.4774\n",
      "theta =  0.0143, omega:  3.4160\n",
      "theta =  0.1146, omega:  4.5705\n",
      "theta =  0.2459, omega:  5.7831\n",
      "theta =  0.4021, omega:  6.5196\n",
      "theta =  0.5678, omega:  6.7607\n",
      "theta =  0.7346, omega:  6.5487\n",
      "theta =  0.8921, omega:  5.9608\n",
      "theta =  1.0317, omega:  5.0954\n",
      "theta =  1.1445, omega:  4.0520\n",
      "theta =  1.2091, omega:  1.0739\n",
      "theta =  1.2034, omega: -1.6219\n",
      "theta =  1.1299, omega: -4.1013\n",
      "theta =  1.0207, omega: -4.5249\n",
      "theta =  0.9063, omega: -4.7461\n",
      "theta =  0.7869, omega: -4.7327\n",
      "theta =  0.6647, omega: -4.9106\n",
      "theta =  0.5243, omega: -6.1474\n",
      "theta =  0.3610, omega: -6.9263\n",
      "theta =  0.1831, omega: -7.1699\n",
      "theta =  0.0068, omega: -6.8542\n",
      "theta = -0.1541, omega: -6.0108\n",
      "theta = -0.2900, omega: -4.7323\n",
      "theta = -0.3652, omega: -1.3143\n",
      "theta = -0.3561, omega:  1.8774\n",
      "theta = -0.2754, omega:  4.7395\n",
      "theta = -0.1452, omega:  5.3271\n",
      "theta = -0.0103, omega:  5.4831\n",
      "theta =  0.1240, omega:  5.2030\n",
      "theta =  0.2698, omega:  6.3473\n",
      "theta =  0.4359, omega:  6.9781\n",
      "theta =  0.6142, omega:  7.0916\n",
      "theta =  0.7870, omega:  6.7468\n",
      "theta =  0.9472, omega:  6.0374\n",
      "theta =  1.0875, omega:  5.0740\n",
      "theta =  1.1762, omega:  2.1200\n",
      "theta =  1.1944, omega: -0.6678\n",
      "theta =  1.1433, omega: -3.1823\n",
      "theta =  1.0413, omega: -5.0511\n",
      "theta =  0.9128, omega: -5.2799\n",
      "theta =  0.7803, omega: -5.2487\n",
      "theta =  0.6536, omega: -4.9248\n",
      "theta =  0.5134, omega: -6.1303\n",
      "theta =  0.3495, omega: -6.8754\n",
      "theta =  0.1756, omega: -7.0896\n",
      "theta =  0.0012, omega: -6.7481\n",
      "theta = -0.1595, omega: -5.8886\n",
      "theta = -0.2919, omega: -4.6048\n",
      "theta = -0.3661, omega: -1.1926\n",
      "theta = -0.3523, omega:  1.9771\n",
      "theta = -0.2655, omega:  4.8190\n",
      "theta = -0.1384, omega:  5.3826\n",
      "theta = -0.0018, omega:  5.5064\n",
      "theta =  0.1335, omega:  5.1966\n",
      "theta =  0.2786, omega:  6.3129\n",
      "theta =  0.4443, omega:  6.9192\n",
      "theta =  0.6194, omega:  7.0134\n",
      "theta =  0.7914, omega:  6.6606\n",
      "theta =  0.9507, omega:  5.9469\n",
      "theta =  1.0870, omega:  4.9851\n",
      "theta =  1.1733, omega:  2.0356\n",
      "theta =  1.1916, omega: -0.7394\n",
      "theta =  1.1641, omega: -1.4115\n",
      "theta =  1.0948, omega: -3.8509\n",
      "theta =  0.9899, omega: -4.6927\n",
      "theta =  0.8693, omega: -4.8478\n",
      "theta =  0.7495, omega: -4.7498\n",
      "theta =  0.6337, omega: -4.3837\n",
      "theta =  0.5087, omega: -5.5752\n",
      "theta =  0.3589, omega: -6.3461\n",
      "theta =  0.1949, omega: -6.6232\n",
      "theta =  0.0550, omega: -4.5638\n",
      "theta = -0.0541, omega: -4.0333\n",
      "theta = -0.1447, omega: -3.2057\n",
      "theta = -0.1889, omega: -0.3318\n",
      "theta = -0.1632, omega:  2.1996\n",
      "theta = -0.0807, omega:  4.4543\n",
      "theta =  0.0333, omega:  4.4643\n",
      "theta =  0.1630, omega:  5.9466\n",
      "theta =  0.3252, omega:  6.9199\n",
      "theta =  0.5059, omega:  7.3487\n",
      "theta =  0.6888, omega:  7.2594\n",
      "theta =  0.8637, omega:  6.7342\n",
      "theta =  1.0198, omega:  5.8786\n",
      "theta =  1.1539, omega:  4.8085\n",
      "theta =  1.2366, omega:  1.7837\n",
      "theta =  1.2463, omega: -1.0291\n",
      "theta =  1.1869, omega: -3.5863\n",
      "theta =  1.0748, omega: -5.4948\n",
      "theta =  0.9323, omega: -5.7541\n",
      "theta =  0.7883, omega: -5.7363\n",
      "theta =  0.6502, omega: -5.4039\n",
      "theta =  0.4990, omega: -6.5667\n",
      "theta =  0.3425, omega: -5.8717\n",
      "theta =  0.1902, omega: -6.1335\n",
      "theta =  0.0404, omega: -5.9107\n",
      "theta = -0.0999, omega: -5.2363\n",
      "theta = -0.2179, omega: -4.1745\n",
      "theta = -0.2829, omega: -1.0038\n",
      "theta = -0.2734, omega:  1.9080\n",
      "theta = -0.1955, omega:  4.0579\n",
      "theta = -0.0653, omega:  6.2782\n",
      "theta =  0.0901, omega:  6.1138\n",
      "theta =  0.2606, omega:  7.2999\n",
      "theta =  0.4494, omega:  7.8941\n",
      "theta =  0.6481, omega:  7.9119\n",
      "theta =  0.8432, omega:  7.4370\n",
      "theta =  1.0156, omega:  6.5838\n",
      "theta =  1.1685, omega:  5.4849\n",
      "theta =  1.2912, omega:  4.2528\n",
      "theta =  1.3575, omega:  1.1238\n",
      "theta =  1.3490, omega: -1.7060\n",
      "theta =  1.2738, omega: -4.3304\n",
      "theta =  1.1586, omega: -4.9277\n",
      "theta =  1.0292, omega: -5.3469\n",
      "theta =  0.8918, omega: -5.5344\n",
      "theta =  0.7531, omega: -5.4453\n",
      "theta =  0.6230, omega: -5.0477\n",
      "theta =  0.4810, omega: -6.1633\n",
      "theta =  0.3164, omega: -6.8138\n",
      "theta =  0.1454, omega: -6.9339\n",
      "theta = -0.0238, omega: -6.5134\n",
      "theta = -0.1544, omega: -3.7761\n",
      "theta = -0.2122, omega: -0.8343\n",
      "theta = -0.1970, omega:  1.8416\n",
      "theta = -0.1204, omega:  4.2255\n",
      "theta = -0.0155, omega:  4.3781\n",
      "theta =  0.0940, omega:  4.1851\n",
      "theta =  0.2164, omega:  5.4920\n",
      "theta =  0.3646, omega:  6.3365\n",
      "theta =  0.5292, omega:  6.6900\n",
      "theta =  0.6948, omega:  6.5781\n",
      "theta =  0.8559, omega:  6.0763\n",
      "theta =  0.9984, omega:  5.2750\n",
      "theta =  1.1183, omega:  4.2707\n",
      "theta =  1.1852, omega:  1.3158\n",
      "theta =  1.1839, omega: -1.3854\n",
      "theta =  1.1174, omega: -3.8564\n",
      "theta =  1.0128, omega: -4.7313\n",
      "theta =  0.8915, omega: -4.9225\n",
      "theta =  0.7670, omega: -4.8655\n",
      "theta =  0.6496, omega: -4.5321\n",
      "theta =  0.5429, omega: -3.9293\n",
      "theta =  0.4322, omega: -4.9058\n",
      "theta =  0.3005, omega: -5.5010\n",
      "theta =  0.1605, omega: -5.6600\n",
      "theta =  0.0206, omega: -5.3787\n",
      "theta = -0.1052, omega: -4.6844\n",
      "theta = -0.2084, omega: -3.6475\n",
      "theta = -0.2632, omega: -0.5424\n",
      "theta = -0.2387, omega:  2.2447\n",
      "theta = -0.1536, omega:  4.7300\n",
      "theta = -0.0325, omega:  4.9466\n",
      "theta =  0.0918, omega:  4.7661\n",
      "theta =  0.2284, omega:  6.0434\n",
      "theta =  0.3897, omega:  6.8153\n",
      "theta =  0.5644, omega:  7.0686\n",
      "theta =  0.7393, omega:  6.8456\n",
      "theta =  0.9033, omega:  6.2355\n",
      "theta =  1.0464, omega:  5.3357\n",
      "theta =  1.1669, omega:  4.2569\n",
      "theta =  1.2372, omega:  1.2419\n",
      "theta =  1.2334, omega: -1.5046\n",
      "theta =  1.1646, omega: -4.0256\n",
      "theta =  1.0565, omega: -4.5006\n",
      "theta =  0.9380, omega: -4.7836\n",
      "theta =  0.8187, omega: -4.8374\n",
      "theta =  0.6981, omega: -4.6290\n",
      "theta =  0.5909, omega: -4.1497\n",
      "theta =  0.4711, omega: -5.2390\n",
      "theta =  0.3311, omega: -5.9267\n",
      "theta =  0.1794, omega: -6.1507\n",
      "theta =  0.0277, omega: -5.8946\n",
      "theta = -0.1119, omega: -5.1812\n",
      "theta = -0.2282, omega: -4.0902\n",
      "theta = -0.2893, omega: -0.9019\n",
      "theta = -0.2766, omega:  2.0202\n",
      "theta = -0.1911, omega:  4.6282\n",
      "theta = -0.0696, omega:  4.9745\n",
      "theta =  0.0535, omega:  4.9186\n",
      "theta =  0.1707, omega:  4.4805\n",
      "theta =  0.2986, omega:  5.5306\n",
      "theta =  0.4463, omega:  6.1318\n",
      "theta =  0.6013, omega:  6.2818\n",
      "theta =  0.7547, omega:  6.0183\n",
      "theta =  0.8966, omega:  5.4213\n",
      "theta =  1.0232, omega:  4.5722\n",
      "theta =  1.1033, omega:  1.7341\n",
      "theta =  1.1114, omega: -0.9189\n",
      "theta =  1.0560, omega: -3.3109\n",
      "theta =  0.9546, omega: -5.0385\n",
      "theta =  0.8277, omega: -5.1046\n",
      "theta =  0.7006, omega: -4.8959\n",
      "theta =  0.5835, omega: -4.3988\n",
      "theta =  0.4593, omega: -5.4575\n",
      "theta =  0.3143, omega: -6.0953\n",
      "theta =  0.1621, omega: -6.2583\n",
      "theta =  0.0062, omega: -5.9302\n",
      "theta = -0.1344, omega: -5.1499\n",
      "theta = -0.2475, omega: -3.9920\n",
      "theta = -0.3099, omega: -0.7498\n",
      "theta = -0.2902, omega:  2.2002\n",
      "theta = -0.1986, omega:  4.8346\n",
      "theta = -0.0761, omega:  5.1910\n",
      "theta =  0.0780, omega:  6.9499\n",
      "theta =  0.2709, omega:  8.1070\n",
      "theta =  0.4770, omega:  8.6170\n",
      "theta =  0.6954, omega:  8.5118\n",
      "theta =  0.9000, omega:  7.8954\n",
      "theta =  1.0873, omega:  6.9150\n",
      "theta =  1.2460, omega:  5.7074\n",
      "theta =  1.3713, omega:  4.3935\n",
      "theta =  1.4628, omega:  3.0503\n",
      "theta =  1.4990, omega: -0.1008\n",
      "theta =  1.4644, omega: -2.8655\n",
      "theta =  1.3568, omega: -5.5173\n",
      "theta =  1.2116, omega: -6.1415\n",
      "theta =  1.0516, omega: -6.5750\n",
      "theta =  0.8859, omega: -6.7392\n",
      "theta =  0.7177, omega: -6.5609\n",
      "theta =  0.5371, omega: -7.8256\n",
      "theta =  0.3303, omega: -8.5219\n",
      "theta =  0.1179, omega: -8.5629\n",
      "theta = -0.0906, omega: -7.9367\n",
      "theta = -0.2758, omega: -6.7122\n",
      "theta = -0.4229, omega: -5.0219\n",
      "theta = -0.5009, omega: -1.2006\n",
      "theta = -0.4840, omega:  2.3508\n",
      "theta = -0.3845, omega:  5.5516\n",
      "theta = -0.2359, omega:  6.4186\n",
      "theta = -0.0690, omega:  6.7692\n",
      "theta =  0.0990, omega:  6.5795\n",
      "theta =  0.2793, omega:  7.7019\n",
      "theta =  0.4614, omega:  6.8433\n",
      "theta =  0.6359, omega:  6.9001\n",
      "theta =  0.8038, omega:  6.5157\n",
      "theta =  0.9581, omega:  5.7913\n",
      "theta =  1.0898, omega:  4.8242\n",
      "theta =  1.1737, omega:  1.8777\n",
      "theta =  1.1862, omega: -0.8794\n",
      "theta =  1.1342, omega: -3.3740\n",
      "theta =  1.0219, omega: -5.2118\n",
      "theta =  0.8909, omega: -5.4020\n",
      "theta =  0.7565, omega: -5.3179\n",
      "theta =  0.6269, omega: -4.9305\n",
      "theta =  0.4914, omega: -6.0698\n",
      "theta =  0.3294, omega: -6.7519\n",
      "theta =  0.1554, omega: -6.9072\n",
      "theta = -0.0142, omega: -6.5238\n",
      "theta = -0.1667, omega: -5.6420\n",
      "theta = -0.2937, omega: -4.3520\n",
      "theta = -0.3586, omega: -0.9555\n",
      "theta = -0.3413, omega:  2.1682\n",
      "theta = -0.2508, omega:  4.9632\n",
      "theta = -0.1199, omega:  5.4711\n",
      "theta =  0.0166, omega:  5.5337\n",
      "theta =  0.1527, omega:  5.1594\n",
      "theta =  0.2953, omega:  6.2222\n",
      "theta =  0.4595, omega:  6.7826\n",
      "theta =  0.6309, omega:  6.8460\n",
      "theta =  0.7981, omega:  6.4775\n",
      "theta =  0.9519, omega:  5.7612\n",
      "theta =  1.0832, omega:  4.8080\n",
      "theta =  1.1680, omega:  1.8685\n",
      "theta =  1.1794, omega: -0.8770\n",
      "theta =  1.1256, omega: -3.3647\n",
      "theta =  1.0190, omega: -5.1942\n",
      "theta =  0.8837, omega: -5.3723\n",
      "theta =  0.7507, omega: -5.2769\n",
      "theta =  0.6235, omega: -4.8843\n",
      "theta =  0.4865, omega: -6.0161\n",
      "theta =  0.3266, omega: -6.6933\n",
      "theta =  0.1562, omega: -6.8505\n",
      "theta = -0.0100, omega: -6.4721\n",
      "theta = -0.1644, omega: -5.5978\n",
      "theta = -0.2871, omega: -4.3217\n",
      "theta = -0.3540, omega: -0.9386\n",
      "theta = -0.3352, omega:  2.1682\n",
      "theta = -0.2472, omega:  4.9521\n",
      "theta = -0.1138, omega:  5.4448\n",
      "theta =  0.0214, omega:  5.4984\n",
      "theta =  0.1553, omega:  5.1163\n",
      "theta =  0.2963, omega:  6.1737\n",
      "theta =  0.4587, omega:  6.7326\n",
      "theta =  0.6292, omega:  6.8027\n",
      "theta =  0.7972, omega:  6.4373\n",
      "theta =  0.9481, omega:  5.7309\n",
      "theta =  1.0814, omega:  4.7829\n",
      "theta =  1.1639, omega:  1.8490\n",
      "theta =  1.1743, omega: -0.8890\n",
      "theta =  1.1220, omega: -3.3686\n",
      "theta =  1.0114, omega: -5.1914\n",
      "theta =  0.8800, omega: -5.3603\n",
      "theta =  0.7470, omega: -5.2562\n",
      "theta =  0.6202, omega: -4.8526\n",
      "theta =  0.4834, omega: -5.9751\n",
      "theta =  0.3258, omega: -6.6470\n",
      "theta =  0.1567, omega: -6.8023\n",
      "theta = -0.0090, omega: -6.4270\n",
      "theta = -0.1608, omega: -5.5570\n",
      "theta = -0.2847, omega: -4.2895\n",
      "theta = -0.3508, omega: -0.9149\n",
      "theta = -0.3320, omega:  2.1815\n",
      "theta = -0.2436, omega:  4.9498\n",
      "theta = -0.1111, omega:  5.4330\n",
      "theta =  0.0245, omega:  5.4744\n",
      "theta =  0.1574, omega:  5.0857\n",
      "theta =  0.2978, omega:  6.1359\n",
      "theta =  0.4600, omega:  6.6942\n",
      "theta =  0.6311, omega:  6.7655\n",
      "theta =  0.7964, omega:  6.4015\n",
      "theta =  0.9478, omega:  5.6991\n",
      "theta =  1.0765, omega:  4.7542\n",
      "theta =  1.1603, omega:  1.8314\n",
      "theta =  1.1683, omega: -0.9037\n",
      "theta =  1.1151, omega: -3.3788\n",
      "theta =  1.0286, omega: -3.8202\n",
      "theta =  0.9262, omega: -4.0901\n",
      "theta =  0.8178, omega: -4.6143\n",
      "theta =  0.7032, omega: -4.4153\n",
      "theta =  0.5995, omega: -3.9602\n",
      "theta =  0.4851, omega: -5.0863\n",
      "theta =  0.3483, omega: -5.8219\n",
      "theta =  0.1986, omega: -6.1052\n",
      "theta =  0.0479, omega: -5.9087\n",
      "theta = -0.0940, omega: -5.2541\n",
      "theta = -0.1911, omega: -2.3921\n",
      "theta = -0.2104, omega:  0.5232\n",
      "theta = -0.1671, omega:  3.0449\n",
      "theta = -0.0627, omega:  5.2471\n",
      "theta =  0.0667, omega:  5.1484\n",
      "theta =  0.1936, omega:  4.6502\n",
      "theta =  0.3214, omega:  5.6294\n",
      "theta =  0.4694, omega:  6.1575\n",
      "theta =  0.6246, omega:  6.2407\n",
      "theta =  0.7775, omega:  5.9218\n",
      "theta =  0.9193, omega:  5.2813\n",
      "theta =  1.0403, omega:  4.4090\n",
      "theta =  1.1143, omega:  1.5559\n",
      "theta =  1.1175, omega: -1.0883\n",
      "theta =  1.0597, omega: -3.4837\n",
      "theta =  0.9514, omega: -5.2047\n",
      "theta =  0.8190, omega: -5.2584\n",
      "theta =  0.6919, omega: -5.0269\n",
      "theta =  0.5711, omega: -4.5022\n",
      "theta =  0.4466, omega: -5.5169\n",
      "theta =  0.2995, omega: -6.1091\n",
      "theta =  0.1443, omega: -6.2267\n",
      "theta = -0.0072, omega: -5.8531\n",
      "theta = -0.1461, omega: -5.0365\n",
      "theta = -0.2574, omega: -3.8530\n",
      "theta = -0.3126, omega: -0.5948\n",
      "theta = -0.2886, omega:  2.3455\n",
      "theta = -0.1967, omega:  4.9729\n",
      "theta = -0.0667, omega:  5.3067\n",
      "theta =  0.0661, omega:  5.2178\n",
      "theta =  0.1910, omega:  4.7239\n",
      "theta =  0.3210, omega:  5.7023\n",
      "theta =  0.4710, omega:  6.2250\n",
      "theta =  0.6296, omega:  6.2960\n",
      "theta =  0.7845, omega:  5.9642\n",
      "theta =  0.9244, omega:  5.3120\n",
      "theta =  1.0468, omega:  4.4251\n",
      "theta =  1.1200, omega:  1.5592\n",
      "theta =  1.1260, omega: -1.0910\n",
      "theta =  1.0669, omega: -3.4988\n",
      "theta =  0.9571, omega: -5.2284\n",
      "theta =  0.8282, omega: -5.2947\n",
      "theta =  0.6969, omega: -5.0722\n",
      "theta =  0.5749, omega: -4.5546\n",
      "theta =  0.4477, omega: -5.5779\n",
      "theta =  0.3006, omega: -6.1714\n",
      "theta =  0.1445, omega: -6.2845\n",
      "theta = -0.0091, omega: -5.9039\n",
      "theta = -0.1491, omega: -5.0745\n",
      "theta = -0.2611, omega: -3.8806\n",
      "theta = -0.3168, omega: -0.6038\n",
      "theta = -0.2954, omega:  2.3505\n",
      "theta = -0.2012, omega:  4.9931\n",
      "theta = -0.0726, omega:  5.3422\n",
      "theta =  0.0612, omega:  5.2634\n",
      "theta =  0.1883, omega:  4.7734\n",
      "theta =  0.3202, omega:  5.7531\n",
      "theta =  0.4729, omega:  6.2750\n",
      "theta =  0.6293, omega:  6.3395\n",
      "theta =  0.7860, omega:  6.0026\n",
      "theta =  0.9267, omega:  5.3405\n",
      "theta =  1.0508, omega:  4.4450\n",
      "theta =  1.1243, omega:  1.5753\n",
      "theta =  1.1304, omega: -1.0858\n",
      "theta =  1.0757, omega: -3.4984\n",
      "theta =  0.9648, omega: -5.2389\n",
      "theta =  0.8316, omega: -5.3099\n",
      "theta =  0.6990, omega: -5.1021\n",
      "theta =  0.5784, omega: -4.5900\n",
      "theta =  0.4489, omega: -5.6186\n",
      "theta =  0.3015, omega: -6.2170\n",
      "theta =  0.1422, omega: -6.3300\n",
      "theta = -0.0122, omega: -5.9468\n",
      "theta = -0.1495, omega: -5.1104\n",
      "theta = -0.2414, omega: -2.0857\n",
      "theta = -0.2553, omega:  0.8564\n",
      "theta = -0.1990, omega:  3.4843\n",
      "theta = -0.1024, omega:  4.3909\n",
      "theta =  0.0091, omega:  4.4705\n",
      "theta =  0.1193, omega:  4.1965\n",
      "theta =  0.2420, omega:  5.4269\n",
      "theta =  0.3868, omega:  6.2043\n",
      "theta =  0.5479, omega:  6.5044\n",
      "theta =  0.7100, omega:  6.3620\n",
      "theta =  0.8616, omega:  5.8426\n",
      "theta =  0.9983, omega:  5.0414\n",
      "theta =  1.1129, omega:  4.0466\n",
      "theta =  1.1758, omega:  1.1107\n",
      "theta =  1.1690, omega: -1.5531\n",
      "theta =  1.1005, omega: -3.9956\n",
      "theta =  0.9968, omega: -4.3790\n",
      "theta =  0.8826, omega: -4.5630\n",
      "theta =  0.7691, omega: -4.5112\n",
      "theta =  0.6592, omega: -4.2063\n",
      "theta =  0.5369, omega: -5.4778\n",
      "theta =  0.3900, omega: -6.3350\n",
      "theta =  0.2248, omega: -6.7032\n",
      "theta =  0.0578, omega: -6.5477\n",
      "theta = -0.1000, omega: -5.8842\n",
      "theta = -0.2328, omega: -4.7852\n",
      "theta = -0.3346, omega: -3.3570\n",
      "theta = -0.3747, omega:  0.0838\n",
      "theta = -0.3343, omega:  3.1231\n",
      "theta = -0.2220, omega:  5.8300\n",
      "theta = -0.0719, omega:  6.1809\n",
      "theta =  0.0827, omega:  6.0397\n",
      "theta =  0.2490, omega:  7.2514\n",
      "theta =  0.4405, omega:  7.8718\n",
      "theta =  0.6392, omega:  7.9157\n",
      "theta =  0.8327, omega:  7.4601\n",
      "theta =  1.0103, omega:  6.6233\n",
      "theta =  1.1628, omega:  5.5347\n",
      "theta =  1.2845, omega:  4.3078\n",
      "theta =  1.3536, omega:  1.1798\n",
      "theta =  1.3474, omega: -1.6530\n"
     ]
    }
   ],
   "source": [
    "env = DQN_UnbalancedDisk()\n",
    "#model = SAC.load('sac_unbalanced_disk_v1', env=env)\n",
    "obs, _ = env.reset()\n",
    "for i in range(5000):\n",
    "    action, _states = model_dqn.predict(obs)  # policy\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    t = (obs[0] + np.pi)%(2*np.pi) - np.pi\n",
    "    print( f'theta = {t: .4f}, omega: {obs[1]: .4f}')\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
