{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load('training-val-test-data.npz')\n",
    "th_train = out['th'] #th[0],th[1],th[2],th[3],...\n",
    "u_train = out['u'] #u[0],u[1],u[2],u[3],...\n",
    "\n",
    "# data = np.load('test-prediction-submission-file.npz')\n",
    "data = np.load('hidden-test-prediction-submission-file.npz')\n",
    "upast_test = data['upast'] #N by u[k-15],u[k-14],...,u[k-1]\n",
    "thpast_test = data['thpast'] #N by y[k-15],y[k-14],...,y[k-1]\n",
    "# thpred = data['thnow'] #all zeros\n",
    "\n",
    "\n",
    "def create_IO_data(u,y,na,nb):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for k in range(max(na,nb), len(y)):\n",
    "        X.append(np.concatenate([u[k-nb:k],y[k-na:k]]))\n",
    "        Y.append(y[k])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "na = 2\n",
    "nb = 3\n",
    "Xtrain, Ytrain = create_IO_data(u_train, th_train, na, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, n_hidden_nodes=40, n_in=nb+na):\n",
    "        super(Network,self).__init__()\n",
    "        self.layer1 = nn.Linear(n_in,n_hidden_nodes).double()\n",
    "        self.layer2 = nn.Linear(n_hidden_nodes,n_hidden_nodes).double()\n",
    "        self.layer3 = nn.Linear(n_hidden_nodes,1).double()\n",
    "\n",
    "    def forward(self,u):\n",
    "        # u = u[:, None]\n",
    "        x1 = torch.nn.functional.leaky_relu(self.layer1(u))\n",
    "        x2 = torch.nn.functional.leaky_relu(self.layer2(x1))\n",
    "        y = self.layer3(x2)[:, 0]\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for layer1.weight: copying a param with shape torch.Size([40, 20]) from checkpoint, the shape in current model is torch.Size([40, 4]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Network()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2589\u001b[0m             ),\n\u001b[0;32m   2590\u001b[0m         )\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2596\u001b[0m         )\n\u001b[0;32m   2597\u001b[0m     )\n\u001b[0;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for layer1.weight: copying a param with shape torch.Size([40, 20]) from checkpoint, the shape in current model is torch.Size([40, 4])."
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model.load_state_dict(torch.load(\"model.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(model, upast, thpast, na=10, nb=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.eval()\n",
    "    upast = upast.copy()\n",
    "    thpast = thpast.copy()\n",
    "    N = upast.shape[0]\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(N):\n",
    "        u_seq = list(upast[i, -nb:])\n",
    "        y_seq = list(thpast[i, -na:])\n",
    "        preds = []\n",
    "\n",
    "        for _ in range(50):  # or however long you want to simulate\n",
    "            inp = np.concatenate([u_seq[-nb:], y_seq[-na:]])\n",
    "            inp_tensor = torch.tensor(inp).double().unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                y_new = model(inp_tensor).cpu().numpy()[0]\n",
    "            preds.append(y_new)\n",
    "            y_seq.append(y_new)\n",
    "            y_seq = y_seq[-na:]\n",
    "\n",
    "        y_pred.append(preds)\n",
    "\n",
    "    return np.array(y_pred)\n",
    "\n",
    "model = Network()\n",
    "model.load_state_dict(torch.load(\"model.pt\", weights_only=True))\n",
    "\n",
    "data = np.load('hidden-test-simulation-submission-file.npz')\n",
    "u_train = data['u'] \n",
    "th_train = data['th'] #only the first 50 values are filled the rest are zeros\n",
    "\n",
    "def create_IO_data(u,y,na,nb):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for k in range(max(na,nb), len(y)):\n",
    "        X.append(np.concatenate([u[k-nb:k],y[k-na:k]]))\n",
    "        Y.append(y[k])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "na = 2\n",
    "nb = 3\n",
    "Xtrain, Ytrain = create_IO_data(u_train, th_train, na, nb)\n",
    "\n",
    "data = np.load('hidden-test-simulation-submission-file.npz')\n",
    "u_test = data['u']\n",
    "th_test = data['th'] #only the first 50 values are filled the rest are zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train prediction errors:\n",
      "RMS: 0.006480454031031707 radians\n",
      "RMS: 0.37130266530665823 degrees\n",
      "NRMS: 19.732015645890392 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(Xtrain,Ytrain)\n",
    "\n",
    "Ytrain_pred = reg.predict(Xtrain)\n",
    "print('train prediction errors:')\n",
    "print('RMS:', np.mean((Ytrain_pred-Ytrain)**2)**0.5,'radians')\n",
    "print('RMS:', np.mean((Ytrain_pred-Ytrain)**2)**0.5/(2*np.pi)*360,'degrees')\n",
    "print('NRMS:', np.mean((Ytrain_pred-Ytrain)**2)**0.5/Ytrain.std()*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train simulation errors:\n",
      "RMS: 0.047552863640730816 radians\n",
      "RMS: 2.7245783903749823 degrees\n",
      "NRMS: 144.45323189933524 %\n"
     ]
    }
   ],
   "source": [
    "def simulation_IO_model(f, ulist, ylist, skip=50):\n",
    "\n",
    "    upast = ulist[skip-na:skip].tolist() #good initialization\n",
    "    ypast = ylist[skip-nb:skip].tolist()\n",
    "    Y = ylist[:skip].tolist()\n",
    "    for u in ulist[skip:]:\n",
    "        x = np.concatenate([upast,ypast],axis=0)\n",
    "        ypred = f(x)\n",
    "        Y.append(ypred)\n",
    "        upast.append(u)\n",
    "        upast.pop(0)\n",
    "        ypast.append(ypred)\n",
    "        ypast.pop(0)\n",
    "    return np.array(Y)\n",
    "\n",
    "skip = max(na,nb)\n",
    "th_train_sim = simulation_IO_model(lambda x: reg.predict(x[None,:])[0], u_train, th_train, skip=skip)\n",
    "print('train simulation errors:')\n",
    "print('RMS:', np.mean((th_train_sim[skip:]-th_train[skip:])**2)**0.5,'radians')\n",
    "print('RMS:', np.mean((th_train_sim[skip:]-th_train[skip:])**2)**0.5/(2*np.pi)*360,'degrees')\n",
    "print('NRMS:', np.mean((th_train_sim[skip:]-th_train[skip:])**2)**0.5/th_train.std()*100,'%')\n",
    "\n",
    "\n",
    "skip = 50\n",
    "th_test_sim = simulation_IO_model(lambda x: reg.predict(x[None,:])[0], u_test, th_test, skip=skip)\n",
    "\n",
    "assert len(th_test_sim)==len(th_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x5 and 20x40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n\u001b[0;32m     11\u001b[0m skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(na, nb)\n\u001b[1;32m---> 12\u001b[0m th_train_sim \u001b[38;5;241m=\u001b[39m simulation_IO_model(nn_predict, u_train, th_train, skip\u001b[38;5;241m=\u001b[39mskip)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain simulation errors:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMS:\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean((th_train_sim[skip:] \u001b[38;5;241m-\u001b[39m th_train[skip:])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradians\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m, in \u001b[0;36msimulation_IO_model\u001b[1;34m(f, ulist, ylist, skip)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m ulist[skip:]:\n\u001b[0;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([upast,ypast],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     ypred \u001b[38;5;241m=\u001b[39m f(x)\n\u001b[0;32m      9\u001b[0m     Y\u001b[38;5;241m.\u001b[39mappend(ypred)\n\u001b[0;32m     10\u001b[0m     upast\u001b[38;5;241m.\u001b[39mappend(u)\n",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m, in \u001b[0;36mnn_predict\u001b[1;34m(x_np)\u001b[0m\n\u001b[0;32m      6\u001b[0m x_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_np, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# shape (1, 2*na)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 8\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(x_tensor)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[1;34m(self, u)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,u):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# u = u[:, None]\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(u))\n\u001b[0;32m     12\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x1))\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# x3 = torch.sigmoid(self.layer3(x2))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x5 and 20x40)"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def nn_predict(x_np):\n",
    "    x_tensor = torch.tensor(x_np, dtype=torch.float64).unsqueeze(0).to(\"cpu\")  # shape (1, 2*na)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_tensor).cpu().numpy()[0]\n",
    "    return y_pred\n",
    "\n",
    "skip = max(na, nb)\n",
    "th_train_sim = simulation_IO_model(nn_predict, u_train, th_train, skip=skip)\n",
    "\n",
    "print('train simulation errors:')\n",
    "print('RMS:', np.mean((th_train_sim[skip:] - th_train[skip:])**2)**0.5, 'radians')\n",
    "print('RMS:', np.mean((th_train_sim[skip:] - th_train[skip:])**2)**0.5 / (2 * np.pi) * 360, 'degrees')\n",
    "print('NRMS:', np.mean((th_train_sim[skip:] - th_train[skip:])**2)**0.5 / th_train.std() * 100, '%')\n",
    "\n",
    "skip = 50\n",
    "th_test_sim = simulation_IO_model(lambda x: model(x[None,:])[0], u_test, th_test, skip=skip)\n",
    "\n",
    "assert len(th_test_sim)==len(th_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
