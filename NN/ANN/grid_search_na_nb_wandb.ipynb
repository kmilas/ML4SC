{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11ee798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_NRMS</td><td>▄▆▆▇▇██▇▇▇▅▄▄▄▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▁▁▁▁▁▂▃▁▁▁</td></tr><tr><td>train_loss</td><td>▅▆▆███▇▇▅▆▅▅▄▄▄▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val_NRMS</td><td>▅███▇▆▄▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▅▆▆▇████▇▆▄▄▄▄▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>279</td></tr><tr><td>train_NRMS</td><td>0.39551</td></tr><tr><td>train_loss</td><td>0.18971</td></tr><tr><td>val_NRMS</td><td>0.48013</td></tr><tr><td>val_loss</td><td>0.23057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sun-2</strong> at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/26btelud' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/26btelud</a><br> View project at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250605_193455-26btelud\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xskap\\Documents\\Eindhoven\\2025_Q4\\5SC28_ML_systems_control\\Assignment\\NN\\wandb\\run-20250605_193623-hqf352ou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hqf352ou' target=\"_blank\">stellar-frog-3</a></strong> to <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hqf352ou' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hqf352ou</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train_NRMS</td><td>▂▄▇▅█████▇▅▄▃▃▄▃▃▃▃▃▃▂▃▂▂▂▁▄▂▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss</td><td>▃▂▂▂▃▇▇█████▇▇▆▄▄▃▆▄▃▃▃▂▂▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_NRMS</td><td>▂▃▄▄▅██▆▆▅▅▂▂▂▂▃▂▂▂▂▂▂▂▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▂▅▅▆▇█▇▇▇▆▃▃▃▂▅▂▂▂▂▂▂▂▂▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>279</td></tr><tr><td>train_NRMS</td><td>0.39551</td></tr><tr><td>train_loss</td><td>0.18971</td></tr><tr><td>val_NRMS</td><td>0.48013</td></tr><tr><td>val_loss</td><td>0.23057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-frog-3</strong> at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hqf352ou' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hqf352ou</a><br> View project at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250605_193623-hqf352ou\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xskap\\Documents\\Eindhoven\\2025_Q4\\5SC28_ML_systems_control\\Assignment\\NN\\wandb\\run-20250605_193720-mc96u561</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/mc96u561' target=\"_blank\">daily-wave-4</a></strong> to <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/mc96u561' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/mc96u561</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_NRMS</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▂▂</td></tr><tr><td>train_loss</td><td>█▄▄▁▁▁▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>val_NRMS</td><td>▂███████▆▆▅▇▅▅▅▂▂▂▂▂▂▂▆▂▂▂▂▃▂▂▂▁▁▄▁▁▁▁▂▁</td></tr><tr><td>val_loss</td><td>▅▇███▇▇▇▇▅▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▁▁▂▁▁▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>279</td></tr><tr><td>train_NRMS</td><td>0.5037</td></tr><tr><td>train_loss</td><td>0.23999</td></tr><tr><td>val_NRMS</td><td>0.47845</td></tr><tr><td>val_loss</td><td>0.23236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-wave-4</strong> at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/mc96u561' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/mc96u561</a><br> View project at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250605_193720-mc96u561\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xskap\\Documents\\Eindhoven\\2025_Q4\\5SC28_ML_systems_control\\Assignment\\NN\\wandb\\run-20250605_193821-tkz18i3l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/tkz18i3l' target=\"_blank\">true-monkey-5</a></strong> to <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/tkz18i3l' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/tkz18i3l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_NRMS</td><td>███▇▇▇▇▆▆▆▅▅▅▅▄▄▃▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▃▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_NRMS</td><td>▅█▇▆▆▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>val_loss</td><td>█▆▆▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>279</td></tr><tr><td>train_NRMS</td><td>0.41968</td></tr><tr><td>train_loss</td><td>0.20151</td></tr><tr><td>val_NRMS</td><td>0.3745</td></tr><tr><td>val_loss</td><td>0.17627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-monkey-5</strong> at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/tkz18i3l' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/tkz18i3l</a><br> View project at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250605_193821-tkz18i3l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xskap\\Documents\\Eindhoven\\2025_Q4\\5SC28_ML_systems_control\\Assignment\\NN\\wandb\\run-20250605_193911-2sn5kmes</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/2sn5kmes' target=\"_blank\">clear-silence-6</a></strong> to <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/2sn5kmes' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/2sn5kmes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>train_NRMS</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▆▆███▇▇▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_NRMS</td><td>█▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>279</td></tr><tr><td>train_NRMS</td><td>0.28105</td></tr><tr><td>train_loss</td><td>0.13468</td></tr><tr><td>val_NRMS</td><td>0.25811</td></tr><tr><td>val_loss</td><td>0.12197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-silence-6</strong> at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/2sn5kmes' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/2sn5kmes</a><br> View project at: <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250605_193911-2sn5kmes\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\xskap\\Documents\\Eindhoven\\2025_Q4\\5SC28_ML_systems_control\\Assignment\\NN\\wandb\\run-20250605_194004-hy35r19t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hy35r19t' target=\"_blank\">toasty-plant-7</a></strong> to <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hy35r19t' target=\"_blank\">https://wandb.ai/skapetis-tu-e/5SC28-NN-grid/runs/hy35r19t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((y_pred \u001b[38;5;241m-\u001b[39m Ytrain_tensor[i:i\u001b[38;5;241m+\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     75\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 76\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    237\u001b[0m         group,\n\u001b[0;32m    238\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         state_steps,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[1;32m--> 246\u001b[0m     adam(\n\u001b[0;32m    247\u001b[0m         params_with_grad,\n\u001b[0;32m    248\u001b[0m         grads,\n\u001b[0;32m    249\u001b[0m         exp_avgs,\n\u001b[0;32m    250\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    251\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    252\u001b[0m         state_steps,\n\u001b[0;32m    253\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    254\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    255\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    256\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    257\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    258\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    259\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    260\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    261\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    262\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    263\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    264\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    265\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    266\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    267\u001b[0m         decoupled_weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoupled_weight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 933\u001b[0m func(\n\u001b[0;32m    934\u001b[0m     params,\n\u001b[0;32m    935\u001b[0m     grads,\n\u001b[0;32m    936\u001b[0m     exp_avgs,\n\u001b[0;32m    937\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    938\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    939\u001b[0m     state_steps,\n\u001b[0;32m    940\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    941\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    942\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    943\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    944\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    945\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    946\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    947\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    948\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    949\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    950\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    951\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    952\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    953\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xskap\\miniconda3\\envs\\ml4sc\\Lib\\site-packages\\torch\\optim\\adam.py:651\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# Update steps\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;66;03m# and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;66;03m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mis_compiling() \u001b[38;5;129;01mand\u001b[39;00m device_state_steps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_cpu:\n\u001b[1;32m--> 651\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(\n\u001b[0;32m    652\u001b[0m         device_state_steps, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    653\u001b[0m     )\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    655\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_state_steps, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data loading\n",
    "out = np.load('../training-val-test-data.npz')\n",
    "th_train = out['th']\n",
    "u_train = out['u']\n",
    "# data = np.load('hidden-test-prediction-submission-file.npz')\n",
    "# upast_test = data['upast']\n",
    "# thpast_test = data['thpast']\n",
    "\n",
    "# Function to create input-output data\n",
    "def create_IO_data(u, y, na, nb):\n",
    "    X, Y = [], []\n",
    "    for k in range(max(na, nb), len(y)):\n",
    "        X.append(np.concatenate([u[k-nb:k], y[k-na:k]]))\n",
    "        Y.append(y[k])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Define the neural network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, n_hidden_nodes=40, n_in=20):\n",
    "        super(Network, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_in, n_hidden_nodes).double()\n",
    "        self.layer2 = nn.Linear(n_hidden_nodes, n_hidden_nodes).double()\n",
    "        self.layer3 = nn.Linear(n_hidden_nodes, 1).double()\n",
    "\n",
    "    def forward(self, u):\n",
    "        x1 = torch.nn.functional.leaky_relu(self.layer1(u))\n",
    "        x2 = torch.nn.functional.leaky_relu(self.layer2(x1))\n",
    "        y = self.layer3(x2)[:, 0]\n",
    "        return y\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Sweep loop for na and nb\n",
    "for na in range(16):\n",
    "    for nb in range(16):\n",
    "        X, Y = create_IO_data(u_train, th_train, na, nb)\n",
    "        Xtemp, Xtest_final, Ytemp, Ytest_final = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "        Xtrain_final, Xval, Ytrain_final, Yval = train_test_split(Xtemp, Ytemp, test_size=0.1765, random_state=42)\n",
    "\n",
    "        wandb.init(\n",
    "            project=\"5SC28-NN-grid\",\n",
    "            config={\n",
    "                \"na\": na,\n",
    "                \"nb\": nb,\n",
    "                \"epochs\": 280,\n",
    "                \"n_hidden_nodes\": 40,\n",
    "                \"learning_rate\": 0.001,\n",
    "                \"batch_size\": 256\n",
    "            }\n",
    "        )\n",
    "\n",
    "        config = wandb.config\n",
    "        model = Network(n_hidden_nodes=config.n_hidden_nodes, n_in=na+nb).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "        Xtrain_tensor = torch.tensor(Xtrain_final).to(device)\n",
    "        Ytrain_tensor = torch.tensor(Ytrain_final).to(device)\n",
    "        Xval_tensor = torch.tensor(Xval).to(device)\n",
    "        Yval_tensor = torch.tensor(Yval).to(device)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            model.train()\n",
    "            for i in range(0, len(Xtrain_tensor), config.batch_size):\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(Xtrain_tensor[i:i+config.batch_size])\n",
    "                loss = torch.mean((y_pred - Ytrain_tensor[i:i+config.batch_size])**2)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = model(Xval_tensor)\n",
    "                val_loss = torch.mean((val_pred - Yval_tensor)**2).item()\n",
    "                val_nrms = val_loss / torch.std(Yval_tensor).item()\n",
    "                train_nrms = loss.item() / torch.std(Ytrain_tensor).item()\n",
    "\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": loss.item(),\n",
    "                \"train_NRMS\": train_nrms,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_NRMS\": val_nrms\n",
    "            })\n",
    "\n",
    "        torch.save(model.state_dict(), f\"model_na{na}_nb{nb}.pt\")\n",
    "        # wandb.save(f\"model_na{na}_nb{nb}.pt\")\n",
    "        wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4sc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
